
<!-- TOC -->

- [1、什么是消息中间件-协议](#1什么是消息中间件-协议)
    - [1、AMQP 协议](#1amqp-协议)
    - [2、MQTT协议](#2mqtt协议)
    - [3、STOMP协议](#3stomp协议)
    - [4、XMPP 协议](#4xmpp-协议)
- [2、使用场景](#2使用场景)
    - [1、异步通信](#1异步通信)
    - [2、解耦](#2解耦)
    - [3、冗余](#3冗余)
    - [4、扩展性](#4扩展性)
    - [5、过载保护](#5过载保护)
    - [6、可恢复性](#6可恢复性)
    - [7、顺序保证](#7顺序保证)
    - [8、缓冲](#8缓冲)
    - [9、数据流处理](#9数据流处理)
- [3、主流消息中间件介绍](#3主流消息中间件介绍)
    - [1、RocketMQ](#1rocketmq)
    - [2、Kafka](#2kafka)
        - [1、高性能](#1高性能)
        - [2、高可用](#2高可用)
        - [3、消息写入过程](#3消息写入过程)
        - [4、消息路由策略](#4消息路由策略)
        - [5、消息发送的可靠性机制](#5消息发送的可靠性机制)
        - [6、消费者消费过程](#6消费者消费过程)
        - [7、Partition Leader 选举](#7partition-leader-选举)
        - [8、重复消费问题及解决方案](#8重复消费问题及解决方案)
    - [3、RabbitMq](#3rabbitmq)
- [4、消息中间件引入的问题](#4消息中间件引入的问题)
    - [1、kafka](#1kafka)
        - [1、高可用（Replicate 副本机制）](#1高可用replicate-副本机制)
    - [2、RocketMQ](#2rocketmq)
        - [1、事务](#1事务)
- [9、零拷贝](#9零拷贝)
    - [1、零拷贝概念](#1零拷贝概念)
    - [2、传统拷贝方式](#2传统拷贝方式)
    - [3、零拷贝方式](#3零拷贝方式)
    - [4、Gather Copy DMA 零拷贝方式（Direct Memory Access）](#4gather-copy-dma-零拷贝方式direct-memory-access)
    - [5、mmap 零拷贝](#5mmap-零拷贝)

<!-- /TOC -->


消息中间件利用高效可靠的消息传递机制进行平台无关的数据交流，并基于数据通信来进行分布式系统的集成。通过提供消息传递和消息排队模型，它可以在分布式环境下扩展进程间的通信

# 1、什么是消息中间件-协议

## 1、AMQP 协议

Advanced Message Queuing Protocol,一个提供统一消息服务的应用层标准高级消息队列协议,是应用层协议的一个开放标准,为面向消息的中间件设计

RabbitMQ

优点：可靠、通用

## 2、MQTT协议

Message Queuing Telemetry Transport 消息队列遥测传输，IBM，物联网

优点：格式简洁、占用带宽小、移动端通信、PUSH、嵌入式系统

## 3、STOMP协议

Streaming Text Orientated Message Protocol 流文本定向消息协议。面向消息设计的简单文本协议

特点：命令模式

## 4、XMPP 协议

Extensible Messaging and Presence Protocol  可扩展消息处理现场协议 ，基于可扩展标记语言（XML）的协议

特点：通用公开、兼容性强、可扩展、安全性高，但XML编码格式占用带宽大


# 2、使用场景

## 1、异步通信
有些业务不想也不需要立即处理消息。消息队列提供了异步处理机制，允许用户把一个消息放入队列，但并不立即处理它。想向队列中放入多少消息就放多少，然后在需要的时候再去处理它们。

## 2、解耦
降低工程间的强依赖程度，针对异构系统进行适配。在项目启动之初来预测将来项目会碰到什么需求，是极其困难的。通过消息系统在处理过程中间插入了一个隐含的、基于数据的接口层，两边的处理过程都要实现这一接口，当应用发生变化时，可以独立的扩展或修改两边的处理过程，只要确保它们遵守同样的接口约束。

## 3、冗余
有些情况下，处理数据的过程会失败。除非数据被持久化，否则将造成丢失。消息队列把数据进行持久化直到它们已经被完全处理，通过这一方式规避了数据丢失风险。许多消息队列所采用的”插入-获取-删除”范式中，在把一个消息从队列中删除之前，需要你的处理系统明确的指出该消息已经被处理完毕，从而确保你的数据被安全的保存直到你使用完毕。


## 4、扩展性
因为消息队列解耦了你的处理过程，所以增大消息入队和处理的频率是很容易的，只要另外增加处理过程即可。不需要改变代码、不需要调节参数。便于分布式扩容。


## 5、过载保护
在访问量剧增的情况下，应用仍然需要继续发挥作用，但是这样的突发流量无法提取预知；如果以为了能处理这类瞬间峰值访问为标准来投入资源随时待命无疑是巨大的浪费。使用消息队列能够使关键组件顶住突发的访问压力，而不会因为突发的超负荷的请求而完全崩溃。

## 6、可恢复性
系统的一部分组件失效时，不会影响到整个系统。消息队列降低了进程间的耦合度，所以即使一个处理消息的进程挂掉，加入队列中的消息仍然可以在系统恢复后被处理。


## 7、顺序保证
在大多使用场景下，数据处理的顺序都很重要。大部分消息队列本来就是排序的，并且能保证数据会按照特定的顺序来处理。


## 8、缓冲
在任何重要的系统中，都会有需要不同的处理时间的元素。消息队列通过一个缓冲层来帮助任务最高效率的执行，该缓冲有助于控制和优化数据流经过系统的速度。以调节系统响应时间。


## 9、数据流处理
分布式系统产生的海量数据流，如：业务日志、监控数据、用户行为等，针对这些数据流进行实时或批量采集汇总，然后进行大数据分析是当前互联网的必备技术，通过消息队列完成此类数据收集是最好的选择。


# 3、主流消息中间件介绍

针对消息中间件，如何解决下面的几个问题;

- 消息队列的高可用
- 保证消息不被重复消费
- 消息不丢失
- 顺序性
- 事务消息

## 1、RocketMQ

![](../../pic/2020-05-01-13-41-18.png)

- Name Server 
- Broker
- Producer
- Consumer  


阿里系下开源的一款分布式、队列模型的消息中间件，原名Metaq，3.0版本名称改为RocketMQ，是阿里参照kafka设计思想使用java实现的一套mq。同时将阿里系内部多款mq产品（Notify、metaq）进行整合，只维护核心功能，去除了所有其他运行时依赖，保证核心功能最简化，在此基础上配合阿里上述其他开源产品实现不同场景下mq的架构，目前主要多用于订单交易系统。

- Name Server 保存 各broker 的topic 信息及 broker 的主备状态

- Broker由 Master 和 Slave 组成，一个Master 可以多个 Slaver；通过 Broker Name 指定 brokerId= 0 为master ；每个 broker 和 name server 保持长连接，Broker 定时向Name Server 同步 topic 信息，Name server 也会定时检测与 Broker 的链接

- Producer  producer 从 Name Server 获取 topic 的路由信息，并与 提供 topic的 Master（broker） 建立长连接

- Consumer consumer 从 Name Server 获取topic 路由信息，consumer 和 master（broker） 和 slaver （broker）都建立连接 通过Broker 配置

> 特点

- 能够保证严格的消息顺序;消息被发送时保持顺序,存储时保持顺序，消费时保持顺序
- 提供针对消息的过滤功能；支持按属性过滤 ，正则过滤基于SQL92
- 提供丰富的消息拉取模式
- 高效的订阅者水平扩展能力
- 实时的消息订阅机制
- 亿级消息堆积能力




## 2、Kafka

http://kafka.apache.org/


Apache下的一个子项目，使用scala实现的一个高性能分布式Publish/Subscribe消息队列系统，具有以下特性：
- 快速持久化：通过磁盘顺序读写与零拷贝机制，可以在O(1)的系统开销下进行消息持久化；
- 高吞吐：在一台普通的服务器上既可以达到10W/s的吞吐速率；
- 高堆积：支持topic下消费者较长时间离线，消息堆积量大；
- 完全的分布式系统：Broker、Producer、Consumer都原生自动支持分布式，依赖zookeeper自动实现复杂均衡；
- 支持Hadoop数据并行加载：对于像Hadoop的一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。
- 支持Kafka Server间的消息分区，及分布式消费，同时保证每个Partition内的消息顺序传输



![](../../pic/2020-05-02-13-37-57.png)

![](../../pic/2020-05-02-13-40-03.png)



![](../../pic/2020-05-01-13-44-47.png)


- Broker：消息中间件处理结点，一个Kafka节点就是一个broker，多个broker可以组成一个Kafka集群。

- Topic：一类消息，Kafka集群能够同时负责多个topic的分发。

- Partition：topic物理上的分组，一个topic可以分为多个partition，每个partition是一个有序的队列。

- Segment：partition物理上由多个segment组成。每个 segment 文件的最大大小相等。segment越大，文件越少，二分查找的次数就越少，效率越高


- offset：每个partition都由一系列有序的、不可变的消息组成，这些消息被连续的追加到partition中。partition中的每个消息都有一个连续的序列号叫做offset，用于partition唯一标识一条消息。

- Producer：负责发布消息到Kafka broker。

- Consumer：消息消费者，向Kafka broker读取消息的客户端。

- Consumer Group：每个Consumer属于一个特定的Consumer Group。


- Broker Controller ：Kafka 集群的多个 broker 中，有一个会被选举为 controller，负责管理整个集群中 partition 和 replicas 的状态。 例如，partition leader 故障，由 Controller 负责从 ISR 中的 followr 中重新选举出一个新的 leader。 再如，当某个 topic 的 partition 数量发生变化时，由 Controller 负责管理 partition 与消费者间的分配关系，即 Rebalance。 当前版本的 Kafka 只有 Controller 会向 zk 中注册 Watcher。 早期版本的 Kafka（0.8 版本及之前），每一个 broker 及 partition（所有副本）都会向 zk中注册 watcher。这种方式会导致 Kafka 的分区中出现脑裂。Controller进行选举期间不对外提供服务，选举出新的leader选举出以后，设置延迟时间来解决。

- Partition Leader ：每个 partition 有多个副本，其中有且仅有一个作为 Leader，Leader 是当前负责消息读写的 partition。即所有读写操作只能发生于 Leader 分区上。 Leader 与 Follower 是主备关系，不是主从关系。 Leader 宕机后，Broker Controller 会从 Follower 中选举出一个新的 Leader。 注意，这个选举不是由 zk 完成的。

- Zookeeper :负责维护和协调 broker，负责 Broker Controller 的选举。 从 Kafka 0.9 版本开始，offset 的管理由 broker（coordinator） 负责管理与保存，不再由 zk 负责管理。 总结：zk 负责 Broker 中 Controller 的选举，Partioin Leader 是由 Controller 负责选举的。 

- Coordinator 一般指的是运行在每个 broker 上的 group Coordinator 进程，用于管理 Consumer Group 中的各个成员，主要用于 offset 位移管理和 Rebalance。一个 Coordinator 可以同时管理多个消费者组。

- Rebalance :当消费者组中消费者数量发生变化，或 Topic 中的 partition 数量发生了变化时， partition的所有权会在消费者间转移，即 partition 会重新分配，这个过程称为再均衡 Rebalance。 再均衡能够给消费者组及 broker 集群带来性高可用性和伸缩，但在再均衡期间消费者是无法读取消息的，即整个 broker 集群有一小段时间是不可用的。因此要避免不必要的再均衡。

- Offset commit :Consumer 从 partition 中取出一批消息写入到 buffer 对其进行消费，在规定时间内消费完消息后，会自动将其消费消息的 offset 提交给 broker，以让 broker 记录下哪些消息是消费过的。当然，若在时限内没有消费完毕，其是不会提交 offset 的。 发生 Rebalance 后会使用到之前提交的 offset。 系统会将提交的 offset 作为消息写入到__consumer_offsets 主题的 partition 中。不过需要注意，这个 offset 消息在写入时是有 key 的，其 key 为该 offset 所示消息的消费者的 id。那么该 offset 应该放到哪个 partition 中呢？其会首先计算出 key 的 hash 值，然后再将此 hash 与 50 进行取模。其余数即为相应的 partition 编号。

![](../../pic/2020-05-02-14-27-47.png)






> ISR集合  （In-SyncReplica）副本同步列表

指目前“可用”（alive）且消息量与Leader相差不多的副本集合，这是整个副本集合的一个子集。

ISR集合中的副本必须满足下面两个条件：
- （1）副本所在节点必须维持着与ZooKeeper的连接。
- （2）副本最后一条消息的offset与Leader副本的最后一条消息的offset之间的差值不能超出指定的阈值。

每个分区中的Leader副本都会维护此分区的ISR集合。写请求首先由Leader副本处理，之后Follower副本会从Leader上拉取写入的消息，这个过程会有一定的延迟，导致Follower副本中保存的消息略少于Leader副本，只要未超出阈值都是可以容忍的。如果一个Follower副本出现异常，比如：宕机，发生长时间GC而导致Kafka僵死或是网络断开连接导致长时间没有拉取消息进行同步，就会违反上面的两个条件，从而被Leader副本踢出ISR集合。当Follower副本从异常中恢复之后，会继续与Leader副本进行同步，当Follower副本“追上”（即最后一条消息的offset的差值小于指定阈值）Leader副本的时候，此Follower副本会被Leader副本重新加入到ISR中。



> Partition & Segment & Message

![](../../pic/2020-05-02-14-16-28.png)

![](../../pic/2020-05-02-13-18-12.png)

顺序读写

![](../../pic/2020-05-02-13-18-46.png)

多副本策略

![](../../pic/2020-05-02-13-20-10.png)

单播与广播

![](../../pic/2020-05-02-13-21-01.png)


> HW 与 LEO 

- HW，HighWatermark，高水位，表示 Consumer 可以消费到的最高 partition 偏移量。HW 保证了 Kafka 集群中消息的一致性。确切地说，是保证了 partition 的 Follower 与 Leader 间数据的一致性。 

- LEO，Log End Offset，日志最后消息的偏移量。消息是被写入到 Kafka 的日志文件中的，这是当前最后一个写入的消息在 Partition 中的偏移量。 
对于 leader 新写入的消息，consumer 是不能立刻消费的。leader 会等待该消息被所有ISR中的partition follower 同步后才会更新HW，此时消息才能被consumer消费。

> HW 截断机制

如果 partition leader 接收到了新的消息， ISR 中其它 Follower 正在同步过程中，还未同步完毕时leader宕机。此时就需要选举出新的leader。若没有HW截断机制，将会导致partition 中 leader 与 follower 数据的不一致。 当原 Leader 宕机后又恢复时，将其 LEO 回退到其宕机时的 HW，然后再与新的 Leader进行数据同步，这种机制称为 HW 截断机制。 HW 截断机制可能会引发消息的丢失。



### 1、高性能


- 不同Partition可位于不同机器，因此可以充分利用集群优势，实现机器间的并行处理

- 同一节点上的不同Partition置于不同的disk drive(负载均衡)上，从而实现磁盘间的并行处理，充分发挥多磁盘的优势

- 充分利用Page Cache，I/O Scheduler会将连续的小块写组装成大块的物理写从而提高性能，顺序写磁盘，减少磁头移动

- Kafka删除Segment的方式，是直接删除Segment对应的整个log文件和整个index文件而非删除文件中的部分内容。

- 如果数据消费速度与生产速度相当，Follower和Leader甚至不需要通过物理磁盘交换数据，而是直接通过Page Cache交换数据

- Linux 2.4+内核通过sendfile系统调用，提供了零拷贝

- batch.size和linger.ms控制实际发送频率，从而实现批量发送

- 数据压缩(高效的序列化)降低网络负载


注: Partition个数决定了可能的最大并行度，Num(customer)>Num(Partion)没用

性能测试对比
http://www.jasongj.com/2015/12/31/KafkaColumn5_kafka_benchmark/


### 2、高可用


- 1、Replication，并HA(将所有Broker（假设共n个Broker）和待分配的Partition排序，将第i个Partition分配到第（i mod n）个Broker上，将第i个Partition的第j个Replica分配到第（(i + j) mod n）个Broker上)。

- 2、基于ISR（In-sync Replica）的数据复制方案，弹性较高，适合自定义

- 3、broker活着的判定。kafka判定broker是否活着，通过以下2个方式：1、和zk的session没有断（通过心跳来维系）；2、follower能及时将leader消息复制过来，不能落后太多（例如默认lag超过4000就会踢出ISR）；

- 4、所有replica都不工作的情况。如果所有副本都出问题，一般有两种选择：1、等待ISR中的任一个Replica“活”过来，并且选它作为Leader（一致性好，但是可用性差）；2、选择第一个“活”过来的Replica（不一定是ISR中的）作为Leader（一致性差，但是可用性相比第一种方式好）




### 3、消息写入过程

消息生产者将消息发送给 broker，并形成最终的可供消费者消费的 log，是一个比较复杂的过程。 

- producer 向 broker 集群提交连接请求，其所连接上的任意 broker 都会向其发送 broker controller 的通信 URL，即配置文件中的 listeners 地址

- 当 producer 指定了要生产的 topic 后，其会向 broker controller 发送请求，请求当前 topic 中所有 partition 的 leader 列表地址 

- broker controller 在接收到请求后，会从zk 中查找到指定topic的所有 partition的 leader，并返回给 producer 

- producer 在接收到 leader 列表地址后，根据消息路由策略找到当前要发送消息所要发送的 partition leader，然后将消息发送给该 leader 

- leader 将消息写入本地 log，并通知 ISR 中的 followers 

- ISR 中的 followers 从 leader 中同步消息后向 leader 发送 ACK 

- leader 收到所有 ISR 中的 followers 的 ACK 后，增加 HW，表示消费者已经可以消费到该位置了


### 4、消息路由策略 

在通过api方式发送消息时生产者是以Record为消息进行发送的。Record中包含key和value，value才是我们真正的消息本身，而key用户路由消息所要存放的Partition。消息要写入到哪个partition不是随机的，而是有路由策略的。

- 若指定了partition，则直接写入到指定的partition。

- 若未指定partition，但指定了key，则通过对key的hash值与partition的数量进行取模，该结果就是要选出的partition索引。

- 若partition和key都未指定，则使用轮询算法选出一个partition。


### 5、消息发送的可靠性机制

生产者向 kafka 发送消息时，可以选择需要的可靠性级别。通过 acks 参数的值进行设置

- 1、0值

异步发送。生产者向 kafka 发送消息而不需要 kafka 反馈成功 ack。该方式效率最高，但可靠性最低。其可能会存在消息丢失的情况。 在传输过程中丢失：由于网络原因，生产者发送的消息根本就没有到达 Kafka，但生产者不知道，其会一直生产并发送消息给 Kafka。这种情况可能会出现大量的消息丢失。 在 broker 中丢失：当 broker 的缓存满时正准备给 partation 中写入时，此时到达的新的消息会丢失。

- 2、1值

同步发送，默认值。生产者发送消息给 kafka，broker 的 partition leader 在收到消息后马上发送成功 ack，生产者收到后知道消息发送成功，然后会再发送消息。如果一直未收到 kafka 的 ack，则生产者会认为消息发送失败，会重发消息。 

该方式不能保证消息发送成功。该方式仍会出现消息丢失的情况。

例如，当 leader 收到 消息后马上向 producer 发送的 ack，但此时在 follower 还没有同步数据时，该 leader 挂了。此时写入到原来 leader 中的消息就丢失了。因为这条消息对于 producer 来说，是发送成功了。但对于剩余的 follower 来说根本就没有存在过。


- 3、-1值

同步发送。生产者发送消息给 kafka，kafka 收到消息后要等到 ISR 列表中的所有副本都同步消息完成后，才向生产者发送成功 ack。如果一直未收到 kafka 的 ack，则认为消息发送失败，会自动重发消息。 

该方式很少会出现消息丢失的情况。但其存在消息重复接收的情况。为了解决重复接收（注意，重复接收，不是重复消费，这是两个概念）问题，Kafka 允许为消息指定唯一标识，并允许用户自定义去重机制。

### 6、消费者消费过程

生产者将消息发送到 topic 中，消费者即可对其进行消费，其消费过程如下：

- consumer 向 broker 集群提交连接请求，其所连接上的任意 broker 都会向其发送 broker controller 的通信 URL，即配置文件中的 listeners 地址

- 当 consumer 指定了要消费的 topic 后，其会向 broker controller 发送消费请求

- broker controller 会为 consumer 分配一个或几个 partition leader，并将该 partitioin 的当前 offset 发送给 consumer

- consumer 会按照 broker controller 分配的 partition 对其中的消息进行消费

- 当消费者消费完该条消息后，消费者会向 broker 发送一个该消息已被消费的反馈，即该消息的 offset 

- 当 broker 接到消费者的 offset 后，会更新到相应的__consumer_offset 中

- 以上过程一直重复，直到消费者停止请求消息 

- 消费者可以重置 offset，从而可以灵活消费存储在 broker 上的消息

### 7、Partition Leader 选举

当 leader 宕机后 broker controller 会从 ISR 中选一个 follower 成为新的 leader。但，若 ISR 中没有其它的副本怎么办？可以通过 unclean.leader.election.enable 的取值来设置 Leader 选举的范围。

- false：必须等待 ISR 列表中有副本活过来才进行新的选举。该策略可靠性有保证，但可用性低。

- true：在 ISR 中没有副本的情况下可以选择任何一个没有宕机主机中该 topic 的 partition 副本作为新的 leader，该策略可用性高，但可靠性没有保证。

### 8、重复消费问题及解决方案

最常见的重复消费有两种：

- 1、同一个 consumer 重复消费

当 Consumer 由于消费能力较低而引发了消费超时时，则可能会形成重复消费。 在时间到达时恰好某数据消费完毕，正准备提交 offset 但还没有提交时，时间到了。此时就会产生重复消费问题。 其解决方案是，延长 offset 提交时间。

- 2、不同的 consumer 重复消费

当 Consumer 消费了消息但还未提交 offset 时宕机，
。 其解决方案是将自动提交改为手动提交。








> 参考

- [/Kafka](http://www.jasongj.com/2015/03/10/KafkaColumn1/)



## 3、RabbitMq

![](../../pic/2020-05-02-11-58-48.png)

- Queue
- Exchange 
- Routing key
- Binding
- Binding key 





使用Erlang编写的一个开源的消息队列，本身支持很多的协议：AMQP，XMPP, SMTP,STOMP，也正是如此，使的它变的非常重量级，更适合于企业级的开发。同时实现了Broker架构，核心思想是生产者不会将消息直接发送给队列，消息在发送给客户端时先在中心队列排队。对路由(Routing)，负载均衡(Load balance)、数据持久化都有很好的支持。多用于进行企业级的ESB整合。


# 4、消息中间件引入的问题

- 消息队列的高可用（分片+副本机制，主分片负责写，然后同步给其他分片；读可以从全部分片选择一个即可）
- 保证消息不被重复消费
- 消息不丢失
- 顺序性
- 事务消息

## 1、kafka

### 1、高可用（Replicate 副本机制）

![](../../pic/2020-05-02-12-02-59.png)


- topic 消息拆分成多个 partition 
- partition 存储在多个 broker 中
- 每个partition 在broker 中存储多份副本
- 每个 partition 会选出一个 leader 其他的均为 flower
- 读写均发生在 leader 中（不能读副本？？？）
- flower 通过pull 从 leader 中拉取数据



## 2、RocketMQ

### 1、事务

> 两阶段提交协议

- 1、执行本地事务前发送 half message
- 2、Server 端标识 消息为 事务消息，并进行持久化；
- 3、执行本地事务
- 4、本地事务结果已异步形式通知Server 事务结果
- 5、Server 定时检查所有事务消息并回调Client 端检查事务状态 

![](../../pic/2020-05-02-12-06-26.png)


Server 端将 所有half message 存储到一个单独的 topic 中；

Server 端检查 事务消息时，是将消息获取出来，检查结束后放回队列中；保证顺序性




# 9、零拷贝

## 1、零拷贝概念 

零拷贝指的是，从一个存储区域到另一个存储区域的 copy 任务没有CPU 参与。零拷贝通常用于网络文件传输，以减少 CPU 消耗和内存带宽占用，减少用户空间与 CPU 内核空间的拷贝过程，减少用户上下文与 CPU 内核上下文间的切换，提高系统效率。  用户空间指的是用户可操作的内存缓存区域，CPU 内核空间是指仅 CPU 可以操作的寄存器缓存及内存缓存区域。
用户上下文指的是用户状态环境，CPU 内核上下文指的是 CPU 内核状态环境。 
零拷贝需要 DMA 控制器的协助。DMA，Direct Memory Access，直接内存存取，是 CPU 的组成部分，其可以在 CPU 内核（算术逻辑运算器 ALU 等）不参与运算的情况下将数据从一个地址空间拷贝到另一个地址空间。


下面均以“将一个硬盘中的文件通过网络发送出去”的过程为例，来详细分析不同拷贝方式的实现细节。

## 2、传统拷贝方式

首先通过应用程序的 read()方法将文件从硬盘读取出来，然后再调用 send()方法将文件发送出去。

该拷贝方式共进行了 4 次用户空间与内核空间的上下文切换，以及 4 次数据拷贝，其中
两次拷贝存在 CPU 参与。 

我们发现一个很明显的问题：应用程序的作用仅仅就是一个数据传输的中介，最后将
kernel buffer 中的数据传递到了 socket buffer。显然这是没有必要的。所以就引入了零拷贝。

![](../../pic/2020-05-02-14-06-43.png)



## 3、零拷贝方式

Linux系统（ CentOS6 及其以上版本）对于零拷贝是通过sendfile系统调用实现的。

该拷贝方式共进行了 2 次用户空间与内核空间的上下文切换，以及 3 次数据拷贝，但整个拷贝过程均没有 CPU 的参与，这就是零拷贝。 

我们发现这里还存在一个问题：

- kernel buffer 到 socket buffer 的拷贝需要吗？
- kernel buffer 与 socket buffer 有什么区别呢？

DMA 控制器所控制的拷贝过程有一个要求，数据在源头的存放地址空间必须是连续的。kernel buffer 中的数据无法保证其连续性，所以需要将数据再拷贝到 socket buffer，socket buffer 可以保证了数据的连续性。 

这个拷贝过程能否避免呢？

可以，只要主机的 DMA 支持 Gather Copy 功能，就可以避免由 kernel buffer 到 socket buffer 的拷贝。

![](../../pic/2020-05-02-14-09-15.png)


## 4、Gather Copy DMA 零拷贝方式（Direct Memory Access）

由于该拷贝方式是由 DMA 完成，与系统无关，所以只要保证系统支持 sendfile 系统调用功能即可。 

该方式中没有数据拷贝到 socket buffer。取而代之的是只是将 kernel buffer 中的数据描述信息写到了 socket buffer 中。数据描述信息包含了两方面的信息：kernel buffer 中数据的地址和偏移量


该拷贝方式共进行了 2 次用户空间与内核空间的上下文切换，以及 2 次数据拷贝，并且整个拷贝过程均没有 CPU 的参与。 

该拷贝方式的系统效率是高了，但与传统相比，也存在有不足。传统拷贝中 user buffer 中存有数据，因此应用程序能够对数据进行修改等操作；零拷贝中的 user buffer 中没有了数据，所以应用程序无法对数据进行操作了。Linux 的 mmap 零拷贝解决了这个问题。

![](../../pic/2020-05-02-14-11-13.png)

## 5、mmap 零拷贝 

mmap 零拷贝是对零拷贝的改进。当然，若当前主机的 DMA 支持 Gather Copy，mmap同样可以实现 Gather Copy DMA 的零拷贝。


该方式与零拷贝的唯一区别是，应用程序与内核共享了 Kernel buffer。由于是共享，所以应用程序也就可以操作该 buffer 了。当然，应用程序对于 Kernel buffer 的操作，就会引发用户空间与内核空间的切换。

该拷贝方式共进行了 4 次用户空间与内核空间的上下文切换，以及 2 次数据拷贝，并且整个拷贝过程均没有 CPU 的参与。虽然较之前面的零拷贝增加了两次上下文切换，但应用程序可以对数据进行修改了。

![](../../pic/2020-05-02-14-13-54.png)











