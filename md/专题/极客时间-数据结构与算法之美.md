

<!-- TOC -->

- [00 开篇词 | 从今天起，跨过“数据结构与算法”这道坎](#00-开篇词--从今天起跨过数据结构与算法这道坎)
- [仙豆 置顶](#仙豆-置顶)
- [01 | 为什么要学习数据结构和算法？](#01--为什么要学习数据结构和算法)
- [02 | 如何抓住重点，系统高效地学习数据结构与算法？](#02--如何抓住重点系统高效地学习数据结构与算法)
- [03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？](#03--复杂度分析上如何分析统计算法的执行效率和资源消耗)
- [04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度](#04--复杂度分析下浅析最好最坏平均均摊时间复杂度)
- [不定期福利第一期 | 数据结构与算法学习书单](#不定期福利第一期--数据结构与算法学习书单)
- [05 | 数组：为什么很多编程语言中数组都从0开始编号？](#05--数组为什么很多编程语言中数组都从0开始编号)
- [06 | 链表（上）：如何实现LRU缓存淘汰算法?](#06--链表上如何实现lru缓存淘汰算法)
- [07 | 链表（下）：如何轻松写出正确的链表代码？](#07--链表下如何轻松写出正确的链表代码)
- [08 | 栈：如何实现浏览器的前进和后退功能？](#08--栈如何实现浏览器的前进和后退功能)
- [09 | 队列：队列在线程池等有限资源池中的应用](#09--队列队列在线程池等有限资源池中的应用)
- [10 | 递归：如何用三行代码找到“最终推荐人”？](#10--递归如何用三行代码找到最终推荐人)
    - [界定问题能否用递归解决](#界定问题能否用递归解决)
    - [编写递归代码的技巧](#编写递归代码的技巧)
    - [递归的缺点](#递归的缺点)
- [11 | 排序（上）：为什么插入排序比冒泡排序更受欢迎？](#11--排序上为什么插入排序比冒泡排序更受欢迎)
- [12 | 排序（下）：如何用快排思想在O(n)内查找第K大元素？](#12--排序下如何用快排思想在on内查找第k大元素)
- [13 | 线性排序：如何根据年龄给100万用户数据排序？](#13--线性排序如何根据年龄给100万用户数据排序)
- [14 | 排序优化：如何实现一个通用的、高性能的排序函数？](#14--排序优化如何实现一个通用的高性能的排序函数)
- [15 | 二分查找（上）：如何用最省内存的方式实现快速查找功能？](#15--二分查找上如何用最省内存的方式实现快速查找功能)
- [16 | 二分查找（下）：如何快速定位IP对应的省份地址？](#16--二分查找下如何快速定位ip对应的省份地址)
- [17 | 跳表：为什么Redis一定要用跳表来实现有序集合？](#17--跳表为什么redis一定要用跳表来实现有序集合)
- [18 | 散列表（上）：Word文档中的单词拼写检查功能是如何实现的？](#18--散列表上word文档中的单词拼写检查功能是如何实现的)
- [19 | 散列表（中）：如何打造一个工业级水平的散列表？](#19--散列表中如何打造一个工业级水平的散列表)
- [20 | 散列表（下）：为什么散列表和链表经常会一起使用？](#20--散列表下为什么散列表和链表经常会一起使用)
- [21 | 哈希算法（上）：如何防止数据库中的用户信息被脱库？](#21--哈希算法上如何防止数据库中的用户信息被脱库)
- [22 | 哈希算法（下）：哈希算法在分布式系统中有哪些应用？](#22--哈希算法下哈希算法在分布式系统中有哪些应用)
- [23 | 二叉树基础（上）：什么样的二叉树适合用数组来存储？](#23--二叉树基础上什么样的二叉树适合用数组来存储)
- [24 | 二叉树基础（下）：有了如此高效的散列表，为什么还需要二叉树？](#24--二叉树基础下有了如此高效的散列表为什么还需要二叉树)
- [25 | 红黑树（上）：为什么工程中都用红黑树这种二叉树？](#25--红黑树上为什么工程中都用红黑树这种二叉树)
- [26 | 红黑树（下）：掌握这些技巧，你也可以实现一个红黑树](#26--红黑树下掌握这些技巧你也可以实现一个红黑树)
- [27 | 递归树：如何借助树来求解递归算法的时间复杂度？](#27--递归树如何借助树来求解递归算法的时间复杂度)
- [不定期福利第二期 | 王争：羁绊前行的，不是肆虐的狂风，而是内心的迷茫](#不定期福利第二期--王争羁绊前行的不是肆虐的狂风而是内心的迷茫)
- [28 | 堆和堆排序：为什么说堆排序没有快速排序快？](#28--堆和堆排序为什么说堆排序没有快速排序快)
    - [第一题：](#第一题)
    - [第二题：](#第二题)
- [29 | 堆的应用：如何快速获取到Top 10最热门的搜索关键词？](#29--堆的应用如何快速获取到top-10最热门的搜索关键词)
- [30 | 图的表示：如何存储微博、微信等社交网络中的好友关系？](#30--图的表示如何存储微博微信等社交网络中的好友关系)
- [31 | 深度和广度优先搜索：如何找出社交网络中的三度好友关系？](#31--深度和广度优先搜索如何找出社交网络中的三度好友关系)
- [32 | 字符串匹配基础（上）：如何借助哈希算法实现高效字符串匹配？](#32--字符串匹配基础上如何借助哈希算法实现高效字符串匹配)
- [33 | 字符串匹配基础（中）：如何实现文本编辑器中的查找功能？](#33--字符串匹配基础中如何实现文本编辑器中的查找功能)
- [34 | 字符串匹配基础（下）：如何借助BM算法轻松理解KMP算法？](#34--字符串匹配基础下如何借助bm算法轻松理解kmp算法)
- [35 | Trie树：如何实现搜索引擎的搜索关键词提示功能？](#35--trie树如何实现搜索引擎的搜索关键词提示功能)
- [define OK 1](#define-ok-1)
- [define ERROR 0](#define-error-0)
- [define TRUE 1](#define-true-1)
- [define FALSE 0](#define-false-0)
- [36 | AC自动机：如何用多模式串匹配实现敏感词过滤功能？](#36--ac自动机如何用多模式串匹配实现敏感词过滤功能)
- [37 | 贪心算法：如何用贪心算法实现Huffman压缩编码？](#37--贪心算法如何用贪心算法实现huffman压缩编码)
- [38 | 分治算法：谈一谈大规模计算框架MapReduce中的分治思想](#38--分治算法谈一谈大规模计算框架mapreduce中的分治思想)
- [不定期福利第三期 | 测一测你的算法阶段学习成果](#不定期福利第三期--测一测你的算法阶段学习成果)
- [39 | 回溯算法：从电影《蝴蝶效应》中学习回溯算法的核心思想](#39--回溯算法从电影蝴蝶效应中学习回溯算法的核心思想)
- [40 | 初识动态规划：如何巧妙解决“双十一”购物时的凑单问题？](#40--初识动态规划如何巧妙解决双十一购物时的凑单问题)
- [不定期福利第四期 | 刘超：我是怎么学习《数据结构与算法之美》的？](#不定期福利第四期--刘超我是怎么学习数据结构与算法之美的)
- [41 | 动态规划理论：一篇文章带你彻底搞懂最优子结构、无后效性和重复子问题](#41--动态规划理论一篇文章带你彻底搞懂最优子结构无后效性和重复子问题)
- [42 | 动态规划实战：如何实现搜索引擎中的拼写纠错功能？](#42--动态规划实战如何实现搜索引擎中的拼写纠错功能)
- [43 | 拓扑排序：如何确定代码源文件的编译依赖关系？](#43--拓扑排序如何确定代码源文件的编译依赖关系)
- [44 | 最短路径：地图软件是如何计算出最优出行路径的？](#44--最短路径地图软件是如何计算出最优出行路径的)
- [45 | 位图：如何实现网页爬虫中的URL去重功能？](#45--位图如何实现网页爬虫中的url去重功能)
- [46 | 概率统计：如何利用朴素贝叶斯算法过滤垃圾短信？](#46--概率统计如何利用朴素贝叶斯算法过滤垃圾短信)
- [47 | 向量空间：如何实现一个简单的音乐推荐系统？](#47--向量空间如何实现一个简单的音乐推荐系统)
- [48 | B+树：MySQL数据库索引是如何实现的？](#48--b树mysql数据库索引是如何实现的)
- [49 | 搜索：如何用A*搜索算法实现游戏中的寻路功能？](#49--搜索如何用a搜索算法实现游戏中的寻路功能)
- [50 | 索引：如何在海量数据中快速查找某个数据？](#50--索引如何在海量数据中快速查找某个数据)
- [51 | 并行算法：如何利用并行处理提高算法的执行效率？](#51--并行算法如何利用并行处理提高算法的执行效率)
- [52 | 算法实战（一）：剖析Redis常用数据类型对应的数据结构](#52--算法实战一剖析redis常用数据类型对应的数据结构)
- [53 | 算法实战（二）：剖析搜索引擎背后的经典数据结构和算法](#53--算法实战二剖析搜索引擎背后的经典数据结构和算法)
- [54 | 算法实战（三）：剖析高性能队列Disruptor背后的数据结构和算法](#54--算法实战三剖析高性能队列disruptor背后的数据结构和算法)
- [55 | 算法实战（四）：剖析微服务接口鉴权限流背后的数据结构和算法](#55--算法实战四剖析微服务接口鉴权限流背后的数据结构和算法)
- [56 | 算法实战（五）：如何用学过的数据结构和算法实现一个短网址系统？](#56--算法实战五如何用学过的数据结构和算法实现一个短网址系统)
- [春节7天练 | Day 1：数组和链表](#春节7天练--day-1数组和链表)
- [春节7天练 | Day 2：栈、队列和递归](#春节7天练--day-2栈队列和递归)
- [一组数据集合的全排列](#一组数据集合的全排列)
- [实现快速排序、归并排序](#实现快速排序归并排序)
- [---------快排(三数取中)---------](#---------快排三数取中---------)
- [---------------归并------------](#---------------归并------------)
- [冒泡、选择、插入排序](#冒泡选择插入排序)
- [插入排序](#插入排序)
- [include<stdlib.h>](#includestdlibh)
- [define true 1](#define-true-1)
- [define false 0](#define-false-0)
- [define ok 1](#define-ok-1)
- [define error 0](#define-error-0)
- [define infeasible 1](#define-infeasible-1)
- [define overflow 0](#define-overflow-0)
- [define stack_size 50](#define-stack_size-50)
- [春节7天练 | Day 3：排序和二分查找](#春节7天练--day-3排序和二分查找)
- [O(n)时间复杂度时间复杂度内找到一组数据的第 n大元素](#on时间复杂度时间复杂度内找到一组数据的第-n大元素)
- [二分查找变种](#二分查找变种)
- [查找第一个值等于给定值的元素](#查找第一个值等于给定值的元素)
- [查找最后一个值等于给定值的元素](#查找最后一个值等于给定值的元素)
- [查找第一个值大于等于给定值的元素](#查找第一个值大于等于给定值的元素)
- [查找最后一个值小于等于给定值的元素](#查找最后一个值小于等于给定值的元素)
- [实现一个有序数组的二分查找算法](#实现一个有序数组的二分查找算法)
- [include<iostream>](#includeiostream)
- [include<cmath>](#includecmath)
- [春节7天练 | Day 4：散列表和字符串](#春节7天练--day-4散列表和字符串)
- [春节7天练 | Day 5：二叉树和堆](#春节7天练--day-5二叉树和堆)
- [春节7天练 | Day 6：图](#春节7天练--day-6图)
- [春节7天练 | Day 7：贪心、分治、回溯和动态规划](#春节7天练--day-7贪心分治回溯和动态规划)
- [include<iostream>](#includeiostream-1)
- [include<algorithm>](#includealgorithm)
- [include<iostream>](#includeiostream-2)
- [include<iostream>](#includeiostream-3)
- [include<cmath>](#includecmath-1)
- [用户故事 | Jerry银银：这一年我的脑海里只有算法](#用户故事--jerry银银这一年我的脑海里只有算法)
- [用户故事 | zixuan：站在思维的高处，才有足够的视野和能力欣赏“美”](#用户故事--zixuan站在思维的高处才有足够的视野和能力欣赏美)
- [总结课 | 在实际开发中，如何权衡选择使用哪种数据结构和算法？](#总结课--在实际开发中如何权衡选择使用哪种数据结构和算法)
- [结束语 | 送君千里，终须一别](#结束语--送君千里终须一别)

<!-- /TOC -->

# 00 开篇词 | 从今天起，跨过“数据结构与算法”这道坎




数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



开篇词 | 从今天起，跨过“数据结构与算法”这道坎
王争 2018-09-17



08:12
讲述：修阳 大小：3.76M
你好，我是王争，毕业于西安交通大学计算机专业。现在回想起来，本科毕业的时候，我的编程水平其实是很差的。直到读研究生的时候，一个师兄给了我一本《算法导论》，说你可以看看，对你的编程会很有帮助。

没想到，从此我对算法的“迷恋”便一发不可收拾。之后，我如饥似渴地把图书馆里几乎所有数据结构和算法书籍都读了一遍。

我常常边读边练。没多久，我就发现，写代码的时候，我会不由自主考虑很多性能方面的问题。我写出时间复杂度高、空间复杂度高的垃圾代码越来越少了，算法能力提升了很多，编程能力也有了质的飞跃。得益于此，研究生毕业后，我直接进入 Google，从事 Google 翻译相关的开发工作。

这是我自己学习数据结构与算法的经历，现在，你可以想想你的情况。

是不是从学校开始，你就觉得数据结构难学，然后一直没认真学？

工作中，一遇到数据结构这个坑，你又发自本能地迅速避让，因为你觉得自己不懂，所以也不想深究，反正看起来无关大局？

当你想换工作面试，或者研究某个开源项目源码，亦或者和团队讨论某个非框架层面的高可用难题的时候，你又发现，自己的基础跟不上别人的节奏？

如果你是这种情况，其实你并不孤独，这不是你一个人遇到的问题。工作十年间，我见过许多程序员。他们有着各种各样的背景，有很多既有潜力又非常努力，但始终无法在自己现有水平上更进一步。

在技术圈里，我们经常喜欢谈论高大上的架构，比如高可用、微服务、服务治理等等。鲜有人关注代码层面的编程能力，而愿意沉下心来，花几个月时间啃一啃计算机基础知识、认认真真夯实基础的人，简直就是凤毛麟角。

我认识一位原来腾讯 T4 的技术大牛。在区块链大潮之前，他在腾讯工作了 10 多年，长期负责手机 QQ 后台整体建设。他经历了手机 QQ 从诞生到亿级用户在线的整个过程。后来他去了微众银行，有一天老板让他去做区块链。他用了不到半年时间，就把区块链的整个技术脉络摸清楚了。 现在，他是微众银行的区块链负责人，微众科技创新产品部的老总。你说厉害不？你可以花半年时间就能精通一个新的领域吗？为什么他就可以做到？

我觉得这其中最重要的就是基础足够扎实。他曾经跟我说，像区块链、人工智能这些看似很新的技术，其实一点儿都不“新”。最初学编程的时候，他就把那些基础的知识都学透了。当面临行业变动、新技术更迭的时候，他不断发现，那些所谓的新技术，核心和本质的东西其实就是当初学的那些知识。掌握了这个“规律”之后，他学任何东西都很快，任何新技术都能快速迎头赶上。这就是他快速学习并且获得成功的秘诀。

所以说，基础知识就像是一座大楼的地基，它决定了我们的技术高度。而要想快速做出点事情，前提条件一定是基础能力过硬，“内功”要到位。

那技术人究竟都需要修炼哪些“内功”呢？我觉得，无外乎就是大学里的那些基础课程，操作系统、计算机网络、编译原理等等，当然还有数据结构和算法。

可是，我们都知道，像《算法导论》这些经典书籍，虽然很全面，但是过于理论，学起来非常枯燥；而市面很多课程大多缺失真实的开发场景，费劲学完感觉好像还是用不上，过不了几天就忘了。

所以，我尝试做一个让你能真正受用的数据结构与算法课程，希望给你指明一个简洁、高效的学习路径，教你一个学习基础知识的通用方法 。那么，关于专栏内容，我是怎样设计的呢？

我根据自己研读数十本算法书籍和多年项目开发的经验，在众多的数据结构和算法中，精选了最实用的内容进行讲解。

我不只会教你怎么用，还会告诉你，我们为什么需要这种数据结构和算法，一点点帮你捋清它们背后的设计思想，培养你举一反三的能力。

对于每种数据结构和算法，我都会结合真实的软件开发案例来讲解，让你知道，数据结构和算法，究竟应该如何应用到实际的编码中。

为了由浅入深地带你学习，我把专栏分成四个递进的模块。

入门篇
时间、空间复杂度分析是数据结构和算法中非常重要的知识点，贯穿整个专栏的学习过程。但同时也是比较难掌握的，所以我用了 2 节课来讲这部分内容，而且还举了大量的实例，让你一边学一边练，真正能掌握复杂度分析，为后面的学习铺路。

我希望通过这一模块，你能掌握时间、空间复杂度的概念，大 O 表示法的由来，各种复杂度分析技巧，以及最好、最坏、平均、均摊复杂度分析方法。之后，面对任何代码的复杂度分析，你都能游刃有余、毫不畏惧！

基础篇
这部分是专栏中篇幅最大的内容，也是我们学习的重点，共有 26 节内容，涵盖了最基础、最常用的数据结构和算法。针对每种数据结构和算法，我都会结合具体的软件开发实例，由浅入深进行讲解，并适时总结一些实用“宝典”，保证你印象深刻、学有所用。

比如递归这一节，我会讲到，为什么递归代码比较难写？如何避免堆栈溢出？如何避免递归冗余计算？如何将递归代码转化为非递归代码？

高级篇
这部分我会讲一些不是那么常用的数据结构和算法。虽然不常用，但是这些内容你也需要知道。设置这一部分的目的，是为了让你开拓视野，强化训练算法思维、逻辑思维。如果说学完基础部分可以考 80 分，那掌握这一部分就能让你成为尖子生！

实战篇
我们整个专栏都是围绕数据结构和算法在具体软件实践中的应用来讲的，所以最后我会通过实战部分串讲一下前面讲到的数据结构和算法。我会拿一些开源项目、框架或者系统设计问题，剖析它们背后的数据结构和算法，让你有一个更加直观的感受。

人生路上，我们会遇到很多的坎。跨过去，你就可以成长，跨不过去就是困难和停滞。而在后面很长的一段时间里，你都需要为这个困难买单。对于我们技术人来说，更是这样。既然数据结构和算法这个坎，我们总归是要跨过去，为什么不是现在呢？

我很感激师兄当年给我的那本《算法导论》，这是我人生中为数不多的转折点之一。没有那本书，也可能就没有今天的我。我希望这个专栏也能成为你的一个人生转折点。

我希望，通过这个专栏，不仅能帮你跨过数据结构与算法这个坎，还能帮你掌握一种学习知识和技能的方法，帮你度过职场甚至人生的重要时刻！一起加油吧！



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(639)

shupian418 置顶
 作者回复

迈不过去你找我退钱

冲这句话，我相信这么有信心的作者！
2018-09-17

4

499

郭蕾 置顶
9 月 21 日起正式更新，更新时间为每周一三五。
2018-09-17


109

YJ、 置顶
作为程序员，学习就是我的使命。
2018-09-17


67

动物园园长 置顶
有两个问题想咨询一下：1、编程语言基础：只会简单的python语言，练习课程中的练习基础够不够？
2、能否大致讲一下学习这门课程的思路？是否有必要将所有练习都全部一一用语言实现一遍？
作者回复: 你问的很到位 后面01 02会详细讲这个专栏怎么学 简单python会就够了 很多大学生学这门课的时候根本不会编程 照样也学了

2018-09-17


39

#仙豆 置顶
课程用的什么语言？
作者回复: 不限语言 java go python 甚至javascript都可以

2018-09-17

1

22

笑容 置顶
算法需要有高等数学基础吧
作者回复: 实际上 初中就够了 搞信息学竞赛的都是些初中生

2018-09-17


21

。 置顶
关注「极客时间」服务号，回复关键词「算法」，提前获取专栏学习思维脑图。
2018-09-19


15

LAMBO 置顶
早上车系列。
早点把基础学好学深，就能更快地写出更好的代码，就能更早走上人生巅峰。
期待大神的点拨。
2018-09-18


14

Leung 置顶
请问，每一节都会有相应的材料输出吗？
作者回复: 材料输出你是指？每节课开篇都有思考题 课后还有思考题 内容也结合实际的软件开发场景来讲

2018-09-17


5

glenny
上车，希望这次能迈过这个坎儿
作者回复: 迈不过去你找我退钱

2018-09-17

1

327

趁此生未老～～～
买的人 这么多，希望作者不要被金钱冲昏头脑。认真对待！对的起大家！说的可能重了点。莫怪！
作者回复: 怎么会呢 我也不缺这点钱 写这个主要还是想提高一下国内程序员的整体水平

2018-09-18

1

100

程序媛shirley
.NET程序媛来报道～
作者回复: 比心

2018-09-18


67

一直
用伪代码讲解的话，那确定我们用自己学过的语言可以实现吗老师？？
作者回复: 实在不行我就开个github账号 把代码实现一遍放上去给你看

2018-09-19


58

Woong
看到有留言说系统作者不要被金钱冲昏头脑，我只想说，希望大家多订阅，作者多赚钱，有动力写出更好的文章，然后带大家一起多赚钱。钱是个好东西！
作者回复: 是的 感谢理解 我也听到一些质疑的声音 不过我花了半年的时间把我积累了这么多年的经验 心得 分享出来 难道还不止一顿饭钱吗？知识这个东西 就是你觉得它对你没用 那它一文不值 如果它对你有用 那就不止值68 甚至680 6800 6万8....

2018-09-19


35

飞灰湮儿灭
忘了是不是陈皓一个文章里写的，程序员两条腿，一条是算法，一条是英文，想跑的更远，这两条腿都不能弱。。。英文已经补了三个月了，算法，迟早要还的债，也得逼自己一把补补课了。
2018-09-17

1

32

Codery
师傅，算法靠你了，你要好好开车啊。千万别翻车，哈哈
2018-09-18


27

Meteor
数据结构和算法永远无法绕开的坑，绕不过就去填上，坐等大佬开讲。
作者回复: 你的选择没错 池老师说了 数据结构和算法是 程序员的金线 一个普通程序员和一个优质高潜程序员 永远的区分线

2018-09-17

2

27

何欢
建议用代码实现比较好，然后把代码放到github上面，我们可以拿来学习。
2018-09-20


23

hxx1221
我之前也看过算法 可是我敲了几年代码 除了业务中用了个递归 真没有用到什么算法 我现在在跟学一遍 我就是特别好奇 这算法什么时候用 工作中 我真没怎么用到 带着一颗好奇心去学呀 希望老师能多讲解讲解工作中的实例
作者回复: 我太懂你了 99%的人都觉得算法 数据结构没啥用 顶多用个数组 链表 散列 排序 那还都是直接调包 用语言提供的容器 函数

2018-09-19


23

Pingkoko
可以的话，希望老师在github上把实例写上去，java或者python都可以，可以搞个点赞看用哪种语言，谢谢！
2018-09-20


22
收起评论

99+99+







# 01 | 为什么要学习数据结构和算法？



数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



01 | 为什么要学习数据结构和算法？
王争 2018-09-21



08:59
讲述：修阳 大小：4.13M
你是不是觉得数据结构和算法，跟操作系统、计算机网络一样，是脱离实际工作的知识？可能除了面试，这辈子也用不着？

尽管计算机相关专业的同学在大学都学过这门课程，甚至很多培训机构也会培训这方面的知识，但是据我了解，很多程序员对数据结构和算法依旧一窍不通。还有一些人也只听说过数组、链表、快排这些最最基本的数据结构和算法，稍微复杂一点的就完全没概念。

当然，也有很多人说，自己实际工作中根本用不到数据结构和算法。所以，就算不懂这块知识，只要 Java API、开发框架用得熟练，照样可以把代码写得“飞”起来。事实真的是这样吗？

今天我们就来详细聊一聊，为什么要学习数据结构和算法。

想要通关大厂面试，千万别让数据结构和算法拖了后腿
很多大公司，比如 BAT、Google、Facebook，面试的时候都喜欢考算法、让人现场写代码。有些人虽然技术不错，但每次去面试都会“跪”在算法上，很是可惜。那你有没有想过，为什么这些大公司都喜欢考算法呢？

校招的时候，参加面试的学生通常没有实际项目经验，公司只能考察他们的基础知识是否牢固。社招就更不用说了，越是厉害的公司，越是注重考察数据结构与算法这类基础知识。相比短期能力，他们更看中你的长期潜力。

你可能要说了，我不懂数据结构与算法，照样找到了好工作啊。那我是不是就不用学数据结构和算法呢？当然不是，你别忘了，我们学任何知识都是为了“用”的，是为了解决实际工作问题的，学习数据结构和算法自然也不例外。

业务开发工程师，你真的愿意做一辈子 CRUD boy 吗？
如果你是一名业务开发工程师，你可能要说，我整天就是做数据库 CRUD（增删改查），哪里用得到数据结构和算法啊？

是的，对于大部分业务开发来说，我们平时可能更多的是利用已经封装好的现成的接口、类库来堆砌、翻译业务逻辑，很少需要自己实现数据结构和算法。但是，不需要自己实现，并不代表什么都不需要了解。

如果不知道这些类库背后的原理，不懂得时间、空间复杂度分析，你如何能用好、用对它们？存储某个业务数据的时候，你如何知道应该用 ArrayList，还是 Linked List 呢？调用了某个函数之后，你又该如何评估代码的性能和资源的消耗呢？

作为业务开发，我们会用到各种框架、中间件和底层系统，比如 Spring、RPC 框架、消息中间件、Redis 等等。在这些基础框架中，一般都揉和了很多基础数据结构和算法的设计思想。

比如，我们常用的 Key-Value 数据库 Redis 中，里面的有序集合是用什么数据结构来实现的呢？为什么要用跳表来实现呢？为什么不用二叉树呢？

如果你能弄明白这些底层原理，你就能更好地使用它们。即便出现问题，也很容易就能定位。因此，掌握数据结构和算法，不管对于阅读框架源码，还是理解其背后的设计思想，都是非常有用的。

在平时的工作中，数据结构和算法的应用到处可见。我来举一个你非常熟悉的例子：如何实时地统计业务接口的 99% 响应时间？

你可能最先想到，每次查询时，从小到大排序所有的响应时间，如果总共有 1200 个数据，那第 1188 个数据就是 99% 的响应时间。很显然，每次用这个方法查询的话都要排序，效率是非常低的。但是，如果你知道“堆”这个数据结构，用两个堆可以非常高效地解决这个问题。

基础架构研发工程师，写出达到开源水平的框架才是你的目标！
现在互联网上的技术文章、架构分享、开源项目满天飞，照猫画虎做一套基础框架并不难。我就拿 RPC 框架举例。

不同的公司、不同的人做出的 RPC 框架，架构设计思路都差不多，最后实现的功能也都差不多。但是有的人做出来的框架，Bug 很多、性能一般、扩展性也不好，只能在自己公司仅有的几个项目里面用一下。而有的人做的框架可以开源到 GitHub 上给很多人用，甚至被 Apache 收录。为什么会有这么大的差距呢？

我觉得，高手之间的竞争其实就在细节。这些细节包括：你用的算法是不是够优化，数据存取的效率是不是够高，内存是不是够节省等等。这些累积起来，决定了一个框架是不是优秀。所以，如果你还不懂数据结构和算法，没听说过大 O 复杂度分析，不知道怎么分析代码的时间复杂度和空间复杂度，那肯定说不过去了，赶紧来补一补吧！

对编程还有追求？不想被行业淘汰？那就不要只会写凑合能用的代码！
何为编程能力强？是代码的可读性好、健壮？还是扩展性好？我觉得没法列，也列不全。但是，在我看来，性能好坏起码是其中一个非常重要的评判标准。但是，如果你连代码的时间复杂度、空间复杂度都不知道怎么分析，怎么写出高性能的代码呢？

你可能会说，我在小公司工作，用户量很少，需要处理的数据量也很少，开发中不需要考虑那么多性能的问题，完成功能就可以，用什么数据结构和算法，差别根本不大。但是你真的想“十年如一日”地做一样的工作吗？

经常有人说，程序员 35 岁之后很容易陷入瓶颈，被行业淘汰，我觉得原因其实就在此。有的人写代码的时候，从来都不考虑非功能性的需求，只是完成功能，凑合能用就好；做事情的时候，也从来没有长远规划，只把眼前事情做好就满足了。

我曾经面试过很多大龄候选人，简历能写十几页，经历的项目有几十个，但是细看下来，每个项目都是重复地堆砌业务逻辑而已，完全没有难度递进，看不出有能力提升。久而久之，十年的积累可能跟一年的积累没有任何区别。这样的人，怎么不会被行业淘汰呢？

如果你在一家成熟的公司，或者 BAT 这样的大公司，面对的是千万级甚至亿级的用户，开发的是 TB、PB 级别数据的处理系统。性能几乎是开发过程中时刻都要考虑的问题。一个简单的 ArrayList、Linked List 的选择问题，就可能会产生成千上万倍的性能差别。这个时候，数据结构和算法的意义就完全凸显出来了。

其实，我觉得，数据结构和算法这个东西，如果你不去学，可能真的这辈子都用不到，也感受不到它的好。但是一旦掌握，你就会常常被它的强大威力所折服。之前你可能需要费很大劲儿来优化的代码，需要花很多心思来设计的架构，用了数据结构和算法之后，很容易就可以解决了。

内容小结
我们学习数据结构和算法，并不是为了死记硬背几个知识点。我们的目的是建立时间复杂度、空间复杂度意识，写出高质量的代码，能够设计基础架构，提升编程技能，训练逻辑思维，积攒人生经验，以此获得工作回报，实现你的价值，完善你的人生。

所以，不管你是业务开发工程师，还是基础架构工程师；不管你是初入职场的初级工程师，还是工作多年的资深架构师，又或者是想转人工智能、区块链这些热门领域的程序员，数据结构与算法作为计算机的基础知识、核心知识，都是必须要掌握的。

掌握了数据结构与算法，你看待问题的深度，解决问题的角度就会完全不一样。因为这样的你，就像是站在巨人的肩膀上，拿着生存利器行走世界。数据结构与算法，会为你的编程之路，甚至人生之路打开一扇通往新世界的大门。

课后思考
你为什么要学习数据结构和算法呢？在过去的软件开发中，数据结构和算法在哪些地方帮到了你？

欢迎留言和我分享，我会第一时间给你反馈。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(621)

姜威
为什么学习数据结构和算法？我认为有3点比较重要
1.直接好处是能够有写出性能更优的代码。
2.算法，是一种解决问题的思路和方法，有机会应用到生活和事业的其他方面。
3.长期来看，大脑思考能力是个人最重要的核心竞争力，而算法是为数不多的能够有效训练大脑思考能力的途径之一。
作者回复: 写的很好 同学们把这条回复顶上去

2018-09-21


2164

HouShangLing
一定要动手写
作者回复: 你掌握了学这门课的最有效的方法。看十遍也没自己实现一遍学的牢。同学们这条也帮忙顶上去

2018-09-21

1

1002

wistbean
其实问题的所在就是现在有很多现成的框架，器又大活又好，拿来就用，还不用太担心性能的问题。就好像那些建楼的工程师不需要懂砖瓦的构成，也能盖楼。司机不需要懂汽车引擎的原理，也能当顺风车司机载美女兜风。

遇到不会的上 Google，懒了就上 GitHub 找框架。所以写了这么多年代码，一直是个菜鸟。

或许是时候修炼自己的内功了。一直 CURD 有意思么？把设计模式，网络原理，数据结构和算法捡起来，或许就没那么容易菜鸟了。怼人也更加自信了。跳槽也不用畏畏缩缩的了。

为了不当菜鸟，我和我的小伙伴们就加入了哇！
作者回复: 写的太好了

2018-09-21


242

两颗小虎牙
可不可以每次多发布几篇？
2018-09-21


125

裴海港
年近40的大叔也有一颗积极向上的心
作者回复: 终身学习 多大年纪也不晚

2018-09-21

2

119

tdytaylor
老师，就像你说的，工作中其实好多都和业务挂钩，基本上都是针对业务做增删改查，很难把所学的算法应用起来，我平时也时不时学习算法，但总感觉学了就忘，忘了又学，如此反复，老师，这种到底是没了解算法的原理导致不会灵活应用，还是写的少导致的，感觉学习算法很少能应用起来
作者回复: 1. 客观的讲，有些项目确实涉及的数据结构和算法少一些，你可以再看下我文章里写的。
2. 你提到学了又忘，我觉得一方面你是没有掌握学习的方法，学习的重点，走马观花的看肯定比较容易忘；我们02节会具体讲；
3. 不会灵活应用？那估计还是没有好的教材教你如何应用，还有可能就是确实还没掌握太牢，只是懂点皮毛，很浅，灵活应用是一个比较的境界，需要一段时间的沉淀学习。
4. 学习算法并不是为了记住几个排序、二分查找、二叉树遍历，他还能锻炼你的逻辑思维、性能意识，而且，如果你写代码能力还有欠缺，你还可以通过把学到的数据结构和算法都实现一遍，这是一种很好很好的锻炼编程能力的方法。所以不要过度追求一定要在项目里手写快排、手写二叉树才能算是用上。

2018-09-21


118

五岳寻仙
老师好！看到专栏第一眼就果断订阅了。我是一个菜鸟程序员，半年的工作经验让我感受到数据结构和算法太重要了！讲一个自己亲身经历的例子。
入职不久，就遇到一个需求，需要建立一个3G(30亿)条键值对映射，已供后续检索。听上去很简单的问题，用python的字典就可以解决。但在实现的过程中，很快就遇到了问题：字典是基于hash的，对于每条键值对要多消耗50个字节的内存维持这种结构(即便使用redis也需要这个内存花销)，再加上键值存储消耗的内存，我大约需要3G×70=210G内存，超过服务器内存了。
后来，想到了可以根据键排序后线性存储，使用二分查找，解决了这个问题，大约消耗的内存也就3G×10=30G左右。
看似简单的问题，当规模大到一定程度，不借助算法和数据结构，就无法解决了。
作者回复: 哈哈 你要是看到我讲的散列那一篇你就知道了 像java里的hashmap是比较耗内存的 你用到的解决方案是一种用时间复杂度换空间复杂度的思路 我们专栏也会讲的 不过你现在的解决办法还可以更高效 利用hash函数 我们专栏也会讲到 还有二分是logn的时间复杂度 是非常高效的一种时间复杂度 2的64次方个有序数据二分查找也顶多循环64次 有没有觉得logn这个复杂度很奇妙

2018-09-21


94

Haoz
一、数据结构和算法是什么

1、数据结构是指一组数据的存储结构
2、算法就是操作数据的方法
3、数据结构和算法是相辅相成的，数据结构是为算法服务的，而算法要作用在特定的数据结构之上

二、学习的重点在什么地方

数据结构和算法解决的是如何更省、更快地存储和处理数据的问题，因此，我们就需要一个考量效率和资源消耗的方法，这就是复杂度分析方法。在学习数据结构和算法的过程中，要学习它的「来历」、「自身的特点」、「适合解决的问题」以及「实际的应用场景」。

1、数据结构和算法学习的精髓-复杂度分析
2、最常用的、最基础的数据结构：数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie 树
3、最常用的算法：递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法

感谢老师的分析，一直以来数据结构和算法都是我的硬伤，学了很多次，也放弃了很多次，可能是方法不对，但更多的是因为自己之前的毅力不够。

在此立下 flag：从本篇文章开始，将老师的文章根据自己的理解进行输出相应的总结和思考，发表成留言，并将每周三篇文章中涉及的数据结构和算法用 Java 实现一次。
作者回复: 写的很好👍

2018-09-25


67

DDT
就是想升工资吧 我知道学技术必须要拿出十年磨一剑的精神 从头开始...
作者回复: 十年磨一剑说的太好了。我也是这么认为的。做技术就是不要浮躁。要耐得住寂寞。沉得下心。

2018-09-21


31

小麦2018
我还是觉得王争老师自己读的音频好，亲切，有听作者亲自讲解的感觉。
2018-09-21


28

邵峰
记得以前看金庸小说，一个人练降龙十八掌，一个人练全真教内功，刚开始练内功的被吊打，十年后练内功的依然被吊打，但是20年后，降龙十八掌就怎么也打不过练内功的了，算法和数据结构就是内功，降龙十八掌我觉得就是各种框架，再怎么熟悉框架，也不如了解它内部的算法和数据结构
作者回复: 太形象了：）

2018-09-21


26

阿康
老师，我是一名iOS开发，怎么听完你这篇文章还是觉得算法对于我开发来说不是那么重要😂后面我有点怕自己听不懂，而且动手写，我该如何下笔，感觉自己很迷茫……
作者回复: 1. 假设我们现在要做这样一个功能，我们希望在app上存储一个多级地址列表，用户可以一层一层的选择地址列表中的地址，来设置自己的所在的省份、市、区，如果这个地址列表不是经常变动的，我们希望保存在app端，这样就不需要每次操作地址列表都要跟后台交互，如果让你存储这个多级地址列表，你会怎么存储呢？
2. 如果地址列表也并不是一直都不变的，如果地址列表改变了，我们又不希望发新版，那如何更新app上的地址列表呢？如果地址列表比较大，我们不希望app重新全量的从服务器再拉一次，那又如何来做呢？
3. 我会用一种语言来实现 你可以翻译成object c

2018-09-21


24

lane
现实，都是面相领导编程…………一言难尽…
作者回复: 没事的 如果工作不满意 不顺心 更要卧薪尝胆 提高能力 沉淀自己。总有一天 机会会到来 你做好充分的抓住它的准备就好。人在职场中 只要抓住一两次大的机会 就能做到很高的职位 就怕的是机会来了我们也抓不住

2018-09-21


22

Liar
不做一个没有追求的码农，那些说过了35就不行的码农大部分都是不求上进的人。
作者回复: 说得好 不管哪个行业都会淘汰不求上进的人 it也不例外

2018-09-21


21

Chevins
今天去面试。数据结构与算法。6道题。一道都不会。我说我3年开发经验，呵呵，自己都觉得可笑。不过无所谓，我会追上来的，加油，菜鸟。
2018-09-22


16

grandcool
没理解统计业务接口99%响应时间啥意思
作者回复: 举一个例子 你写了一个接口 每天有成千上万的访问 你如何知道这个接口够不够快？响应时间是1s还是5s？如何统计度量？用平均值？显然不是太适合？那用什么值来统计度量呢？你可以自己搜索研究下

2018-09-21


16

xuan zhu
年近40的大妈也有一颗积极向上的心
2018-09-22


12

demo
双非，不是CS专业的本科生，学校里边学的太少了。自己虽然有坚持刷leetcode，但是好多都是先看人家的思路才可以写出来的。自己一个自学，压力大，效率低吧.希望通过这个课程开阔自己的视野。
之后不管考研还是找工作，数据结构都是重中之重。所以 我一定要好好学。
2018-09-21


12

小行家
为什么学习数据结构与算法？
1.作为一名程序员，我觉得这个是基本功，就好比建房子一样，地基一定要牢固
2.现在有如此多的开源项目，人们往往开发中只是照搬，调试，集成，然后很少会去注意性能和优化方面，慢慢的也就成了CRUD boy
3.算法提供的是一种思想，这个思想真的可以让你超神，让你对待问题有着独特的见解，我觉得这个才是最重要的。不再是原来的，没有思考
4.数据结构作为cs的基本专业，并且贯穿整个cs学习生涯，在cs方面的研究还是有很大的实用价值。
数据结构与算法的意义？
1.在本科开发中，曾经就自己写了一个类似于目录搜索的算法，就是简单的for循环，性能极其低下，改为二叉树后，性能大大提升
2.目前读研，接触机器学习理论和深度学习，原有的算法和数据结构的学习中，你所掌握的思想，确实会有很大的意义。
 最后，我认为，学习最重要的是你能够自己成长，这个才是最棒的。
作者回复: 说的好

2018-09-21


12

松鼠君
有一个机电学长和我说，学习数据结构和算法可以改变你的思维方式，我信了，然后学了。
2018-09-21


11
收起评论

99+99+





# 02 | 如何抓住重点，系统高效地学习数据结构与算法？



数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



02 | 如何抓住重点，系统高效地学习数据结构与算法？
王争 2018-09-24



14:21
讲述：修阳 大小：6.58M
你是否曾跟我一样，因为看不懂数据结构和算法，而一度怀疑是自己太笨？实际上，很多人在第一次接触这门课时，都会有这种感觉，觉得数据结构和算法很抽象，晦涩难懂，宛如天书。正是这个原因，让很多初学者对这门课望而却步。

我个人觉得，其实真正的原因是你没有找到好的学习方法，没有抓住学习的重点。实际上，数据结构和算法的东西并不多，常用的、基础的知识点更是屈指可数。只要掌握了正确的学习方法，学起来并没有看上去那么难，更不需要什么高智商、厚底子。

还记得大学里每次考前老师都要划重点吗？今天，我就给你划划我们这门课的重点，再告诉你一些我总结的学习小窍门。相信有了这些之后，你学起来就会有的放矢、事半功倍了。

什么是数据结构？什么是算法？
大部分数据结构和算法教材，在开篇都会给这两个概念下一个明确的定义。但是，这些定义都很抽象，对理解这两个概念并没有实质性的帮助，反倒会让你陷入死抠定义的误区。毕竟，我们现在学习，并不是为了考试，所以，概念背得再牢，不会用也就没什么用。

虽然我们说没必要深挖严格的定义，但是这并不等于不需要理解概念。 下面我就从广义和狭义两个层面，来帮你理解数据结构与算法这两个概念。

从广义上讲，数据结构就是指一组数据的存储结构。算法就是操作数据的一组方法。

图书馆储藏书籍你肯定见过吧？为了方便查找，图书管理员一般会将书籍分门别类进行“存储”。按照一定规律编号，就是书籍这种“数据”的存储结构。

那我们如何来查找一本书呢？有很多种办法，你当然可以一本一本地找，也可以先根据书籍类别的编号，是人文，还是科学、计算机，来定位书架，然后再依次查找。笼统地说，这些查找方法都是算法。

从狭义上讲，也就是我们专栏要讲的，是指某些著名的数据结构和算法，比如队列、栈、堆、二分查找、动态规划等。这些都是前人智慧的结晶，我们可以直接拿来用。我们要讲的这些经典数据结构和算法，都是前人从很多实际操作场景中抽象出来的，经过非常多的求证和检验，可以高效地帮助我们解决很多实际的开发问题。

那数据结构和算法有什么关系呢？为什么大部分书都把这两个东西放到一块儿来讲呢？

这是因为，数据结构和算法是相辅相成的。数据结构是为算法服务的，算法要作用在特定的数据结构之上。 因此，我们无法孤立数据结构来讲算法，也无法孤立算法来讲数据结构。

比如，因为数组具有随机访问的特点，常用的二分查找算法需要用数组来存储数据。但如果我们选择链表这种数据结构，二分查找算法就无法工作了，因为链表并不支持随机访问。

数据结构是静态的，它只是组织数据的一种方式。如果不在它的基础上操作、构建算法，孤立存在的数据结构就是没用的。

现在你对数据结构与算法是不是有了比较清晰的理解了呢？有了这些储备，下面我们来看看，究竟该怎么学数据结构与算法。

学习这个专栏需要什么基础？
看到数据结构和算法里的“算法”两个字，很多人就会联想到“数学”，觉得算法会涉及到很多深奥的数学知识。那我数学基础不是很好，学起来会不会很吃力啊？

数据结构和算法课程确实会涉及一些数学方面的推理、证明，尤其是在分析某个算法的时间、空间复杂度的时候，但是这个你完全不需要担心。

这个专栏不会像《算法导论》那样，里面有非常复杂的数学证明和推理。我会由浅入深，从概念到应用，一点一点给你解释清楚。你只要有高中数学水平，就完全可以学习。

当然，我希望你最好有些编程基础，如果有项目经验就更好了。这样我给你讲数据结构和算法如何提高效率、如何节省存储空间，你就会有很直观的感受。因为，对于每个概念和实现过程，我都会从实际场景出发，不仅教你“是什么”，还会教你“为什么”，并且告诉你遇到同类型问题应该“怎么做”。

学习的重点在什么地方？
提到数据结构和算法，很多人就很头疼，因为这里面的内容实在是太多了。这里，我就帮你梳理一下，应该先学什么，后学什么。你可以对照看看，你属于哪个阶段，然后有针对地进行学习。

想要学习数据结构与算法，首先要掌握一个数据结构与算法中最重要的概念——复杂度分析。

这个概念究竟有多重要呢？可以这么说，它几乎占了数据结构和算法这门课的半壁江山，是数据结构和算法学习的精髓。

数据结构和算法解决的是如何更省、更快地存储和处理数据的问题，因此，我们就需要一个考量效率和资源消耗的方法，这就是复杂度分析方法。所以，如果你只掌握了数据结构和算法的特点、用法，但是没有学会复杂度分析，那就相当于只知道操作口诀，而没掌握心法。只有把心法了然于胸，才能做到无招胜有招！

所以，复杂度分析这个内容，我会用很大篇幅给你讲透。你也一定要花大力气来啃，必须要拿下，并且要搞得非常熟练。否则，后面的数据结构和算法也很难学好。

搞定复杂度分析，下面就要进入数据结构与算法的正文内容了。

为了让你对数据结构和算法能有个全面的认识，我画了一张图，里面几乎涵盖了所有数据结构和算法书籍中都会讲到的知识点。


（图谱内容较多，建议长按保存后浏览）

但是，作为初学者，或者一个非算法工程师来说，你并不需要掌握图里面的所有知识点。很多高级的数据结构与算法，比如二分图、最大流等，这些在我们平常的开发中很少会用到。所以，你暂时可以不用看。我还是那句话，咱们学习要学会找重点。如果不分重点地学习，眉毛胡子一把抓，学起来肯定会比较吃力。

所以，结合我自己的学习心得，还有这些年的面试、开发经验，我总结了20 个最常用的、最基础数据结构与算法，不管是应付面试还是工作需要，只要集中精力逐一攻克这 20 个知识点就足够了。

这里面有 10 个数据结构：数组、链表、栈、队列、散列表、二叉树、堆、跳表、图、Trie 树；10 个算法：递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法。

掌握了这些基础的数据结构和算法，再学更加复杂的数据结构和算法，就会非常容易、非常快。

在学习数据结构和算法的过程中，你也要注意，不要只是死记硬背，不要为了学习而学习，而是要学习它的“来历”“自身的特点”“适合解决的问题”以及“实际的应用场景”。对于每一种数据结构或算法，我都会从这几个方面进行详细讲解。只要你掌握了我每节课里讲的内容，就能在开发中灵活应用。

学习数据结构和算法的过程，是非常好的思维训练的过程，所以，千万不要被动地记忆，要多辩证地思考，多问为什么。如果你一直这么坚持做，你会发现，等你学完之后，写代码的时候就会不由自主地考虑到很多性能方面的事情，时间复杂度、空间复杂度非常高的垃圾代码出现的次数就会越来越少。你的编程内功就真正得到了修炼。

一些可以让你事半功倍的学习技巧
前面我给你划了学习的重点，也讲了学习这门课需要具备的基础。作为一个过来人，现在我就给你分享一下，专栏学习的一些技巧。掌握了这些技巧，可以让你化被动为主动，学起来更加轻松，更加有动力！

1. 边学边练，适度刷题
“边学边练”这一招非常有用。建议你每周花 1～2 个小时的时间，集中把这周的三节内容涉及的数据结构和算法，全都自己写出来，用代码实现一遍。这样一定会比单纯地看或者听的效果要好很多！

有面试需求的同学，可能会问了，那我还要不要去刷题呢？

我个人的观点是可以“适度”刷题，但一定不要浪费太多时间在刷题上。我们学习的目的还是掌握，然后应用。除非你要面试 Google、Facebook 这样的公司，它们的算法题目非常非常难，必须大量刷题，才能在短期内提升应试正确率。如果是应对国内公司的技术面试，即便是 BAT 这样的公司，你只要彻底掌握这个专栏的内容，就足以应对。

2. 多问、多思考、多互动
学习最好的方法是，找到几个人一起学习，一块儿讨论切磋，有问题及时寻求老师答疑。 但是，离开大学之后，既没有同学也没有老师，这个条件就比较难具备了。

不过，这也就是咱们专栏学习的优势。专栏里有很多跟你一样的学习者。你可以多在留言区写下自己的疑问、思考和总结，也可以经常看看别人的留言，和他们进行互动。

除此之外，如果你有疑问，你可以随时在留言区给我留言，我只要有空就会及时回复你。你不要担心问的问题太小白。因为我初学的时候，也常常会被一些小白问题困扰。不懂一点都不丢人，只要你勇敢提出来，我们一起解决了就可以了。

我也会力争每节课都最大限度地给你讲透，帮你扫除知识盲点，而你要做的就是，避免一知半解，要想尽一切办法去搞懂我讲的所有内容。

3. 打怪升级学习法
学习的过程中，我们碰到最大的问题就是，坚持不下来。 是的，很多基础课程学起来都非常枯燥。为此，我自己总结了一套“打怪升级学习法”。

游戏你肯定玩过吧？为什么很多看起来非常简单又没有乐趣的游戏，你会玩得不亦乐乎呢？这是因为，当你努力打到一定级别之后，每天看着自己的经验值、战斗力在慢慢提高，那种每天都在一点一点成长的成就感就不由自主地产生了。

所以，我们在枯燥的学习过程中，也可以给自己设立一个切实可行的目标，就像打怪升级一样。

比如，针对这个专栏，你就可以设立这样一个目标：每节课后的思考题都认真思考，并且回复到留言区。当你看到很多人给你点赞之后，你就会为了每次都能发一个漂亮的留言，而更加认真地学习。

当然，还有很多其他的目标，比如，每节课后都写一篇学习笔记或者学习心得；或者你还可以每节课都找一下我讲得不对、不合理的地方……诸如此类，你可以总结一个适合你的“打怪升级攻略”。

如果你能这样学习一段时间，不仅能收获到知识，你还会有意想不到的成就感。因为，这其实帮你改掉了一点学习的坏习惯。这个习惯一旦改掉了，你的人生也会变得不一样。

4. 知识需要沉淀，不要想试图一下子掌握所有
在学习的过程中，一定会碰到“拦路虎”。如果哪个知识点没有怎么学懂，不要着急，这是正常的。因为，想听一遍、看一遍就把所有知识掌握，这肯定是不可能的。学习知识的过程是反复迭代、不断沉淀的过程。

如果碰到“拦路虎”，你可以尽情地在留言区问我，也可以先沉淀一下，过几天再重新学一遍。所谓，书读百遍其义自见，我觉得是很有道理的！

我讲的这些学习方法，不仅仅针对咱们这一个课程的学习，其实完全适用任何知识的学习过程。你可以通过这个专栏的学习，实践一下这些方法。如果效果不错，再推广到之后的学习过程中。

内容小结
今天，我带你划了划数据结构和算法的学习重点，复杂度分析，以及 10 个数据结构和 10 个算法。

这些内容是我根据平时的学习和工作、面试经验积累，精心筛选出来的。只要掌握这些内容，应付日常的面试、工作，基本不会有问题。

除此之外，我还给你分享了我总结的一些学习技巧，比如边学边练、多问、多思考，还有两个比较通用的学习方法，打怪升级法和沉淀法。掌握了这些学习技巧，可以让你学习过程中事半功倍。所以，你一定要好好实践哦！

课后思考
今天的内容是一个准备课，从下节开始，我们就要正式开始学习精心筛选出的这 20 个数据结构和算法了。所以，今天给你布置一个任务，对照我上面讲的“打怪升级学习法”，请思考一下你自己学习这个专栏的方法，让我们一起在留言区立下 Flag，相互鼓励！

另外，你在之前学习数据结构和算法的过程中，遇到过什么样的困难或者疑惑吗？

欢迎留言和我分享，我会第一时间给你反馈。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(1389)

强
1、所有数据结构与算法用C++实现一遍;
2、所有数据结构与算法用Python实现一遍;
3、学完就辞职。
2018-09-24

16

1570

wean
是什么：
数据结构指的是“一组数据的存储结构”，算法指的是“操作数据的一组方法”。
数据结构是为算法服务的，算法是要作用再特定的数据结构上的。
学什么：
1. 效率和资源消耗的度量衡--复杂度分析。
2. 最常用、最基础的20个数据结构与算法，学习他们的：“来历”、“特点”、“适合解决什么问题”和“实际的应用场景”。
数据结构：数组、链表、栈、队列、散列表、二叉树‘、堆、跳表、图、Tire树
算法： 递归、排序、二分查找、搜索、哈希算法、贪心算法、分治算法、回溯算法、动态规划、字符串匹配算法
怎么学
1. 边学边练，每周花 1~2 小时集中攻关三节课涉及的数据结构和算法，全部写出来。
2. 主动提问、多思考、多互动。在留言区增加自己的留言。
3. 自我激励，每次学习完做一篇学习笔记。
4. 沉下心不要浮躁，先把这些基础的数据结构和算法，还有学习方法熟练掌握后，再追求更高层次。
------------
flag：每篇文章必写学习笔记，每周必实现一次该周代码。
2018-09-24

1

757

$Jason
BAT我明年年初一定进入一个
2018-09-24

12

412

一条咸鱼
非科班。。马上就28岁了，一直有个计算机梦。来这学习不为别的，只为能慢慢成为一位合格的计算机人
2018-09-24


293

187J3X1
https://www.cs.usfca.edu/~galles/visualization/Algorithms.html
此网站可以将指定算法可视化，能方便理解。麻烦顶上去让更多人看到，谢谢。
2018-10-01

3

237

zyzheng
“学习最好的方法是，找到几个人一起学习，一块儿讨论切磋，有问题及时寻求老师答疑。”
老师说的这个方法非常赞同，之前在学其他内容时经常遇到个人单独学习坚持不下来的问题。这次和公司里有兴趣的同事一起成立了一个五人学习小组，计划每周组织一个小时交流会，每人讲10分钟，自由讨论10分钟，希望能对自己和大家的学习都有帮助，希望能坚持下去✊
作者回复: 太赞太用心了

2018-09-24


172

EidLeung
敲代码，回想起自己大学的时候，课本上的每一段代码都敲一边！甚至敲完了整本《C++ primer》😓
2018-09-24

1

142

觉良
当我们要谈一个事物/概念的时候，需要问自己三个终极问题--是什么？为什么？怎么样？

什么是数据结构和算法
数据结构，就是一组数据的存储结构。
算法，就是操作数据的一组方法。
数据结构是为算法服务的，算法要作用在特定的数据结构之上。

为什么需要数据结构和算法
来谈谈应用层面的原因。在计算机科学和互联网迅猛发展下，需要计算的数据量越来越庞大。但是计算机的计算能力是有限的，这么大量的数据计算，需要越来越多的计算机，需要越来越长的计算时间，注重效率的我们需要尽可能的提高计算效率。其中重要的一项，就是使用合适的数据结构和算法。选用合适的数据结构和算法，特别是在处理体量非常庞大的数据的时候，可以极大提高计算效率。那么，第三个问题来了，我们怎么选用合适的数据结构和算法？有什么衡量标准吗？

怎么样衡量数据结构和算法
需要引入一个衡量的标准(metric)---时间复杂度和空间复杂度。
学习数据结构和算法的基石，就是要学会`复杂度分析`。知道怎么去分析复杂度，才能作出正确的判断，在特定的场景下选用合适的正确的算法。而不是盲目的死记烂背，机械操作。

在本专栏中，重点学习20个最常用的最基础的数据结构和算法，需要我们逐一攻克。
10个数据结构: 数组，链表，栈，队列，散列表，二叉树，堆，跳表，图，Trie树
10个算法： 递归，排序，二分查找，搜索，哈希算法，贪心算法，分治算法，回溯算法，动态规划，字符串匹配算法
作者回复: 写的好！

2018-09-24

1

137

墨墨
对于比较笨的我来说，我的学习方法就是边学边练，这个方法务实有效。在此立下flag，不学会数据结构与算法，就掉光头发！哈哈
2018-09-24

1

50

吉祥
Flag: 课程内容用 python 实现一遍，有不懂的及时留言提问，每周写总结。
2018-09-24


48

与路同飞
完美主义在作怪。在看《算法》这本书的时候，总想着做完所有习题在看后面的章节。导致后面没坚持下去
2018-09-24

1

44

zeta
35岁瓶颈失业程序员过来报道，继续精进，顺便当怪给新同学点点赞
2018-09-27

4

40

Joshua 兆甲
需要教材吗？老师？
自己学习的方法: 排个队想到队列，火车进站想到堆栈，看到树上开花想到树的某些指标，导航想到贪心，将生活场景与算法和数据结构的场景结合起来。
遇到的困难: 应用和实践不行。你看树是数据结构，而大众有更约定俗成的固有看法，切磋估计不大可行，且自己学习，首先需要一个代码开发的条件，不断思考练习，不易坚持。
数据结构不容易可视化呈现。靠画图建立初始的结构，靠脑补数据变化的过程，再靠心算将结果呈现为“可视”图景。中间，一般在机器上就是简单plain text输入输出.不是第一信号系统，接受收效率慢。
没有大图景，只有片面观察。即便会了一招半式，获得敢不强，信心不足，真正应用中，或许没有直接上两个循环嵌套来得直接，明了，易懂。容易生出百无一用是书生的瞎想
以上。老师中秋快乐！循环链表代表我的心。
作者回复: 写得好 你可以看看大话数据结构和算法图解。里面的学习方法跟你的很相似

2018-09-25


37

黄海娜
学习了，也理解了，当时可以写出代码来，但是长时间就忘记了😣，这个难道真的如果日常不用的话，的确会忘记，那是不是就要先当公式一样记下来再说？
作者回复: 完全不需要死记硬背的，我也记不住快排，红黑树，但是只要你掌握分析的能力，等你真的需要的时候，花不到半个小时就弄懂了。你要记住的是，这些算法的特点，应用场景，用到了能想到他就好了。

2018-09-24


37

lxb
我想问问用JavaScript真能实现这些算法跟数据结构吗？
作者回复: 我觉得能 后面如果你觉得不能你就再给我留言吧

2018-09-24


27

王宇
我的学习法：
1.从老师这里获取知识
2.学习理解知识，继续思考，提出疑问，先自己解决，实在想不出了问老师
3.总结知识
4.运用知识，解决问题
5.写博客教别人学到的知识
已经意识到算法对面试工作的重要性，也喜欢锻炼自己的思维，想体验不知道哪一天解决了个什么事，突然发现自己变聪明了的快感
2018-09-24


25

Silence
Flag：在这几个月内一定要掌握并学会运用文中提到的算法，不管多难都要坚持看下去，这次，不想再逃了！
2018-09-24


21

确认过眼神
本人学的Java，想通过这个课程学习如何把数据结构和算法切实的用到编程中，来实现用空间换时间。
1、提高每个接口的访问速度，可否实现？
2、时间复杂度越高，执行效率越低吗？
3、两张表联查后再遍历查询第三张表是否比三张表联查效率高？利用数据结构和算法是否有更优的解决方案？
希望老师给出三个问题的答案，伙伴们一起讨论。
作者回复: 1. 学习的过程可以锻炼你的性能意识，写代码的时候会不自觉的考虑性能问题，所以写出低效代码的情况就少了
2. 理论上是的，但实际上时间复杂度与执行时间并不划等号，我后面会讲到，有时候O(logn)的算法要比O(1)算法还快
3. 这个没有确切的场景我也不好说，你可以自己测试一下。 一般来说，海量数据的存储一般都是分库分表，所以join操作可能就无法用上了。

2018-09-24


20

Yafei
大学学这门课的时候，一碰到那种递归求复杂度就懵逼，这次一定搞定它！
2018-09-24


18

五岳寻仙
老师给的思路非常非常清晰，不愧是IT大牛，我很喜欢这种结构化的思维方式，相信同学也有同感！
已经决定严格跟随老师的思路这门课。在执行前遇到三个困难：

1. 想请老师推荐刷题的地方；
2. 想知道每种算法和数据结构在现实中的应用场景，因为很多时候不是学不懂，是积极性不够，所以我觉得只有意识到它的重要作用，才会深入地钻研。
3. 没有交流的对象和途径，希望咱们专栏能有个微信群，方便交流。(我微信jjjzzz2014，期待和各位同学一起交流成长！)
作者回复: 1. 刷题的话leetcode比较火
2. 会讲的 放心
3. 暂时就在留言区交流吧

2018-09-24

1

17
收起评论

99+99+






# 03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？



数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
王争 2018-09-26



19:42
讲述：修阳 大小：9.04M
我们都知道，数据结构和算法本身解决的是“快”和“省”的问题，即如何让代码运行得更快，如何让代码更省存储空间。所以，执行效率是算法一个非常重要的考量指标。那如何来衡量你编写的算法代码的执行效率呢？这里就要用到我们今天要讲的内容：时间、空间复杂度分析。

其实，只要讲到数据结构与算法，就一定离不开时间、空间复杂度分析。而且，我个人认为，复杂度分析是整个算法学习的精髓，只要掌握了它，数据结构和算法的内容基本上就掌握了一半。

复杂度分析实在太重要了，因此我准备用两节内容来讲。希望你学完这个内容之后，无论在任何场景下，面对任何代码的复杂度分析，你都能做到“庖丁解牛”般游刃有余。

为什么需要复杂度分析？
你可能会有些疑惑，我把代码跑一遍，通过统计、监控，就能得到算法执行的时间和占用的内存大小。为什么还要做时间、空间复杂度分析呢？这种分析方法能比我实实在在跑一遍得到的数据更准确吗？

首先，我可以肯定地说，你这种评估算法执行效率的方法是正确的。很多数据结构和算法书籍还给这种方法起了一个名字，叫事后统计法。但是，这种统计方法有非常大的局限性。

1. 测试结果非常依赖测试环境

测试环境中硬件的不同会对测试结果有很大的影响。比如，我们拿同样一段代码，分别用 Intel Core i9 处理器和 Intel Core i3 处理器来运行，不用说，i9 处理器要比 i3 处理器执行的速度快很多。还有，比如原本在这台机器上 a 代码执行的速度比 b 代码要快，等我们换到另一台机器上时，可能会有截然相反的结果。

2. 测试结果受数据规模的影响很大

后面我们会讲排序算法，我们先拿它举个例子。对同一个排序算法，待排序数据的有序度不一样，排序的执行时间就会有很大的差别。极端情况下，如果数据已经是有序的，那排序算法不需要做任何操作，执行时间就会非常短。除此之外，如果测试数据规模太小，测试结果可能无法真实地反应算法的性能。比如，对于小规模的数据排序，插入排序可能反倒会比快速排序要快！

所以，我们需要一个不用具体的测试数据来测试，就可以粗略地估计算法的执行效率的方法。这就是我们今天要讲的时间、空间复杂度分析方法。

大 O 复杂度表示法
算法的执行效率，粗略地讲，就是算法代码执行的时间。但是，如何在不运行代码的情况下，用“肉眼”得到一段代码的执行时间呢？

这里有段非常简单的代码，求 1,2,3…n 的累加和。现在，我就带你一块来估算一下这段代码的执行时间。

 int cal(int n) {
   int sum = 0;
   int i = 1;
   for (; i <= n; ++i) {
     sum = sum + i;
   }
   return sum;
 }
从 CPU 的角度来看，这段代码的每一行都执行着类似的操作：读数据-运算-写数据。尽管每行代码对应的 CPU 执行的个数、执行的时间都不一样，但是，我们这里只是粗略估计，所以可以假设每行代码执行的时间都一样，为 unit_time。在这个假设的基础之上，这段代码的总执行时间是多少呢？

第 2、3 行代码分别需要 1 个 unit_time 的执行时间，第 4、5 行都运行了 n 遍，所以需要 2n*unit_time 的执行时间，所以这段代码总的执行时间就是 (2n+2)*unit_time。可以看出来，所有代码的执行时间 T(n) 与每行代码的执行次数成正比。

按照这个分析思路，我们再来看这段代码。

 int cal(int n) {
   int sum = 0;
   int i = 1;
   int j = 1;
   for (; i <= n; ++i) {
     j = 1;
     for (; j <= n; ++j) {
       sum = sum +  i * j;
     }
   }
 }
我们依旧假设每个语句的执行时间是 unit_time。那这段代码的总执行时间 T(n) 是多少呢？

第 2、3、4 行代码，每行都需要 1 个 unit_time 的执行时间，第 5、6 行代码循环执行了 n 遍，需要 2n * unit_time 的执行时间，第 7、8 行代码循环执行了 n2遍，所以需要 2n2 * unit_time 的执行时间。所以，整段代码总的执行时间 T(n) = (2n2+2n+3)*unit_time。

尽管我们不知道 unit_time 的具体值，但是通过这两段代码执行时间的推导过程，我们可以得到一个非常重要的规律，那就是，所有代码的执行时间 T(n) 与每行代码的执行次数 n 成正比。

我们可以把这个规律总结成一个公式。注意，大 O 就要登场了！



我来具体解释一下这个公式。其中，T(n) 我们已经讲过了，它表示代码执行的时间；n 表示数据规模的大小；f(n) 表示每行代码执行的次数总和。因为这是一个公式，所以用 f(n) 来表示。公式中的 O，表示代码的执行时间 T(n) 与 f(n) 表达式成正比。

所以，第一个例子中的 T(n) = O(2n+2)，第二个例子中的 T(n) = O(2n2+2n+3)。这就是大 O 时间复杂度表示法。大 O 时间复杂度实际上并不具体表示代码真正的执行时间，而是表示代码执行时间随数据规模增长的变化趋势，所以，也叫作渐进时间复杂度（asymptotic time complexity），简称时间复杂度。

当 n 很大时，你可以把它想象成 10000、100000。而公式中的低阶、常量、系数三部分并不左右增长趋势，所以都可以忽略。我们只需要记录一个最大量级就可以了，如果用大 O 表示法表示刚讲的那两段代码的时间复杂度，就可以记为：T(n) = O(n)； T(n) = O(n2)。

时间复杂度分析
前面介绍了大 O 时间复杂度的由来和表示方法。现在我们来看下，如何分析一段代码的时间复杂度？我这儿有三个比较实用的方法可以分享给你。

1. 只关注循环执行次数最多的一段代码

我刚才说了，大 O 这种复杂度表示方法只是表示一种变化趋势。我们通常会忽略掉公式中的常量、低阶、系数，只需要记录一个最大阶的量级就可以了。所以，我们在分析一个算法、一段代码的时间复杂度的时候，也只关注循环执行次数最多的那一段代码就可以了。这段核心代码执行次数的 n 的量级，就是整段要分析代码的时间复杂度。

为了便于你理解，我还拿前面的例子来说明。

 int cal(int n) {
   int sum = 0;
   int i = 1;
   for (; i <= n; ++i) {
     sum = sum + i;
   }
   return sum;
 }
其中第 2、3 行代码都是常量级的执行时间，与 n 的大小无关，所以对于复杂度并没有影响。循环执行次数最多的是第 4、5 行代码，所以这块代码要重点分析。前面我们也讲过，这两行代码被执行了 n 次，所以总的时间复杂度就是 O(n)。

2. 加法法则：总复杂度等于量级最大的那段代码的复杂度

我这里还有一段代码。你可以先试着分析一下，然后再往下看跟我的分析思路是否一样。

int cal(int n) {
   int sum_1 = 0;
   int p = 1;
   for (; p < 100; ++p) {
     sum_1 = sum_1 + p;
   }
 
   int sum_2 = 0;
   int q = 1;
   for (; q < n; ++q) {
     sum_2 = sum_2 + q;
   }
 
   int sum_3 = 0;
   int i = 1;
   int j = 1;
   for (; i <= n; ++i) {
     j = 1; 
     for (; j <= n; ++j) {
       sum_3 = sum_3 +  i * j;
     }
   }
 
   return sum_1 + sum_2 + sum_3;
 }
这个代码分为三部分，分别是求 sum_1、sum_2、sum_3。我们可以分别分析每一部分的时间复杂度，然后把它们放到一块儿，再取一个量级最大的作为整段代码的复杂度。

第一段的时间复杂度是多少呢？这段代码循环执行了 100 次，所以是一个常量的执行时间，跟 n 的规模无关。

这里我要再强调一下，即便这段代码循环 10000 次、100000 次，只要是一个已知的数，跟 n 无关，照样也是常量级的执行时间。当 n 无限大的时候，就可以忽略。尽管对代码的执行时间会有很大影响，但是回到时间复杂度的概念来说，它表示的是一个算法执行效率与数据规模增长的变化趋势，所以不管常量的执行时间多大，我们都可以忽略掉。因为它本身对增长趋势并没有影响。

那第二段代码和第三段代码的时间复杂度是多少呢？答案是 O(n) 和 O(n2)，你应该能容易就分析出来，我就不啰嗦了。

综合这三段代码的时间复杂度，我们取其中最大的量级。所以，整段代码的时间复杂度就为 O(n2)。也就是说：总的时间复杂度就等于量级最大的那段代码的时间复杂度。那我们将这个规律抽象成公式就是：

如果 T1(n)=O(f(n))，T2(n)=O(g(n))；那么 T(n)=T1(n)+T2(n)=max(O(f(n)), O(g(n))) =O(max(f(n), g(n))).

3. 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积

我刚讲了一个复杂度分析中的加法法则，这儿还有一个乘法法则。类比一下，你应该能“猜到”公式是什么样子的吧？

如果 T1(n)=O(f(n))，T2(n)=O(g(n))；那么 T(n)=T1(n)*T2(n)=O(f(n))*O(g(n))=O(f(n)*g(n)).

也就是说，假设 T1(n) = O(n)，T2(n) = O(n2)，则 T1(n) * T2(n) = O(n3)。落实到具体的代码上，我们可以把乘法法则看成是嵌套循环，我举个例子给你解释一下。

int cal(int n) {
   int ret = 0; 
   int i = 1;
   for (; i < n; ++i) {
     ret = ret + f(i);
   } 
 } 
 
 int f(int n) {
  int sum = 0;
  int i = 1;
  for (; i < n; ++i) {
    sum = sum + i;
  } 
  return sum;
 }
我们单独看 cal() 函数。假设 f() 只是一个普通的操作，那第 4～6 行的时间复杂度就是，T1(n) = O(n)。但 f() 函数本身不是一个简单的操作，它的时间复杂度是 T2(n) = O(n)，所以，整个 cal() 函数的时间复杂度就是，T(n) = T1(n) * T2(n) = O(n*n) = O(n2)。

我刚刚讲了三种复杂度的分析技巧。不过，你并不用刻意去记忆。实际上，复杂度分析这个东西关键在于“熟练”。你只要多看案例，多分析，就能做到“无招胜有招”。

几种常见时间复杂度实例分析
虽然代码千差万别，但是常见的复杂度量级并不多。我稍微总结了一下，这些复杂度量级几乎涵盖了你今后可以接触的所有代码的复杂度量级。



对于刚罗列的复杂度量级，我们可以粗略地分为两类，多项式量级和非多项式量级。其中，非多项式量级只有两个：O(2n) 和 O(n!)。

我们把时间复杂度为非多项式量级的算法问题叫作 NP（Non-Deterministic Polynomial，非确定多项式）问题。

当数据规模 n 越来越大时，非多项式量级算法的执行时间会急剧增加，求解问题的执行时间会无限增长。所以，非多项式时间复杂度的算法其实是非常低效的算法。因此，关于 NP 时间复杂度我就不展开讲了。我们主要来看几种常见的多项式时间复杂度。

1. O(1)

首先你必须明确一个概念，O(1) 只是常量级时间复杂度的一种表示方法，并不是指只执行了一行代码。比如这段代码，即便有 3 行，它的时间复杂度也是 O(1），而不是 O(3)。

 int i = 8;
 int j = 6;
 int sum = i + j;
我稍微总结一下，只要代码的执行时间不随 n 的增大而增长，这样代码的时间复杂度我们都记作 O(1)。或者说，一般情况下，只要算法中不存在循环语句、递归语句，即使有成千上万行的代码，其时间复杂度也是Ο(1)。

2. O(logn)、O(nlogn)

对数阶时间复杂度非常常见，同时也是最难分析的一种时间复杂度。我通过一个例子来说明一下。

 i=1;
 while (i <= n)  {
   i = i * 2;
 }
根据我们前面讲的复杂度分析方法，第三行代码是循环执行次数最多的。所以，我们只要能计算出这行代码被执行了多少次，就能知道整段代码的时间复杂度。

从代码中可以看出，变量 i 的值从 1 开始取，每循环一次就乘以 2。当大于 n 时，循环结束。还记得我们高中学过的等比数列吗？实际上，变量 i 的取值就是一个等比数列。如果我把它一个一个列出来，就应该是这个样子的：



所以，我们只要知道 x 值是多少，就知道这行代码执行的次数了。通过 2x=n 求解 x 这个问题我们想高中应该就学过了，我就不多说了。x=log2n，所以，这段代码的时间复杂度就是 O(log2n)。

现在，我把代码稍微改下，你再看看，这段代码的时间复杂度是多少？

 i=1;
 while (i <= n)  {
   i = i * 3;
 }
根据我刚刚讲的思路，很简单就能看出来，这段代码的时间复杂度为 O(log3n)。

实际上，不管是以 2 为底、以 3 为底，还是以 10 为底，我们可以把所有对数阶的时间复杂度都记为 O(logn)。为什么呢？

我们知道，对数之间是可以互相转换的，log3n 就等于 log32 * log2n，所以 O(log3n) = O(C * log2n)，其中 C=log32 是一个常量。基于我们前面的一个理论：在采用大 O 标记复杂度的时候，可以忽略系数，即 O(Cf(n)) = O(f(n))。所以，O(log2n) 就等于 O(log3n)。因此，在对数阶时间复杂度的表示方法里，我们忽略对数的“底”，统一表示为 O(logn)。

如果你理解了我前面讲的 O(logn)，那 O(nlogn) 就很容易理解了。还记得我们刚讲的乘法法则吗？如果一段代码的时间复杂度是 O(logn)，我们循环执行 n 遍，时间复杂度就是 O(nlogn) 了。而且，O(nlogn) 也是一种非常常见的算法时间复杂度。比如，归并排序、快速排序的时间复杂度都是 O(nlogn)。

3. O(m+n)、O(m*n)

我们再来讲一种跟前面都不一样的时间复杂度，代码的复杂度由两个数据的规模来决定。老规矩，先看代码！

int cal(int m, int n) {
  int sum_1 = 0;
  int i = 1;
  for (; i < m; ++i) {
    sum_1 = sum_1 + i;
  }
 
  int sum_2 = 0;
  int j = 1;
  for (; j < n; ++j) {
    sum_2 = sum_2 + j;
  }
 
  return sum_1 + sum_2;
}
从代码中可以看出，m 和 n 是表示两个数据规模。我们无法事先评估 m 和 n 谁的量级大，所以我们在表示复杂度的时候，就不能简单地利用加法法则，省略掉其中一个。所以，上面代码的时间复杂度就是 O(m+n)。

针对这种情况，原来的加法法则就不正确了，我们需要将加法规则改为：T1(m) + T2(n) = O(f(m) + g(n))。但是乘法法则继续有效：T1(m)*T2(n) = O(f(m) * f(n))。

空间复杂度分析
前面，咱们花了很长时间讲大 O 表示法和时间复杂度分析，理解了前面讲的内容，空间复杂度分析方法学起来就非常简单了。

前面我讲过，时间复杂度的全称是渐进时间复杂度，表示算法的执行时间与数据规模之间的增长关系。类比一下，空间复杂度全称就是渐进空间复杂度（asymptotic space complexity），表示算法的存储空间与数据规模之间的增长关系。

我还是拿具体的例子来给你说明。（这段代码有点“傻”，一般没人会这么写，我这么写只是为了方便给你解释。）

void print(int n) {
  int i = 0;
  int[] a = new int[n];
  for (i; i <n; ++i) {
    a[i] = i * i;
  }
 
  for (i = n-1; i >= 0; --i) {
    print out a[i]
  }
}
跟时间复杂度分析一样，我们可以看到，第 2 行代码中，我们申请了一个空间存储变量 i，但是它是常量阶的，跟数据规模 n 没有关系，所以我们可以忽略。第 3 行申请了一个大小为 n 的 int 类型数组，除此之外，剩下的代码都没有占用更多的空间，所以整段代码的空间复杂度就是 O(n)。

我们常见的空间复杂度就是 O(1)、O(n)、O(n2 )，像 O(logn)、O(nlogn) 这样的对数阶复杂度平时都用不到。而且，空间复杂度分析比时间复杂度分析要简单很多。所以，对于空间复杂度，掌握刚我说的这些内容已经足够了。

内容小结
基础复杂度分析的知识到此就讲完了，我们来总结一下。

复杂度也叫渐进复杂度，包括时间复杂度和空间复杂度，用来分析算法执行效率与数据规模之间的增长关系，可以粗略地表示，越高阶复杂度的算法，执行效率越低。常见的复杂度并不多，从低阶到高阶有：O(1)、O(logn)、O(n)、O(nlogn)、O(n2 )。等你学完整个专栏之后，你就会发现几乎所有的数据结构和算法的复杂度都跑不出这几个。



复杂度分析并不难，关键在于多练。 之后讲后面的内容时，我还会带你详细地分析每一种数据结构和算法的时间、空间复杂度。只要跟着我的思路学习、练习，你很快就能和我一样，每次看到代码的时候，简单的一眼就能看出其复杂度，难的稍微分析一下就能得出答案。

课后思考
有人说，我们项目之前都会进行性能测试，再做代码的时间复杂度、空间复杂度分析，是不是多此一举呢？而且，每段代码都分析一下时间复杂度、空间复杂度，是不是很浪费时间呢？你怎么看待这个问题呢？

欢迎留言和我分享，我会第一时间给你反馈。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(932)

xr
我不认为是多此一举，渐进时间，空间复杂度分析为我们提供了一个很好的理论分析的方向，并且它是宿主平台无关的，能够让我们对我们的程序或算法有一个大致的认识，让我们知道，比如在最坏的情况下程序的执行效率如何，同时也为我们交流提供了一个不错的桥梁，我们可以说，算法1的时间复杂度是O(n)，算法2的时间复杂度是O(logN)，这样我们立刻就对不同的算法有了一个“效率”上的感性认识。

当然，渐进式时间，空间复杂度分析只是一个理论模型，只能提供给粗略的估计分析，我们不能直接断定就觉得O(logN)的算法一定优于O(n), 针对不同的宿主环境，不同的数据集，不同的数据量的大小，在实际应用上面可能真正的性能会不同，个人觉得，针对不同的实际情况，进而进行一定的性能基准测试是很有必要的，比如在统一一批手机上(同样的硬件，系统等等)进行横向基准测试，进而选择适合特定应用场景下的最有算法。

综上所述，渐进式时间，空间复杂度分析与性能基准测试并不冲突，而是相辅相成的，但是一个低阶的时间复杂度程序有极大的可能性会优于一个高阶的时间复杂度程序，所以在实际编程中，时刻关心理论时间，空间度模型是有助于产出效率高的程序的，同时，因为渐进式时间，空间复杂度分析只是提供一个粗略的分析模型，因此也不会浪费太多时间，重点在于在编程时，要具有这种复杂度分析的思维。
作者回复: 写得很好。理解的到位

2018-09-26

6

904

姜威
总结
一、什么是复杂度分析？
1.数据结构和算法解决是“如何让计算机更快时间、更省空间的解决问题”。
2.因此需从执行时间和占用空间两个维度来评估数据结构和算法的性能。
3.分别用时间复杂度和空间复杂度两个概念来描述性能问题，二者统称为复杂度。
4.复杂度描述的是算法执行时间（或占用空间）与数据规模的增长关系。
二、为什么要进行复杂度分析？
1.和性能测试相比，复杂度分析有不依赖执行环境、成本低、效率高、易操作、指导性强的特点。
2.掌握复杂度分析，将能编写出性能更优的代码，有利于降低系统开发和维护成本。
三、如何进行复杂度分析？
1.大O表示法
1）来源
算法的执行时间与每行代码的执行次数成正比，用T(n) = O(f(n))表示，其中T(n)表示算法执行总时间，f(n)表示每行代码执行总次数，而n往往表示数据的规模。
2）特点
以时间复杂度为例，由于时间复杂度描述的是算法执行时间与数据规模的增长变化趋势，所以常量阶、低阶以及系数实际上对这种增长趋势不产决定性影响，所以在做时间复杂度分析时忽略这些项。
2.复杂度分析法则
1）单段代码看高频：比如循环。
2）多段代码取最大：比如一段代码中有单循环和多重循环，那么取多重循环的复杂度。
3）嵌套代码求乘积：比如递归、多重循环等
4）多个规模求加法：比如方法有两个参数控制两个循环的次数，那么这时就取二者复杂度相加。
四、常用的复杂度级别？
多项式阶：随着数据规模的增长，算法的执行时间和空间占用，按照多项式的比例增长。包括，
O(1)（常数阶）、O(logn)（对数阶）、O(n)（线性阶）、O(nlogn)（线性对数阶）、O(n^2)（平方阶）、O(n^3)（立方阶）
非多项式阶：随着数据规模的增长，算法的执行时间和空间占用暴增，这类算法性能极差。包括，
O(2^n)（指数阶）、O(n!)（阶乘阶）
五、如何掌握好复杂度分析方法？
复杂度分析关键在于多练，所谓孰能生巧。
作者回复: 总结的很棒

2018-09-26

3

604

芳芳
糟糕，是看不懂的感觉
2018-09-26

1

208

吕宁
老师好，我们上算法课，老师讲到存储一个二进制数，输入规模（空间复杂度）是O(logn) bit。请问如何理解？
作者回复: 比如8用二进制表示就是3个bit。16用二进制表示就是4个bit。以此类推 n用二进制表示就是logn个bit

2018-09-26

6

115

Orcsir
老师，代码片段把行号也写上吧。
作者回复: 嗯嗯 我联系运营加上

2018-09-26


69

realEago
看不懂别慌，也别忙着总结，先读五遍文章先，无他，唯手熟尔~
作者回复: 说的太好了 我这里也没葵花宝典 学还是得靠自己

2018-09-26

2

47

起名好难
文章里也说了，性能测试这种是受环境所影响的。作为程序员，我们能做的就是尽可能的降低复杂度，才能让代码在不同的环境下以最快的效率执行。至于是不是浪费时间，我觉得其实是个伪命题。首先按刚刚分析过程来看，通过熟悉练习，简单的代码是可以直接看出来复杂度的也就是不费时间；而比较复杂的代码就容易“一不小心”太“复杂”了，这个时候，为了代码质量考虑分析复杂度的时间也并不浪费。再有甚者，我们学习这个分析法，我觉得更多的是要明白这个理念，在写代码的时候就能关注一下这方面的问题，毕竟复杂的代码在写的过程往往是先分析整体逻辑结构的，并且写的过程也需要不断思考，了解这个理念后才能在写的过程中也思考关注这个点。不然，复杂的一段代码一旦写成，日后因为性能问题重构，更费时间。

以上是对课后题的思考，欢迎批评指正☺。
另: 感觉加法法则那个图，maxf(n)+g(n) 换成max(f(n)+g(n))会不会更好些？
作者回复: 理解的非常透彻 非常有逻辑性 很赞。ps 图画错了 我联系运营改下

2018-09-26


46

halweg
第二个例子中，第6.7行为什么是2n平方遍而不是n平方遍呢？
作者回复: 因为两层循环 一层是n 两层是n*n。不信你自己令n=5 自己算算

2018-09-26

1

39

有一天
一直有一个很纠结的问题，烦请解答一下：O具体是哪一个英文字母的缩写？
作者回复: 不是英文缩写 就是一个数学符号而已

2018-09-26

2

35

最爱小黑黑
睡前刷一遍 明早起来再细看一遍 加油各位！
2018-09-26


31

scarlett
回答 thinkings 的问题
i=1;
while (i <= n) {
i = i * 2
}
假设n= 20，i每次的取值是2 4 8 16 执行4次，时间复杂度是O(log2n)
i=1;
while (i <= n) {
i = i + 2
}
假设 n=20 i每次取值：3，5，7，9，11，13，15，17，19 ，执行9次，时间复杂度是O(n/2),根据老师讲的 公式中的低阶、常量、系数三部分并不左右增长趋势，所以都可以忽略，所以是O（n）
作者回复: 👍 分析的通俗易懂 棒棒哒

2018-09-26


27

冯剑
在分析多项式复杂度的时候，有根据输入规模确定复杂度O(m+n),我的理解是 假设n是相对比较大的值，那么这个复杂度O(m+n)<=O(2n)，2是常量，这样的话复杂度不就是O(n),请问下，O(n)和O(m+n)的区别在什么地方？有什么应用场景能体现出二者不同
2018-09-26

1

25

dickwxyz@126.com
没有看懂，所以，我们只要知道 x 值是多少，就知道这行代码执行的次数了。通过 2x=n 求解 x 这个问题我们想高中应该就学过了，我就不多说了。 这里的x不就是代码里的n吗，时间复杂度不是O(n)吗？
作者回复: i 第一次等于1
第2次等于2
第3次等于2*2
第4次等于2*2*2
.....
第x次等于2的x-1次方
……
那第几次之后等于n呢

也就是2的x-1次方等于n求解x

x粗略点讲就近似于logn

也就是代码执行了logn遍就退出循环了

所以根据大o标记法 为logn




2018-09-26

3

22

Monday
本节通读两遍，通俗易懂，对复杂度的概念有了新的认识。
复杂度就是用来分析算法执行效率与数据规模之间增长关系。
思考题，性能测试与复杂度分析不冲突，原因如下：
1、性能测试是依附于具体的环境，如SIT、UAT机器配置及实例数量不一致结果也有差别。
2、复杂度分析是独立于环境的，可以大致估算出程序所执行的效率。
3、将复杂度熟记于心，能够写出更高效率、更好性能的代码。若某接口通过性能测试，达不到预期，还可以用复杂度分析接口代码，找出最影响性能的代码，进行优化。

每段代码都分析一下时间复杂度、空间复杂度，是不是很浪费时间呢？
这个问题分两种情况讨论
1、开发过程中，码代码的过程中就能得出其复杂度，这并不会太多的浪费时间，同时只有分析了每段代码的复杂度，才能估算出它们的执行效率。
2、优化代码时，只有在分析每段代码的复杂度后，才能定位问题代码，才能做相应优化

另外提出两个问题：
1、评论太多，也无法进行关键字搜索，一般没有时间爬楼全部看完，导致不同学友提出一样的问题
2、评论太多，可能有些评论不正确，需要官方确认正确与否，以免误导学友。


作者回复: 理解的很透彻！

2018-09-26

1

21

陈华应
有必要，基准测试是事后，也是理论验证，有时候O(n)未必一定比O(1)效率低。
       复杂度分析是理论，整体趋势上反应了一个算法的时间或者空间利用率与数据规模的渐进关系，并且像程序员之间使用设计模式来讨论代码设计一样，说出名字就大致知道代码是如何组织的，大O也是一样。
        随着自己使用大O分析代码复杂度的熟练程度增加，判断一段代码的复杂度可能分分钟的事情，甚至更快。
作者回复: 理解的很透彻！

2018-09-26


18

Dwyane
03
大家好，这是我的总结：

公式中的低阶、常量、系数三部分并不左右增长趋势，所以都可以忽略
1. 只关注循环执行次数最多的一段代码
2.加法法则：总复杂度等于量级最大的那段代码的复杂度
3. 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积


只要代码的执行时间不随 n 的增大而增长，这样代码的时间复杂度我们集作O(1)
不同数据规模，无法评估 m 和 n 的量级大，所以不能利用加法法则，去掉某一个，而是 O(m+n)

空间复杂度：表示算法的存储空间与数据规模之间的增加关系

额外说一下：log3n 就等于 log32 * log2n 其实是利用换底公示推导，有疑问的搜一下。
作者回复: 是换底公式 👍

2018-09-26


15

短迪大魔王
很有必要，现在是大数据时代，如果是矩阵计算，那就是on，如果是传统双for遍历那就是on²，做lr不依托矩阵都要天荒地老，那神经网络尤其是rnn就不用做了，即使是84万文本数据，长度为20个词，用单机gpu加速要跑七天。双for是几天那？经典例子是马踏棋盘，没优化代码跑几天，优化了又看不懂，问问老师如何对代码做优化，因为优化了就读不懂了有没有？
空间复杂度也有必要，还是nlp的例子，如果是embending的话，内存开销和磁盘开销都小的多，虽然现在分布式允许无限大，但是生产环境要把数据传到hdfs，再传到训练集群上，这都有网络传输开销啊，其二是可能没有这个权限，不安全。其三，生成npy文件不能shuffle，很不便利，也不允许分割，所以事先要想好空间要怎么来。当然时间更重要，敏捷迭代。
2018-09-26


13


考研数据结构会考到🤓🤓
2018-09-26


12

huangjh
有必要，性能测试更多的是一种实验结果。而复杂度分析，可以帮助我们分析内因。
作者回复: 简洁到位！

2018-09-27


11

ChaoYrAx
老师 空间复杂度 和时间复杂度的 具体区别是什么，我怎么看上去像一样的
作者回复: 一个表示内存的消耗 一个表示执行的快慢

2018-09-26


11
收起评论

99+99+





# 04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度




数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
王争 2018-09-28



12:44
讲述：修阳 大小：5.84M
上一节，我们讲了复杂度的大 O 表示法和几个分析技巧，还举了一些常见复杂度分析的例子，比如 O(1)、O(logn)、O(n)、O(nlogn) 复杂度分析。掌握了这些内容，对于复杂度分析这个知识点，你已经可以到及格线了。但是，我想你肯定不会满足于此。

今天我会继续给你讲四个复杂度分析方面的知识点，最好情况时间复杂度（best case time complexity）、最坏情况时间复杂度（worst case time complexity）、平均情况时间复杂度（average case time complexity）、均摊时间复杂度（amortized time complexity）。如果这几个概念你都能掌握，那对你来说，复杂度分析这部分内容就没什么大问题了。

最好、最坏情况时间复杂度
上一节我举的分析复杂度的例子都很简单，今天我们来看一个稍微复杂的。你可以用我上节教你的分析技巧，自己先试着分析一下这段代码的时间复杂度。

// n 表示数组 array 的长度
int find(int[] array, int n, int x) {
  int i = 0;
  int pos = -1;
  for (; i < n; ++i) {
    if (array[i] == x) pos = i;
  }
  return pos;
}
你应该可以看出来，这段代码要实现的功能是，在一个无序的数组（array）中，查找变量 x 出现的位置。如果没有找到，就返回 -1。按照上节课讲的分析方法，这段代码的复杂度是 O(n)，其中，n 代表数组的长度。

我们在数组中查找一个数据，并不需要每次都把整个数组都遍历一遍，因为有可能中途找到就可以提前结束循环了。但是，这段代码写得不够高效。我们可以这样优化一下这段查找代码。

// n 表示数组 array 的长度
int find(int[] array, int n, int x) {
  int i = 0;
  int pos = -1;
  for (; i < n; ++i) {
    if (array[i] == x) {
       pos = i;
       break;
    }
  }
  return pos;
}
这个时候，问题就来了。我们优化完之后，这段代码的时间复杂度还是 O(n) 吗？很显然，咱们上一节讲的分析方法，解决不了这个问题。

因为，要查找的变量 x 可能出现在数组的任意位置。如果数组中第一个元素正好是要查找的变量 x，那就不需要继续遍历剩下的 n-1 个数据了，那时间复杂度就是 O(1)。但如果数组中不存在变量 x，那我们就需要把整个数组都遍历一遍，时间复杂度就成了 O(n)。所以，不同的情况下，这段代码的时间复杂度是不一样的。

为了表示代码在不同情况下的不同时间复杂度，我们需要引入三个概念：最好情况时间复杂度、最坏情况时间复杂度和平均情况时间复杂度。

顾名思义，最好情况时间复杂度就是，在最理想的情况下，执行这段代码的时间复杂度。就像我们刚刚讲到的，在最理想的情况下，要查找的变量 x 正好是数组的第一个元素，这个时候对应的时间复杂度就是最好情况时间复杂度。

同理，最坏情况时间复杂度就是，在最糟糕的情况下，执行这段代码的时间复杂度。就像刚举的那个例子，如果数组中没有要查找的变量 x，我们需要把整个数组都遍历一遍才行，所以这种最糟糕情况下对应的时间复杂度就是最坏情况时间复杂度。

平均情况时间复杂度
我们都知道，最好情况时间复杂度和最坏情况时间复杂度对应的都是极端情况下的代码复杂度，发生的概率其实并不大。为了更好地表示平均情况下的复杂度，我们需要引入另一个概念：平均情况时间复杂度，后面我简称为平均时间复杂度。

平均时间复杂度又该怎么分析呢？我还是借助刚才查找变量 x 的例子来给你解释。

要查找的变量 x 在数组中的位置，有 n+1 种情况：在数组的 0～n-1 位置中和不在数组中。我们把每种情况下，查找需要遍历的元素个数累加起来，然后再除以 n+1，就可以得到需要遍历的元素个数的平均值，即：



我们知道，时间复杂度的大 O 标记法中，可以省略掉系数、低阶、常量，所以，咱们把刚刚这个公式简化之后，得到的平均时间复杂度就是 O(n)。

这个结论虽然是正确的，但是计算过程稍微有点儿问题。究竟是什么问题呢？我们刚讲的这 n+1 种情况，出现的概率并不是一样的。我带你具体分析一下。（这里要稍微用到一点儿概率论的知识，不过非常简单，你不用担心。）

我们知道，要查找的变量 x，要么在数组里，要么就不在数组里。这两种情况对应的概率统计起来很麻烦，为了方便你理解，我们假设在数组中与不在数组中的概率都为 1/2。另外，要查找的数据出现在 0～n-1 这 n 个位置的概率也是一样的，为 1/n。所以，根据概率乘法法则，要查找的数据出现在 0～n-1 中任意位置的概率就是 1/(2n)。

因此，前面的推导过程中存在的最大问题就是，没有将各种情况发生的概率考虑进去。如果我们把每种情况发生的概率也考虑进去，那平均时间复杂度的计算过程就变成了这样：



这个值就是概率论中的加权平均值，也叫作期望值，所以平均时间复杂度的全称应该叫加权平均时间复杂度或者期望时间复杂度。

引入概率之后，前面那段代码的加权平均值为 (3n+1)/4。用大 O 表示法来表示，去掉系数和常量，这段代码的加权平均时间复杂度仍然是 O(n)。

你可能会说，平均时间复杂度分析好复杂啊，还要涉及概率论的知识。实际上，在大多数情况下，我们并不需要区分最好、最坏、平均情况时间复杂度三种情况。像我们上一节课举的那些例子那样，很多时候，我们使用一个复杂度就可以满足需求了。只有同一块代码在不同的情况下，时间复杂度有量级的差距，我们才会使用这三种复杂度表示法来区分。

均摊时间复杂度
到此为止，你应该已经掌握了算法复杂度分析的大部分内容了。下面我要给你讲一个更加高级的概念，均摊时间复杂度，以及它对应的分析方法，摊还分析（或者叫平摊分析）。

均摊时间复杂度，听起来跟平均时间复杂度有点儿像。对于初学者来说，这两个概念确实非常容易弄混。我前面说了，大部分情况下，我们并不需要区分最好、最坏、平均三种复杂度。平均复杂度只在某些特殊情况下才会用到，而均摊时间复杂度应用的场景比它更加特殊、更加有限。

老规矩，我还是借助一个具体的例子来帮助你理解。（当然，这个例子只是我为了方便讲解想出来的，实际上没人会这么写。）

 // array 表示一个长度为 n 的数组
 // 代码中的 array.length 就等于 n
 int[] array = new int[n];
 int count = 0;
 
 void insert(int val) {
    if (count == array.length) {
       int sum = 0;
       for (int i = 0; i < array.length; ++i) {
          sum = sum + array[i];
       }
       array[0] = sum;
       count = 1;
    }
 
    array[count] = val;
    ++count;
 }
我先来解释一下这段代码。这段代码实现了一个往数组中插入数据的功能。当数组满了之后，也就是代码中的 count == array.length 时，我们用 for 循环遍历数组求和，并清空数组，将求和之后的 sum 值放到数组的第一个位置，然后再将新的数据插入。但如果数组一开始就有空闲空间，则直接将数据插入数组。

那这段代码的时间复杂度是多少呢？你可以先用我们刚讲到的三种时间复杂度的分析方法来分析一下。

最理想的情况下，数组中有空闲空间，我们只需要将数据插入到数组下标为 count 的位置就可以了，所以最好情况时间复杂度为 O(1)。最坏的情况下，数组中没有空闲空间了，我们需要先做一次数组的遍历求和，然后再将数据插入，所以最坏情况时间复杂度为 O(n)。

那平均时间复杂度是多少呢？答案是 O(1)。我们还是可以通过前面讲的概率论的方法来分析。

假设数组的长度是 n，根据数据插入的位置的不同，我们可以分为 n 种情况，每种情况的时间复杂度是 O(1)。除此之外，还有一种“额外”的情况，就是在数组没有空闲空间时插入一个数据，这个时候的时间复杂度是 O(n)。而且，这 n+1 种情况发生的概率一样，都是 1/(n+1)。所以，根据加权平均的计算方法，我们求得的平均时间复杂度就是：



至此为止，前面的最好、最坏、平均时间复杂度的计算，理解起来应该都没有问题。但是这个例子里的平均复杂度分析其实并不需要这么复杂，不需要引入概率论的知识。这是为什么呢？我们先来对比一下这个 insert() 的例子和前面那个 find() 的例子，你就会发现这两者有很大差别。

首先，find() 函数在极端情况下，复杂度才为 O(1)。但 insert() 在大部分情况下，时间复杂度都为 O(1)。只有个别情况下，复杂度才比较高，为 O(n)。这是 insert()第一个区别于 find() 的地方。

我们再来看第二个不同的地方。对于 insert() 函数来说，O(1) 时间复杂度的插入和 O(n) 时间复杂度的插入，出现的频率是非常有规律的，而且有一定的前后时序关系，一般都是一个 O(n) 插入之后，紧跟着 n-1 个 O(1) 的插入操作，循环往复。

所以，针对这样一种特殊场景的复杂度分析，我们并不需要像之前讲平均复杂度分析方法那样，找出所有的输入情况及相应的发生概率，然后再计算加权平均值。

针对这种特殊的场景，我们引入了一种更加简单的分析方法：摊还分析法，通过摊还分析得到的时间复杂度我们起了一个名字，叫均摊时间复杂度。

那究竟如何使用摊还分析法来分析算法的均摊时间复杂度呢？

我们还是继续看在数组中插入数据的这个例子。每一次 O(n) 的插入操作，都会跟着 n-1 次 O(1) 的插入操作，所以把耗时多的那次操作均摊到接下来的 n-1 次耗时少的操作上，均摊下来，这一组连续的操作的均摊时间复杂度就是 O(1)。这就是均摊分析的大致思路。你都理解了吗？

均摊时间复杂度和摊还分析应用场景比较特殊，所以我们并不会经常用到。为了方便你理解、记忆，我这里简单总结一下它们的应用场景。如果你遇到了，知道是怎么回事儿就行了。

对一个数据结构进行一组连续操作中，大部分情况下时间复杂度都很低，只有个别情况下时间复杂度比较高，而且这些操作之间存在前后连贯的时序关系，这个时候，我们就可以将这一组操作放在一块儿分析，看是否能将较高时间复杂度那次操作的耗时，平摊到其他那些时间复杂度比较低的操作上。而且，在能够应用均摊时间复杂度分析的场合，一般均摊时间复杂度就等于最好情况时间复杂度。

尽管很多数据结构和算法书籍都花了很大力气来区分平均时间复杂度和均摊时间复杂度，但其实我个人认为，均摊时间复杂度就是一种特殊的平均时间复杂度，我们没必要花太多精力去区分它们。你最应该掌握的是它的分析方法，摊还分析。至于分析出来的结果是叫平均还是叫均摊，这只是个说法，并不重要。

内容小结
今天我们学习了几个复杂度分析相关的概念，分别有：最好情况时间复杂度、最坏情况时间复杂度、平均情况时间复杂度、均摊时间复杂度。之所以引入这几个复杂度概念，是因为，同一段代码，在不同输入的情况下，复杂度量级有可能是不一样的。

在引入这几个概念之后，我们可以更加全面地表示一段代码的执行效率。而且，这几个概念理解起来都不难。最好、最坏情况下的时间复杂度分析起来比较简单，但平均、均摊两个复杂度分析相对比较复杂。如果你觉得理解得还不是很深入，不用担心，在后续具体的数据结构和算法学习中，我们可以继续慢慢实践！

课后思考
我们今天学的几个复杂度分析方法，你都掌握了吗？你可以用今天学习的知识，来分析一下下面这个 add() 函数的时间复杂度。

// 全局变量，大小为 10 的数组 array，长度 len，下标 i。
int array[] = new int[10]; 
int len = 10;
int i = 0;
 
// 往数组中添加一个元素
void add(int element) {
   if (i >= len) { // 数组空间不够了
     // 重新申请一个 2 倍大小的数组空间
     int new_array[] = new int[len*2];
     // 把原来 array 数组中的数据依次 copy 到 new_array
     for (int j = 0; j < len; ++j) {
       new_array[j] = array[j];
     }
     // new_array 复制给 array，array 现在大小就是 2 倍 len 了
     array = new_array;
     len = 2 * len;
   }
   // 将 element 放到下标为 i 的位置，下标 i 加一
   array[i] = element;
   ++i;
}
欢迎留言和我分享，我会第一时间给你反馈。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(567)

Alvin
老师讲的很好，练习题最好是O(1)，最差是O(n), 均摊是O(1)。

看到好多人纠结于清空数组的问题: 对于可反复读写的存储空间，使用者认为它是空的它就是空的。如果你定义清空是全部重写为0或者某个值，那也可以！但是老师举的例子完全没必要啊！写某个值和写任意值在这里有区别吗，使用值只关心要存的新值！所以老师的例子，清空把下标指到第一个位置就可以了！
作者回复: 嗯嗯 是的 多谢你。同学们帮把这一条顶上去吧 可以让其他同学都看看

2018-09-28

2

1140

阿杜S考特
当i < len时, 即 i = 0,1,2,...,n-1的时候，for循环不走，所以这n次的时间复杂度都是O(1);
当i >= len时, 即 i = n的时候，for循环进行数组的copy，所以只有这1次的时间复杂度是O(n);
由此可知:
该算法的最好情况时间复杂度(best case time complexity)为O(1);
最坏情况时间复杂度(worst case time complexity)为O(n);
平均情况时间复杂度(average case time complexity),
第一种计算方式: (1+1+...+1+n)/(n+1) = 2n/(n+1) 【注: 式子中1+1+...+1中有n个1】,所以平均复杂度为O(1);
第二种计算方式(加权平均法，又称期望): 1*(1/n+1)+1*(1/n+1)+...+1*(1/n+1)+n*(1/(n+1))=1，所以加权平均时间复杂度为O(1);
第三种计算方式(均摊时间复杂度): 前n个操作复杂度都是O(1)，第n+1次操作的复杂度是O(n)，所以把最后一次的复杂度分摊到前n次上，那么均摊下来每次操作的复杂度为O(1)
2018-09-28

2

316

姜威
总结

一、复杂度分析的4个概念
1.最坏情况时间复杂度：代码在最理想情况下执行的时间复杂度。
2.最好情况时间复杂度：代码在最坏情况下执行的时间复杂度。
3.平均时间复杂度：用代码在所有情况下执行的次数的加权平均值表示。
4.均摊时间复杂度：在代码执行的所有复杂度情况中绝大部分是低级别的复杂度，个别情况是高级别复杂度且发生具有时序关系时，可以将个别高级别复杂度均摊到低级别复杂度上。基本上均摊结果就等于低级别复杂度。

二、为什么要引入这4个概念？
1.同一段代码在不同情况下时间复杂度会出现量级差异，为了更全面，更准确的描述代码的时间复杂度，所以引入这4个概念。
2.代码复杂度在不同情况下出现量级差别时才需要区别这四种复杂度。大多数情况下，是不需要区别分析它们的。

三、如何分析平均、均摊时间复杂度？
1.平均时间复杂度
代码在不同情况下复杂度出现量级差别，则用代码所有可能情况下执行次数的加权平均值表示。
2.均摊时间复杂度
两个条件满足时使用：1）代码在绝大多数情况下是低级别复杂度，只有极少数情况是高级别复杂度；2）低级别和高级别复杂度出现具有时序规律。均摊结果一般都等于低级别复杂度。
2018-09-28

2

196

小白一只
最好是O(1),最坏是O(n),平均平摊是O(1).


不要纠结add和insert在哪儿被调用了。。。代码都写出来反而不好看。

个人体会: 平均和平摊基本就是一个概念，平摊是特殊的平均。在分析时间复杂度是O(1)还是O(n)的时候最简单就是凭感觉，，，，，，，，出现O(1)的次数远大于出现O(n)出现的次数，那么平均平摊时间复杂度就是O(1)。。。。
作者回复: 留言看似很平淡 但透漏着高手的气息。说的没错。高手就是凭感觉👍

2018-09-29


188

Stalary
递归的时间复杂度怎么算呀
作者回复: 这个话题有点大 要具体看了 重点应该分析递归调用的次数吧。然后再看每次调用的耗时。综合考虑

2018-09-28


65

jon
看了大家的留言总结的很好，自己把练习题的答案整理了一下与大家分享：
1. 最好情况时间复杂度为 O(1)
2.最坏情况分析：
最坏情况代码执行的次数跟每次数组的长度有关
第1次调用insert的执行的次数为 n ,
第2次调用insert的执行的次数为 2n ,
第3次调用insert的执行的次数为 2^2 * n
第k次调用insert的执行的次数为 2^(k-1) * n
最坏时间复杂度为 O(n)。
3. 平均情况分析
当每次遇到最坏情况时数组会进行2倍扩容，原数组被导入新数组，虽然数组的长度变大了，但是插入操作落在的区间的长度是一样的，分别是0~len-1, len~(2len-1),....；
插入的情况仍是len+1种：0~len-1和插满之后的O(len)；所以每次插入的概率是：p= 1/len+1，
最后求出加权平均时间复杂度为 1*p + 2*p+ ▪▪▪ + len*p + len * p = O(1) ;
4. 均摊时间复杂度 O(1)
而均摊复杂度由于每次O(len)的出现都跟着len次O(1)，是前后连贯的，因而将O(len)平摊到前len次上，得出平摊复杂度是O(1)
作者回复: 👍

2018-10-01

2

60

蝴蝶
insert方法中有清空数组吗？抱歉，能指出哪行吗？真不明白😂
作者回复: count=1；count被重置为1。之后再插入的数据就会覆盖掉原来的数据。就相当于将原数组清空了。并不需要显示的去清空

2018-09-28


56

Kealina.
调皮一下，还请老师来衡量下这例子恰当不。

举个栗子🌰：
今天你准备去老王家拜访下，可惜老王的爱人叫他去打个酱油，她告诉你说她限时n分钟🕒给他去买。那么你想着以他家到楼下小卖部来回最多一分钟，那么 “最好的情况”就是你只用等他一分钟。那么也有可能遇到突发情况，比如说电梯人多吖，路上摔了一胶，天知道他去干了什么，用了n分钟，没办法👐，主上有令，n分钟限时，那这就是“最坏的情况”。难点，平均时间复杂度 就是他有可能是第1.2.3...n，中的某个分钟回来，那平均就是1+2+3+...n/n，把 所有可能出现的情况的时间复杂度 相加除以 情况数 。均摊的话就是把花时间多的分给花时间少的，得到一个中间值，所以说这就会和平均混淆，个人觉得主要还是概念不同。假如n是10分钟，那么9分钟分4分钟到1分钟那，8分3给2...，那均摊下来就是5分钟.编不下去了🤦🏼‍♀️
作者回复: 哈哈，写的太好了。留言区卧虎藏龙啊~

2018-10-04


40

Silence
老师，加权平均值那个公式是怎么来的，每个的概率都是 1/2n，平均的不应该也是 1/2n 吗？为什么后面成了 2*（1/2n）+3*（1/2n）+.....n*（1/2n）+n*（1/2）
2018-09-28

2

37

赤身马可
报告老师，我好像走错了教室。

我是一个文科转行过来的菜鸟，刚刚学完Python，基本搞懂了“遍历”、“循环”、“判断”等概念。

您开篇讲的课，我都基本都能明白，也提起了兴趣和信心，准备好好跟您学习。但这两次课听完，我又晕菜了。

想请问一下，如果听不太懂(也可以去掉“太”)，需要补哪些课？您能告诉我进入您课程的坡道和垫脚石么？有没有稍低一点年级的资料，让我可以补补课呢？

还请抽时间回答，谢谢。
作者回复: 嗯嗯，同学你好.

 你说了刚学完python，可能代码还没写熟练，所以我建议把python书上的所有实例代码都自己敲一遍，默写一遍。学编程，光看不写肯定是不行的。

等你python代码写熟练了，你可以再开始学我这个专栏。 因为你没有数据结构和算法的基础，所以我建议，配合着《大话数据结构》《算法图解》两本书一块来学习。

学习这个专栏的过程中，你可以把我讲到的数据结构和算法都用python代码实现一遍，如果实现不了，可以参照我放在Github上的代码，自己看懂之后，默写一遍。这个步骤非常锻炼你的编程能力，不要忽视！

在学习专栏的过程中，不要一觉得看不懂就放弃，师傅领进门，修行靠个人。这里没有葵花宝典一样的捷径。学习还要靠自己。看不懂？那就自己多百度一下，看不懂也可以问问你同学、同事、学长，用一个星期来看一篇文章，狠下心来，别怕麻烦，不会学不会的。

还有很多时候看不懂，你就硬着头皮看，都看完一遍，就会有感觉。之后再等有空了，再来看一遍，慢慢的都懂了。这门课很难，对于初学者来说，应该是计算机里最难的之一了，所以不要期望轻松就学会，这是不现实的。

2018-09-29


34

张三丰
1+2+3....+n+n ／ n+1 = n(n+3)/2(n+1) 老师这个公式怎么推导出来的 能一步步展示下吗
作者回复: 公式是求平均比对多少个数组元素才能找到x。如果x再第一个位置，那需要1次比对，如果再第二个位置，就需要比对2次，一次类推，如果在第n个位置，就需要比对n次。如果不在数组中，也需要比对n次。所有的次数之和除以n+1中情况，就是平均比对元素个数。

2018-09-29

1

28

leo
画的前两节思维导图：
https://share.weiyun.com/5D2VFqS
作者回复: 👍

2018-09-29


21

ppingfann
课后题的最坏时间复杂度不应该是O(1)吗？按照上一节讲的，循环的次数如果是有限次，就算数量极大，那么也应该是O(1)不是吗？
如果答案如大家所说的是O(n)，那么原题的len=10这个初始条件就应该改写为len=n。
作者回复: 因为len并不是个确定量 初始值是10而已

2018-09-28


20

天天向上
高中的数学已经忘光了，又回去补了下， 现在将推导的结果分享给大家
1、1+2+3+....+n+n 首先知道这是一个等差数列，等差数列的定义：每一项与前一个项的差都等于一个常数，这就是等差数列
2、计算等差数列的求和公式： n(1+n)/2 ，这是一个已经推导出来的公式，至于怎么推导出来的，自行去学习吧
好了， 现在开始推导：
1、主要就是推导分子，1+2+3+...+n+n = n(1+n)/2 + n = n(1+n)+2n /2 = n+n²+2n/2 = n² + 3n /2 = n(n+3)/2
2、将 n(n+3)/2 代入式子中，就成了 n(n+3)/2 / n+1 = n(n+3) /2(n+1)

好了，打完收功
2018-12-28

2

14

A_F
最大的疑惑就是，insert()方法和add()方法是如何被调用的？？？
2018-09-28


11

极客人哈哈
第二个例子中，为什么是n+1次遍历？
2018-09-28

1

11

蝴蝶
我算了下，最小是O(1)，最大是O(n)，平均和分摊都是O(1),对吗？😀
作者回复: 是的 分析正确。不过我们一般情况下平均 均摊说一个就好了

2018-09-28


11

刘浩
这道题按照老师所讲的 答案是 O(1)，每次扩容的数量都是原来的2倍，都是经历之前数组长度的次数再次进行扩容，所以完全被均摊开了。

但是老师我有一个问题，就是按照您讲的确实时间复杂度被均摊成了O(1)，在这是一个理论的平均值，但终究不能忽略O(n)的存在，当n到达一定量级的时候，这个风险还是存在的，如果把他等同于O(1)，真的没关系吗？
作者回复: 你理解的很对啊，均摊只是其中一种复杂度度量方法，并不是说我们只关注均摊，不关注最坏。我们评价一段代码或者算法的时候，还是会综合这几种复杂度的。用什么表示复杂度不重要，初衷还是能更好的体现出这个算法或者代码的性能。

2018-09-29


9

molybdenum
答案与add例子相同，
至于大家纠结的清空问题，可以看做是标记清除，在同一地址空间上再写上新的值即可，没有必要硬删除，再开辟空间，或者名义上重置成某个数，直接用新的值覆盖即可
作者回复: 是的 因为有些编程基础比较差的同学 他可能之前学清空就是一个一个的删 或者置为0

2018-09-29


9

木心
老师，我是跨行学习Python。希望每次进步一点～早安(^O^)!
2018-09-28


9
收起评论

99+99+






# 不定期福利第一期 | 数据结构与算法学习书单



数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



不定期福利第一期 | 数据结构与算法学习书单
王争 2018-09-30



08:36
讲述：修阳 大小：3.94M
你好，我是王争。欢迎来到不定期更新的周末福利时间。

专栏已经上线两周了，看到这么多人在留言区写下自己的疑惑或者观点，我特别开心。在留言里，很多同学让我推荐一些学习数据结构与算法的书籍。因此我特意跟编辑商量了，给你一个周末福利。所以这一期呢，我们就来聊一聊数据结构和算法学习过程中有哪些必读书籍。

有的同学还在读大学，代码还没写过几行；有的同学已经工作数十年，这之间的差别还是挺大的。而不同基础的人，适宜看的书是完全不一样的。因此，针对不同层次、不同语言的同学，我分别推荐了不同的书。希望每个同学，都能找到适合自己的学习资料，都能在现有水平上有所提高。

针对入门的趣味书
入门的同学，我建议你不要过度追求上去就看经典书。像《算法导论》《算法》这些书，虽然比较经典、比较权威，但是非常厚。初学就去啃这些书肯定会很费劲。而一旦啃不下来，挫败感就会很强。所以，入门的同学，我建议你找一些比较容易看的书来看，比如《大话数据结构》和《算法图解》。不要太在意书写得深浅，重要的是能不能坚持看完。

《大话数据结构》 这本书最大的特点是，它把理论讲得很有趣，不枯燥。而且每个数据结构和算法，作者都结合生活中的例子进行了讲解， 能让你有非常直观的感受。虽然这本书有 400 多页，但是花两天时间读完，应该是没问题的。如果你之前完全不懂数据结构和算法，可以先从这本书看起。

《算法图解》 跟《大话数据结构》走的是同样的路线，就像这本书副标题写的那样，“像小说一样有趣的算法入门书”，主打“图解”，通俗易懂。它只有不到 200 页，所以内容比较少。作为入门，看看这本书，能让你对数据结构和算法有个大概的认识。

这些入门书共同的问题是，缺少细节，不够系统，也不够严谨。所以，如果你想要系统地学数据结构和算法，看这两本书肯定是不够的。

针对特定编程语言的教科书
讲数据结构和算法，肯定会跟代码实现挂钩。所以，很多人就很关心，某某书籍是用什么语言实现的，是不是自己熟悉的语言。市面大部分数据结构和算法书籍都是用 C、C++、Java 语言实现的，还有些是用伪代码。而使用 Python、Go、PHP、JavaScript、Objective-C 这些编程语言实现的就更少了。

我这里推荐《数据结构和算法分析》。国内外很多大学都拿这本书当作教材。这本书非常系统、全面、严谨，而且又不是特别难，适合对数据结构和算法有些了解，并且掌握了至少一门编程语言的同学。而且，这个作者也很用心。他用了三种语言，写了三个版本，分别是：《数据结构与算法分析 ：C 语言描述》《数据结构与算法分析：C++ 描述》《数据结构与算法分析：Java 语言描述》。

如果你熟悉的是 Python 或者 JavaScript，可以参考《数据结构与算法 JavaScript 描述》《数据结构与算法：Python 语言描述》 。至于其他语言的算法书籍，确实比较少。如果你有推荐，可以在留言区补充一下。

面试必刷的宝典
算法对面试很重要，很多人也很关心。我这里推荐几本有益于面试的书籍，分别是：《剑指 offer》《编程珠玑》《编程之美》。

从《剑指 offer》这本书的名字就可以看出，作者的写作目的非常明确，就是为了面试。这本书几乎包含了所有常见的、经典的面试题。如果能搞懂这本书里的内容，应付一般公司的面试应该不成问题。

《编程珠玑》这本书的豆瓣评分非常高，有 9 分。这本书最大的特色就是讲了很多针对海量数据的处理技巧。这个可能是其他算法书籍很少涉及的。面试的时候，海量数据处理的问题也是经常会问的，特别是校招面试。不管是开拓眼界，还是应付面试，这本书都很值得一看。

《编程之美》这本书有多位作者，其中绝大部分是微软的工程师，所以书的质量很有保证。不过，这里面的算法题目稍微有点难，也不是很系统，这也是我把它归到面试这一部分的原因。如果你有一定基础，也喜欢钻研些算法问题，或者要面试 Google、Facebook 这样的公司，可以拿这本书里的题，先来自测一下。

经典大部头
很多人一提到算法书就会搬出《算法导论》和《算法》。这两本确实非常经典，但是都太厚了，看起来比较费劲，我估计很少有人能坚持全部看下来。如果你想更加深入地学一学数据结构和算法，我还是强烈建议你看看。

我个人觉得，《算法导论》这本书的章节安排不是循序渐进的，里面充斥着各种算法的正确性、复杂度的证明、推导，数学公式比较多，一般人看起来会比较吃力。所以，作为入门书籍，并不是很推荐。

《算法》这本书也是一本经典大部头，不过它比起《算法导论》来要友好很多，更容易看懂，更适合初学者入门。但是这本书的缺点也很明显，就是内容不够全面，比如动态规划这么重要的知识点，这本书就没有讲。对于数据结构的东西，它讲的也不多，基本就是偏重讲算法。

殿堂级经典
说到殿堂级经典书，如果《计算机程序设计艺术》称第二，我想没人敢称第一。这本书包括很多卷。说实话，我也只看过比较简单的几卷，比如《基本算法》《排序和查找》。

这套书的深度、广度、系统性、全面性是其他所有数据结构和算法书籍都无法相比的。但是，如果你对算法和数据结构不是特别感兴趣，没有很好的数学、算法、计算机基础，想要把这套书读完、读懂是比较难的。你可以把它当作你算法学习的终极挑战。

闲暇阅读
算法无处不在。我这里再推荐几本适合闲暇时间阅读的书：《算法帝国》《数学之美》《算法之美》。

这些书共同的特点是，都列举了大量的例子，非常通俗易懂。夸张点说，像《算法帝国》，文科生都能读懂。当你看这些书的时候，你常常会深深感受到算法的力量，被算法的优美之处折服。即便不是从事 IT 工作的，看完这几本书也可以开拓眼界。



书籍差不多就是这些。除此之外，留言区很多人问到算法的实现语言。我这里也解释一下。因为我现在比较常用的编程语言是 Java。所以，在专栏里，特别简单的、不涉及高级语法的，我会用 Java 或者 C、C++ 来实现。稍微复杂的，为了让你能看懂，我会用伪代码。所以你完全不用担心语言的问题。

每节课中有需要代码实现的数据结构和算法，我都另外用 Java 语言实现一遍，然后放到 Github 上，供你参考。Github 的地址我放在这里，你可以收藏一下：https://github.com/wangzheng0822/algo。

至于其他语言的同学，比如 C、C++、Python、Go、PHP、JavaScript、Objective-C 等，我想了一个 crowd sourcing 的方法。

我希望基础较好的同学，参照我的 Java 实现，用你熟悉的编程语言再实现一遍，并且将代码留言给我。如果你写得正确，我会将你的代码上传到 Github 上，分享给更多人。

还有人问，我学完这个专栏，就可以拿下数据结构和算法吗？我想说的是，每个人的基础、学习能力都不一样，掌握程度取决于你的努力程度。除了你之外，没有人能百分之百保证你能掌握什么知识。

有的同学只是把每一节课听下来、看下来，就束之高阁，也不求甚解，那效果肯定会很差。而有些同学除了听、看之外，遇到不懂的会自己去查资料、看参考书籍，还会把我讲的数据结构和算法都认真地实现一遍，这样的学习效果自然就比只听一遍、看一遍要好很多。即便我已经尽我所能我这些知识讲得深入浅出，通俗易懂，但是学习依然还是要靠你自己啊。

这种答疑的方式也会成为我们之后的固定动作，我会把留言里有价值的问题和反馈沉淀下来，希望对你的日常学习起到补充作用。如果你有什么看不懂、听不懂的地方，或者工作中有遇到算法问题、技术难题，欢迎写在留言区。（我发现留言区里卧虎藏龙啊，没事儿可以多扫扫留言区。）

这次的周末福利时间就到这啦，我们下次见！



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(116)

nkulpj
老师推荐的书80以上都看过，总结一下：
1:《算法第四版》Java语言写的，不过动态规划（没记错的话）没有涉及、很厚！这本书挺推荐的、特别是javaer！
2:《剑指offer》个人觉得题目经典都是老题！但是难度好像很一般啊（还是学生 不太清楚面试内容）、然后里面确实讲了一些很细的东西值得学习！还有本书所有题目作者都提供了C代码和大量的测试案例！nice；
3:编程珠玑：国外作者，这本书我看了不多 但是初步觉得好像是对超大量数据处理的算法！
4:编程之美：微软的书、难度较高、题目很深！这本书里面的题 代码不超过2页的估计作者都不会选上！！！！书不厚 、一般般
5:数据结构和算法分析：我们大学教材！我们老师教的书里都有、代码是伪代码！
6:算法导论：这本书我用来垫电脑！很厚 很无聊0.0！！！
作者回复: 👍

2018-09-30


141

呵呵
这个图是编辑妹子辛辛苦苦手绘的，尔等以为一个软件能搞成这样么？
2018-09-30


131

千凡谷梦
老师推荐的书大部分我都了解过，写一写我个人的感受吧。
如果是Java程序员的话，强烈推荐《算法》，书中的代码特别的简洁，水准特别高。书的配套资源也相当不错，B站有教学视频、Github有官方代码、还有专门的测试数据。
至于轻松一些的《大话数据结构》，代码和书的基本源于严蔚敏老师的《数据结构》。代码是C语言，但因为作者没有考虑工程上的抽象，代码的水准并不是特别高，至少，我个人是不太喜欢那种编码方式。
《算法图解》很薄，图的风格我也很喜欢，非常基础，小白入门首选。代码实现是基于Python。
《算法导论》能啃下来，就够了。但是全书伪代码，如果能把公式搞懂、代码自己实现一次，基本上足以秒杀绝大多人了。如果想读懂这本书，必要的级数、概率还是要学一下的。
接下来，垫笔记本电脑的《计算机程序设计艺术》。这套书非常伟大，据说高德纳老爷子刚写了两卷就拿到了图灵奖。时间复杂度理论分析算法也是高德纳老爷子奠定的，大半个算法领域的结论几乎都是高德纳老爷子证明的。如果你真想读这本书，首先我要告诉你，书中代码是古老的MIX汇编，其次，你可能需要更多的数学基础。就如同书中所说，必要的复变函数的基础是必要的。
如果你想提高一下个人的计算机数学功底，为了算法的话，可以读《离散数学及其应用》。当然，如果你想要啃《算法导论》或者近距离膜拜《计算机程序设计艺术》，推荐高德纳老爷子参与编著的《具体数学》。
我自己觉得，掌握《算法导论》一书的90%，就已经是非常、非常优秀的程序员了。殿堂级的书买回来收藏、垫笔记本电脑或者显示屏，实在不行，镇宅辟邪也是极好的，就没必要费力地读了。😂
作者回复: 👍

2018-09-30

1

118

李易峰的峰
老师，那个图片是用什么软件做的呀
2018-09-30


44

观弈道人
能有这个能力，两天时间看完（理解）大话数据结构的人，感觉一般不会参与这个专栏的学习吧~
作者回复: 😂

2018-10-01


32

LAMBO
买了十几个专栏，看下来，还是觉得王争大神的专栏质量最高。
2018-11-04


24

A_foreign 이호연 wuli 혜리
程序员代码面试指南 左程云。王老师觉得怎么样
2018-09-30


19

yongxiang
向大家推荐 清华 邓俊辉 《数据结构（c++语言版）（第3版）》，豆瓣评分9.3，这本书是我目前遇到的唯一一本能有兴趣翻开的数据结构的书，可以坚持粗略地翻一遍，其他的书一翻开，密密麻麻的文字和代码，直接想睡觉，而这本书看起来就很舒服，而且是少有的彩色印刷。
非常重要的是，邓俊辉老师还替这本书录制了配套的视频公开课，非常受欢迎，里面有各种形象生动的动画，可以在 edx 或者 学堂在线 上免费观看学习。邓老师的课可以说颠覆了我对数据结构与算法课的认知（想想普通大学上课，拿一本密密麻麻满是文字和代码的书，上课就是老师读课本，黑板上写，真的是疯了）。
我把视频和书本粗略地过了一遍，如果没有这个专栏，我接下去深入学习数据结构与算法，肯定使用这本书和对应的公开课。
不过，由于我水平有限，目前没有深入学习，讲的只是我目前的印象。老师如果有空，也可以点评一下书和公开课，看看适合什么基础的人使用。
2018-10-11


16

晶晶
谢谢老师的推荐 已购入大话数据结构和算法图解 参加这个课程很机缘巧合 主要目的是为了提升自我给6岁宝贝通过简单有趣的方式灌输一些计算机基础知识 准备把这两本书的内容吃透编成一些小游戏和孩子玩起来
2019-02-12

1

15

BeautifulSoup
数据结构真的很重要，真的很重要，真的很重要。像我大一的时候，没有人督促，我还能认真的将课本伪代码认认真真用c语言实现一遍，而我自从开始安卓开发，后来到现在一直做后台，其中大多都是轮子，就算能有几个分布式的问题，基本的解决方案也够了。至少目前为止，自己感觉，自己的路好像越走越窄了，从前天去北邮研究生导师给我面试，我当时才发现，我原来是走的远了，走的偏了，数据结构都被我丢了，怪不得我水平越来越低了唉。导致我面试结构也很差，以后一定以数据结构和算法为核心。你可以不会前段，可以不会移动端，可以不会后台，但是你一定要会数据结构！！！！！！
作者回复: 👍

2018-10-01


15

落叶🍂建良
很棒的周末福利,但是在刷了留意之后就慌了,难道没有人打算用javascript实现一遍☺
2018-09-30


14

Nirvanaliu
向大家推荐一本可以配套 严蔚敏老师 《数据结构》学习的代码书。高一凡的《数据结构与算法解析》，西电的高老师，用C 把严的伪代码全部实现，并能运行，非常生猛。
作者回复: 严老师写的我也觉得不错

2018-09-30


14

玉皇大亮
老师推荐的书大部分都了解过，比如算法导论啃到二叉树就啃不动了，啃不动的原因主要是课后题就算自己回答了，也不知道是否正确，我觉得学习是需要反馈的，学习成果需要验证，老师可否提供一些资料可以辅助算法导论这本书的学习呢？谢谢，另祝假期愉快
2018-09-30


13

耿老的竹林
感谢周末的福利。书籍推荐的确实不少，有空看看工作中实用的，谢谢。另外有个建议，可以剖析一些开源代码，看看其中那些地方有用到算法，比如hash，二叉树，排序查找算法，这些看似简单的算法究竟实际怎么用的，估计印象更深，这也是最近思考项目中，哪些地方用到了算法的一些收获。
作者回复: 实战部分的5篇基本都是分析开源项目

2018-09-30


11

安静的boy
老师，上篇文章问的问题，你没有回答我，我又看了几遍还是不明白。希望看到给我解答一下。
上篇均摊时间复杂度 insert 那个例子用加权时间复杂度分析。 1 * 1 / ( n + 1 ) + 1 * 1 / ( n + 1 ) ＋ … ＋ 1 * 1 / ( n + 1 ) + n * 1 / ( n + 1 ）= O ( 1 ）这个公式怎么推出来等于 O ( 1 ）的。按照我的理解 n 个 1 / ( n + 1 ）相加再与 n / ( n + 1 ）相加应该是 2n / ( n + 1 ）才对。而这个结果也化不成 O (1) 呀。我真的是百思不得其解。还请老师帮忙解答下，谢谢！
作者回复: 不好意思 留言太多 有时候就淹没了 实在抱歉
即便是你说的2n/（n+1） 那分子和分母是相同量级的。如果我们忽略分母的1 就简化为2n除以n。就等于2。复杂度上讲过常量级的都可以表示为O（1）

2018-09-30


10

LucianBen
老师，我想咨询一下。你写的内容，我这边可以根据我的理解然后写一篇文章发布出去吗？可能会有部分的复制...如果这样，需要得到你的授权吗？
2018-09-30


9

godtrue
阅后留痕
惭愧
争哥推荐的书，有买但没看，这里留个名目，一个个一步步补上来！
1：入门
《图解算法》、《大话数据结构》、《啊哈算法》
2：面试
《编程之美》、《剑指offer》、《编程珠玑》
3：编程语言
《数据结构与算法分析：Java语言描述》
4：闲暇阅读
《算法帝国》、《数学之美》、《算法之美》
5：经典大部头
《算法导论》、《算法》
6：殿堂级
《计算机程序设计艺术》
2018-10-20


7

玄奘大弟子
哎，惭愧，大学的时候学习数据结构，还挂科了，从那以后到现在工作三年，都没有接触过数据结构，面试和工作中因为这个吃过的亏跟别提了，真的难以启齿。国庆回来，好好的系统的学习一下数据结构，每个帖子认真的多看几遍，自己记记笔记，那怕把帖子抄一遍，也要做到看一篇掌握一篇，也会按照推荐的书籍，一本一本的啃下来。评论区的优秀评论优秀总结，真的很不错，看评论有时候真心能感觉到差距.....
2018-10-06


7

赵阿海
谢谢老师的推荐，国庆快乐。
2018-09-30


7

鹰
算法导论有视频滴 没记错的话 麻省理工的公开课
作者回复: 是的 我也看过

2018-10-08


6
收起评论

99+99+




# 05 | 数组：为什么很多编程语言中数组都从0开始编号？


提到数组，我想你肯定不陌生，甚至还会自信地说，它很简单啊。

是的，在每一种编程语言中，基本都会有数组这种数据类型。不过，它不仅仅是一种编程语言中的数据类型，还是一种最基础的数据结构。尽管数组看起来非常基础、简单，但是我估计很多人都并没有理解这个基础数据结构的精髓。

在大部分编程语言中，数组都是从 0 开始编号的，但你是否下意识地想过，为什么数组要从 0 开始编号，而不是从 1 开始呢？ 从 1 开始不是更符合人类的思维习惯吗？

你可以带着这个问题来学习接下来的内容。

> 如何实现随机访问？

什么是数组？我估计你心中已经有了答案。不过，我还是想用专业的话来给你做下解释。数组（Array）是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。

这个定义里有几个关键词，理解了这几个关键词，我想你就能彻底掌握数组的概念了。下面就从我的角度分别给你“点拨”一下。

第一是线性表（Linear List）。顾名思义，线性表就是数据排成像一条线一样的结构。每个线性表上的数据最多只有前和后两个方向。其实除了数组，链表、队列、栈等也是线性表结构。

![](../../pic/2019-10-19-22-55-24.png)

而与它相对立的概念是非线性表，比如二叉树、堆、图等。之所以叫非线性，是因为，在非线性表中，数据之间并不是简单的前后关系。

![](../../pic/2019-10-19-22-57-01.png)

第二个是连续的内存空间和相同类型的数据。正是因为这两个限制，它才有了一个堪称“杀手锏”的特性：“随机访问”。但有利就有弊，这两个限制也让数组的很多操作变得非常低效，比如要想在数组中删除、插入一个数据，为了保证连续性，就需要做大量的数据搬移工作。

说到数据的访问，那你知道数组是如何实现根据下标随机访问数组元素的吗？

我们拿一个长度为 10 的 int 类型的数组 int[] a = new int[10] 来举例。在我画的这个图中，计算机给数组 a[10]，分配了一块连续内存空间 1000～1039，其中，内存块的首地址为 base_address = 1000。

![](../../pic/2019-10-19-22-58-08.png)

我们知道，计算机会给每个内存单元分配一个地址，计算机通过地址来访问内存中的数据。当计算机需要随机访问数组中的某个元素时，它会首先通过下面的寻址公式，计算出该元素存储的内存地址：

a[i]_address = base_address + i * data_type_size

其中 data_type_size 表示数组中每个元素的大小。我们举的这个例子里，数组中存储的是 int 类型数据，所以 data_type_size 就为 4 个字节。这个公式非常简单，我就不多做解释了。

这里我要特别纠正一个“错误”。我在面试的时候，常常会问数组和链表的区别，很多人都回答说，“链表适合插入、删除，时间复杂度 O(1)；数组适合查找，查找时间复杂度为 O(1)”。

实际上，这种表述是不准确的。数组是适合查找操作，但是查找的时间复杂度并不为 O(1)。即便是排好序的数组，你用二分查找，时间复杂度也是 O(logn)。所以，正确的表述应该是，数组支持随机访问，根据下标随机访问的时间复杂度为 O(1)。

> 低效的“插入”和“删除”

前面概念部分我们提到，数组为了保持内存数据的连续性，会导致插入、删除这两个操作比较低效。现在我们就来详细说一下，究竟为什么会导致低效？又有哪些改进方法呢？

我们先来看插入操作。

假设数组的长度为 n，现在，如果我们需要将一个数据插入到数组中的第 k 个位置。为了把第 k 个位置腾出来，给新来的数据，我们需要将第 k～n 这部分的元素都顺序地往后挪一位。那插入操作的时间复杂度是多少呢？你可以自己先试着分析一下。

如果在数组的末尾插入元素，那就不需要移动数据了，这时的时间复杂度为 O(1)。但如果在数组的开头插入元素，那所有的数据都需要依次往后移动一位，所以最坏时间复杂度是 O(n)。 因为我们在每个位置插入元素的概率是一样的，所以平均情况时间复杂度为 (1+2+…n)/n=O(n)。

如果数组中的数据是有序的，我们在某个位置插入一个新的元素时，就必须按照刚才的方法搬移 k 之后的数据。但是，如果数组中存储的数据并没有任何规律，数组只是被当作一个存储数据的集合。在这种情况下，如果要将某个数组插入到第 k 个位置，为了避免大规模的数据搬移，我们还有一个简单的办法就是，直接将第 k 位的数据搬移到数组元素的最后，把新的元素直接放入第 k 个位置。

为了更好地理解，我们举一个例子。假设数组 a[10] 中存储了如下 5 个元素：a，b，c，d，e。

我们现在需要将元素 x 插入到第 3 个位置。我们只需要将 c 放入到 a[5]，将 a[2] 赋值为 x 即可。最后，数组中的元素如下： a，b，x，d，e，c。



利用这种处理技巧，在特定场景下，在第 k 个位置插入一个元素的时间复杂度就会降为 O(1)。这个处理思想在快排中也会用到，我会在排序那一节具体来讲，这里就说到这儿。

我们再来看删除操作。

跟插入数据类似，如果我们要删除第 k 个位置的数据，为了内存的连续性，也需要搬移数据，不然中间就会出现空洞，内存就不连续了。

和插入类似，如果删除数组末尾的数据，则最好情况时间复杂度为 O(1)；如果删除开头的数据，则最坏情况时间复杂度为 O(n)；平均情况时间复杂度也为 O(n)。

实际上，在某些特殊场景下，我们并不一定非得追求数组中数据的连续性。如果我们将多次删除操作集中在一起执行，删除的效率是不是会提高很多呢？

我们继续来看例子。数组 a[10] 中存储了 8 个元素：a，b，c，d，e，f，g，h。现在，我们要依次删除 a，b，c 三个元素。



为了避免 d，e，f，g，h 这几个数据会被搬移三次，我们可以先记录下已经删除的数据。每次的删除操作并不是真正地搬移数据，只是记录数据已经被删除。当数组没有更多空间存储数据时，我们再触发执行一次真正的删除操作，这样就大大减少了删除操作导致的数据搬移。

如果你了解 JVM，你会发现，这不就是 JVM 标记清除垃圾回收算法的核心思想吗？没错，数据结构和算法的魅力就在于此，很多时候我们并不是要去死记硬背某个数据结构或者算法，而是要学习它背后的思想和处理技巧，这些东西才是最有价值的。如果你细心留意，不管是在软件开发还是架构设计中，总能找到某些算法和数据结构的影子。

警惕数组的访问越界问题
了解了数组的几个基本操作后，我们来聊聊数组访问越界的问题。

首先，我请你来分析一下这段 C 语言代码的运行结果：

int main(int argc, char* argv[]){
    int i = 0;
    int arr[3] = {0};
    for(; i<=3; i++){
        arr[i] = 0;
        printf("hello world\n");
    }
    return 0;
}
你发现问题了吗？这段代码的运行结果并非是打印三行“hello word”，而是会无限打印“hello world”，这是为什么呢？

因为，数组大小为 3，a[0]，a[1]，a[2]，而我们的代码因为书写错误，导致 for 循环的结束条件错写为了 i<=3 而非 i<3，所以当 i=3 时，数组 a[3] 访问越界。

我们知道，在 C 语言中，只要不是访问受限的内存，所有的内存空间都是可以自由访问的。根据我们前面讲的数组寻址公式，a[3] 也会被定位到某块不属于数组的内存地址上，而这个地址正好是存储变量 i 的内存地址，那么 a[3]=0 就相当于 i=0，所以就会导致代码无限循环。

数组越界在 C 语言中是一种未决行为，并没有规定数组访问越界时编译器应该如何处理。因为，访问数组的本质就是访问一段连续内存，只要数组通过偏移计算得到的内存地址是可用的，那么程序就可能不会报任何错误。

这种情况下，一般都会出现莫名其妙的逻辑错误，就像我们刚刚举的那个例子，debug 的难度非常的大。而且，很多计算机病毒也正是利用到了代码中的数组越界可以访问非法地址的漏洞，来攻击系统，所以写代码的时候一定要警惕数组越界。

但并非所有的语言都像 C 一样，把数组越界检查的工作丢给程序员来做，像 Java 本身就会做越界检查，比如下面这几行 Java 代码，就会抛出 java.lang.ArrayIndexOutOfBoundsException。

int[] a = new int[3];
a[3] = 10;
容器能否完全替代数组？
针对数组类型，很多语言都提供了容器类，比如 Java 中的 ArrayList、C++ STL 中的 vector。在项目开发中，什么时候适合用数组，什么时候适合用容器呢？

这里我拿 Java 语言来举例。如果你是 Java 工程师，几乎天天都在用 ArrayList，对它应该非常熟悉。那它与数组相比，到底有哪些优势呢？

我个人觉得，ArrayList 最大的优势就是可以将很多数组操作的细节封装起来。比如前面提到的数组插入、删除数据时需要搬移其他数据等。另外，它还有一个优势，就是支持动态扩容。

数组本身在定义的时候需要预先指定大小，因为需要分配连续的内存空间。如果我们申请了大小为 10 的数组，当第 11 个数据需要存储到数组中时，我们就需要重新分配一块更大的空间，将原来的数据复制过去，然后再将新的数据插入。

如果使用 ArrayList，我们就完全不需要关心底层的扩容逻辑，ArrayList 已经帮我们实现好了。每次存储空间不够的时候，它都会将空间自动扩容为 1.5 倍大小。

不过，这里需要注意一点，因为扩容操作涉及内存申请和数据搬移，是比较耗时的。所以，如果事先能确定需要存储的数据大小，最好在创建 ArrayList 的时候事先指定数据大小。

比如我们要从数据库中取出 10000 条数据放入 ArrayList。我们看下面这几行代码，你会发现，相比之下，事先指定数据大小可以省掉很多次内存申请和数据搬移操作。

ArrayList<User> users = new ArrayList(10000);
for (int i = 0; i < 10000; ++i) {
  users.add(xxx);
}
作为高级语言编程者，是不是数组就无用武之地了呢？当然不是，有些时候，用数组会更合适些，我总结了几点自己的经验。

1.Java ArrayList 无法存储基本类型，比如 int、long，需要封装为 Integer、Long 类，而 Autoboxing、Unboxing 则有一定的性能消耗，所以如果特别关注性能，或者希望使用基本类型，就可以选用数组。

2. 如果数据大小事先已知，并且对数据的操作非常简单，用不到 ArrayList 提供的大部分方法，也可以直接使用数组。

3. 还有一个是我个人的喜好，当要表示多维数组时，用数组往往会更加直观。比如 Object[][] array；而用容器的话则需要这样定义：ArrayList<ArrayList > array。
我总结一下，对于业务开发，直接使用容器就足够了，省时省力。毕竟损耗一丢丢性能，完全不会影响到系统整体的性能。但如果你是做一些非常底层的开发，比如开发网络框架，性能的优化需要做到极致，这个时候数组就会优于容器，成为首选。

解答开篇
现在我们来思考开篇的问题：为什么大多数编程语言中，数组要从 0 开始编号，而不是从 1 开始呢？

从数组存储的内存模型上来看，“下标”最确切的定义应该是“偏移（offset）”。前面也讲到，如果用 a 来表示数组的首地址，a[0] 就是偏移为 0 的位置，也就是首地址，a[k] 就表示偏移 k 个 type_size 的位置，所以计算 a[k] 的内存地址只需要用这个公式：

a[k]_address = base_address + k * type_size
但是，如果数组从 1 开始计数，那我们计算数组元素 a[k] 的内存地址就会变为：

a[k]_address = base_address + (k-1)*type_size
对比两个公式，我们不难发现，从 1 开始编号，每次随机访问数组元素都多了一次减法运算，对于 CPU 来说，就是多了一次减法指令。

数组作为非常基础的数据结构，通过下标随机访问数组元素又是其非常基础的编程操作，效率的优化就要尽可能做到极致。所以为了减少一次减法操作，数组选择了从 0 开始编号，而不是从 1 开始。

不过我认为，上面解释得再多其实都算不上压倒性的证明，说数组起始编号非 0 开始不可。所以我觉得最主要的原因可能是历史原因。

C 语言设计者用 0 开始计数数组下标，之后的 Java、JavaScript 等高级语言都效仿了 C 语言，或者说，为了在一定程度上减少 C 语言程序员学习 Java 的学习成本，因此继续沿用了从 0 开始计数的习惯。实际上，很多语言中数组也并不是从 0 开始计数的，比如 Matlab。甚至还有一些语言支持负数下标，比如 Python。

内容小结
我们今天学习了数组。它可以说是最基础、最简单的数据结构了。数组用一块连续的内存空间，来存储相同类型的一组数据，最大的特点就是支持随机访问，但插入、删除操作也因此变得比较低效，平均情况时间复杂度为 O(n)。在平时的业务开发中，我们可以直接使用编程语言提供的容器类，但是，如果是特别底层的开发，直接使用数组可能会更合适。

课后思考
前面我基于数组的原理引出 JVM 的标记清除垃圾回收算法的核心理念。我不知道你是否使用 Java 语言，理解 JVM，如果你熟悉，可以在评论区回顾下你理解的标记清除垃圾回收算法。

前面我们讲到一维数组的内存寻址公式，那你可以思考一下，类比一下，二维数组的内存寻址公式是怎样的呢？

欢迎留言和我分享，我会第一时间给你反馈。

我已将本节内容相关的详细代码更新到 GitHub，戳此即可查看。




© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(493)

杰杰 置顶
JVM标记清除算法：

大多数主流虚拟机采用可达性分析算法来判断对象是否存活，在标记阶段，会遍历所有 GC ROOTS，将所有 GC ROOTS 可达的对象标记为存活。只有当标记工作完成后，清理工作才会开始。

不足：1.效率问题。标记和清理效率都不高，但是当知道只有少量垃圾产生时会很高效。2.空间问题。会产生不连续的内存空间碎片。

二维数组内存寻址：

对于 m * n 的数组，a [ i ][ j ] (i < m,j < n)的地址为：

address = base_address + ( i * n + j) * type_size

另外，对于数组访问越界造成无限循环，我理解是编译器的问题，对于不同的编译器，在内存分配时，会按照内存地址递增或递减的方式进行分配。老师的程序，如果是内存地址递减的方式，就会造成无限循环。

不知我的解答和理解是否正确，望老师解答？

作者回复: 完全正确✅

2018-10-01

5

572

slvher
对文中示例的无限循环有疑问的同学，建议去查函数调用的栈桢结构细节（操作系统或计算机体系结构的教材应该会讲到）。

函数体内的局部变量存在栈上，且是连续压栈。在Linux进程的内存布局中，栈区在高地址空间，从高向低增长。变量i和arr在相邻地址，且i比arr的地址大，所以arr越界正好访问到i。当然，前提是i和arr元素同类型，否则那段代码仍是未决行为。
作者回复: 👍 高手！

2018-10-01

3

893

不诉离殇
例子中死循环的问题跟编译器分配内存和字节对齐有关 数组3个元素 加上一个变量a 。4个整数刚好能满足8字节对齐 所以i的地址恰好跟着a2后面 导致死循环。。如果数组本身有4个元素 则这里不会出现死循环。。因为编译器64位操作系统下 默认会进行8字节对齐 变量i的地址就不紧跟着数组后面了。
作者回复: 高手！

2018-10-01

3

354

夜下凝月
突然想到了垃圾桶。
生活中，我们扔进屋里垃圾桶的垃圾，
并没有消失，只是被 ''标记'' 成了垃圾，
只有垃圾桶塞满时，才会清理垃圾桶。
再次存放垃圾
2018-10-07

2

299

zyzheng
关于数组越界访问导致死循环的问题，我也动手实践了一下，发现结果和编译器的实现有关，gcc有一个编译选项（-fno-stack-protector）用于关闭堆栈保护功能。默认情况下启动了堆栈保护，不管i声明在前还是在后，i都会在数组之后压栈，只会循环4次；如果关闭堆栈保护功能，则会出现死循环。请参考：https://www.ibm.com/developerworks/cn/linux/l-cn-gccstack/index.html
作者回复: 就喜欢你这种自己动手研究的同学

2018-10-03

4

176

Rain
根据我们前面讲的数组寻址公式，a[3] 也会被定位到某块不属于数组的内存地址上，而这个地址正好是存储变量 i 的内存地址，那么 a[3]=0 就相当于 i=0，所以就会导致代码无限循环。

*而这个地址正好是存储变量 i 的内存地址*这个地方没看太懂，为什么正好就是i的内存地址呢？

谢谢老师。
2018-10-01

1

165

Nirvanaliu
文章结构：
数组看起来简单基础，但是很多人没有理解这个数据结构的精髓。带着为什么数组要从0开始编号，而不是从1开始的问题，进入主题。
1. 数组如何实现随机访问
1） 数组是一种线性数据结构，用连续的存储空间存储相同类型数据
I） 线性表：数组、链表、队列、栈 非线性表：树 图
II） 连续的内存空间、相同的数据，所以数组可以随机访问，但对数组进行删除插入，为了保证数组的连续性，就要做大量的数据搬移工作
a) 数组如何实现下标随机访问。
引入数组再内存种的分配图，得出寻址公式
b) 纠正数组和链表的错误认识。数组的查找操作时间复杂度并不是O(1)。即便是排好的数组，用二分查找，时间复杂度也是O（logn）。
正确表述：数组支持随机访问，根据下标随机访问的时间复杂度为O（1）
2. 低效的插入和删除
1） 插入：从最好O(1) 最坏O(n) 平均O(n)
2） 插入：数组若无序，插入新的元素时，可以将第K个位置元素移动到数组末尾，把心的元素，插入到第k个位置，此处复杂度为O(1)。作者举例说明
3） 删除：从最好O(1) 最坏O(n) 平均O(n)
4） 多次删除集中在一起，提高删除效率
记录下已经被删除的数据，每次的删除操作并不是搬移数据，只是记录数据已经被删除，当数组没有更多的存储空间时，再触发一次真正的删除操作。即JVM标记清除垃圾回收算法。
3. 警惕数组的访问越界问题
用C语言循环越界访问的例子说明访问越界的bug。此例在《C陷阱与缺陷》出现过，很惭愧，看过但是现在也只有一丢丢印象。翻了下书，替作者加上一句话：如果用来编译这段程序的编译器按照内存地址递减的方式给变量分配内存，那么内存中的i将会被置为0，则为死循环永远出不去。
4. 容器能否完全替代数组
相比于数字，java中的ArrayList封装了数组的很多操作，并支持动态扩容。一旦超过村塾容量，扩容时比较耗内存，因为涉及到内存申请和数据搬移。
数组适合的场景：
1） Java ArrayList 的使用涉及装箱拆箱，有一定的性能损耗，如果特别管柱性能，可以考虑数组
2） 若数据大小事先已知，并且涉及的数据操作非常简单，可以使用数组
3） 表示多维数组时，数组往往更加直观。
4） 业务开发容器即可，底层开发，如网络框架，性能优化。选择数组。
5. 解答开篇问题
1） 从偏移角度理解a[0] 0为偏移量，如果从1计数，会多出K-1。增加cpu负担。为什么循环要写成for(int i = 0;i<3;i++) 而不是for(int i = 0 ;i<=2;i++)。第一个直接就可以算出3-0 = 3 有三个数据，而后者 2-0+1个数据，多出1个加法运算，很恼火。
2） 也有一定的历史原因
2018-10-01

1

138

Zzzzz
对于死循环那个问题，要了解栈这个东西。栈是向下增长的，首先压栈的i，a[2]，a[1]，a[0]，这是我在我vc上调试查看汇编的时候看到的压栈顺序。相当于访问a[3]的时候，是在访问i变量，而此时i变量的地址是数组当前进程的，所以进行修改的时候，操作系统并不会终止进程。
作者回复: 👍

2018-10-01


87

何江
有个小问题，我觉得 随机访问Ramdom Acess 更应该翻译成 任意访问，更能表达数组的特性。不过国内书籍都是翻译成随机。新手朋友刚看到时会有一些理解问题，如数组怎么会是随机访问的呢(当初我就是这么想的)
2018-10-02


70

李朋远
老师，您好，个人觉得您举例的内存越界的循环应该限制在x86架构的小端模式，在别的架构平台上的大端模式应该不是这样的！
作者回复: 说的没错 👍

2018-10-03


42

港
1. 我认为文中更准确的说法可能是标记-整理垃圾回收算法。标记-清除算法在垃圾收集时会先标记出需要回收的对象，标记完成后统一回收所有被标记的对象。清除之后会产生大量不连续的内存碎片。标记-整理垃圾回收算法在标记完成之后让所有存活的对象都向一端移动，然后直接清理掉边界以外的内存。
2. 假设二维数组大小为m*n，那么寻址公式为
a[i][j]_address = base_address + (i * n+j)*data_type_size

3. C语言变量的内存申请可以看做是地址按照从大到小连续申请的，因为i在arr前面申请，所以arr[3]的地址和i的地址相同。

例如对于如下代码：
int i = 0;int j = 1;int k = 2; int arr[3] = {0}; cout<<"i-"<<&i<<endl;
cout<<"j-"<<&j<<endl;
cout<<"k-"<<&k<<endl;
cout<<"arr-"<<&arr<<endl;
cout<<"arr3-"<<&arr[3]<<endl;

运行结果：
i-0x28ff0c

j-0x28ff08

k-0x28ff04

arr-0x28fef8

arr3-0x28ff04
作者回复: 👍

2018-10-03


34

shane
无限循环的问题，我认为内存分配是从后往前分配的。例如，在Excel中从上往下拉4个格子，变量i会先被分配到第4个格子的内存，然后变量arr往上数分配3个格子的内存，但arr的数据是从分配3个格子的第一个格子从上往下存储数据的，当访问第3索引时，这时刚好访问到第4个格子变量i的内存。
不知道对不对，望指正！
作者回复: 形象👍

2018-10-01


34

hope
根据我们前面讲的数组寻址公式，a[3] 也会被定位到某块不属于数组的内存地址上，而这个地址正好是存储变量 i 的内存地址，那么 a[3]=0 就相当于 i=0，所以就会导致代码无限循环。

这块不是十分清晰，希望老师详细解答一下，谢谢！

看完了 ，之前说总结但是没总结，这次前连天的总结也补上了，打卡
作者回复: 1. 不同的语言对数组访问越界的处理方式不同，即便是同一种语言，不同的编译器处理的方式也不同。至于你熟悉的语言是怎么处理的，请行百度。
2. C语言中，数组访问越界的处理是未决。并不一定是错，有同学做实验说没问题，那并不代表就是正确的。
3. 我觉得那个例子，栈是由高到低位增长的，所以，i和数组的数据从高位地址到低位地址依次是：i, a[2], a[1], a[0]。a[3]通过寻址公式，计算得到地址正好是i的存储地址，所以a[3]=0，就相当于i=0.
4. 大家有不懂的多看看留言，留言区还是有很多大牛的！我可能有时候回复的不及时，或者同样的问题只回复一个同学！

2018-10-01


29

wistbean
————总结一下————

什么是数组

数组（Array）是一种线性表数据结构。它用一组连续的内存空间，来存储一组具有相同类型的数据。



1.线性表
线性表就是数据排成像一条线一样的结构。
常见的线性表结构：数组，链表、队列、栈等。

2. 连续的内存空间和相同类型的数据

优点：两限制使得具有随机访问的特性
缺点：删除，插入数据效率低

数组怎么根据下标随机访问的？

通过寻址公式，计算出该元素存储的内存地址：
a[i]_address = base_address + i * data_type_size

为何数组插入和删除低效

插入：
若有一元素想往int[n]的第k个位置插入数据，需要在k-n的位置往后移。
最好情况时间复杂度 O(1)
最坏情况复杂度为O(n)
平均负责度为O(n)

如果数组中的数据不是有序的，也就是无规律的情况下，可以直接把第k个位置上的数据移到最后，然后将插入的数据直接放在第k个位置上。

这样时间复杂度就将为 O（1）了。

删除：
与插入类似，为了保持内存的连续性。
最好情况时间复杂度 O(1)
最坏情况复杂度为O(n)
平均负责度为O(n)

提高效率：将多次删除操作中集中在一起执行，可以先记录已经删除的数据，但是不进行数据迁移，而仅仅是记录，当发现没有更多空间存储时，再执行真正的删除操作。这也是 JVM 标记清除垃圾回收算法的核心思想。

数组访问越界问题
C语言中的数据越界是一种未决行为，一般比较难发现的逻辑错误。相比之下，Java会有越界检查。

用数组还是容器？
数组先指定了空间大小
容器如ArrayList可以动态扩容。
1.希望存储基本类型数据，可以用数组
2.事先知道数据大小，并且操作简单，可以用数组
3.直观表示多维，可以用数组
4.业务开发，使用容器足够，开发框架，追求性能，首先数组。

为什么数组要从 0 开始编号？
由于数组是通过寻址公式，计算出该元素存储的内存地址：
a[i]_address = base_address + i * data_type_size
如果数组是从 1 开始计数，那么就会变成：
a[i]_address = base_address + （i-1）* data_type_size

对于CPU来说，多了一次减法的指令。
当然，还有一定的历史原因。

————课后思考————

1.我理解的JVM标记清除垃圾回收算法：在标记阶段会标记所有的可访问的对象，在清除阶段会遍历堆，回收那些没有被标记的对象。现在想想，和「如果数组中的数据不是有序的，也就是无规律的情况下，可以直接把第k个位置上的数据移到最后，然后将插入的数据直接放在第k个位置上。」思想类似。

2. 对于一维数组：a[i]_address = base_address + （i）* data_type_size
二维数组如果是m*n，那么a[i][j]== base_address + （i*n+j）* data_type_size。
2.
2018-10-02


22

qx
1.老师您好，二维数组存储也是连续的吧。
2.对于数组删除abc，还没太理解?申请的是三个地址空间，a（3）越界了，那么它会去找哪个地址的数据呢？而且for循环就是三次啊，如何无限打印?
3.老师时候每讲完一节数据结构可以对应到一些编程题目给大家思考啊例如leetcode或其他的?
2018-10-01


22

HCG
对于无线循环那个问题解释

个人认为应该按照这样的顺序声明：
int arr［3］＝｛0｝;
int i;
因为在计算机中程序一般顺序分配存储空间，这样声明，首先分配0 1 2三个存储单元给数组arr，然后再分配 4 存储单元给变量i，然后根据数组访问公式即会出现无线循环。
不知道对不对，还请老师指点。
2018-10-01


19

CathyLin
看完 & 写完笔记来打卡，发现评论区好多大牛！光是翻看了评论区就收获了好多！
2018-10-02


15

韩某众
我也是js开发者，前面的那位js开发者同学的问题其实不难解决。
如果不知道老师的“数组”究竟是什么，只要查一下数据结构里的“数组”和“链表”的定义，然后搜一些关于js引擎对js定义下“数组”的底层实现的文章，比如“深究 JavaScript 数组 —— 演进&性能”。就知道老师在说什么了。
互联网从业者更要善用互联网，加油！
作者回复: 说得好！

2018-10-01


13

HI
标记清除：就是将要释放清除的对象标记，之后再执行清除操作，缺点就是会产生内存碎片的问题，很有可能导致下一次分配一块连续较大的内存空间，由于找不到合适的，又触发一次垃圾回收操作，一般试用于老年代的回收

二维数组的寻址操作：首先二维数组本质也是一个连续的一维数组，只不过每个元素都为一个一维数组，在内存空间的分配是按照行的方式将每一行拼接起来，比如数组a[1][2] 来说，看做是一个一维数组的话1就代表这个一维属于的第二个元素，第二个元素为一维数组然后根据2找到这一维数组中第三的元素
2018-10-01


12

Kudo
假设二维数组的维度为m * n，则 a[i][j]_address = base_address + (i * n + j) * type_size
2018-10-01


11
收起评论

99+99+





# 06 | 链表（上）：如何实现LRU缓存淘汰算法?




数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



06 | 链表（上）：如何实现LRU缓存淘汰算法?
王争 2018-10-03



17:06
讲述：修阳 大小：7.85M
今天我们来聊聊“链表（Linked list）”这个数据结构。学习链表有什么用呢？为了回答这个问题，我们先来讨论一个经典的链表应用场景，那就是 LRU 缓存淘汰算法。

缓存是一种提高数据读取性能的技术，在硬件设计、软件开发中都有着非常广泛的应用，比如常见的 CPU 缓存、数据库缓存、浏览器缓存等等。

缓存的大小有限，当缓存被用满时，哪些数据应该被清理出去，哪些数据应该被保留？这就需要缓存淘汰策略来决定。常见的策略有三种：先进先出策略 FIFO（First In，First Out）、最少使用策略 LFU（Least Frequently Used）、最近最少使用策略 LRU（Least Recently Used）。

这些策略你不用死记，我打个比方你很容易就明白了。假如说，你买了很多本技术书，但有一天你发现，这些书太多了，太占书房空间了，你要做个大扫除，扔掉一些书籍。那这个时候，你会选择扔掉哪些书呢？对应一下，你的选择标准是不是和上面的三种策略神似呢？

好了，回到正题，我们今天的开篇问题就是：如何用链表来实现 LRU 缓存淘汰策略呢？ 带着这个问题，我们开始今天的内容吧！

五花八门的链表结构
相比数组，链表是一种稍微复杂一点的数据结构。对于初学者来说，掌握起来也要比数组稍难一些。这两个非常基础、非常常用的数据结构，我们常常将会放到一块儿来比较。所以我们先来看，这两者有什么区别。

我们先从底层的存储结构上来看一看。

为了直观地对比，我画了一张图。从图中我们看到，数组需要一块连续的内存空间来存储，对内存的要求比较高。如果我们申请一个 100MB 大小的数组，当内存中没有连续的、足够大的存储空间时，即便内存的剩余总可用空间大于 100MB，仍然会申请失败。

而链表恰恰相反，它并不需要一块连续的内存空间，它通过“指针”将一组零散的内存块串联起来使用，所以如果我们申请的是 100MB 大小的链表，根本不会有问题。



链表结构五花八门，今天我重点给你介绍三种最常见的链表结构，它们分别是：单链表、双向链表和循环链表。我们首先来看最简单、最常用的单链表。

我们刚刚讲到，链表通过指针将一组零散的内存块串联在一起。其中，我们把内存块称为链表的“结点”。为了将所有的结点串起来，每个链表的结点除了存储数据之外，还需要记录链上的下一个结点的地址。如图所示，我们把这个记录下个结点地址的指针叫作后继指针 next。



从我画的单链表图中，你应该可以发现，其中有两个结点是比较特殊的，它们分别是第一个结点和最后一个结点。我们习惯性地把第一个结点叫作头结点，把最后一个结点叫作尾结点。其中，头结点用来记录链表的基地址。有了它，我们就可以遍历得到整条链表。而尾结点特殊的地方是：指针不是指向下一个结点，而是指向一个空地址 NULL，表示这是链表上最后一个结点。

与数组一样，链表也支持数据的查找、插入和删除操作。

我们知道，在进行数组的插入、删除操作时，为了保持内存数据的连续性，需要做大量的数据搬移，所以时间复杂度是 O(n)。而在链表中插入或者删除一个数据，我们并不需要为了保持内存的连续性而搬移结点，因为链表的存储空间本身就不是连续的。所以，在链表中插入和删除一个数据是非常快速的。

为了方便你理解，我画了一张图，从图中我们可以看出，针对链表的插入和删除操作，我们只需要考虑相邻结点的指针改变，所以对应的时间复杂度是 O(1)。



但是，有利就有弊。链表要想随机访问第 k 个元素，就没有数组那么高效了。因为链表中的数据并非连续存储的，所以无法像数组那样，根据首地址和下标，通过寻址公式就能直接计算出对应的内存地址，而是需要根据指针一个结点一个结点地依次遍历，直到找到相应的结点。

你可以把链表想象成一个队伍，队伍中的每个人都只知道自己后面的人是谁，所以当我们希望知道排在第 k 位的人是谁的时候，我们就需要从第一个人开始，一个一个地往下数。所以，链表随机访问的性能没有数组好，需要 O(n) 的时间复杂度。

好了，单链表我们就简单介绍完了，接着来看另外两个复杂的升级版，循环链表和双向链表。

循环链表是一种特殊的单链表。实际上，循环链表也很简单。它跟单链表唯一的区别就在尾结点。我们知道，单链表的尾结点指针指向空地址，表示这就是最后的结点了。而循环链表的尾结点指针是指向链表的头结点。从我画的循环链表图中，你应该可以看出来，它像一个环一样首尾相连，所以叫作“循环”链表。



和单链表相比，循环链表的优点是从链尾到链头比较方便。当要处理的数据具有环型结构特点时，就特别适合采用循环链表。比如著名的约瑟夫问题。尽管用单链表也可以实现，但是用循环链表实现的话，代码就会简洁很多。

单链表和循环链表是不是都不难？接下来我们再来看一个稍微复杂的，在实际的软件开发中，也更加常用的链表结构：双向链表。

单向链表只有一个方向，结点只有一个后继指针 next 指向后面的结点。而双向链表，顾名思义，它支持两个方向，每个结点不止有一个后继指针 next 指向后面的结点，还有一个前驱指针 prev 指向前面的结点。



从我画的图中可以看出来，双向链表需要额外的两个空间来存储后继结点和前驱结点的地址。所以，如果存储同样多的数据，双向链表要比单链表占用更多的内存空间。虽然两个指针比较浪费存储空间，但可以支持双向遍历，这样也带来了双向链表操作的灵活性。那相比单链表，双向链表适合解决哪种问题呢？

从结构上来看，双向链表可以支持 O(1) 时间复杂度的情况下找到前驱结点，正是这样的特点，也使双向链表在某些情况下的插入、删除等操作都要比单链表简单、高效。

你可能会说，我刚讲到单链表的插入、删除操作的时间复杂度已经是 O(1) 了，双向链表还能再怎么高效呢？别着急，刚刚的分析比较偏理论，很多数据结构和算法书籍中都会这么讲，但是这种说法实际上是不准确的，或者说是有先决条件的。我再来带你分析一下链表的两个操作。

我们先来看删除操作。

在实际的软件开发中，从链表中删除一个数据无外乎这两种情况：

删除结点中“值等于某个给定值”的结点；

删除给定指针指向的结点。

对于第一种情况，不管是单链表还是双向链表，为了查找到值等于给定值的结点，都需要从头结点开始一个一个依次遍历对比，直到找到值等于给定值的结点，然后再通过我前面讲的指针操作将其删除。

尽管单纯的删除操作时间复杂度是 O(1)，但遍历查找的时间是主要的耗时点，对应的时间复杂度为 O(n)。根据时间复杂度分析中的加法法则，删除值等于给定值的结点对应的链表操作的总时间复杂度为 O(n)。

对于第二种情况，我们已经找到了要删除的结点，但是删除某个结点 q 需要知道其前驱结点，而单链表并不支持直接获取前驱结点，所以，为了找到前驱结点，我们还是要从头结点开始遍历链表，直到 p->next=q，说明 p 是 q 的前驱结点。

但是对于双向链表来说，这种情况就比较有优势了。因为双向链表中的结点已经保存了前驱结点的指针，不需要像单链表那样遍历。所以，针对第二种情况，单链表删除操作需要 O(n) 的时间复杂度，而双向链表只需要在 O(1) 的时间复杂度内就搞定了！

同理，如果我们希望在链表的某个指定结点前面插入一个结点，双向链表比单链表有很大的优势。双向链表可以在 O(1) 时间复杂度搞定，而单向链表需要 O(n) 的时间复杂度。你可以参照我刚刚讲过的删除操作自己分析一下。

除了插入、删除操作有优势之外，对于一个有序链表，双向链表的按值查询的效率也要比单链表高一些。因为，我们可以记录上次查找的位置 p，每次查询时，根据要查找的值与 p 的大小关系，决定是往前还是往后查找，所以平均只需要查找一半的数据。

现在，你有没有觉得双向链表要比单链表更加高效呢？这就是为什么在实际的软件开发中，双向链表尽管比较费内存，但还是比单链表的应用更加广泛的原因。如果你熟悉 Java 语言，你肯定用过 LinkedHashMap 这个容器。如果你深入研究 LinkedHashMap 的实现原理，就会发现其中就用到了双向链表这种数据结构。

实际上，这里有一个更加重要的知识点需要你掌握，那就是用空间换时间的设计思想。当内存空间充足的时候，如果我们更加追求代码的执行速度，我们就可以选择空间复杂度相对较高、但时间复杂度相对很低的算法或者数据结构。相反，如果内存比较紧缺，比如代码跑在手机或者单片机上，这个时候，就要反过来用时间换空间的设计思路。

还是开篇缓存的例子。缓存实际上就是利用了空间换时间的设计思想。如果我们把数据存储在硬盘上，会比较节省内存，但每次查找数据都要询问一次硬盘，会比较慢。但如果我们通过缓存技术，事先将数据加载在内存中，虽然会比较耗费内存空间，但是每次数据查询的速度就大大提高了。

所以我总结一下，对于执行较慢的程序，可以通过消耗更多的内存（空间换时间）来进行优化；而消耗过多内存的程序，可以通过消耗更多的时间（时间换空间）来降低内存的消耗。你还能想到其他时间换空间或者空间换时间的例子吗？

了解了循环链表和双向链表，如果把这两种链表整合在一起就是一个新的版本：双向循环链表。我想不用我多讲，你应该知道双向循环链表长什么样子了吧？你可以自己试着在纸上画一画。



链表 VS 数组性能大比拼
通过前面内容的学习，你应该已经知道，数组和链表是两种截然不同的内存组织方式。正是因为内存存储的区别，它们插入、删除、随机访问操作的时间复杂度正好相反。



不过，数组和链表的对比，并不能局限于时间复杂度。而且，在实际的软件开发中，不能仅仅利用复杂度分析就决定使用哪个数据结构来存储数据。

数组简单易用，在实现上使用的是连续的内存空间，可以借助 CPU 的缓存机制，预读数组中的数据，所以访问效率更高。而链表在内存中并不是连续存储，所以对 CPU 缓存不友好，没办法有效预读。

数组的缺点是大小固定，一经声明就要占用整块连续内存空间。如果声明的数组过大，系统可能没有足够的连续内存空间分配给它，导致“内存不足（out of memory）”。如果声明的数组过小，则可能出现不够用的情况。这时只能再申请一个更大的内存空间，把原数组拷贝进去，非常费时。链表本身没有大小的限制，天然地支持动态扩容，我觉得这也是它与数组最大的区别。

你可能会说，我们 Java 中的 ArrayList 容器，也可以支持动态扩容啊？我们上一节课讲过，当我们往支持动态扩容的数组中插入一个数据时，如果数组中没有空闲空间了，就会申请一个更大的空间，将数据拷贝过去，而数据拷贝的操作是非常耗时的。

我举一个稍微极端的例子。如果我们用 ArrayList 存储了了 1GB 大小的数据，这个时候已经没有空闲空间了，当我们再插入数据的时候，ArrayList 会申请一个 1.5GB 大小的存储空间，并且把原来那 1GB 的数据拷贝到新申请的空间上。听起来是不是就很耗时？

除此之外，如果你的代码对内存的使用非常苛刻，那数组就更适合你。因为链表中的每个结点都需要消耗额外的存储空间去存储一份指向下一个结点的指针，所以内存消耗会翻倍。而且，对链表进行频繁的插入、删除操作，还会导致频繁的内存申请和释放，容易造成内存碎片，如果是 Java 语言，就有可能会导致频繁的 GC（Garbage Collection，垃圾回收）。

所以，在我们实际的开发中，针对不同类型的项目，要根据具体情况，权衡究竟是选择数组还是链表。

解答开篇
好了，关于链表的知识我们就讲完了。我们现在回过头来看下开篇留给你的思考题。如何基于链表实现 LRU 缓存淘汰算法？

我的思路是这样的：我们维护一个有序单链表，越靠近链表尾部的结点是越早之前访问的。当有一个新的数据被访问时，我们从链表头开始顺序遍历链表。

1. 如果此数据之前已经被缓存在链表中了，我们遍历得到这个数据对应的结点，并将其从原来的位置删除，然后再插入到链表的头部。

2. 如果此数据没有在缓存链表中，又可以分为两种情况：

如果此时缓存未满，则将此结点直接插入到链表的头部；

如果此时缓存已满，则链表尾结点删除，将新的数据结点插入链表的头部。

这样我们就用链表实现了一个 LRU 缓存，是不是很简单？

现在我们来看下 m 缓存访问的时间复杂度是多少。因为不管缓存有没有满，我们都需要遍历一遍链表，所以这种基于链表的实现思路，缓存访问的时间复杂度为 O(n)。

实际上，我们可以继续优化这个实现思路，比如引入散列表（Hash table）来记录每个数据的位置，将缓存访问的时间复杂度降到 O(1)。因为要涉及我们还没有讲到的数据结构，所以这个优化方案，我现在就不详细说了，等讲到散列表的时候，我会再拿出来讲。

除了基于链表的实现思路，实际上还可以用数组来实现 LRU 缓存淘汰策略。如何利用数组实现 LRU 缓存淘汰策略呢？我把这个问题留给你思考。

内容小结
今天我们讲了一种跟数组“相反”的数据结构，链表。它跟数组一样，也是非常基础、非常常用的数据结构。不过链表要比数组稍微复杂，从普通的单链表衍生出来好几种链表结构，比如双向链表、循环链表、双向循环链表。

和数组相比，链表更适合插入、删除操作频繁的场景，查询的时间复杂度较高。不过，在具体软件开发中，要对数组和链表的各种性能进行对比，综合来选择使用两者中的哪一个。

课后思考
如何判断一个字符串是否是回文字符串的问题，我想你应该听过，我们今天的题目就是基于这个问题的改造版本。如果字符串是通过单链表来存储的，那该如何来判断是一个回文串呢？你有什么好的解决思路呢？相应的时间空间复杂度又是多少呢？

欢迎留言和我分享，我会第一时间给你反馈。

我已将本节内容相关的详细代码更新到 GitHub，戳此即可查看。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(416)

Rain 置顶
Re Ydyhm:

“数组简单易用，在实现上使用的是连续的内存空间，可以借助 CPU 的缓存机制，预读数组中的数据，所以访问效率更高。而链表在内存中并不是连续存储，所以对 CPU 缓存不友好，没办法有效预读。” 这里的CPU缓存机制指的是什么？为什么就数组更好了？

----

我没有百度也没有Google。之前开发时遇到过，我斗胆说下。
CPU在从内存读取数据的时候，会先把读取到的数据加载到CPU的缓存中。而CPU每次从内存读取数据并不是只读取那个特定要访问的地址，而是读取一个数据块(这个大小我不太确定。。)并保存到CPU缓存中，然后下次访问内存数据的时候就会先从CPU缓存开始查找，如果找到就不需要再从内存中取。这样就实现了比内存访问速度更快的机制，也就是CPU缓存存在的意义:为了弥补内存访问速度过慢与CPU执行速度快之间的差异而引入。

对于数组来说，存储空间是连续的，所以在加载某个下标的时候可以把以后的几个下标元素也加载到CPU缓存这样执行速度会快于存储空间不连续的链表存储。

大牛请指正哈！
作者回复: 同学，太爱你了。写的太好了！就喜欢你这样的，减轻了我很多回复留言的工作量。👍

2018-10-04

4

496

andavid 置顶
思考题：

使用快慢两个指针找到链表中点，慢指针每次前进一步，快指针每次前进两步。在慢指针前进的过程中，同时修改其 next 指针，使得链表前半部分反序。最后比较中点两侧的链表是否相等。

时间复杂度：O(n)
空间复杂度：O(1)

https://github.com/andavid/leetcode-java/blob/master/note/234/README.md
作者回复: 思路正确，不过空间复杂度计算的不对，应该是O(1)，不是O(n)。我们要看额外的内存消耗，不是看链表本身存储需要多少空间。

2018-10-03

8

150

Liam 置顶
1 快慢指针定位中间节点
2 从中间节点对后半部分逆序
3 前后半部分比较，判断是否为回文
4 后半部分逆序复原

时间复杂度On, 空间复杂度O1
把LRU和回文都实现了一遍~~

如果是双向链表，时间效率更高，看了下LinkedList，底层也是用双向链表实现
作者回复: 回答的很好！👍

2018-10-03


73

glbfor.gtw 置顶
1 快慢指针定位中间节点（这里要区分奇偶情况）
1.1 奇数情况，中点位置不需要矫正
1.2 偶数情况，使用偶数定位中点策略，要确定是返回上中位数或下中位数
1.2.1 如果是返回上中位数，后半部分串头取next
1.2.2 如果是返回下中位数，后半部分串头既是当前节点位置，但前半部分串尾要删除掉当前节点
2 从中间节点对后半部分逆序，或者将前半部分逆序
3 一次循环比较，判断是否为回文
4 恢复现场

题外话，这种操作有点BT啊？实际运用场景中，也真的直接改变引用值吗？至少在多线程情况，要加N多锁（Read Write都要加锁），这个时间成本就不能简单用时间复杂度来衡量了。如果是用copy 机制，不论是倒置前半段还是后半段，至少有一段是需要n/2个节点副本的空间消耗的，那么空间复杂度就是O（n）？？啦~跑题了，跑题了~~

老师，你给我评价被~ 我比较容易钻牛角尖。。
作者回复: 👍 回答的非常好

2018-10-11

2

35

sky 置顶
用快慢指针先找到中点，然后把后半段链表reversed，然后一个指针在头部，一个指针再中点，开始逐个比较，时间复杂度是O（n)
作者回复: 对的！👍

2018-10-09


17

姜威
五、应用
1.如何分别用链表和数组实现LRU缓冲淘汰策略？
1）什么是缓存？
缓存是一种提高数据读取性能的技术，在硬件设计、软件开发中都有着非广泛的应用，比如常见的CPU缓存、数据库缓存、浏览器缓存等等。
2）为什么使用缓存？即缓存的特点
缓存的大小是有限的，当缓存被用满时，哪些数据应该被清理出去，哪些数据应该被保留？就需要用到缓存淘汰策略。
3）什么是缓存淘汰策略？
指的是当缓存被用满时清理数据的优先顺序。
4）有哪些缓存淘汰策略？
常见的3种包括先进先出策略FIFO（First In，First Out）、最少使用策略LFU（Least Frenquently Used）、最近最少使用策略LRU（Least Recently Used）。
5）链表实现LRU缓存淘汰策略
当访问的数据没有存储在缓存的链表中时，直接将数据插入链表表头，时间复杂度为O(1)；当访问的数据存在于存储的链表中时，将该数据对应的节点，插入到链表表头,时间复杂度为O(n)。如果缓存被占满，则从链表尾部的数据开始清理，时间复杂度为O(1)。
6）数组实现LRU缓存淘汰策略
方式一：首位置保存最新访问数据，末尾位置优先清理
当访问的数据未存在于缓存的数组中时，直接将数据插入数组第一个元素位置，此时数组所有元素需要向后移动1个位置，时间复杂度为O(n)；当访问的数据存在于缓存的数组中时，查找到数据并将其插入数组的第一个位置，此时亦需移动数组元素，时间复杂度为O(n)。缓存用满时，则清理掉末尾的数据，时间复杂度为O(1)。
方式二：首位置优先清理，末尾位置保存最新访问数据
当访问的数据未存在于缓存的数组中时，直接将数据添加进数组作为当前最有一个元素时间复杂度为O(1)；当访问的数据存在于缓存的数组中时，查找到数据并将其插入当前数组最后一个元素的位置，此时亦需移动数组元素，时间复杂度为O(n)。缓存用满时，则清理掉数组首位置的元素，且剩余数组元素需整体前移一位，时间复杂度为O(n)。（优化：清理的时候可以考虑一次性清理一定数量，从而降低清理次数，提高性能。）
2.如何通过单链表实现“判断某个字符串是否为水仙花字符串”？（比如 上海自来水来自海上）
1）前提：字符串以单个字符的形式存储在单链表中。
2）遍历链表，判断字符个数是否为奇数，若为偶数，则不是。
3）将链表中的字符倒序存储一份在另一个链表中。
4）同步遍历2个链表，比较对应的字符是否相等，若相等，则是水仙花字串，否则，不是。
六、设计思想
时空替换思想：“用空间换时间” 与 “用时间换空间”
当内存空间充足的时候，如果我们更加追求代码的执行速度，我们就可以选择空间复杂度相对较高，时间复杂度小相对较低的算法和数据结构，缓存就是空间换时间的例子。如果内存比较紧缺，比如代码跑在手机或者单片机上，这时，就要反过来用时间换空间的思路。
作者回复: 👍

2018-10-03


187

molybdenum
看了大家的评论学习到了快慢指针法，看语言描述没太懂，自己用代码写了下才明白。
大致思路如下
由于回文串最重要的就是对称，那么最重要的问题就是找到那个中心，用快指针每步两格走，当他到达链表末端的时候，慢指针刚好到达中心，慢指针在过来的这趟路上还做了一件事，他把走过的节点反向了，在中心点再开辟一个新的指针用于往回走，而慢指针继续向前，当慢指针扫完整个链表，就可以判断这是回文串，否则就提前退出，总的来说时间复杂度按慢指针遍历一遍来算是O(n),空间复杂度因为只开辟了3个额外的辅助，所以是o(1)
2018-10-07

6

181

姜威
总结
一、什么是链表？
1.和数组一样，链表也是一种线性表。
2.从内存结构来看，链表的内存结构是不连续的内存空间，是将一组零散的内存块串联起来，从而进行数据存储的数据结构。
3.链表中的每一个内存块被称为节点Node。节点除了存储数据外，还需记录链上下一个节点的地址，即后继指针next。
二、为什么使用链表？即链表的特点
1.插入、删除数据效率高O(1)级别（只需更改指针指向即可），随机访问效率低O(n)级别（需要从链头至链尾进行遍历）。
2.和数组相比，内存空间消耗更大，因为每个存储数据的节点都需要额外的空间存储后继指针。
三、常用链表：单链表、循环链表和双向链表
1.单链表
1）每个节点只包含一个指针，即后继指针。
2）单链表有两个特殊的节点，即首节点和尾节点。为什么特殊？用首节点地址表示整条链表，尾节点的后继指针指向空地址null。
3）性能特点：插入和删除节点的时间复杂度为O（1），查找的时间复杂度为O(n)。
2.循环链表
1）除了尾节点的后继指针指向首节点的地址外均与单链表一致。
2）适用于存储有循环特点的数据，比如约瑟夫问题。
3.双向链表
1）节点除了存储数据外，还有两个指针分别指向前一个节点地址（前驱指针prev）和下一个节点地址（后继指针next）。
2）首节点的前驱指针prev和尾节点的后继指针均指向空地址。
3）性能特点：
和单链表相比，存储相同的数据，需要消耗更多的存储空间。
插入、删除操作比单链表效率更高O(1)级别。以删除操作为例，删除操作分为2种情况：给定数据值删除对应节点和给定节点地址删除节点。对于前一种情况，单链表和双向链表都需要从头到尾进行遍历从而找到对应节点进行删除，时间复杂度为O(n)。对于第二种情况，要进行删除操作必须找到前驱节点，单链表需要从头到尾进行遍历直到p->next = q，时间复杂度为O(n)，而双向链表可以直接找到前驱节点，时间复杂度为O(1)。
对于一个有序链表，双向链表的按值查询效率要比单链表高一些。因为我们可以记录上次查找的位置p，每一次查询时，根据要查找的值与p的大小关系，决定是往前还是往后查找，所以平均只需要查找一半的数据。
4.双向循环链表：首节点的前驱指针指向尾节点，尾节点的后继指针指向首节点。
四、选择数组还是链表？
1.插入、删除和随机访问的时间复杂度
数组：插入、删除的时间复杂度是O(n)，随机访问的时间复杂度是O(1)。
链表：插入、删除的时间复杂度是O(1)，随机访问的时间复杂端是O(n)。
2.数组缺点
1）若申请内存空间很大，比如100M，但若内存空间没有100M的连续空间时，则会申请失败，尽管内存可用空间超过100M。
2）大小固定，若存储空间不足，需进行扩容，一旦扩容就要进行数据复制，而这时非常费时的。
3.链表缺点
1）内存空间消耗更大，因为需要额外的空间存储指针信息。
2）对链表进行频繁的插入和删除操作，会导致频繁的内存申请和释放，容易造成内存碎片，如果是Java语言，还可能会造成频繁的GC（自动垃圾回收器）操作。
4.如何选择？
数组简单易用，在实现上使用连续的内存空间，可以借助CPU的缓冲机制预读数组中的数据，所以访问效率更高，而链表在内存中并不是连续存储，所以对CPU缓存不友好，没办法预读。
如果代码对内存的使用非常苛刻，那数组就更适合。
作者回复: 👍

2018-10-03


64

_stuView
双向链表存储，两个指针分别从头节点和尾节点开始遍历，依次比较节点value，判断是否为回文序列
2018-10-03


46

Joshua 兆甲
习题解答
1.快进慢进法[两组指针，从头开始，a组一次进一，b组一次进二，b组到终点时，a组位置即为链表中间结点，循环次数为链表除去中间结点后前后两组的长度] 求得单向链表“中间”节点。并计算遍历次数，经过验证，遍历次数为‘’半链表‘’长度
2.从中间结点开始，以动态步长[每第i次步长是半链表长度-i+1]遍历链表，同时，从头节点开始，以1步长遍历。比较两组对应元素是否相同，相同继续，不同退出，返回不是回文字符串的结论。
3.返回是回文字符串的结论，退出.
空间复杂度O(n). 不用连续内存，可以磁盘操作
时间复杂度度O(n). 主要费时操作遍历

  算了，不够直观，不易别人看懂。还是先把单项链表转存为线性表。
1.单向遍历，获得对应的线性表Arr，求线性表长度为L
2.运用线性表可以任意访问的性质，遍历Arr，令下标i从0。比较Arr[i]和Arr[L－i]是否相等 相等继续，不等报告不是回文字符串结论，退出
3.报告是回文字符串结论，结束。
空间复杂度O(n)
时间复杂度O(n)
看起来一样，这个就需要字符串不太大，有足够的连续内存可以分配，而且，预先不知道链表多长，可能还会遇到扩容问题。
2018-10-03


33

雨山
果然有程序员风格，放假还更新，昨天临睡前就看完了，但是没有评价，总之这个课绝对物有所值。
2018-10-03


30

徐凯
通过一个栈 遍历整个链表 然后再从栈中弹出 如果元素都匹配则为回文
2018-10-03

1

28

无崖子🍀
用数组解决Lru缓存问题：
维护一个有序的数组，越靠近数组首位置的数据越是最早访问的。
1.如果这个数据已经存在于数组中，把对应位置的数据删掉，直接把这个数据加到数组的最后一位。时间复杂度为o(n)
2.如果数据不存在这个数组中，数据还有空间的话，就把数据直接插到最后一位。没有的话，就把第一个数据删掉，然后把数据插入到数组最后一个。这样的时间复杂度为o(n）。

第一个小伙伴的留言有点问题。判断是否为回文串和奇偶数没关系吧，偶数个字符串也可以是哈，比如abccba。
2018-10-05


24

落叶飞逝的恋
老师，关于解答开篇那边，能不能附加一些代码示例，这样配合代码跟思路讲解，可能更好的理解呢。
2018-10-03


22

JStFs
LRU：活在当下。比如在公司中，一个新员工做出新业绩，马上会得到重用。

LFU：以史为镜。还是比如在公司中，新员工必须做出比那些功勋卓著的老员工更多更好的业绩才可以受到老板重视，这样的方式比较尊重“前辈”。
作者回复: 哈哈 形象！

2018-10-04


18

null
老师，您回复 JK David 说到：
空间复杂度计算的不对，应该是O(1)，不是O(n)。我们要看额外的内存消耗，不是看链表本身存储需要多少空间。


在《复杂度分析（上）》提到：
第 3 行申请了一个大小为 n 的 int 类型数组，所以整段代码的空间复杂度就是 O(n)。


----


疑问一：
为什么两处计算空间复杂度的方法不一致，回复评论是以额外消耗为准，而文章中是以分配存储的空间为准？


疑问二：
《复杂度分析（上）》中介绍空间复杂度没有时间复杂度详细且带例子，看到老师您回复 JK David 以额外消耗为分析对象，就更懵圈了。
如果说：
1. 额外消耗常量值内存的空间复杂度是 O(1)；
2. 额外消耗 n 内存的空间复杂度是 O(n)；
那么空间复杂度是 O(n 的平方)，如何才能额外消耗 n 的平方空间呀？
老师能否针对空间复杂度，有一个更详细的说明和举例呢？


谢谢老师
2018-10-07


14

Kevin.zhang🌏
习题解，大部分同学都说到了方法一：半栈法
　　　　　１．用快慢两个指针遍历，同时用栈copy慢指针指向的data。
　　　　　２．完成后，慢指针指向中间节点，耗时为N/2.
　　　　　３．最后用pop栈中的data和慢指针指向的data比较，耗时也是N/2.
          所以时间复杂度为：Ｏ(N)，空间复杂度因栈额外存储了一半的data，故为O(N/2)

方法二：全栈法
　　　　　１．全部遍历，data压栈，额外空间消耗N
                    ２．再次全部遍历取data，同时pop栈取data, 二者比较，时间消耗2N
          所以时间复杂度为O(3N)，空间复杂度为O(N)
          该法算法最简单，但复杂度高。可以用栈存储节点指针，而非data来改进。

方法三：硬干法
　　　　　1. 一个指针从头取data，另一个指针遍历到底取data，比较二者
　　　　　２．删除尾部节点，重复１．
　　　时间复杂度高达　O(N^2)，空间复杂度却最低Ｏ(1)
2018-11-09

1

10

Smallfly
思考题：根据原有单链表回文创建一个逆向的单链表回文，while 循环遍历比较，复杂度为 O(N)。
2018-10-03


9

六六六
判断单链表是否是回文，只想到了这种low一些的做法，时间复杂度为O(n^2)：
public static boolean isHuiwen(LinkedList linkedList) {
        Node first = linkedList.getFirst();
        int size = linkedList.getSize();
        Node head = null;
        Node foot = null;
        for (int a = 0; a < size / 2; a++) {
            head = head == null ? first : head.next;
            foot = head;
            for (int i = a; i < size - 1 - a; i++) {
                foot = foot.next;
            }
            if (!head.getData().equals(foot.getData())) {
                return false;
            }
        }
        return true;
    }
2018-10-03

1

8

阳仔
学习反馈：
链表也是一种基础的线性表结构。由于它的很多特点跟数组是相反的，因此可以与数组一起对比着学习。
数组的存储空间是连续，而链表不是；数组可以通过寻址公式计算通过下标来访问，而链表访问元素需要遍历。
常见的链表有：
单链表、双向链表、循环链表、双向循环链表。
链表擅长插入、删除操作，时间复杂度为O(1)；查询的效率不高，时间复杂度为O(n)。
数组擅长通过下标随机访问元素，时间复杂度为O(1)；插入、删除的效率不高，时间复杂度为O(n)。
在实际项目开发中，选择数组或者链表不能只关注时间复杂度，还需要考虑具体业务，综合考虑选择数组还是链表。
了解了链表的数据结构，那么实现一个机遇链表数据结构的LRU算法就比较简单了：
从链表中查询此缓存数据是否存在：
1、如果存在，则删除该缓存数据节点，并把数据插入到链表头部的位置；
1、如果不存在，则也考虑两种情况：
    1、如果缓存充足，则把数据插入到链表头部的位置；
    2、如果缓存不足，则把链表中的末尾节点删除，再把缓存数据插入到头部。
思考题：
如果是只使用单链表的话，假设存储回文的链表是L1，再用一个链表L2来存储逆文；
我的思路是这样：
1、循环这个回文链表L1，在遍历到一半之前把逆文存在一个L2中；
例如L1 为A->B->C->B->A，那么遍历到一半时，L2为：B->A；
偶数和奇数的区别在与中间的节点要不要放在L2中。
2、继续遍历比较L1,L2两个链表各个元素是否相等，如果不相等则立即返回；如果比较到最后遍历结束，则说明是回文；
因此通过一次遍历就知道这个链表是否为回文。时间复杂度为O(n)。
作者回复: 👍

2018-10-03


7
收起评论

99+99+




# 07 | 链表（下）：如何轻松写出正确的链表代码？





数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



07 | 链表（下）：如何轻松写出正确的链表代码？
王争 2018-10-05



12:30
讲述：修阳 大小：5.73M
上一节我讲了链表相关的基础知识。学完之后，我看到有人留言说，基础知识我都掌握了，但是写链表代码还是很费劲。哈哈，的确是这样的！

想要写好链表代码并不是容易的事儿，尤其是那些复杂的链表操作，比如链表反转、有序链表合并等，写的时候非常容易出错。从我上百场面试的经验来看，能把“链表反转”这几行代码写对的人不足 10%。

为什么链表代码这么难写？究竟怎样才能比较轻松地写出正确的链表代码呢？

只要愿意投入时间，我觉得大多数人都是可以学会的。比如说，如果你真的能花上一个周末或者一整天的时间，就去写链表反转这一个代码，多写几遍，一直练到能毫不费力地写出 Bug free 的代码。这个坎还会很难跨吗？

当然，自己有决心并且付出精力是成功的先决条件，除此之外，我们还需要一些方法和技巧。我根据自己的学习经历和工作经验，总结了几个写链表代码技巧。如果你能熟练掌握这几个技巧，加上你的主动和坚持，轻松拿下链表代码完全没有问题。

技巧一：理解指针或引用的含义
事实上，看懂链表的结构并不是很难，但是一旦把它和指针混在一起，就很容易让人摸不着头脑。所以，要想写对链表代码，首先就要理解好指针。

我们知道，有些语言有“指针”的概念，比如 C 语言；有些语言没有指针，取而代之的是“引用”，比如 Java、Python。不管是“指针”还是“引用”，实际上，它们的意思都是一样的，都是存储所指对象的内存地址。

接下来，我会拿 C 语言中的“指针”来讲解，如果你用的是 Java 或者其他没有指针的语言也没关系，你把它理解成“引用”就可以了。

实际上，对于指针的理解，你只需要记住下面这句话就可以了：

将某个变量赋值给指针，实际上就是将这个变量的地址赋值给指针，或者反过来说，指针中存储了这个变量的内存地址，指向了这个变量，通过指针就能找到这个变量。

这句话听起来还挺拗口的，你可以先记住。我们回到链表代码的编写过程中，我来慢慢给你解释。

在编写链表代码的时候，我们经常会有这样的代码：p->next=q。这行代码是说，p 结点中的 next 指针存储了 q 结点的内存地址。

还有一个更复杂的，也是我们写链表代码经常会用到的：p->next=p->next->next。这行代码表示，p 结点的 next 指针存储了 p 结点的下下一个结点的内存地址。

掌握了指针或引用的概念，你应该可以很轻松地看懂链表代码。恭喜你，已经离写出链表代码近了一步！

技巧二：警惕指针丢失和内存泄漏
不知道你有没有这样的感觉，写链表代码的时候，指针指来指去，一会儿就不知道指到哪里了。所以，我们在写的时候，一定注意不要弄丢了指针。

指针往往都是怎么弄丢的呢？我拿单链表的插入操作为例来给你分析一下。



如图所示，我们希望在结点 a 和相邻的结点 b 之间插入结点 x，假设当前指针 p 指向结点 a。如果我们将代码实现变成下面这个样子，就会发生指针丢失和内存泄露。

p->next = x;  // 将 p 的 next 指针指向 x 结点；
x->next = p->next;  // 将 x 的结点的 next 指针指向 b 结点；
初学者经常会在这儿犯错。p->next 指针在完成第一步操作之后，已经不再指向结点 b 了，而是指向结点 x。第 2 行代码相当于将 x 赋值给 x->next，自己指向自己。因此，整个链表也就断成了两半，从结点 b 往后的所有结点都无法访问到了。

对于有些语言来说，比如 C 语言，内存管理是由程序员负责的，如果没有手动释放结点对应的内存空间，就会产生内存泄露。所以，我们插入结点时，一定要注意操作的顺序，要先将结点 x 的 next 指针指向结点 b，再把结点 a 的 next 指针指向结点 x，这样才不会丢失指针，导致内存泄漏。所以，对于刚刚的插入代码，我们只需要把第 1 行和第 2 行代码的顺序颠倒一下就可以了。

同理，删除链表结点时，也一定要记得手动释放内存空间，否则，也会出现内存泄漏的问题。当然，对于像 Java 这种虚拟机自动管理内存的编程语言来说，就不需要考虑这么多了。

技巧三：利用哨兵简化实现难度
首先，我们先来回顾一下单链表的插入和删除操作。如果我们在结点 p 后面插入一个新的结点，只需要下面两行代码就可以搞定。

new_node->next = p->next;
p->next = new_node;
但是，当我们要向一个空链表中插入第一个结点，刚刚的逻辑就不能用了。我们需要进行下面这样的特殊处理，其中 head 表示链表的头结点。所以，从这段代码，我们可以发现，对于单链表的插入操作，第一个结点和其他结点的插入逻辑是不一样的。

if (head == null) {
  head = new_node;
}
我们再来看单链表结点删除操作。如果要删除结点 p 的后继结点，我们只需要一行代码就可以搞定。

p->next = p->next->next;
但是，如果我们要删除链表中的最后一个结点，前面的删除代码就不 work 了。跟插入类似，我们也需要对于这种情况特殊处理。写成代码是这样子的：

if (head->next == null) {
   head = null;
}
从前面的一步一步分析，我们可以看出，针对链表的插入、删除操作，需要对插入第一个结点和删除最后一个结点的情况进行特殊处理。这样代码实现起来就会很繁琐，不简洁，而且也容易因为考虑不全而出错。如何来解决这个问题呢？

技巧三中提到的哨兵就要登场了。哨兵，解决的是国家之间的边界问题。同理，这里说的哨兵也是解决“边界问题”的，不直接参与业务逻辑。

还记得如何表示一个空链表吗？head=null 表示链表中没有结点了。其中 head 表示头结点指针，指向链表中的第一个结点。

如果我们引入哨兵结点，在任何时候，不管链表是不是空，head 指针都会一直指向这个哨兵结点。我们也把这种有哨兵结点的链表叫带头链表。相反，没有哨兵结点的链表就叫作不带头链表。

我画了一个带头链表，你可以发现，哨兵结点是不存储数据的。因为哨兵结点一直存在，所以插入第一个结点和插入其他结点，删除最后一个结点和删除其他结点，都可以统一为相同的代码实现逻辑了。



实际上，这种利用哨兵简化编程难度的技巧，在很多代码实现中都有用到，比如插入排序、归并排序、动态规划等。这些内容我们后面才会讲，现在为了让你感受更深，我再举一个非常简单的例子。代码我是用 C 语言实现的，不涉及语言方面的高级语法，很容易看懂，你可以类比到你熟悉的语言。

代码一：

// 在数组 a 中，查找 key，返回 key 所在的位置
// 其中，n 表示数组 a 的长度
int find(char* a, int n, char key) {
  // 边界条件处理，如果 a 为空，或者 n<=0，说明数组中没有数据，就不用 while 循环比较了
  if(a == null || n <= 0) {
    return -1;
  }
  
  int i = 0;
  // 这里有两个比较操作：i<n 和 a[i]==key.
  while (i < n) {
    if (a[i] == key) {
      return i;
    }
    ++i;
  }
  
  return -1;
}
代码二：

// 在数组 a 中，查找 key，返回 key 所在的位置
// 其中，n 表示数组 a 的长度
// 我举 2 个例子，你可以拿例子走一下代码
// a = {4, 2, 3, 5, 9, 6}  n=6 key = 7
// a = {4, 2, 3, 5, 9, 6}  n=6 key = 6
int find(char* a, int n, char key) {
  if(a == null || n <= 0) {
    return -1;
  }
  
  // 这里因为要将 a[n-1] 的值替换成 key，所以要特殊处理这个值
  if (a[n-1] == key) {
    return n-1;
  }
  
  // 把 a[n-1] 的值临时保存在变量 tmp 中，以便之后恢复。tmp=6。
  // 之所以这样做的目的是：希望 find() 代码不要改变 a 数组中的内容
  char tmp = a[n-1];
  // 把 key 的值放到 a[n-1] 中，此时 a = {4, 2, 3, 5, 9, 7}
  a[n-1] = key;
  
  int i = 0;
  // while 循环比起代码一，少了 i<n 这个比较操作
  while (a[i] != key) {
    ++i;
  }
  
  // 恢复 a[n-1] 原来的值, 此时 a= {4, 2, 3, 5, 9, 6}
  a[n-1] = tmp;
  
  if (i == n-1) {
    // 如果 i == n-1 说明，在 0...n-2 之间都没有 key，所以返回 -1
    return -1;
  } else {
    // 否则，返回 i，就是等于 key 值的元素的下标
    return i;
  }
}
对比两段代码，在字符串 a 很长的时候，比如几万、几十万，你觉得哪段代码运行得更快点呢？答案是代码二，因为两段代码中执行次数最多就是 while 循环那一部分。第二段代码中，我们通过一个哨兵 a[n-1] = key，成功省掉了一个比较语句 i<n，不要小看这一条语句，当累积执行万次、几十万次时，累积的时间就很明显了。

当然，这只是为了举例说明哨兵的作用，你写代码的时候千万不要写第二段那样的代码，因为可读性太差了。大部分情况下，我们并不需要如此追求极致的性能。

技巧四：重点留意边界条件处理
软件开发中，代码在一些边界或者异常情况下，最容易产生 Bug。链表代码也不例外。要实现没有 Bug 的链表代码，一定要在编写的过程中以及编写完成之后，检查边界条件是否考虑全面，以及代码在边界条件下是否能正确运行。

我经常用来检查链表代码是否正确的边界条件有这样几个：

如果链表为空时，代码是否能正常工作？

如果链表只包含一个结点时，代码是否能正常工作？

如果链表只包含两个结点时，代码是否能正常工作？

代码逻辑在处理头结点和尾结点的时候，是否能正常工作？

当你写完链表代码之后，除了看下你写的代码在正常的情况下能否工作，还要看下在上面我列举的几个边界条件下，代码仍然能否正确工作。如果这些边界条件下都没有问题，那基本上可以认为没有问题了。

当然，边界条件不止我列举的那些。针对不同的场景，可能还有特定的边界条件，这个需要你自己去思考，不过套路都是一样的。

实际上，不光光是写链表代码，你在写任何代码时，也千万不要只是实现业务正常情况下的功能就好了，一定要多想想，你的代码在运行的时候，可能会遇到哪些边界情况或者异常情况。遇到了应该如何应对，这样写出来的代码才够健壮！

技巧五：举例画图，辅助思考
对于稍微复杂的链表操作，比如前面我们提到的单链表反转，指针一会儿指这，一会儿指那，一会儿就被绕晕了。总感觉脑容量不够，想不清楚。所以这个时候就要使用大招了，举例法和画图法。

你可以找一个具体的例子，把它画在纸上，释放一些脑容量，留更多的给逻辑思考，这样就会感觉到思路清晰很多。比如往单链表中插入一个数据这样一个操作，我一般都是把各种情况都举一个例子，画出插入前和插入后的链表变化，如图所示：



看图写代码，是不是就简单多啦？而且，当我们写完代码之后，也可以举几个例子，画在纸上，照着代码走一遍，很容易就能发现代码中的 Bug。

技巧六：多写多练，没有捷径
如果你已经理解并掌握了我前面所讲的方法，但是手写链表代码还是会出现各种各样的错误，也不要着急。因为我最开始学的时候，这种状况也持续了一段时间。

现在我写这些代码，简直就和“玩儿”一样，其实也没有什么技巧，就是把常见的链表操作都自己多写几遍，出问题就一点一点调试，熟能生巧！

所以，我精选了 5 个常见的链表操作。你只要把这几个操作都能写熟练，不熟就多写几遍，我保证你之后再也不会害怕写链表代码。

单链表反转

链表中环的检测

两个有序的链表合并

删除链表倒数第 n 个结点

求链表的中间结点

内容小结
这节我主要和你讲了写出正确链表代码的六个技巧。分别是理解指针或引用的含义、警惕指针丢失和内存泄漏、利用哨兵简化实现难度、重点留意边界条件处理，以及举例画图、辅助思考，还有多写多练。

我觉得，写链表代码是最考验逻辑思维能力的。因为，链表代码到处都是指针的操作、边界条件的处理，稍有不慎就容易产生 Bug。链表代码写得好坏，可以看出一个人写代码是否够细心，考虑问题是否全面，思维是否缜密。所以，这也是很多面试官喜欢让人手写链表代码的原因。所以，这一节讲到的东西，你一定要自己写代码实现一下，才有效果。

课后思考
今天我们讲到用哨兵来简化编码实现，你是否还能够想到其他场景，利用哨兵可以大大地简化编码难度？

欢迎留言和我分享，我会第一时间给你反馈。

我已将本节内容相关的详细代码更新到 GitHub，戳此即可查看。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(261)

zeta 置顶
建议大家在实现之前的思考时间不要太长。一是先用自己能想到的暴力方法实现试试。另外就是在一定时间内(比如半个到一个小时)实在想不到就要在网上搜搜答案。有的算法，比如链表中环的检测，的最优解法还是挺巧妙的，一般来说不是生想就能想到的
作者回复: 👍，高手！实际上，写链表代码还是主要为了锻炼写代码的能力，倒不是思考解决办法。像环的检测这种解决办法我也想不出来，都是看了答案之后恍然大悟。

2018-10-06

2

194

0xFFFFFFFF
练习题LeetCode对应编号：206，141，21，19，876。大家可以去练习，另外建议作者兄每章直接给出LC的题目编号或链接方便大家练习。
作者回复: 我可以集中写一篇练习题的。现在这种思考题的方式是早就定好的了。不好改了。

2018-10-06

2

294

姜威
总结：如何优雅的写出链表代码？6大学习技巧

一、理解指针或引用的含义
1.含义：将某个变量（对象）赋值给指针（引用），实际上就是就是将这个变量（对象）的地址赋值给指针（引用）。
2.示例：
p—>next = q; 表示p节点的后继指针存储了q节点的内存地址。
p—>next = p—>next—>next; 表示p节点的后继指针存储了p节点的下下个节点的内存地址。

二、警惕指针丢失和内存泄漏（单链表）
1.插入节点
在节点a和节点b之间插入节点x，b是a的下一节点，，p指针指向节点a，则造成指针丢失和内存泄漏的代码：p—>next = x;x—>next = p—>next; 显然这会导致x节点的后继指针指向自身。
正确的写法是2句代码交换顺序，即：x—>next = p—>next; p—>next = x;
2.删除节点
在节点a和节点b之间删除节点b，b是a的下一节点，p指针指向节点a：p—>next = p—>next—>next;

三、利用“哨兵”简化实现难度
1.什么是“哨兵”？
链表中的“哨兵”节点是解决边界问题的，不参与业务逻辑。如果我们引入“哨兵”节点，则不管链表是否为空，head指针都会指向这个“哨兵”节点。我们把这种有“哨兵”节点的链表称为带头链表，相反，没有“哨兵”节点的链表就称为不带头链表。
2.未引入“哨兵”的情况
如果在p节点后插入一个节点，只需2行代码即可搞定：
new_node—>next = p—>next;
p—>next = new_node;
但，若向空链表中插入一个节点，则代码如下：
if(head == null){
head = new_node;
}
如果要删除节点p的后继节点，只需1行代码即可搞定：
p—>next = p—>next—>next;
但，若是删除链表的最有一个节点（链表中只剩下这个节点），则代码如下：
if(head—>next == null){
head = null;
}
从上面的情况可以看出，针对链表的插入、删除操作，需要对插入第一个节点和删除最后一个节点的情况进行特殊处理。这样代码就会显得很繁琐，所以引入“哨兵”节点来解决这个问题。
3.引入“哨兵”的情况
“哨兵”节点不存储数据，无论链表是否为空，head指针都会指向它，作为链表的头结点始终存在。这样，插入第一个节点和插入其他节点，删除最后一个节点和删除其他节点都可以统一为相同的代码实现逻辑了。
4.“哨兵”还有哪些应用场景？
这个知识有限，暂时想不出来呀！但总结起来，哨兵最大的作用就是简化边界条件的处理。

四、重点留意边界条件处理
经常用来检查链表是否正确的边界4个边界条件：
1.如果链表为空时，代码是否能正常工作？
2.如果链表只包含一个节点时，代码是否能正常工作？
3.如果链表只包含两个节点时，代码是否能正常工作？
4.代码逻辑在处理头尾节点时是否能正常工作？

五、举例画图，辅助思考
核心思想：释放脑容量，留更多的给逻辑思考，这样就会感觉到思路清晰很多。

六、多写多练，没有捷径
5个常见的链表操作：
1.单链表反转
2.链表中环的检测
3.两个有序链表合并
4.删除链表倒数第n个节点
5.求链表的中间节点
2018-10-05

1

127

optvxq
哨兵可以理解为它可以减少特殊情况的判断，比如判空，比如判越界，比如减少链表插入删除中对空链表的判断，比如例子中对i越界的判断。

空与越界可以认为是小概率情况，所以代码每一次操作都走一遍判断，在大部分情况下都会是多余的。

哨兵的巧妙就是提前将这种情况去除，比如给一个哨兵结点，以及将key赋值给数组末元素，让数组遍历不用判断越界也可以因为相等停下来。

使用哨兵的指导思想应该是将小概率需要的判断先提前扼杀，比如提前给他一个值让他不为null，或者提前预设值，或者多态的时候提前给个空实现，然后在每一次操作中不必再判断以增加效率。
2018-10-10


60

Rain
谢谢老师，这节课又学到了，写完留言我要去思考那几个问题了，一个都不会。。

----

文中提到，

但是，如果我们要删除链表中的最后一个结点，前面的删除代码就不 work 了。跟插入类似，我们也需要对于这种情况特殊处理。写成代码是这样子的：

if (head->next == null) {
   head = null;
}

----

感觉此处代码处理的是当链表中只有表头一个节点的删除情况，而不是"要删除链表中的最后一个结点"的情况。是不是head应该改成p?
2018-10-05


54

五岳寻仙
老师您好！请教您一个问题。在学习了数组和链表之后，想知道在现实应用中有没有将二者结合起来的情况。
比如，我想用数组存储数据，但数组大小提前无法知道，如果使用动态数组的话，中间涉及到数组拷贝；如果使用链表的话，每增加一个元素都要malloc一次（频繁的malloc会不会影响效率并且导致内存碎片？）。
可不可以用链表将数组链接起来？也就是说链表里每个node存储了数组指针，这样每增加一个节点就可以多存放很多元素。如果可以的话，与直接使用动态数组或者直接使用链表比有没有什么优缺点，为何在网上搜索几乎找不到人这样用？
作者回复: 👍 思考的深入 你说的这个很像内存池 你可以百度一下看看是不是你想要的

2018-10-07

5

39

zyzheng
一直对手写链表代码有恐惧心理，这次硬着头皮也要迈过这个坎
2018-10-05


37

千方残光
/**
public class Node {
public char c;
public Node next;

public Node(char c) {
this.c = c;
}
}
**/

public static Node reverse(Node head) {
if(head == null || head.next == null) {
return head;
}

Node prev = null;
Node cur = head;
Node next = head.next;

while(next != null) {
cur.next = prev;
prev = cur;
cur = next;
next = cur.next;
}
cur.next = prev;
return cur;
}


public static boolean existsCircle(Node head) {
Node slow = head;
Node fast = head;
while(fast != null && fast.next != null) {
slow = slow.next;
fast = fast.next.next;
if(slow == fast) {
return true;
}
}
return false;
}

public static Node merge(Node head1, Node head2) {

Node guard = new Node('/');
Node cur = guard;

while(head1 != null && head2 != null) {
if(head1.c <= head2.c) {
while(head1 != null && head1.c <= head2.c) {
cur.next = head1;
cur = cur.next;
head1 = head1.next;

}
} else {
while(head2 != null && head1.c > head2.c) {
cur.next = head2;
cur = cur.next;
head2 = head2.next;

}
}
}

if(head1 != null) {
cur.next = head1;
}
if(head2 != null) {
cur.next = head2;
}

return guard.next;

}

public static Node deleteLastN(Node head, int n) {
if(n < 1 || head == null) {
return head;
}
Node guard = new Node('/');
guard.next = head;

Node slow = guard;
Node fast = guard;

for(int i = 0; i < n; i++) {
if(fast != null) {
fast = fast.next;
}
}
while(fast != null && fast.next != null) {
slow = slow.next;
fast = fast.next;
}
slow.next = slow.next.next;
return guard.next;
}

public static Node getMiddle(Node head, int n) {
Node slow = head;
Node fast = head;

while(fast.next != null && fast.next.next != null) {
slow = slow.next;
fast = fast.next.next;
}

return slow;
}
2018-10-09

1

31

来自地狱的勇士
问题一：文中提到，指针丢失会导致内存泄露，老师能解释下如何导致的内存泄露吗？
问题二：讲哨兵那块的内容时，说代码二比代码一成功省掉了一次比较i<n，这句不大理解，代码二中，while的条件a[i]!=key也是在比较吧？
2018-10-05

2

28

小喵喵
学习了好几节数据结构和算法了，我是也CRUD业务代码的，感觉还是用不着啊？
作者回复: 1. 建议再看下“为什么要学习数据结构和算法”那节课，包括里面的留言，有很多留言都写的很好，很多人都对这门课有比较清晰深刻的认识。
2. 你的疑问应该是：局限于你现在的工作，你觉得用不上对吧。这个是很有可能的。如果你做的项目都是很小的项目，也没有什么性能压力，平时自己也不去思考非功能性的需求，只是完成业务代码就ok了，那确实感觉用不到。但这是你个人的原因，并不代表就真用不到呢，兄弟！
3. 专栏里有很多贴近开发的内容，比如链表这一节，我就讲了LRU算法。数组这一节，我讲了容器和数组的选择。复杂度这一节，我讲了如何预判代码的性能。这些都是很贴合开发的。
4. 我尽量将内容贴近实际的开发，但并不代表一定贴近你的CRUD开发。知识如何用到你的项目中，需要你自己根据我的文章举一反三的思考。

2018-10-05


15

Smallfly
如何写好链表代码？

1. 理解指针或引用的含义
什么是指针？指针是一个变量，该变量中存的是其它变量的地址。将普通变量赋值给指针变量，其实是把它的地址赋值给指针变量。

2. 警惕指针丢失和内存泄漏
在插入和删除结点时，要注意先持有后面的结点再操作，否者一旦后面结点的前继指针被断开，就无法再访问，导致内存泄漏。

3. 利用哨兵简化难度
链表的插入、删除操作，需要对插入第一个结点和删除最后一个节点做特殊处理。利用哨兵对象可以不用边界判断，链表的哨兵对象是只存指针不存数据的头结点。

4. 重点留意边界条件处理
操作链表时要考虑链表为空、一个结点、两个结点、头结点、尾结点的情况。学习数据结构和算法主要是掌握一系列思想，能在其它的编码中也养成考虑边界的习惯。

5. 举例画图，辅助思考
对于比较复杂的操作，可以用纸笔画一画，释放脑容量来做逻辑处理（时间换空间思想），也便于完成后的检查。

6. 多写多练，没有捷径
孰能生巧，不管是什么算法，只有经过反复的练习，才能信手拈来。


哨兵对象思想，在 iOS AutoreleasePool 中有用到，在 AutoreleasePoolPush 时添加一个哨兵对象，Pop 时将到哨兵对象之间的所有 Autorelease 对象发送 release 消息。
2018-10-05


12

gogo
c语言不熟悉 看起来有点吃力
作者回复: 不好意思 我尽量写简单点 多加点注释

2018-10-05


12

王振华 程序员 区块链
但是，如果我们要删除链表中的最后一个结点，前面的删除代码就不work了。
```
if (head->next == null) {
    head = null
}
```
这里的head表示的是最后一个结点吗？

“对于带头链表，插入头结点和插入其它节点，可以统一为相同的逻辑。”这我可以理解

但即使是带头链表，删除尾结点和删除其它节点，还是不能统一代码呀。

`p->next = p->next->next;` 无论是否是带头链表，对尾结点都没有影响呀。这行代码还是不能用于尾结点的删除呀？
作者回复: 你理解错我的意思了。我说的最后一个结点的意思是：链表中只剩下一个结点。并不是指尾结点。

2018-10-06

2

11

失火的夏天
1.三个节点p.pre，p，p.next，将p的next指针指向p.pre，然后p.pre=p，p=p.next，p.next=p.next.next移动指针，就可以实现单链表反转。
2.最简单就是一个节点在头，一个节点一直遍历，地址相等就是环，不过好像还有一种简单的办法，快慢前进，一次就能搞定。这个老师能不能说下自己的思路，我有点想不明白。
3.建立第三个链表，每次比较a链表当前节点和b链表当前节点的大小。如果a比b小，则c的next指针指向a当前节点，c=c.next，然后a指针后移。接着继续比较a.b当前节点大小，反之则把a换成b就行了。
4.一个p节点，然后找到距离p有n个next节点的点，一起往后遍历，到pn.next为空的时候，p就是我们要求的那个地址。
5.快慢指针，一个每次前进2个节点一个每次前进1节点。前进两个节点到表尾的时候，前进一个的就是中间点。
2018-10-05


10

匆匆
关于练习链表的一点体会

1、 函数中需要移动链表时，最好新建一个指针来移动，以免更改原始指针位置。

2、 单链表有带头节点和不带头结点的链表之分，一般做题默认头结点是有值的。

3、 链表的内存时不连续的，一个节点占一块内存，每块内存中有一块位置（next）存放下一节点的地址（这是单链表为例）。

3、 链表中找环的思想：创建两个指针一个快指针一次走两步一个慢指针一次走一步，若相遇则有环，若先指向nullptr则无环。

4、 链表找倒数第k个节点思想：创建两个指针，第一个先走k-1步然后两个在一同走。第一个走到最后时则第二个指针指向倒数第k位置。

5、 反向链表思想：从前往后将每个节点的指针反向，即.next内的地址换成前一个节点的，但为了防止后面链表的丢失，在每次换之前需要先创建个指针指向下一个节点。

6、 两个有序链表合并思想：这里用到递归思想。先判断是否有一个链表是空链表，是则返回两一个链表，免得指针指向不知名区域引发程序崩溃。然后每次比较两个链表的头结点，小的值做新链表的头结点，此节点的next指针指向本函数（递归开始，参数是较小值所在链表.next和另一个链表）。
2018-12-02


9

鲫鱼
快哭了，跨专业学习，就自学了一点python。都不知道要怎么去理解了😭
但是还是能理解一点的，慢慢坑了
作者回复: 买本大话数据结构或者算法图解结合着看吧 这门课本身就比较难学 只能多花点时间了呢

2018-10-09


9

Miletos
C语言，二级指针可以绕过不带头结点链表删除操作的边界检查。
2018-10-05


9

hope
看完了，打卡，稍后手写作业，去GitHub上看了下 ，希望老师把c的代码也添加上，谢谢
作者回复: 要不你写下 提个pull request？

2018-10-05


7

广进
作为一个小白，每节课都有看不懂的，这次又来了，那个代码二，从while往下就不懂了，怎么感觉和一的功能不一样了。求指导。

还有您都觉得二可读性差了，加点注释照顾照顾我们这些小白呀。😭
作者回复: 不好意思 我以后多加点注释 不过两段代码的功能是一样的

2018-10-05


6

莫弹弹
代码二示例返回值int是不是写成inf了哈哈哈

算法设计思路应该是
// 用来找出给定key在数组中的下标，找不到则返回-1

a是被遍历的数组
n是数组长度
key是要寻找的值

1， 判断尾节点是不是要寻找的值，是的话返回n-1，因为数组下标从0开始所以要长度-1才是下标

2， 使用哨兵变量保存尾节点

3， 把key放到尾节点，让key成为数组中最后一个值，这样做是为了下一步的遍历

4， 开始从头开始遍历数组，i为数组下标，如果找到与key相等的元素则退出遍历，否则遍历整个数组

5， 如果i是尾节点下标，说明没有找到key，如果不是则i为寻找的节点下标，返回i

6， 把哨兵变量还原赋值到数组尾节点，也就是还原数组

也就是说平时用的临时变量就是哨兵变量
2018-10-06


5
收起评论

99+99+





# 08 | 栈：如何实现浏览器的前进和后退功能？




数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



08 | 栈：如何实现浏览器的前进和后退功能？
王争 2018-10-08



14:12
讲述：修阳 大小：6.51M
浏览器的前进、后退功能，我想你肯定很熟悉吧？

当你依次访问完一串页面 a-b-c 之后，点击浏览器的后退按钮，就可以查看之前浏览过的页面 b 和 a。当你后退到页面 a，点击前进按钮，就可以重新查看页面 b 和 c。但是，如果你后退到页面 b 后，点击了新的页面 d，那就无法再通过前进、后退功能查看页面 c 了。

假设你是 Chrome 浏览器的开发工程师，你会如何实现这个功能呢？

这就要用到我们今天要讲的“栈”这种数据结构。带着这个问题，我们来学习今天的内容。

如何理解“栈”？
关于“栈”，我有一个非常贴切的例子，就是一摞叠在一起的盘子。我们平时放盘子的时候，都是从下往上一个一个放；取的时候，我们也是从上往下一个一个地依次取，不能从中间任意抽出。后进者先出，先进者后出，这就是典型的“栈”结构。



从栈的操作特性上来看，栈是一种“操作受限”的线性表，只允许在一端插入和删除数据。

我第一次接触这种数据结构的时候，就对它存在的意义产生了很大的疑惑。因为我觉得，相比数组和链表，栈带给我的只有限制，并没有任何优势。那我直接使用数组或者链表不就好了吗？为什么还要用这个“操作受限”的“栈”呢？

事实上，从功能上来说，数组或链表确实可以替代栈，但你要知道，特定的数据结构是对特定场景的抽象，而且，数组或链表暴露了太多的操作接口，操作上的确灵活自由，但使用时就比较不可控，自然也就更容易出错。

当某个数据集合只涉及在一端插入和删除数据，并且满足后进先出、先进后出的特性，我们就应该首选“栈”这种数据结构。

如何实现一个“栈”？
从刚才栈的定义里，我们可以看出，栈主要包含两个操作，入栈和出栈，也就是在栈顶插入一个数据和从栈顶删除一个数据。理解了栈的定义之后，我们来看一看如何用代码实现一个栈。

实际上，栈既可以用数组来实现，也可以用链表来实现。用数组实现的栈，我们叫作顺序栈，用链表实现的栈，我们叫作链式栈。

我这里实现一个基于数组的顺序栈。基于链表实现的链式栈的代码，你可以自己试着写一下。我会将我写好的代码放到 Github 上，你可以去看一下自己写的是否正确。

我这段代码是用 Java 来实现的，但是不涉及任何高级语法，并且我还用中文做了详细的注释，所以你应该是可以看懂的。

// 基于数组实现的顺序栈
public class ArrayStack {
  private String[] items;  // 数组
  private int count;       // 栈中元素个数
  private int n;           // 栈的大小
 
  // 初始化数组，申请一个大小为 n 的数组空间
  public ArrayStack(int n) {
    this.items = new String[n];
    this.n = n;
    this.count = 0;
  }
 
  // 入栈操作
  public boolean push(String item) {
    // 数组空间不够了，直接返回 false，入栈失败。
    if (count == n) return false;
    // 将 item 放到下标为 count 的位置，并且 count 加一
    items[count] = item;
    ++count;
    return true;
  }
  
  // 出栈操作
  public String pop() {
    // 栈为空，则直接返回 null
    if (count == 0) return null;
    // 返回下标为 count-1 的数组元素，并且栈中元素个数 count 减一
    String tmp = items[count-1];
    --count;
    return tmp;
  }
}
了解了定义和基本操作，那它的操作的时间、空间复杂度是多少呢？

不管是顺序栈还是链式栈，我们存储数据只需要一个大小为 n 的数组就够了。在入栈和出栈过程中，只需要一两个临时变量存储空间，所以空间复杂度是 O(1)。

注意，这里存储数据需要一个大小为 n 的数组，并不是说空间复杂度就是 O(n)。因为，这 n 个空间是必须的，无法省掉。所以我们说空间复杂度的时候，是指除了原本的数据存储空间外，算法运行还需要额外的存储空间。

空间复杂度分析是不是很简单？时间复杂度也不难。不管是顺序栈还是链式栈，入栈、出栈只涉及栈顶个别数据的操作，所以时间复杂度都是 O(1)。

支持动态扩容的顺序栈
刚才那个基于数组实现的栈，是一个固定大小的栈，也就是说，在初始化栈时需要事先指定栈的大小。当栈满之后，就无法再往栈里添加数据了。尽管链式栈的大小不受限，但要存储 next 指针，内存消耗相对较多。那我们如何基于数组实现一个可以支持动态扩容的栈呢？

你还记得，我们在数组那一节，是如何来实现一个支持动态扩容的数组的吗？当数组空间不够时，我们就重新申请一块更大的内存，将原来数组中数据统统拷贝过去。这样就实现了一个支持动态扩容的数组。

所以，如果要实现一个支持动态扩容的栈，我们只需要底层依赖一个支持动态扩容的数组就可以了。当栈满了之后，我们就申请一个更大的数组，将原来的数据搬移到新数组中。我画了一张图，你可以对照着理解一下。



实际上，支持动态扩容的顺序栈，我们平时开发中并不常用到。我讲这一块的目的，主要还是希望带你练习一下前面讲的复杂度分析方法。所以这一小节的重点是复杂度分析。

你不用死记硬背入栈、出栈的时间复杂度，你需要掌握的是分析方法。能够自己分析才算是真正掌握了。现在我就带你分析一下支持动态扩容的顺序栈的入栈、出栈操作的时间复杂度。

对于出栈操作来说，我们不会涉及内存的重新申请和数据的搬移，所以出栈的时间复杂度仍然是 O(1)。但是，对于入栈操作来说，情况就不一样了。当栈中有空闲空间时，入栈操作的时间复杂度为 O(1)。但当空间不够时，就需要重新申请内存和数据搬移，所以时间复杂度就变成了 O(n)。

也就是说，对于入栈操作来说，最好情况时间复杂度是 O(1)，最坏情况时间复杂度是 O(n)。那平均情况下的时间复杂度又是多少呢？还记得我们在复杂度分析那一节中讲的摊还分析法吗？这个入栈操作的平均情况下的时间复杂度可以用摊还分析法来分析。我们也正好借此来实战一下摊还分析法。

为了分析的方便，我们需要事先做一些假设和定义：

栈空间不够时，我们重新申请一个是原来大小两倍的数组；

为了简化分析，假设只有入栈操作没有出栈操作；

定义不涉及内存搬移的入栈操作为 simple-push 操作，时间复杂度为 O(1)。

如果当前栈大小为 K，并且已满，当再有新的数据要入栈时，就需要重新申请 2 倍大小的内存，并且做 K 个数据的搬移操作，然后再入栈。但是，接下来的 K-1 次入栈操作，我们都不需要再重新申请内存和搬移数据，所以这 K-1 次入栈操作都只需要一个 simple-push 操作就可以完成。为了让你更加直观地理解这个过程，我画了一张图。



你应该可以看出来，这 K 次入栈操作，总共涉及了 K 个数据的搬移，以及 K 次 simple-push 操作。将 K 个数据搬移均摊到 K 次入栈操作，那每个入栈操作只需要一个数据搬移和一个 simple-push 操作。以此类推，入栈操作的均摊时间复杂度就为 O(1)。

通过这个例子的实战分析，也印证了前面讲到的，均摊时间复杂度一般都等于最好情况时间复杂度。因为在大部分情况下，入栈操作的时间复杂度 O 都是 O(1)，只有在个别时刻才会退化为 O(n)，所以把耗时多的入栈操作的时间均摊到其他入栈操作上，平均情况下的耗时就接近 O(1)。

栈在函数调用中的应用
前面我讲的都比较偏理论，我们现在来看下，栈在软件工程中的实际应用。栈作为一个比较基础的数据结构，应用场景还是蛮多的。其中，比较经典的一个应用场景就是函数调用栈。

我们知道，操作系统给每个线程分配了一块独立的内存空间，这块内存被组织成“栈”这种结构, 用来存储函数调用时的临时变量。每进入一个函数，就会将临时变量作为一个栈帧入栈，当被调用函数执行完成，返回之后，将这个函数对应的栈帧出栈。为了让你更好地理解，我们一块来看下这段代码的执行过程。

int main() {
   int a = 1; 
   int ret = 0;
   int res = 0;
   ret = add(3, 5);
   res = a + ret;
   printf("%d", res);
   reuturn 0;
}
 
int add(int x, int y) {
   int sum = 0;
   sum = x + y;
   return sum;
}
从代码中我们可以看出，main() 函数调用了 add() 函数，获取计算结果，并且与临时变量 a 相加，最后打印 res 的值。为了让你清晰地看到这个过程对应的函数栈里出栈、入栈的操作，我画了一张图。图中显示的是，在执行到 add() 函数时，函数调用栈的情况。



栈在表达式求值中的应用
我们再来看栈的另一个常见的应用场景，编译器如何利用栈来实现表达式求值。

为了方便解释，我将算术表达式简化为只包含加减乘除四则运算，比如：34+13*9+44-12/3。对于这个四则运算，我们人脑可以很快求解出答案，但是对于计算机来说，理解这个表达式本身就是个挺难的事儿。如果换作你，让你来实现这样一个表达式求值的功能，你会怎么做呢？

实际上，编译器就是通过两个栈来实现的。其中一个保存操作数的栈，另一个是保存运算符的栈。我们从左向右遍历表达式，当遇到数字，我们就直接压入操作数栈；当遇到运算符，就与运算符栈的栈顶元素进行比较。

如果比运算符栈顶元素的优先级高，就将当前运算符压入栈；如果比运算符栈顶元素的优先级低或者相同，从运算符栈中取栈顶运算符，从操作数栈的栈顶取 2 个操作数，然后进行计算，再把计算完的结果压入操作数栈，继续比较。

我将 3+5*8-6 这个表达式的计算过程画成了一张图，你可以结合图来理解我刚讲的计算过程。



这样用两个栈来解决的思路是不是非常巧妙？你有没有想到呢？

栈在括号匹配中的应用
除了用栈来实现表达式求值，我们还可以借助栈来检查表达式中的括号是否匹配。

我们同样简化一下背景。我们假设表达式中只包含三种括号，圆括号 ()、方括号 [] 和花括号{}，并且它们可以任意嵌套。比如，{[{}]}或 [{()}([])] 等都为合法格式，而{[}()] 或 [({)] 为不合法的格式。那我现在给你一个包含三种括号的表达式字符串，如何检查它是否合法呢？

这里也可以用栈来解决。我们用栈来保存未匹配的左括号，从左到右依次扫描字符串。当扫描到左括号时，则将其压入栈中；当扫描到右括号时，从栈顶取出一个左括号。如果能够匹配，比如“(”跟“)”匹配，“[”跟“]”匹配，“{”跟“}”匹配，则继续扫描剩下的字符串。如果扫描的过程中，遇到不能配对的右括号，或者栈中没有数据，则说明为非法格式。

当所有的括号都扫描完成之后，如果栈为空，则说明字符串为合法格式；否则，说明有未匹配的左括号，为非法格式。

解答开篇
好了，我想现在你已经完全理解了栈的概念。我们再回来看看开篇的思考题，如何实现浏览器的前进、后退功能？其实，用两个栈就可以非常完美地解决这个问题。

我们使用两个栈，X 和 Y，我们把首次浏览的页面依次压入栈 X，当点击后退按钮时，再依次从栈 X 中出栈，并将出栈的数据依次放入栈 Y。当我们点击前进按钮时，我们依次从栈 Y 中取出数据，放入栈 X 中。当栈 X 中没有数据时，那就说明没有页面可以继续后退浏览了。当栈 Y 中没有数据，那就说明没有页面可以点击前进按钮浏览了。

比如你顺序查看了 a，b，c 三个页面，我们就依次把 a，b，c 压入栈，这个时候，两个栈的数据就是这个样子：



当你通过浏览器的后退按钮，从页面 c 后退到页面 a 之后，我们就依次把 c 和 b 从栈 X 中弹出，并且依次放入到栈 Y。这个时候，两个栈的数据就是这个样子：



这个时候你又想看页面 b，于是你又点击前进按钮回到 b 页面，我们就把 b 再从栈 Y 中出栈，放入栈 X 中。此时两个栈的数据是这个样子：



这个时候，你通过页面 b 又跳转到新的页面 d 了，页面 c 就无法再通过前进、后退按钮重复查看了，所以需要清空栈 Y。此时两个栈的数据这个样子：



内容小结
我们来回顾一下今天讲的内容。栈是一种操作受限的数据结构，只支持入栈和出栈操作。后进先出是它最大的特点。栈既可以通过数组实现，也可以通过链表来实现。不管基于数组还是链表，入栈、出栈的时间复杂度都为 O(1)。除此之外，我们还讲了一种支持动态扩容的顺序栈，你需要重点掌握它的均摊时间复杂度分析方法。

课后思考
我们在讲栈的应用时，讲到用函数调用栈来保存临时变量，为什么函数调用要用“栈”来保存临时变量呢？用其他数据结构不行吗？

我们都知道，JVM 内存管理中有个“堆栈”的概念。栈内存用来存储局部变量和方法调用，堆内存用来存储 Java 中的对象。那 JVM 里面的“栈”跟我们这里说的“栈”是不是一回事呢？如果不是，那它为什么又叫作“栈”呢？

欢迎留言和我分享，我会第一时间给你反馈。

我已将本节内容相关的详细代码更新到 GitHub，戳此即可查看。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(217)

阿杜S考特 置顶
内存中的堆栈和数据结构堆栈不是一个概念，可以说内存中的堆栈是真实存在的物理区，数据结构中的堆栈是抽象的数据存储结构。
        内存空间在逻辑上分为三部分：代码区、静态数据区和动态数据区，动态数据区又分为栈区和堆区。
代码区：存储方法体的二进制代码。高级调度（作业调度）、中级调度（内存调度）、低级调度（进程调度）控制代码区执行代码的切换。
静态数据区：存储全局变量、静态变量、常量，常量包括final修饰的常量和String常量。系统自动分配和回收。
栈区：存储运行方法的形参、局部变量、返回值。由系统自动分配和回收。
堆区：new一个对象的引用或地址存储在栈区，指向该对象存储在堆区中的真实数据。

2018-10-08


286

王争 置顶
为什么函数调用要用“栈”来保存临时变量呢？用其他数据结构不行吗？

其实，我们不一定非要用栈来保存临时变量，只不过如果这个函数调用符合后进先出的特性，用栈这种数据结构来实现，是最顺理成章的选择。

从调用函数进入被调用函数，对于数据来说，变化的是什么呢？是作用域。所以根本上，只要能保证每进入一个新的函数，都是一个新的作用域就可以。而要实现这个，用栈就非常方便。在进入被调用函数的时候，分配一段栈空间给这个函数的变量，在函数结束的时候，将栈顶复位，正好回到调用函数的作用域内。
2018-11-01

3

155

他在她城断了弦
leetcode上关于栈的题目大家可以先做20,155,232,844,224,682,496.
2018-10-15


331

阿杜S考特
内存中的堆栈和数据结构堆栈不是一个概念，可以说内存中的堆栈是真实存在的物理区，数据结构中的堆栈是抽象的数据存储结构。
        内存空间在逻辑上分为三部分：代码区、静态数据区和动态数据区，动态数据区又分为栈区和堆区。
代码区：存储方法体的二进制代码。高级调度（作业调度）、中级调度（内存调度）、低级调度（进程调度）控制代码区执行代码的切换。
静态数据区：存储全局变量、静态变量、常量，常量包括final修饰的常量和String常量。系统自动分配和回收。
栈区：存储运行方法的形参、局部变量、返回值。由系统自动分配和回收。
堆区：new一个对象的引用或地址存储在栈区，指向该对象存储在堆区中的真实数据。

2018-10-08


183

姜威
一、什么是栈？
1.后进者先出，先进者后出，这就是典型的“栈”结构。
2.从栈的操作特性来看，是一种“操作受限”的线性表，只允许在端插入和删除数据。
二、为什么需要栈？
1.栈是一种操作受限的数据结构，其操作特性用数组和链表均可实现。
2.但，任何数据结构都是对特定应用场景的抽象，数组和链表虽然使用起来更加灵活，但却暴露了几乎所有的操作，难免会引发错误操作的风险。
3.所以，当某个数据集合只涉及在某端插入和删除数据，且满足后进者先出，先进者后出的操作特性时，我们应该首选栈这种数据结构。
三、如何实现栈？
1.栈的API
public class Stack<Item> {
//压栈
public void push(Item item){}
//弹栈
public Item pop(){}
//是否为空
public boolean isEmpty(){}
//栈中数据的数量
public int size(){}
//返回栈中最近添加的元素而不删除它
public Item peek(){}
}
2.数组实现（自动扩容）
时间复杂度分析：根据均摊复杂度的定义，可以得数组实现（自动扩容）符合大多数情况是O(1)级别复杂度，个别情况是O(n)级别复杂度，比如自动扩容时，会进行完整数据的拷贝。
空间复杂度分析：在入栈和出栈的过程中，只需要一两个临时变量存储空间，所以O(1)级别。我们说空间复杂度的时候，是指除了原本的数据存储空间外，算法运行还需要额外的存储空间。
实现代码：（见另一条留言）

3.链表实现
时间复杂度分析：压栈和弹栈的时间复杂度均为O(1)级别，因为只需更改单个节点的索引即可。
空间复杂度分析：在入栈和出栈的过程中，只需要一两个临时变量存储空间，所以O(1)级别。我们说空间复杂度的时候，是指除了原本的数据存储空间外，算法运行还需要额外的存储空间。
实现代码：（见另一条留言）

四、栈的应用
1.栈在函数调用中的应用
操作系统给每个线程分配了一块独立的内存空间，这块内存被组织成“栈”这种结构，用来存储函数调用时的临时变量。每进入一个函数，就会将其中的临时变量作为栈帧入栈，当被调用函数执行完成，返回之后，将这个函数对应的栈帧出栈。
2.栈在表达式求值中的应用（比如：34+13*9+44-12/3）
利用两个栈，其中一个用来保存操作数，另一个用来保存运算符。我们从左向右遍历表达式，当遇到数字，我们就直接压入操作数栈；当遇到运算符，就与运算符栈的栈顶元素进行比较，若比运算符栈顶元素优先级高，就将当前运算符压入栈，若比运算符栈顶元素的优先级低或者相同，从运算符栈中取出栈顶运算符，从操作数栈顶取出2个操作数，然后进行计算，把计算完的结果压入操作数栈，继续比较。
3.栈在括号匹配中的应用（比如：{}{[()]()}）
用栈保存为匹配的左括号，从左到右一次扫描字符串，当扫描到左括号时，则将其压入栈中；当扫描到右括号时，从栈顶取出一个左括号，如果能匹配上，则继续扫描剩下的字符串。如果扫描过程中，遇到不能配对的右括号，或者栈中没有数据，则说明为非法格式。
当所有的括号都扫描完成之后，如果栈为空，则说明字符串为合法格式；否则，说明未匹配的左括号为非法格式。
4.如何实现浏览器的前进后退功能？
我们使用两个栈X和Y，我们把首次浏览的页面依次压如栈X，当点击后退按钮时，再依次从栈X中出栈，并将出栈的数据一次放入Y栈。当点击前进按钮时，我们依次从栈Y中取出数据，放入栈X中。当栈X中没有数据时，说明没有页面可以继续后退浏览了。当Y栈没有数据，那就说明没有页面可以点击前进浏览了。
五、思考
1. 我们在讲栈的应用时，讲到用函数调用栈来保存临时变量，为什么函数调用要用“栈”来保存临时变量呢？用其他数据结构不行吗？
答：因为函数调用的执行顺序符合后进者先出，先进者后出的特点。比如函数中的局部变量的生命周期的长短是先定义的生命周期长，后定义的生命周期短；还有函数中调用函数也是这样，先开始执行的函数只有等到内部调用的其他函数执行完毕，该函数才能执行结束。
正是由于函数调用的这些特点，根据数据结构是特定应用场景的抽象的原则，我们优先考虑栈结构。
2.我们都知道，JVM 内存管理中有个“堆栈”的概念。栈内存用来存储局部变量和方法调用，堆内存用来存储 Java 中的对象。那 JVM 里面的“栈”跟我们这里说的“栈”是不是一回事呢？如果不是，那它为什么又叫作“栈”呢？
答：JVM里面的栈和我们这里说的是一回事，被称为方法栈。和前面函数调用的作用是一致的，用来存储方法中的局部变量。
2018-10-08


164

观弈道人
感觉在留言区做笔记没多大意义，留言区还是提问问题或回答问题笔记合适，长篇累牍的笔记给谁看啊，占空间~~
作者回复: 还是有很多同学看的 个人喜好吧 不必强求

2018-10-08

4

146

王争
为什么函数调用要用“栈”来保存临时变量呢？用其他数据结构不行吗？

其实，我们不一定非要用栈来保存临时变量，只不过如果这个函数调用符合后进先出的特性，用栈这种数据结构来实现，是最顺理成章的选择。

从调用函数进入被调用函数，对于数据来说，变化的是什么呢？是作用域。所以根本上，只要能保证每进入一个新的函数，都是一个新的作用域就可以。而要实现这个，用栈就非常方便。在进入被调用函数的时候，分配一段栈空间给这个函数的变量，在函数结束的时候，将栈顶复位，正好回到调用函数的作用域内。
作者回复: 答案 大家可以参考下

2018-11-01

1

91

小洋洋
函数调用之所以用栈，是因为函数调用中经常嵌套，栗子：A调用B，B又调用C，那么就需要先把C执行完，结果赋值给B中的临时变量，B的执行结果再赋值给A的临时变量，嵌套越深的函数越需要被先执行，这样刚好符合栈的特点，因此每次遇到函数调用，只需要压栈，最后依次从栈顶弹出依次执行即可，这个过程很像文稿中的3+5*8-6//小白之拙见，欢迎拍砖*^o^*
2018-10-08

1

85

鲫鱼
对我来说理解有些困难，所以姜威的笔记给了我很大的帮助的。给了我更好完善笔记的构架，以及用不同方式解释加深理解和记忆。真的有的人不喜欢看不看就好，划掉不过两秒的事情。
2018-10-10


62

姜威
实现代码：（栈的数组实现）
public class StackOfArray<Item> implements Iterable<Item>{
//存储数据的数组
Item[] a = (Item[])new Object[1];
//记录元素个数N
int N = 0;
//构造器
public StackOfArray(){}
//添加元素
public void push(Item item){
//自动扩容
if (N == a.length ) resize(2*a.length );
a[N++] = item;
}
//删除元素
public Item pop(){
Item item = a[--N];
a[N] = null;
if (N > 0 && N == a.length / 4) resize(a.length / 2);
return item;
}
//是否为空
public boolean isEmpty(){
return N == 0;
}
//元素个数
public int size(){
return N;
}
//改变数组容量
private void resize(int length) {
Item[] temp = (Item[])new Object[length];
for (int i = 0; i < N; i++) {
temp[i] = a[i];
}
a = temp;
}
//返回栈中最近添加的元素而不删除它
public Item peek(){
return a[N-1];
}
@Override
public Iterator<Item> iterator() {
return new ArrayIterator();
}
//内部类
class ArrayIterator implements Iterator{
//控制迭代数量
int i = N;
@Override
public boolean hasNext() {
return i > 0;
}
@Override
public Item next() {
return a[--i];
}
}
}

实现代码：（栈的链表实现）
public class StackOfLinked<Item> implements Iterable<Item> {
//定义一个内部类，就可以直接使用类型参数
private class Node{
Item item;
Node next;
}
private Node first;
private int N;
//构造器
public StackOfLinked(){}
//添加
public void push(Item item){
Node oldfirst = first;
first = new Node();
first.item = item;
first.next = oldfirst;
N++;
}
//删除
public Item pop(){
Item item = first.item;
first = first.next;
N--;
return item;
}
//是否为空
public boolean isEmpty(){
return N == 0;
}
//元素数量
public int size(){
return N;
}
//返回栈中最近添加的元素而不删除它
public Item peek(){
return first.item;
}
@Override
public Iterator<Item> iterator() {
return new LinkedIterator();
}
//内部类：迭代器
class LinkedIterator implements Iterator{
int i = N;
Node t = first;
@Override
public boolean hasNext() {
return i > 0;
}
@Override
public Item next() {
Item item = (Item) t.item;
t = t.next;
i--;
return item;
}
}
}
2018-10-08


32

Jerry银银
置顶的留言中还有一个问题没有回答——为什么内存中的“栈”也叫“栈”，而且英文都是stack？

我认为，虽然内存中的栈和数据结构的栈不是一回事，即内存中的栈是一段虚拟的内存空间，数据结构中的栈是一种抽象的数据类型，但是它们都有“栈”的特性——后进先出，所以都叫“栈”也无可厚非。

-----

还有，置顶留言中说，内存中的堆栈是真实存在的物理区，这个说法有点不精确，因为大部分人所说的，以及应用编程中所用到的内存，一般情况下指的都是虚拟内存空间，英文为：Virtual Memory，是物理内存的映射。
2019-03-07

1

24

Monday
对于每次留下的思考题都希望老师在n（n>1）天后给出权威的答案，谢谢。
国庆在家里只看文档和听音频没有记录笔记，回去工作了，一定补上。个人认为本课题是最实惠的知识付费，没有之一。❤
作者回复: 关于思考题 很多同学的留言都已经回答的很好了 关于权威答案 我可以集中写篇文章说说

2018-10-09


24

清以轻尘
关于这个浏览器的前进和后退，老师您说的是用两个栈实现，其实开篇我已经想到，但是，我还有一个很不错的解决思路，对于内存消耗可能会高点，但是时间复杂度也很低，就是使用双向链表，用 pre和next 来实现前进和后退
作者回复: 也可以的 👍

2018-10-22


21

Liam
1 函数调用和返回符合后进先出原则，而局部变量的生命周期应该和函数一致，因此用栈保存局部变量是合适的，函数出栈时同时销毁局部变量

2 jvm的栈就是一种栈数据结构，本质相同
2018-10-08


18

thewangzl
JVM中的“栈”应该有两个。
一个是每个线程中方法调用用到的栈。该栈以栈帧为元素，当调用一个方法时，会把方法相关的局部变量表、操作数栈、方法返回地址等信息封装到栈帧中，把该栈帧入栈；当方法执行结束后，把该栈帧出栈。
第二个栈就是栈帧中的操作数栈。JVM的解释执行引擎是“基于栈的执行引擎”，是因为JVM的指令都是对操作数栈中的元素进行入栈出栈操作。
两者应该都是标准的栈。
2018-10-08


15

席尔
老师早上好!想请问下:如果当前栈大小为 K，并且已满，当再有新的数据要入栈时，就需要重新申请 2 倍大小的内存，并且做 K 个数据的搬移操作，然后再入栈。但是，接下来的 K-1 次入栈操作？
 不是k次入栈操作吗？为什么是k–1次？ 新的栈空间还剩余k的大小呀，不是还能进行k次入栈操作吗？麻烦老师解答一下，非常感谢!
2019-01-11

4

12

zyzheng
函数调用使用的栈是有硬件基础的，所有的CPU都有相应的SP寄存器用于存储栈顶指针，也有相应的入栈出栈指令，用于实现函数调用栈效率很高，和软件数据结构的栈有所不同。

如果要回答为什么函数调用要要用栈，个人理解是CPU设计就是如此
2018-10-08


9

Smallfly
函数调用为什么用栈实现，其中一个原因是为了满足递归的需求。
2018-10-08


8

陈华应
1，方法调用是有先后顺序的，并且一个线程中同一时间点只会处理一个方法，若方法中调用其他方法，则被调用方法会入栈并且方法体被执行，执行完后方法出栈，并将执行结果相关信息向下一个执行方法传递(方法所有信息被封装为一个栈元素)。方法执行过程中产生的数据存储特点非常符合栈数据结构特点。
2，概念和用途是一个意思，jvm的栈稍有复杂，每个栈元素叫做栈帧(一个包含被执行方法所有信息的元素，栈最顶部是当前栈帧，也就是正在被执行的方法)，栈元素是一个具体方法，又包含了操作数栈，用于方法的具体执行中的数据计算。
2018-10-08


6

kylexu
看完再睡！
2018-10-08


6
收起评论

99+99+





# 09 | 队列：队列在线程池等有限资源池中的应用




数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



09 | 队列：队列在线程池等有限资源池中的应用
王争 2018-10-10



12:34
讲述：修阳 大小：5.05M
我们知道，CPU 资源是有限的，任务的处理速度与线程个数并不是线性正相关。相反，过多的线程反而会导致 CPU 频繁切换，处理性能下降。所以，线程池的大小一般都是综合考虑要处理任务的特点和硬件环境，来事先设置的。

当我们向固定大小的线程池中请求一个线程时，如果线程池中没有空闲资源了，这个时候线程池如何处理这个请求？是拒绝请求还是排队请求？各种处理策略又是怎么实现的呢？

实际上，这些问题并不复杂，其底层的数据结构就是我们今天要学的内容，队列（queue）。

如何理解“队列”？
队列这个概念非常好理解。你可以把它想象成排队买票，先来的先买，后来的人只能站末尾，不允许插队。先进者先出，这就是典型的“队列”。

我们知道，栈只支持两个基本操作：入栈 push()和出栈 pop()。队列跟栈非常相似，支持的操作也很有限，最基本的操作也是两个：入队 enqueue()，放一个数据到队列尾部；出队 dequeue()，从队列头部取一个元素。



所以，队列跟栈一样，也是一种操作受限的线性表数据结构。

队列的概念很好理解，基本操作也很容易掌握。作为一种非常基础的数据结构，队列的应用也非常广泛，特别是一些具有某些额外特性的队列，比如循环队列、阻塞队列、并发队列。它们在很多偏底层系统、框架、中间件的开发中，起着关键性的作用。比如高性能队列 Disruptor、Linux 环形缓存，都用到了循环并发队列；Java concurrent 并发包利用 ArrayBlockingQueue 来实现公平锁等。

顺序队列和链式队列
我们知道了，队列跟栈一样，也是一种抽象的数据结构。它具有先进先出的特性，支持在队尾插入元素，在队头删除元素，那究竟该如何实现一个队列呢？

跟栈一样，队列可以用数组来实现，也可以用链表来实现。用数组实现的栈叫作顺序栈，用链表实现的栈叫作链式栈。同样，用数组实现的队列叫作顺序队列，用链表实现的队列叫作链式队列。

我们先来看下基于数组的实现方法。我用 Java 语言实现了一下，不过并不包含 Java 语言的高级语法，而且我做了比较详细的注释，你应该可以看懂。

// 用数组实现的队列
public class ArrayQueue {
  // 数组：items，数组大小：n
  private String[] items;
  private int n = 0;
  // head 表示队头下标，tail 表示队尾下标
  private int head = 0;
  private int tail = 0;
 
  // 申请一个大小为 capacity 的数组
  public ArrayQueue(int capacity) {
    items = new String[capacity];
    n = capacity;
  }
 
  // 入队
  public boolean enqueue(String item) {
    // 如果 tail == n 表示队列已经满了
    if (tail == n) return false;
    items[tail] = item;
    ++tail;
    return true;
  }
 
  // 出队
  public String dequeue() {
    // 如果 head == tail 表示队列为空
    if (head == tail) return null;
    // 为了让其他语言的同学看的更加明确，把 -- 操作放到单独一行来写了
    String ret = items[head];
    ++head;
    return ret;
  }
}
比起栈的数组实现，队列的数组实现稍微有点儿复杂，但是没关系。我稍微解释一下实现思路，你很容易就能明白了。

对于栈来说，我们只需要一个栈顶指针就可以了。但是队列需要两个指针：一个是 head 指针，指向队头；一个是 tail 指针，指向队尾。

你可以结合下面这幅图来理解。当 a、b、c、d 依次入队之后，队列中的 head 指针指向下标为 0 的位置，tail 指针指向下标为 4 的位置。



当我们调用两次出队操作之后，队列中 head 指针指向下标为 2 的位置，tail 指针仍然指向下标为 4 的位置。



你肯定已经发现了，随着不停地进行入队、出队操作，head 和 tail 都会持续往后移动。当 tail 移动到最右边，即使数组中还有空闲空间，也无法继续往队列中添加数据了。这个问题该如何解决呢？

你是否还记得，在数组那一节，我们也遇到过类似的问题，就是数组的删除操作会导致数组中的数据不连续。你还记得我们当时是怎么解决的吗？对，用数据搬移！但是，每次进行出队操作都相当于删除数组下标为 0 的数据，要搬移整个队列中的数据，这样出队操作的时间复杂度就会从原来的 O(1) 变为 O(n)。能不能优化一下呢？

实际上，我们在出队时可以不用搬移数据。如果没有空闲空间了，我们只需要在入队时，再集中触发一次数据的搬移操作。借助这个思想，出队函数 dequeue() 保持不变，我们稍加改造一下入队函数 enqueue() 的实现，就可以轻松解决刚才的问题了。下面是具体的代码：

   // 入队操作，将 item 放入队尾
  public boolean enqueue(String item) {
    // tail == n 表示队列末尾没有空间了
    if (tail == n) {
      // tail ==n && head==0，表示整个队列都占满了
      if (head == 0) return false;
      // 数据搬移
      for (int i = head; i < tail; ++i) {
        items[i-head] = items[i];
      }
      // 搬移完之后重新更新 head 和 tail
      tail -= head;
      head = 0;
    }
    
    items[tail] = item;
    ++tail;
    return true;
  }
从代码中我们看到，当队列的 tail 指针移动到数组的最右边后，如果有新的数据入队，我们可以将 head 到 tail 之间的数据，整体搬移到数组中 0 到 tail-head 的位置。



这种实现思路中，出队操作的时间复杂度仍然是 O(1)，但入队操作的时间复杂度还是 O(1) 吗？你可以用我们第 3 节、第 4 节讲的算法复杂度分析方法，自己试着分析一下。

接下来，我们再来看下基于链表的队列实现方法。

基于链表的实现，我们同样需要两个指针：head 指针和 tail 指针。它们分别指向链表的第一个结点和最后一个结点。如图所示，入队时，tail->next= new_node, tail = tail->next；出队时，head = head->next。我将具体的代码放到 GitHub 上，你可以自己试着实现一下，然后再去 GitHub 上跟我实现的代码对比下，看写得对不对。



循环队列
我们刚才用数组来实现队列的时候，在 tail==n 时，会有数据搬移操作，这样入队操作性能就会受到影响。那有没有办法能够避免数据搬移呢？我们来看看循环队列的解决思路。

循环队列，顾名思义，它长得像一个环。原本数组是有头有尾的，是一条直线。现在我们把首尾相连，扳成了一个环。我画了一张图，你可以直观地感受一下。



我们可以看到，图中这个队列的大小为 8，当前 head=4，tail=7。当有一个新的元素 a 入队时，我们放入下标为 7 的位置。但这个时候，我们并不把 tail 更新为 8，而是将其在环中后移一位，到下标为 0 的位置。当再有一个元素 b 入队时，我们将 b 放入下标为 0 的位置，然后 tail 加 1 更新为 1。所以，在 a，b 依次入队之后，循环队列中的元素就变成了下面的样子：



通过这样的方法，我们成功避免了数据搬移操作。看起来不难理解，但是循环队列的代码实现难度要比前面讲的非循环队列难多了。要想写出没有 bug 的循环队列的实现代码，我个人觉得，最关键的是，确定好队空和队满的判定条件。

在用数组实现的非循环队列中，队满的判断条件是 tail == n，队空的判断条件是 head == tail。那针对循环队列，如何判断队空和队满呢？

队列为空的判断条件仍然是 head == tail。但队列满的判断条件就稍微有点复杂了。我画了一张队列满的图，你可以看一下，试着总结一下规律。



就像我图中画的队满的情况，tail=3，head=4，n=8，所以总结一下规律就是：(3+1)%8=4。多画几张队满的图，你就会发现，当队满时，(tail+1)%n=head。

你有没有发现，当队列满时，图中的 tail 指向的位置实际上是没有存储数据的。所以，循环队列会浪费一个数组的存储空间。

Talk is cheap，如果还是没怎么理解，那就 show you code 吧。

public class CircularQueue {
  // 数组：items，数组大小：n
  private String[] items;
  private int n = 0;
  // head 表示队头下标，tail 表示队尾下标
  private int head = 0;
  private int tail = 0;
 
  // 申请一个大小为 capacity 的数组
  public CircularQueue(int capacity) {
    items = new String[capacity];
    n = capacity;
  }
 
  // 入队
  public boolean enqueue(String item) {
    // 队列满了
    if ((tail + 1) % n == head) return false;
    items[tail] = item;
    tail = (tail + 1) % n;
    return true;
  }
 
  // 出队
  public String dequeue() {
    // 如果 head == tail 表示队列为空
    if (head == tail) return null;
    String ret = items[head];
    head = (head + 1) % n;
    return ret;
  }
}
阻塞队列和并发队列
前面讲的内容理论比较多，看起来很难跟实际的项目开发扯上关系。确实，队列这种数据结构很基础，平时的业务开发不大可能从零实现一个队列，甚至都不会直接用到。而一些具有特殊特性的队列应用却比较广泛，比如阻塞队列和并发队列。

阻塞队列其实就是在队列基础上增加了阻塞操作。简单来说，就是在队列为空的时候，从队头取数据会被阻塞。因为此时还没有数据可取，直到队列中有了数据才能返回；如果队列已经满了，那么插入数据的操作就会被阻塞，直到队列中有空闲位置后再插入数据，然后再返回。



你应该已经发现了，上述的定义就是一个“生产者 - 消费者模型”！是的，我们可以使用阻塞队列，轻松实现一个“生产者 - 消费者模型”！

这种基于阻塞队列实现的“生产者 - 消费者模型”，可以有效地协调生产和消费的速度。当“生产者”生产数据的速度过快，“消费者”来不及消费时，存储数据的队列很快就会满了。这个时候，生产者就阻塞等待，直到“消费者”消费了数据，“生产者”才会被唤醒继续“生产”。

而且不仅如此，基于阻塞队列，我们还可以通过协调“生产者”和“消费者”的个数，来提高数据的处理效率。比如前面的例子，我们可以多配置几个“消费者”，来应对一个“生产者”。



前面我们讲了阻塞队列，在多线程情况下，会有多个线程同时操作队列，这个时候就会存在线程安全问题，那如何实现一个线程安全的队列呢？

线程安全的队列我们叫作并发队列。最简单直接的实现方式是直接在 enqueue()、dequeue() 方法上加锁，但是锁粒度大并发度会比较低，同一时刻仅允许一个存或者取操作。实际上，基于数组的循环队列，利用 CAS 原子操作，可以实现非常高效的并发队列。这也是循环队列比链式队列应用更加广泛的原因。在实战篇讲 Disruptor 的时候，我会再详细讲并发队列的应用。

解答开篇
队列的知识就讲完了，我们现在回过来看下开篇的问题。线程池没有空闲线程时，新的任务请求线程资源时，线程池该如何处理？各种处理策略又是如何实现的呢？

我们一般有两种处理策略。第一种是非阻塞的处理方式，直接拒绝任务请求；另一种是阻塞的处理方式，将请求排队，等到有空闲线程时，取出排队的请求继续处理。那如何存储排队的请求呢？

我们希望公平地处理每个排队的请求，先进者先服务，所以队列这种数据结构很适合来存储排队请求。我们前面说过，队列有基于链表和基于数组这两种实现方式。这两种实现方式对于排队请求又有什么区别呢？

基于链表的实现方式，可以实现一个支持无限排队的无界队列（unbounded queue），但是可能会导致过多的请求排队等待，请求处理的响应时间过长。所以，针对响应时间比较敏感的系统，基于链表实现的无限排队的线程池是不合适的。

而基于数组实现的有界队列（bounded queue），队列的大小有限，所以线程池中排队的请求超过队列大小时，接下来的请求就会被拒绝，这种方式对响应时间敏感的系统来说，就相对更加合理。不过，设置一个合理的队列大小，也是非常有讲究的。队列太大导致等待的请求太多，队列太小会导致无法充分利用系统资源、发挥最大性能。

除了前面讲到队列应用在线程池请求排队的场景之外，队列可以应用在任何有限资源池中，用于排队请求，比如数据库连接池等。实际上，对于大部分资源有限的场景，当没有空闲资源时，基本上都可以通过“队列”这种数据结构来实现请求排队。

内容小结
今天我们讲了一种跟栈很相似的数据结构，队列。关于队列，你能掌握下面的内容，这节就没问题了。

队列最大的特点就是先进先出，主要的两个操作是入队和出队。跟栈一样，它既可以用数组来实现，也可以用链表来实现。用数组实现的叫顺序队列，用链表实现的叫链式队列。特别是长得像一个环的循环队列。在数组实现队列的时候，会有数据搬移操作，要想解决数据搬移的问题，我们就需要像环一样的循环队列。

循环队列是我们这节的重点。要想写出没有 bug 的循环队列实现代码，关键要确定好队空和队满的判定条件，具体的代码你要能写出来。

除此之外，我们还讲了几种高级的队列结构，阻塞队列、并发队列，底层都还是队列这种数据结构，只不过在之上附加了很多其他功能。阻塞队列就是入队、出队操作可以阻塞，并发队列就是队列的操作多线程安全。

课后思考
除了线程池这种池结构会用到队列排队请求，你还知道有哪些类似的池结构或者场景中会用到队列的排队请求呢？

今天讲到并发队列，关于如何实现无锁并发队列，网上有非常多的讨论。对这个问题，你怎么看呢？

欢迎留言和我分享，我会第一时间给你反馈。

我已将本节内容相关的详细代码更新到 GitHub，戳此即可查看。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(233)

城 置顶
1.分布式应用中的消息队列，也是一种队列结构
2.考虑使用CAS实现无锁队列，则在入队前，获取tail位置，入队时比较tail是否发生变化，如果否，则允许入队，反之，本次入队失败。出队则是获取head位置，进行cas。
个人浅见，请批评指正
作者回复: 👍

2018-10-10

3

133

wean 置顶
队列也是一种“操作受限”的线性表，只支持两种基本操作：入队和出队。

队列的应用非常广泛，特别是一些具有某些额外特性的队列，比如循环队列、阻塞队列、并发队列。它们在很多偏底层的系统、框架、中间件的开发中，起着关键性的作用。比如高性能队列 Disruptor、Linux 环形缓存，都用到了循环并发队列；Java concurrent 并发包利用 ArrayBlockingQueue 来实现公平锁等。

关于如何实现无锁并发队列
可以使用 cas + 数组的方式实现。

队列的其他应用
分布式消息队列，如 kafka 也是一种队列。
作者回复: 👍

2018-10-10

1

32

花见笑 置顶
循环队列的长度设定需要对并发数据有一定的预测，否则会丢失太多请求。
作者回复: 👍

2018-10-10


27

只会安卓De小鹿
王争老师，为了更好的区分队列和栈，小鹿给大家一个更好的口诀。
“吃多了拉就是队列，吃多了吐就是栈”。哈哈！
作者回复: 😂

2018-10-11

3

334

计科一班
老师，循环队列的数组实现，在您的代码中，入队时会空留出一个位置，而且我感觉不太好理解。我定义一个记录队列大小的值size，当这个值与数组大小相等时，表示队列已满，当tail达到最底时，size不等于数组大小时，tail就指向数组第一个位置。当出队时，size—，入队时size++
作者回复: 你这个思路挺巧妙的 👍 我暂时还没有想到破绽

2018-10-10


142

樱小路依然
循环队列：队列满的表达式
这里讲一下，这个表达式是怎么来的。在一般情况下，我们可以看出来，当队列满时，tail+1=head。但是，有个特殊情况，就是tail=n-1，而head=0时，这时候，tail+1=n，而head=0，所以用(tail+1)%n == n%n == 0。而且，tail+1最大的情况就是 n ，不会大于 n，这样，tail+1 除了最大情况，不然怎么余 n 都是 tail+1 本身，也就是 head。这样，表达式就出现了。
作者回复: 👍

2018-11-12

1

45

姜威
队列实现
一、数组实现
public class ArrayQueue {
//存储数据的数组
private String[] items;
//记录数组容量
private int n;
private int size;
//head记录队头索引，tail记录队尾索引
private int head = 0;
private int tail = 0;
//申请一个指定容量的队列
public ArrayQueue(int capacity){
items = new String[capacity];
n = capacity;
}
/*
* 入队：
* 1.堆满的时，入队失败
* 1.1频繁出入队，造成数组使用不连续
* 1.2在入队的时候，集中触发进行数据搬移
* 2.在末尾插入数据，注意tail指向队尾元素的索引+1
*/
public boolean enqueue(String item){
//表示队满
if(head == 0 && tail == n)
return false;
//表示需要数据搬移
else if(head != 0 && tail == n){
for (int i = head; i < tail; i++) {
items[i-head] = items[i];
}
head = 0;
tail = tail - head;
}
//将数据加入队列
items[tail++] = item;
size++;
return true;
}
//出队：1.队空时，出队失败;2.出队，head索引+1
public String dequeue(){
String res = null;
if(head == tail) return res;
res = items[head++];
size--;
return res;
}
}
二、循环队列
public class LoopArrayQueue {
//存储数据的数组
private String[] items;
//记录数组容量
private int n;
private int size = 0;
//head记录队头索引，tail记录队尾索引
private int head = 0;
private int tail = 0;
//申请一个指定容量的队列
public LoopArrayQueue(int capacity){
items = new String[capacity];
n = capacity;
}
//入队：关键在于队满的条件
public boolean enqueue(String item){
if ((tail + 1) % n == head) return false;
items[tail] = item;
tail = (tail + 1) % n;
size++;
return true;
}
//出队：关键在于队空的条件
public String dequeue(){
String res = null;
if(head == tail) return res;
res = items[head];
head = (head + 1) % n;
size--;
return res;
}
}
三、链表实现
public class LinkedQueue {
//定义一个节点类
private class Node{
String value;
Node next;
}
//记录队列元素个数
private int size = 0;
//head指向队头结点，tail指向队尾节点
private Node head;
private Node tail;
//申请一个队列
public LinkedQueue(){}
//入队
public boolean enqueue(String item){
Node newNode = new Node();
newNode.value = item;
if (size == 0) head = newNode;
else tail.next = newNode;
tail = newNode;
size++;
return true;
}
//出队
public String dequeue(){
String res = null;
if(size == 0) return res;
if(size == 1) tail = null;
res = head.value;
head = head.next;
size--;
return res;
}
}
作者回复: 👍

2018-10-12


39

姜威
总结
一、什么是队列？
1.先进者先出，这就是典型的“队列”结构。
2.支持两个操作：入队enqueue()，放一个数据到队尾；出队dequeue()，从队头取一个元素。
3.所以，和栈一样，队列也是一种操作受限的线性表。
二、如何实现队列？
1.队列API
public interface Queue<T> {
public void enqueue(T item); //入队
public T dequeue(); //出队
public int size(); //统计元素数量
public boolean isNull(); //是否为空
}
2.数组实现（顺序队列）：见下一条留言
3.链表实现（链式队列）：见下一条留言
4.循环队列（基于数组）：见下一条留言
三、队列有哪些常见的应用？
1.阻塞队列
1）在队列的基础上增加阻塞操作，就成了阻塞队列。
2）阻塞队列就是在队列为空的时候，从队头取数据会被阻塞，因为此时还没有数据可取，直到队列中有了数据才能返回；如果队列已经满了，那么插入数据的操作就会被阻塞，直到队列中有空闲位置后再插入数据，然后在返回。
3）从上面的定义可以看出这就是一个“生产者-消费者模型”。这种基于阻塞队列实现的“生产者-消费者模型”可以有效地协调生产和消费的速度。当“生产者”生产数据的速度过快，“消费者”来不及消费时，存储数据的队列很快就会满了，这时生产者就阻塞等待，直到“消费者”消费了数据，“生产者”才会被唤醒继续生产。不仅如此，基于阻塞队列，我们还可以通过协调“生产者”和“消费者”的个数，来提高数据处理效率，比如配置几个消费者，来应对一个生产者。
2.并发队列
1）在多线程的情况下，会有多个线程同时操作队列，这时就会存在线程安全问题。能够有效解决线程安全问题的队列就称为并发队列。
2）并发队列简单的实现就是在enqueue()、dequeue()方法上加锁，但是锁粒度大并发度会比较低，同一时刻仅允许一个存或取操作。
3）实际上，基于数组的循环队列利用CAS原子操作，可以实现非常高效的并发队列。这也是循环队列比链式队列应用更加广泛的原因。
3.线程池资源枯竭是的处理
在资源有限的场景，当没有空闲资源时，基本上都可以通过“队列”这种数据结构来实现请求排队。
四、思考
1.除了线程池这种池结构会用到队列排队请求，还有哪些类似线程池结构或者场景中会用到队列的排队请求呢？
2.今天讲到并发队列，关于如何实现无锁的并发队列，网上有很多讨论。对这个问题，你怎么看？
作者回复: 👍

2018-10-12


26

蝴蝶
这种实现思路中，出队操作的时间复杂度仍然是 O(1)，但入队操作的时间复杂度还是 O(1) 吗想了一下，考虑到head可能等于1,2,n-1,经过计算，觉得均摊和平均时间复杂度还是O(1),对么？
2018-10-10

1

26

Peter丶桥
老师要是有时间对课后问题集中式做下解答就好了
作者回复: 行的

2018-10-10


22

老司机
循环队列真的是比较牛逼的思路，尤其是linux内核源码的kfifo的实现，无论是取模运算转换成取与运算，还是考虑head，tail的溢出，牛逼
2018-10-10


22

asule
很多同学都提到循环队列增加flag来避免浪费最后一个存储空间，那是不是flag本身也需要一个存储空间？
作者回复: 😄 是的

2018-10-18

2

18

阿阳
这里我真心给老师点赞。每节课都是由易到难，由基础到实战场景。比如这一节，先讲解队列的基本性质和实现方式，并做了对比；更重要的是，后面讲到了阻塞队列和并发队列，这个和平时开发遇到的场景类似，理论联系实际，又有代码的实现。
作为老程序员，这次学习数据结构与算法，不再迷惘，反而激发了学习兴趣。真心感谢老师！
2018-10-29


13

allean
Q: 「Talk is cheap. Show me the code」怎么翻译比较好？

A: 屁话少说，放码过来。
作者回复: 😄

2018-11-02

1

9

我以为你不看
一直想不明白为什么队列要空出一个空的格不存数据，不是可以直接入队存在tail里，tail＋＋再比较是否超出容量吗。
作者回复: 循环队列不行的 不然无法区分队空和队满

2018-10-17

1

9

bro.
老师，课后习题有空讲解一下理解呀！每次看评论，有的还是不太明白的地方
作者回复: 行的呢 我抽空集中答疑一下

2018-10-10


9

最初的印象
能不能写下阻塞队列和并发队列的代码
作者回复: 等我有空了吧 最近有点忙

2018-10-10


9

HunterYuan
思考题：
1. 在网卡的收发数据包操作，linux内核协议栈采用循环队列的方式进行处理。
2.linux内核态ruc和用户态urcu实现了无锁并发访问共享数据，非常适合于读多写少的场景。其核心思想是，拷贝复制链表数据，原子操作移动链表指针，实现真正的无锁操作。
2019-03-14


8

oldman
使用列表实现队列和循环队列，我用python实现了一遍，各位看官一起交流。
https://github.com/lipeng1991/testdemo/blob/master/38_array_implementation_queue.py
https://github.com/lipeng1991/testdemo/blob/master/39_array_implementation_loop_queue.py
2018-10-12


8

火火火
您尽管更新，我按顺序看。本来就是队列啊
2018-10-19


7
收起评论

99+99+




# 10 | 递归：如何用三行代码找到“最终推荐人”？



数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



10 | 递归：如何用三行代码找到“最终推荐人”？
王争 2018-10-12



15:35
讲述：修阳 大小：7.15M
推荐注册返佣金的这个功能我想你应该不陌生吧？现在很多 App 都有这个功能。这个功能中，用户 A 推荐用户 B 来注册，用户 B 又推荐了用户 C 来注册。我们可以说，用户 C 的“最终推荐人”为用户 A，用户 B 的“最终推荐人”也为用户 A，而用户 A 没有“最终推荐人”。

一般来说，我们会通过数据库来记录这种推荐关系。在数据库表中，我们可以记录两行数据，其中 actor_id 表示用户 id，referrer_id 表示推荐人 id。



基于这个背景，我的问题是，给定一个用户 ID，如何查找这个用户的“最终推荐人”？ 带着这个问题，我们来学习今天的内容，递归（Recursion）！

如何理解“递归”？
从我自己学习数据结构和算法的经历来看，我个人觉得，有两个最难理解的知识点，一个是动态规划，另一个就是递归。

递归是一种应用非常广泛的算法（或者编程技巧）。之后我们要讲的很多数据结构和算法的编码实现都要用到递归，比如 DFS 深度优先搜索、前中后序二叉树遍历等等。所以，搞懂递归非常重要，否则，后面复杂一些的数据结构和算法学起来就会比较吃力。

不过，别看我说了这么多，递归本身可是一点儿都不“高冷”，咱们生活中就有很多用到递归的例子。

周末你带着女朋友去电影院看电影，女朋友问你，咱们现在坐在第几排啊？电影院里面太黑了，看不清，没法数，现在你怎么办？

别忘了你是程序员，这个可难不倒你，递归就开始排上用场了。于是你就问前面一排的人他是第几排，你想只要在他的数字上加一，就知道自己在哪一排了。但是，前面的人也看不清啊，所以他也问他前面的人。就这样一排一排往前问，直到问到第一排的人，说我在第一排，然后再这样一排一排再把数字传回来。直到你前面的人告诉你他在哪一排，于是你就知道答案了。

这就是一个非常标准的递归求解问题的分解过程，去的过程叫“递”，回来的过程叫“归”。基本上，所有的递归问题都可以用递推公式来表示。刚刚这个生活中的例子，我们用递推公式将它表示出来就是这样的：

f(n)=f(n-1)+1 其中，f(1)=1
f(n) 表示你想知道自己在哪一排，f(n-1) 表示前面一排所在的排数，f(1)=1 表示第一排的人知道自己在第一排。有了这个递推公式，我们就可以很轻松地将它改为递归代码，如下：

int f(int n) {
  if (n == 1) return 1;
  return f(n-1) + 1;
}
递归需要满足的三个条件
刚刚这个例子是非常典型的递归，那究竟什么样的问题可以用递归来解决呢？我总结了三个条件，只要同时满足以下三个条件，就可以用递归来解决。

1. 一个问题的解可以分解为几个子问题的解

何为子问题？子问题就是数据规模更小的问题。比如，前面讲的电影院的例子，你要知道，“自己在哪一排”的问题，可以分解为“前一排的人在哪一排”这样一个子问题。

2. 这个问题与分解之后的子问题，除了数据规模不同，求解思路完全一样

比如电影院那个例子，你求解“自己在哪一排”的思路，和前面一排人求解“自己在哪一排”的思路，是一模一样的。

3. 存在递归终止条件

把问题分解为子问题，把子问题再分解为子子问题，一层一层分解下去，不能存在无限循环，这就需要有终止条件。

还是电影院的例子，第一排的人不需要再继续询问任何人，就知道自己在哪一排，也就是 f(1)=1，这就是递归的终止条件。

如何编写递归代码？
刚刚铺垫了这么多，现在我们来看，如何来写递归代码？我个人觉得，写递归代码最关键的是写出递推公式，找到终止条件，剩下将递推公式转化为代码就很简单了。

你先记住这个理论。我举一个例子，带你一步一步实现一个递归代码，帮你理解。

假如这里有 n 个台阶，每次你可以跨 1 个台阶或者 2 个台阶，请问走这 n 个台阶有多少种走法？如果有 7 个台阶，你可以 2，2，2，1 这样子上去，也可以 1，2，1，1，2 这样子上去，总之走法有很多，那如何用编程求得总共有多少种走法呢？

我们仔细想下，实际上，可以根据第一步的走法把所有走法分为两类，第一类是第一步走了 1 个台阶，另一类是第一步走了 2 个台阶。所以 n 个台阶的走法就等于先走 1 阶后，n-1 个台阶的走法 加上先走 2 阶后，n-2 个台阶的走法。用公式表示就是：

f(n) = f(n-1)+f(n-2)
有了递推公式，递归代码基本上就完成了一半。我们再来看下终止条件。当有一个台阶时，我们不需要再继续递归，就只有一种走法。所以 f(1)=1。这个递归终止条件足够吗？我们可以用 n=2，n=3 这样比较小的数试验一下。

n=2 时，f(2)=f(1)+f(0)。如果递归终止条件只有一个 f(1)=1，那 f(2) 就无法求解了。所以除了 f(1)=1 这一个递归终止条件外，还要有 f(0)=1，表示走 0 个台阶有一种走法，不过这样子看起来就不符合正常的逻辑思维了。所以，我们可以把 f(2)=2 作为一种终止条件，表示走 2 个台阶，有两种走法，一步走完或者分两步来走。

所以，递归终止条件就是 f(1)=1，f(2)=2。这个时候，你可以再拿 n=3，n=4 来验证一下，这个终止条件是否足够并且正确。

我们把递归终止条件和刚刚得到的递推公式放到一起就是这样的：

f(1) = 1;
f(2) = 2;
f(n) = f(n-1)+f(n-2)
有了这个公式，我们转化成递归代码就简单多了。最终的递归代码是这样的：

int f(int n) {
  if (n == 1) return 1;
  if (n == 2) return 2;
  return f(n-1) + f(n-2);
}
我总结一下，写递归代码的关键就是找到如何将大问题分解为小问题的规律，并且基于此写出递推公式，然后再推敲终止条件，最后将递推公式和终止条件翻译成代码。

虽然我讲了这么多方法，但是作为初学者的你，现在是不是还是有种想不太清楚的感觉呢？实际上，我刚学递归的时候，也有这种感觉，这也是文章开头我说递归代码比较难理解的地方。

刚讲的电影院的例子，我们的递归调用只有一个分支，也就是说“一个问题只需要分解为一个子问题”，我们很容易能够想清楚“递“和”归”的每一个步骤，所以写起来、理解起来都不难。

但是，当我们面对的是一个问题要分解为多个子问题的情况，递归代码就没那么好理解了。

像我刚刚讲的第二个例子，人脑几乎没办法把整个“递”和“归”的过程一步一步都想清楚。

计算机擅长做重复的事情，所以递归正和它的胃口。而我们人脑更喜欢平铺直叙的思维方式。当我们看到递归时，我们总想把递归平铺展开，脑子里就会循环，一层一层往下调，然后再一层一层返回，试图想搞清楚计算机每一步都是怎么执行的，这样就很容易被绕进去。

对于递归代码，这种试图想清楚整个递和归过程的做法，实际上是进入了一个思维误区。很多时候，我们理解起来比较吃力，主要原因就是自己给自己制造了这种理解障碍。那正确的思维方式应该是怎样的呢？

如果一个问题 A 可以分解为若干子问题 B、C、D，你可以假设子问题 B、C、D 已经解决，在此基础上思考如何解决问题 A。而且，你只需要思考问题 A 与子问题 B、C、D 两层之间的关系即可，不需要一层一层往下思考子问题与子子问题，子子问题与子子子问题之间的关系。屏蔽掉递归细节，这样子理解起来就简单多了。

因此，编写递归代码的关键是，只要遇到递归，我们就把它抽象成一个递推公式，不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤。

递归代码要警惕堆栈溢出
在实际的软件开发中，编写递归代码时，我们会遇到很多问题，比如堆栈溢出。而堆栈溢出会造成系统性崩溃，后果会非常严重。为什么递归代码容易造成堆栈溢出呢？我们又该如何预防堆栈溢出呢？

我在“栈”那一节讲过，函数调用会使用栈来保存临时变量。每调用一个函数，都会将临时变量封装为栈帧压入内存栈，等函数执行完成返回时，才出栈。系统栈或者虚拟机栈空间一般都不大。如果递归求解的数据规模很大，调用层次很深，一直压入栈，就会有堆栈溢出的风险。

比如前面的讲到的电影院的例子，如果我们将系统栈或者 JVM 堆栈大小设置为 1KB，在求解 f(19999) 时便会出现如下堆栈报错：

Exception in thread "main" java.lang.StackOverflowError
那么，如何避免出现堆栈溢出呢？

我们可以通过在代码中限制递归调用的最大深度的方式来解决这个问题。递归调用超过一定深度（比如 1000）之后，我们就不继续往下再递归了，直接返回报错。还是电影院那个例子，我们可以改造成下面这样子，就可以避免堆栈溢出了。不过，我写的代码是伪代码，为了代码简洁，有些边界条件没有考虑，比如 x<=0。

// 全局变量，表示递归的深度。
int depth = 0;
 
int f(int n) {
  ++depth；
  if (depth > 1000) throw exception;
  
  if (n == 1) return 1;
  return f(n-1) + 1;
}
但这种做法并不能完全解决问题，因为最大允许的递归深度跟当前线程剩余的栈空间大小有关，事先无法计算。如果实时计算，代码过于复杂，就会影响代码的可读性。所以，如果最大深度比较小，比如 10、50，就可以用这种方法，否则这种方法并不是很实用。

递归代码要警惕重复计算
除此之外，使用递归时还会出现重复计算的问题。刚才我讲的第二个递归代码的例子，如果我们把整个递归过程分解一下的话，那就是这样的：



从图中，我们可以直观地看到，想要计算 f(5)，需要先计算 f(4) 和 f(3)，而计算 f(4) 还需要计算 f(3)，因此，f(3) 就被计算了很多次，这就是重复计算问题。

为了避免重复计算，我们可以通过一个数据结构（比如散列表）来保存已经求解过的 f(k)。当递归调用到 f(k) 时，先看下是否已经求解过了。如果是，则直接从散列表中取值返回，不需要重复计算，这样就能避免刚讲的问题了。

按照上面的思路，我们来改造一下刚才的代码：

public int f(int n) {
  if (n == 1) return 1;
  if (n == 2) return 2;
  
  // hasSolvedList 可以理解成一个 Map，key 是 n，value 是 f(n)
  if (hasSolvedList.containsKey(n)) {
    return hasSovledList.get(n);
  }
  
  int ret = f(n-1) + f(n-2);
  hasSovledList.put(n, ret);
  return ret;
}
除了堆栈溢出、重复计算这两个常见的问题。递归代码还有很多别的问题。

在时间效率上，递归代码里多了很多函数调用，当这些函数调用的数量较大时，就会积聚成一个可观的时间成本。在空间复杂度上，因为递归调用一次就会在内存栈中保存一次现场数据，所以在分析递归代码空间复杂度时，需要额外考虑这部分的开销，比如我们前面讲到的电影院递归代码，空间复杂度并不是 O(1)，而是 O(n)。

怎么将递归代码改写为非递归代码？
我们刚说了，递归有利有弊，利是递归代码的表达力很强，写起来非常简洁；而弊就是空间复杂度高、有堆栈溢出的风险、存在重复计算、过多的函数调用会耗时较多等问题。所以，在开发过程中，我们要根据实际情况来选择是否需要用递归的方式来实现。

那我们是否可以把递归代码改写为非递归代码呢？比如刚才那个电影院的例子，我们抛开场景，只看 f(x) =f(x-1)+1 这个递推公式。我们这样改写看看：

int f(int n) {
  int ret = 1;
  for (int i = 2; i <= n; ++i) {
    ret = ret + 1;
  }
  return ret;
}
同样，第二个例子也可以改为非递归的实现方式。

int f(int n) {
  if (n == 1) return 1;
  if (n == 2) return 2;
  
  int ret = 0;
  int pre = 2;
  int prepre = 1;
  for (int i = 3; i <= n; ++i) {
    ret = pre + prepre;
    prepre = pre;
    pre = ret;
  }
  return ret;
}
那是不是所有的递归代码都可以改为这种迭代循环的非递归写法呢？

笼统地讲，是的。因为递归本身就是借助栈来实现的，只不过我们使用的栈是系统或者虚拟机本身提供的，我们没有感知罢了。如果我们自己在内存堆上实现栈，手动模拟入栈、出栈过程，这样任何递归代码都可以改写成看上去不是递归代码的样子。

但是这种思路实际上是将递归改为了“手动”递归，本质并没有变，而且也并没有解决前面讲到的某些问题，徒增了实现的复杂度。

解答开篇
到此为止，递归相关的基础知识已经讲完了，咱们来看一下开篇的问题：如何找到“最终推荐人”？我的解决方案是这样的：

long findRootReferrerId(long actorId) {
  Long referrerId = select referrer_id from [table] where actor_id = actorId;
  if (referrerId == null) return actorId;
  return findRootReferrerId(referrerId);
}
是不是非常简洁？用三行代码就能搞定了，不过在实际项目中，上面的代码并不能工作，为什么呢？这里面有两个问题。

第一，如果递归很深，可能会有堆栈溢出的问题。

第二，如果数据库里存在脏数据，我们还需要处理由此产生的无限递归问题。比如 demo 环境下数据库中，测试工程师为了方便测试，会人为地插入一些数据，就会出现脏数据。如果 A 的推荐人是 B，B 的推荐人是 C，C 的推荐人是 A，这样就会发生死循环。

第一个问题，我前面已经解答过了，可以用限制递归深度来解决。第二个问题，也可以用限制递归深度来解决。不过，还有一个更高级的处理方法，就是自动检测 A-B-C-A 这种“环”的存在。如何来检测环的存在呢？这个我暂时不细说，你可以自己思考下，后面的章节我们还会讲。

内容小结
关于递归的知识，到这里就算全部讲完了。我来总结一下。

递归是一种非常高效、简洁的编码技巧。只要是满足“三个条件”的问题就可以通过递归代码来解决。

不过递归代码也比较难写、难理解。编写递归代码的关键就是不要把自己绕进去，正确姿势是写出递推公式，找出终止条件，然后再翻译成递归代码。

递归代码虽然简洁高效，但是，递归代码也有很多弊端。比如，堆栈溢出、重复计算、函数调用耗时多、空间复杂度高等，所以，在编写递归代码的时候，一定要控制好这些副作用。

课后思考
我们平时调试代码喜欢使用 IDE 的单步跟踪功能，像规模比较大、递归层次很深的递归代码，几乎无法使用这种调试方式。对于递归代码，你有什么好的调试方法呢？

欢迎留言和我分享，我会第一时间给你反馈。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(241)

博金
调试递归:
1.打印日志发现，递归值。
2.结合条件断点进行调试。
作者回复: 答案正确 大家可以把这一条顶上去

2018-10-12

1

1144

刘強
那个陷入思维误区的说法产生共鸣了，原来总以为自己脑容量不足，看来牛人也一样。
2018-10-12

2

315

一步
哈哈，在电影院看是第几排，我直接看电影票，直接用索引找到了
作者回复: 哈哈😄

2018-10-12

1

168

姜威
总结

一、什么是递归？

1.递归是一种非常高效、简洁的编码技巧，一种应用非常广泛的算法，比如DFS深度优先搜索、前中后序二叉树遍历等都是使用递归。
2.方法或函数调用自身的方式称为递归调用，调用称为递，返回称为归。
3.基本上，所有的递归问题都可以用递推公式来表示，比如
f(n) = f(n-1) + 1;
f(n) = f(n-1) + f(n-2);
f(n)=n*f(n-1);

二、为什么使用递归？递归的优缺点？

1.优点：代码的表达力很强，写起来简洁。
2.缺点：空间复杂度高、有堆栈溢出风险、存在重复计算、过多的函数调用会耗时较多等问题。

三、什么样的问题可以用递归解决呢？

一个问题只要同时满足以下3个条件，就可以用递归来解决：
1.问题的解可以分解为几个子问题的解。何为子问题？就是数据规模更小的问题。
2.问题与子问题，除了数据规模不同，求解思路完全一样
3.存在递归终止条件

四、如何实现递归？

1.递归代码编写
写递归代码的关键就是找到如何将大问题分解为小问题的规律，并且基于此写出递推公式，然后再推敲终止条件，最后将递推公式和终止条件翻译成代码。
2.递归代码理解
对于递归代码，若试图想清楚整个递和归的过程，实际上是进入了一个思维误区。
那该如何理解递归代码呢？如果一个问题A可以分解为若干个子问题B、C、D，你可以假设子问题B、C、D已经解决。而且，你只需要思考问题A与子问题B、C、D两层之间的关系即可，不需要一层层往下思考子问题与子子问题，子子问题与子子子问题之间的关系。屏蔽掉递归细节，这样子理解起来就简单多了。
因此，理解递归代码，就把它抽象成一个递推公式，不用想一层层的调用关系，不要试图用人脑去分解递归的每个步骤。

五、递归常见问题及解决方案

1.警惕堆栈溢出：可以声明一个全局变量来控制递归的深度，从而避免堆栈溢出。
2.警惕重复计算：通过某种数据结构来保存已经求解过的值，从而避免重复计算。

六、如何将递归改写为非递归代码？

笼统的讲，所有的递归代码都可以改写为迭代循环的非递归写法。如何做？抽象出递推公式、初始值和边界条件，然后用迭代循环实现。
2018-10-12

1

95

范柏柏
希望老师多分享一些经典习题。比如链表那一章课后所说的，掌握这几道题就基本掌握了链表。
2018-10-12


84

柠檬C
递归和数学归纳法非常像，所以可以利用数学归纳法的思路，先验证边界条件，再假设n-1的情况正确，思考n和n-1的关系写出递推公式
2018-10-12


58

涛
终于在认知层面得到了提升，递归是什么，在我看来递归就是用栈的数据结构，加上一个简单的逻辑算法实现了业务功能。
作者回复: 👍

2018-10-12


45

失火的夏天
检测环可以构造一个set集合或者散列表(下面都叫散列表吧，为了方便)。每次获取到上层推荐人就去散列表里先查，没有查到的话就加入，如果存在则表示存在环了。当然，每一次查询都是一个自己的散列表，不能共用。不过这样请求量大的话，会不会造成内存空间开辟太多？这里老师能帮忙解答一下吗？
作者回复: 你这种办法可行的 👍。实际情况 内存也不会耗太多

2018-10-12


29

zl
Debug不行就打日志
2018-10-12


28

一步
说的对的，每次写递归代码，或者看递归代码，都会不自觉的在大脑中复现整个递和归的过程
2018-10-12


23

mj
我对台阶问题的理解是:到达n阶只可能来自n-1和n-2,所以f(n)=f(n-1)+f(n-2)
作者回复: 你理解的也对

2018-10-12

1

22

L
解答楼上的问题，数据规模较大的情况用循环，也就是老师讲的非递归代码
作者回复: 是的 👍

2018-10-12


15

Geek_8a2f3f
王老师，你好！说那个限制递归深度的做法只适合规模比较小的情况，那如果规模大了，怎么限制呢？
作者回复: 自己模拟一个栈 用非递归代码实现

2018-10-12

1

15

墨墨
老师好，你的github地址可以发下吗？我在前面的章节没看到
作者回复: github上艘wangzheng0822

2018-10-12


14

风起
调试递归就像写递归一样，
不要被每一步的细节所困，
重点在于确认递推关系与结束条件是否正确，
用条件断点着重调试最初两步与最终两步即可。
2018-10-12


12

Monday
原以为老师会先讲完10个基本的数据结构再讲十种基本的算法。没想到老师会穿插着讲。冒昧的问下老师设计课程的思路。谢谢
作者回复: 因为后面的内容会用到递归 而递归不依赖后面的内容 拓扑排序了解一下😄

2018-10-12


11

塘泥
尾递归的问题，想听听老师的讲解
2018-10-26


10

Smallfly
## 界定问题能否用递归解决
1. 一个问题的解可以分解为几个子问题的解；
2. 这个问题与分解子问题的求解思路完全相同；
3. 存在终止条件

## 编写递归代码的技巧
1. 终止条件
2. 递推公式
3. 清理现场

编写递归的关键是思考终止条件，把问题抽象成一个递推公式，并信任它一定能帮我们完成任务，不用想一层层的调用关系，试图用人脑分解递归是反人类的，最多只能想两三层。

## 递归的缺点
递归会利用栈保存临时变量，如果递归过深，会造成栈溢出。解决方案是控制递归的深度。

递归要警惕重复计算，递归分解的子问题、子子问题可能存在相同的情况，如果都一一计算的话，就会发生重复计算。解决方案是使用散列表来保存结算结果，每次开始计算前检查散列表是否已经有结算结果。

笼统地讲，递归代码都能用迭代循环来替换。


免费加入知识星球「极客星球」讨论算法问题。
2018-10-12


10

A_F
检测环的答案其实老师已经在文章中的一个例子中讲过了，就是用一个数据结构把查询过的元素放到这个数据结构里面，新来的就先查这个数据结构里面有没有，有就返回，没有就放入到这个数据结构里面。
2018-10-12


9

bro.
判断环的思路,使用链表:判断是否有环:使用步长法判断: 思路,从起点开始分别以2x,1x速度出发两个指针,当遇到null停止,相遇点为null时说明没有环,如果相遇点不为null,说明有环,注意有两个地方:
1.首次相遇点速度为1的指针是进入环的第一圈,切记切记
      证明一下呗: 设 圆环总长为: R , 指针分别设置为 1, 2吧,当1指针首次进入圆环交点时,2指针在圆环位置为 x ,则 2->1 步长为 (R - x)
      此时开始走i步以后相遇则: (R - x) + i = 2i; (原来相距位置加上1走的距离等于 2倍的1走距离)
      则 i = R - x ; (X <= R) 的,所以 i < R (肯定在第一圈相遇)
     由上可得:
      在第一圈相遇的时候1走的距离为: 设 起始点至环入口位置为 L ,则 1路程为(L + i)
      2走的距离为 (L + nR + i) ,n为圈数
      则: (L + nR + i) = 2(L + i); (切记:n >= 1 -> 2比1先进圈)(2速度为1的2倍,1的总路程 * 2)
      即: L = nR - i = (n - 1)R + (R - i) ; (n >= 1) 我们不管(n - 1)R,只是简单的绕圈数
      所以 L = R - i ; 而首次进入圈相遇的位置为 i ,整个圈长为 R ,
      所以当首次相遇的时候,重新以1为步长,一个以相交点为起始,一个以首节点开始,首次相遇点即为环的起始点;
2018-10-16


8
收起评论

99+99+




# 11 | 排序（上）：为什么插入排序比冒泡排序更受欢迎？



数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



11 | 排序（上）：为什么插入排序比冒泡排序更受欢迎？
王争 2018-10-15



21:13
讲述：修阳 大小：8.52M
排序对于任何一个程序员来说，可能都不会陌生。你学的第一个算法，可能就是排序。大部分编程语言中，也都提供了排序函数。在平常的项目中，我们也经常会用到排序。排序非常重要，所以我会花多一点时间来详细讲一讲经典的排序算法。

排序算法太多了，有很多可能你连名字都没听说过，比如猴子排序、睡眠排序、面条排序等。我只讲众多排序算法中的一小撮，也是最经典的、最常用的：冒泡排序、插入排序、选择排序、归并排序、快速排序、计数排序、基数排序、桶排序。我按照时间复杂度把它们分成了三类，分三节课来讲解。



带着问题去学习，是最有效的学习方法。所以按照惯例，我还是先给你出一个思考题：插入排序和冒泡排序的时间复杂度相同，都是 O(n2)，在实际的软件开发里，为什么我们更倾向于使用插入排序算法而不是冒泡排序算法呢？

你可以先思考一两分钟，带着这个问题，我们开始今天的内容！

如何分析一个“排序算法”？
学习排序算法，我们除了学习它的算法原理、代码实现之外，更重要的是要学会如何评价、分析一个排序算法。那分析一个排序算法，要从哪几个方面入手呢？

排序算法的执行效率
对于排序算法执行效率的分析，我们一般会从这几个方面来衡量：

1. 最好情况、最坏情况、平均情况时间复杂度

我们在分析排序算法的时间复杂度时，要分别给出最好情况、最坏情况、平均情况下的时间复杂度。除此之外，你还要说出最好、最坏时间复杂度对应的要排序的原始数据是什么样的。

为什么要区分这三种时间复杂度呢？第一，有些排序算法会区分，为了好对比，所以我们最好都做一下区分。第二，对于要排序的数据，有的接近有序，有的完全无序。有序度不同的数据，对于排序的执行时间肯定是有影响的，我们要知道排序算法在不同数据下的性能表现。

2. 时间复杂度的系数、常数 、低阶

我们知道，时间复杂度反应的是数据规模 n 很大的时候的一个增长趋势，所以它表示的时候会忽略系数、常数、低阶。但是实际的软件开发中，我们排序的可能是 10 个、100 个、1000 个这样规模很小的数据，所以，在对同一阶时间复杂度的排序算法性能对比的时候，我们就要把系数、常数、低阶也考虑进来。

3. 比较次数和交换（或移动）次数

这一节和下一节讲的都是基于比较的排序算法。基于比较的排序算法的执行过程，会涉及两种操作，一种是元素比较大小，另一种是元素交换或移动。所以，如果我们在分析排序算法的执行效率的时候，应该把比较次数和交换（或移动）次数也考虑进去。

排序算法的内存消耗
我们前面讲过，算法的内存消耗可以通过空间复杂度来衡量，排序算法也不例外。不过，针对排序算法的空间复杂度，我们还引入了一个新的概念，原地排序（Sorted in place）。原地排序算法，就是特指空间复杂度是 O(1) 的排序算法。我们今天讲的三种排序算法，都是原地排序算法。

排序算法的稳定性
仅仅用执行效率和内存消耗来衡量排序算法的好坏是不够的。针对排序算法，我们还有一个重要的度量指标，稳定性。这个概念是说，如果待排序的序列中存在值相等的元素，经过排序之后，相等元素之间原有的先后顺序不变。

我通过一个例子来解释一下。比如我们有一组数据 2，9，3，4，8，3，按照大小排序之后就是 2，3，3，4，8，9。

这组数据里有两个 3。经过某种排序算法排序之后，如果两个 3 的前后顺序没有改变，那我们就把这种排序算法叫作稳定的排序算法；如果前后顺序发生变化，那对应的排序算法就叫作不稳定的排序算法。

你可能要问了，两个 3 哪个在前，哪个在后有什么关系啊，稳不稳定又有什么关系呢？为什么要考察排序算法的稳定性呢？

很多数据结构和算法课程，在讲排序的时候，都是用整数来举例，但在真正软件开发中，我们要排序的往往不是单纯的整数，而是一组对象，我们需要按照对象的某个 key 来排序。

比如说，我们现在要给电商交易系统中的“订单”排序。订单有两个属性，一个是下单时间，另一个是订单金额。如果我们现在有 10 万条订单数据，我们希望按照金额从小到大对订单数据排序。对于金额相同的订单，我们希望按照下单时间从早到晚有序。对于这样一个排序需求，我们怎么来做呢？

最先想到的方法是：我们先按照金额对订单数据进行排序，然后，再遍历排序之后的订单数据，对于每个金额相同的小区间再按照下单时间排序。这种排序思路理解起来不难，但是实现起来会很复杂。

借助稳定排序算法，这个问题可以非常简洁地解决。解决思路是这样的：我们先按照下单时间给订单排序，注意是按照下单时间，不是金额。排序完成之后，我们用稳定排序算法，按照订单金额重新排序。两遍排序之后，我们得到的订单数据就是按照金额从小到大排序，金额相同的订单按照下单时间从早到晚排序的。为什么呢？

稳定排序算法可以保持金额相同的两个对象，在排序之后的前后顺序不变。第一次排序之后，所有的订单按照下单时间从早到晚有序了。在第二次排序中，我们用的是稳定的排序算法，所以经过第二次排序之后，相同金额的订单仍然保持下单时间从早到晚有序。



冒泡排序（Bubble Sort）
我们从冒泡排序开始，学习今天的三种排序算法。

冒泡排序只会操作相邻的两个数据。每次冒泡操作都会对相邻的两个元素进行比较，看是否满足大小关系要求。如果不满足就让它俩互换。一次冒泡会让至少一个元素移动到它应该在的位置，重复 n 次，就完成了 n 个数据的排序工作。

我用一个例子，带你看下冒泡排序的整个过程。我们要对一组数据 4，5，6，3，2，1，从小到到大进行排序。第一次冒泡操作的详细过程就是这样：



可以看出，经过一次冒泡操作之后，6 这个元素已经存储在正确的位置上。要想完成所有数据的排序，我们只要进行 6 次这样的冒泡操作就行了。



实际上，刚讲的冒泡过程还可以优化。当某次冒泡操作已经没有数据交换时，说明已经达到完全有序，不用再继续执行后续的冒泡操作。我这里还有另外一个例子，这里面给 6 个元素排序，只需要 4 次冒泡操作就可以了。



冒泡排序算法的原理比较容易理解，具体的代码我贴到下面，你可以结合着代码来看我前面讲的原理。

// 冒泡排序，a 表示数组，n 表示数组大小
public void bubbleSort(int[] a, int n) {
  if (n <= 1) return;
 
 for (int i = 0; i < n; ++i) {
    // 提前退出冒泡循环的标志位
    boolean flag = false;
    for (int j = 0; j < n - i - 1; ++j) {
      if (a[j] > a[j+1]) { // 交换
        int tmp = a[j];
        a[j] = a[j+1];
        a[j+1] = tmp;
        flag = true;  // 表示有数据交换      
      }
    }
    if (!flag) break;  // 没有数据交换，提前退出
  }
}
现在，结合刚才我分析排序算法的三个方面，我有三个问题要问你。

第一，冒泡排序是原地排序算法吗？

冒泡的过程只涉及相邻数据的交换操作，只需要常量级的临时空间，所以它的空间复杂度为 O(1)，是一个原地排序算法。

第二，冒泡排序是稳定的排序算法吗？

在冒泡排序中，只有交换才可以改变两个元素的前后顺序。为了保证冒泡排序算法的稳定性，当有相邻的两个元素大小相等的时候，我们不做交换，相同大小的数据在排序前后不会改变顺序，所以冒泡排序是稳定的排序算法。

第三，冒泡排序的时间复杂度是多少？

最好情况下，要排序的数据已经是有序的了，我们只需要进行一次冒泡操作，就可以结束了，所以最好情况时间复杂度是 O(n)。而最坏的情况是，要排序的数据刚好是倒序排列的，我们需要进行 n 次冒泡操作，所以最坏情况时间复杂度为 O(n2)。



最好、最坏情况下的时间复杂度很容易分析，那平均情况下的时间复杂是多少呢？我们前面讲过，平均时间复杂度就是加权平均期望时间复杂度，分析的时候要结合概率论的知识。

对于包含 n 个数据的数组，这 n 个数据就有 n! 种排列方式。不同的排列方式，冒泡排序执行的时间肯定是不同的。比如我们前面举的那两个例子，其中一个要进行 6 次冒泡，而另一个只需要 4 次。如果用概率论方法定量分析平均时间复杂度，涉及的数学推理和计算就会很复杂。我这里还有一种思路，通过“有序度”和“逆序度”这两个概念来进行分析。

有序度是数组中具有有序关系的元素对的个数。有序元素对用数学表达式表示就是这样：

有序元素对：a[i] <= a[j], 如果 i < j。


同理，对于一个倒序排列的数组，比如 6，5，4，3，2，1，有序度是 0；对于一个完全有序的数组，比如 1，2，3，4，5，6，有序度就是n*(n-1)/2，也就是 15。我们把这种完全有序的数组的有序度叫作满有序度。

逆序度的定义正好跟有序度相反（默认从小到大为有序），我想你应该已经想到了。关于逆序度，我就不举例子讲了。你可以对照我讲的有序度的例子自己看下。

逆序元素对：a[i] > a[j], 如果 i < j。
关于这三个概念，我们还可以得到一个公式：逆序度 = 满有序度 - 有序度。我们排序的过程就是一种增加有序度，减少逆序度的过程，最后达到满有序度，就说明排序完成了。

我还是拿前面举的那个冒泡排序的例子来说明。要排序的数组的初始状态是 4，5，6，3，2，1 ，其中，有序元素对有 (4，5) (4，6)(5，6)，所以有序度是 3。n=6，所以排序完成之后终态的满有序度为 n*(n-1)/2=15。



冒泡排序包含两个操作原子，比较和交换。每交换一次，有序度就加 1。不管算法怎么改进，交换次数总是确定的，即为逆序度，也就是n*(n-1)/2–初始有序度。此例中就是 15–3=12，要进行 12 次交换操作。

对于包含 n 个数据的数组进行冒泡排序，平均交换次数是多少呢？最坏情况下，初始状态的有序度是 0，所以要进行 n*(n-1)/2 次交换。最好情况下，初始状态的有序度是 n*(n-1)/2，就不需要进行交换。我们可以取个中间值 n*(n-1)/4，来表示初始有序度既不是很高也不是很低的平均情况。

换句话说，平均情况下，需要 n*(n-1)/4 次交换操作，比较操作肯定要比交换操作多，而复杂度的上限是 O(n2)，所以平均情况下的时间复杂度就是 O(n2)。

这个平均时间复杂度推导过程其实并不严格，但是很多时候很实用，毕竟概率论的定量分析太复杂，不太好用。等我们讲到快排的时候，我还会再次用这种“不严格”的方法来分析平均时间复杂度。

插入排序（Insertion Sort）
我们先来看一个问题。一个有序的数组，我们往里面添加一个新的数据后，如何继续保持数据有序呢？很简单，我们只要遍历数组，找到数据应该插入的位置将其插入即可。



这是一个动态排序的过程，即动态地往有序集合中添加数据，我们可以通过这种方法保持集合中的数据一直有序。而对于一组静态数据，我们也可以借鉴上面讲的插入方法，来进行排序，于是就有了插入排序算法。

那插入排序具体是如何借助上面的思想来实现排序的呢？

首先，我们将数组中的数据分为两个区间，已排序区间和未排序区间。初始已排序区间只有一个元素，就是数组的第一个元素。插入算法的核心思想是取未排序区间中的元素，在已排序区间中找到合适的插入位置将其插入，并保证已排序区间数据一直有序。重复这个过程，直到未排序区间中元素为空，算法结束。

如图所示，要排序的数据是 4，5，6，1，3，2，其中左侧为已排序区间，右侧是未排序区间。



插入排序也包含两种操作，一种是元素的比较，一种是元素的移动。当我们需要将一个数据 a 插入到已排序区间时，需要拿 a 与已排序区间的元素依次比较大小，找到合适的插入位置。找到插入点之后，我们还需要将插入点之后的元素顺序往后移动一位，这样才能腾出位置给元素 a 插入。

对于不同的查找插入点方法（从头到尾、从尾到头），元素的比较次数是有区别的。但对于一个给定的初始序列，移动操作的次数总是固定的，就等于逆序度。

为什么说移动次数就等于逆序度呢？我拿刚才的例子画了一个图表，你一看就明白了。满有序度是 n*(n-1)/2=15，初始序列的有序度是 5，所以逆序度是 10。插入排序中，数据移动的个数总和也等于 10=3+3+4。



插入排序的原理也很简单吧？我也将代码实现贴在这里，你可以结合着代码再看下。

// 插入排序，a 表示数组，n 表示数组大小
public void insertionSort(int[] a, int n) {
  if (n <= 1) return;
 
  for (int i = 1; i < n; ++i) {
    int value = a[i];
    int j = i - 1;
    // 查找插入的位置
    for (; j >= 0; --j) {
      if (a[j] > value) {
        a[j+1] = a[j];  // 数据移动
      } else {
        break;
      }
    }
    a[j+1] = value; // 插入数据
  }
}
现在，我们来看点稍微复杂的东西。我这里还是有三个问题要问你。

第一，插入排序是原地排序算法吗？

从实现过程可以很明显地看出，插入排序算法的运行并不需要额外的存储空间，所以空间复杂度是 O(1)，也就是说，这是一个原地排序算法。

第二，插入排序是稳定的排序算法吗？

在插入排序中，对于值相同的元素，我们可以选择将后面出现的元素，插入到前面出现元素的后面，这样就可以保持原有的前后顺序不变，所以插入排序是稳定的排序算法。

第三，插入排序的时间复杂度是多少？

如果要排序的数据已经是有序的，我们并不需要搬移任何数据。如果我们从尾到头在有序数据组里面查找插入位置，每次只需要比较一个数据就能确定插入的位置。所以这种情况下，最好是时间复杂度为 O(n)。注意，这里是从尾到头遍历已经有序的数据。

如果数组是倒序的，每次插入都相当于在数组的第一个位置插入新的数据，所以需要移动大量的数据，所以最坏情况时间复杂度为 O(n2)。

还记得我们在数组中插入一个数据的平均时间复杂度是多少吗？没错，是 O(n)。所以，对于插入排序来说，每次插入操作都相当于在数组中插入一个数据，循环执行 n 次插入操作，所以平均时间复杂度为 O(n2)。

选择排序（Selection Sort）
选择排序算法的实现思路有点类似插入排序，也分已排序区间和未排序区间。但是选择排序每次会从未排序区间中找到最小的元素，将其放到已排序区间的末尾。



照例，也有三个问题需要你思考，不过前面两种排序算法我已经分析得很详细了，这里就直接公布答案了。

首先，选择排序空间复杂度为 O(1)，是一种原地排序算法。选择排序的最好情况时间复杂度、最坏情况和平均情况时间复杂度都为 O(n2)。你可以自己来分析看看。

那选择排序是稳定的排序算法吗？这个问题我着重来说一下。

答案是否定的，选择排序是一种不稳定的排序算法。从我前面画的那张图中，你可以看出来，选择排序每次都要找剩余未排序元素中的最小值，并和前面的元素交换位置，这样破坏了稳定性。

比如 5，8，5，2，9 这样一组数据，使用选择排序算法来排序的话，第一次找到最小元素 2，与第一个 5 交换位置，那第一个 5 和中间的 5 顺序就变了，所以就不稳定了。正是因此，相对于冒泡排序和插入排序，选择排序就稍微逊色了。

解答开篇
基本的知识都讲完了，我们来看开篇的问题：冒泡排序和插入排序的时间复杂度都是 O(n2)，都是原地排序算法，为什么插入排序要比冒泡排序更受欢迎呢？

我们前面分析冒泡排序和插入排序的时候讲到，冒泡排序不管怎么优化，元素交换的次数是一个固定值，是原始数据的逆序度。插入排序是同样的，不管怎么优化，元素移动的次数也等于原始数据的逆序度。

但是，从代码实现上来看，冒泡排序的数据交换要比插入排序的数据移动要复杂，冒泡排序需要 3 个赋值操作，而插入排序只需要 1 个。我们来看这段操作：

冒泡排序中数据的交换操作：
if (a[j] > a[j+1]) { // 交换
   int tmp = a[j];
   a[j] = a[j+1];
   a[j+1] = tmp;
   flag = true;
}
 
插入排序中数据的移动操作：
if (a[j] > value) {
  a[j+1] = a[j];  // 数据移动
} else {
  break;
}
我们把执行一个赋值语句的时间粗略地计为单位时间（unit_time），然后分别用冒泡排序和插入排序对同一个逆序度是 K 的数组进行排序。用冒泡排序，需要 K 次交换操作，每次需要 3 个赋值语句，所以交换操作总耗时就是 3*K 单位时间。而插入排序中数据移动操作只需要 K 个单位时间。

这个只是我们非常理论的分析，为了实验，针对上面的冒泡排序和插入排序的 Java 代码，我写了一个性能对比测试程序，随机生成 10000 个数组，每个数组中包含 200 个数据，然后在我的机器上分别用冒泡和插入排序算法来排序，冒泡排序算法大约 700ms 才能执行完成，而插入排序只需要 100ms 左右就能搞定！

所以，虽然冒泡排序和插入排序在时间复杂度上是一样的，都是 O(n2)，但是如果我们希望把性能优化做到极致，那肯定首选插入排序。插入排序的算法思路也有很大的优化空间，我们只是讲了最基础的一种。如果你对插入排序的优化感兴趣，可以自行学习一下希尔排序。

内容小结
要想分析、评价一个排序算法，需要从执行效率、内存消耗和稳定性三个方面来看。因此，这一节，我带你分析了三种时间复杂度是 O(n2) 的排序算法，冒泡排序、插入排序、选择排序。你需要重点掌握的是它们的分析方法。



这三种时间复杂度为 O(n2) 的排序算法中，冒泡排序、选择排序，可能就纯粹停留在理论的层面了，学习的目的也只是为了开拓思维，实际开发中应用并不多，但是插入排序还是挺有用的。后面讲排序优化的时候，我会讲到，有些编程语言中的排序函数的实现原理会用到插入排序算法。

今天讲的这三种排序算法，实现代码都非常简单，对于小规模数据的排序，用起来非常高效。但是在大规模数据排序的时候，这个时间复杂度还是稍微有点高，所以我们更倾向于用下一节要讲的时间复杂度为 O(nlogn) 的排序算法。

课后思考
我们讲过，特定算法是依赖特定的数据结构的。我们今天讲的几种排序算法，都是基于数组实现的。如果数据存储在链表中，这三种排序算法还能工作吗？如果能，那相应的时间、空间复杂度又是多少呢？

欢迎留言和我分享，我会第一时间给你反馈。

我已将本节内容相关的详细代码更新到 GitHub，戳此即可查看。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(219)

双木公子 置顶
对于老师所提课后题，觉得应该有个前提，是否允许修改链表的节点value值，还是只能改变节点的位置。一般而言，考虑只能改变节点位置，冒泡排序相比于数组实现，比较次数一致，但交换时操作更复杂；插入排序，比较次数一致，不需要再有后移操作，找到位置后可以直接插入，但排序完毕后可能需要倒置链表；选择排序比较次数一致，交换操作同样比较麻烦。综上，时间复杂度和空间复杂度并无明显变化，若追求极致性能，冒泡排序的时间复杂度系数会变大，插入排序系数会减小，选择排序无明显变化。
作者回复: 👍 回答的很好 可以作为标准答案了 同学们把这条顶上去吧

2018-10-15

6

752

Monday
本节从昨天更新到今天，一共前前后后认认真真听了五遍，再到今天晚上花3小时把3个排序算法实现，做了冒泡排序与插入排序的测试实验。随机生成二维数组a[200][10000]和b[200][10000]（a,b数组数据一致），然后在我的机器上分别用冒泡和插入排序算法来排序（a数组冒泡，b数组插入），冒泡排序算法大约 16332ms 才能执行完成，而插入排序只需要 2228ms 左右。
总结一句：听五遍不如敲一遍！
2018-10-16


124

德拉
有同学提到的算法过程动态图，可以看看这个https://visualgo.net/
2018-10-27


79

myrabbit
王老师，我发现你文章中的图画的很漂亮，字也写得很漂亮，图文结合的形式对于表达的帮助真的很大！有时候做笔记也可以用此方法，请问你的图文是用什么软件画的？
作者回复: 不是我画的 大编辑画的

2018-10-15

2

60

靑城
总结

一、排序方法与复杂度归类
（1）几种最经典、最常用的排序方法：冒泡排序、插入排序、选择排序、快速排序、归并排序、计数排序、基数排序、桶排序。
（2）复杂度归类
冒泡排序、插入排序、选择排序 O(n^2)
快速排序、归并排序 O(nlogn)
计数排序、基数排序、桶排序 O(n)

二、如何分析一个“排序算法”？
<1>算法的执行效率
1. 最好、最坏、平均情况时间复杂度。
2. 时间复杂度的系数、常数和低阶。
3. 比较次数，交换（或移动）次数。
<2>排序算法的稳定性
1. 稳定性概念：如果待排序的序列中存在值相等的元素，经过排序之后，相等元素之间原有的先后顺序不变。
2. 稳定性重要性：可针对对象的多种属性进行有优先级的排序。
3. 举例：给电商交易系统中的“订单”排序，按照金额大小对订单数据排序，对于相同金额的订单以下单时间早晚排序。用稳定排序算法可简洁地解决。先按照下单时间给订单排序，排序完成后用稳定排序算法按照订单金额重新排序。
<3>排序算法的内存损耗
原地排序算法：特指空间复杂度是O(1)的排序算法。

三、冒泡排序
       冒泡排序只会操作相邻的两个数据。每次冒泡操作都会对相邻的两个元素进行比较，看是否满足大小关系要求，如果不满足就让它俩互换。
稳定性：冒泡排序是稳定的排序算法。
空间复杂度：冒泡排序是原地排序算法。
时间复杂度：
1. 最好情况（满有序度）：O(n)。
2. 最坏情况（满逆序度）：O(n^2)。
3. 平均情况：
       “有序度”和“逆序度”：对于一个不完全有序的数组，如4，5，6，3，2，1，有序元素对为3个（4，5），（4，6），（5，6），有序度为3，逆序度为12；对于一个完全有序的数组，如1，2，3，4，5，6，有序度就是n*(n-1)/2，也就是15，称作满有序度；逆序度=满有序度-有序度；冒泡排序、插入排序交换（或移动）次数=逆序度。
       最好情况下初始有序度为n*(n-1)/2，最坏情况下初始有序度为0，则平均初始有序度为n*(n-1)/4，即交换次数为n*(n-1)/4，因交换次数<比较次数<最坏情况时间复杂度，所以平均时间复杂度为O(n^2)。

四、插入排序
       插入排序将数组数据分成已排序区间和未排序区间。初始已排序区间只有一个元素，即数组第一个元素。在未排序区间取出一个元素插入到已排序区间的合适位置，直到未排序区间为空。
空间复杂度：插入排序是原地排序算法。
时间复杂度：
1. 最好情况：O(n)。
2. 最坏情况：O(n^2)。
3. 平均情况：O(n^2)（往数组中插入一个数的平均时间复杂度是O(n)，一共重复n次）。
稳定性：插入排序是稳定的排序算法。

五、选择排序
       选择排序将数组分成已排序区间和未排序区间。初始已排序区间为空。每次从未排序区间中选出最小的元素插入已排序区间的末尾，直到未排序区间为空。
空间复杂度：选择排序是原地排序算法。
时间复杂度：（都是O(n^2)）
1. 最好情况：O(n^2)。
2. 最坏情况：O(n^2)。
3. 平均情况：O(n^2)。
稳定性：选择排序不是稳定的排序算法。

思考
       选择排序和插入排序的时间复杂度相同，都是O(n^2)，在实际的软件开发中，为什么我们更倾向于使用插入排序而不是冒泡排序算法呢？
       答：从代码实现上来看，冒泡排序的数据交换要比插入排序的数据移动要复杂，冒泡排序需要3个赋值操作，而插入排序只需要1个，所以在对相同数组进行排序时，冒泡排序的运行时间理论上要长于插入排序。
2018-10-15


40

陈问渔
https://mp.weixin.qq.com/s/HQg3BzzQfJXcWyltsgOfCQ

这里面的图解排序算法，很形象。java实现的代码
2018-11-22


28

姜威
总结：
一、几种经典排序算法及其时间复杂度级别
冒泡、插入、选择 O(n^2) 基于比较
快排、归并 O(nlogn) 基于比较
计数、基数、桶 O(n) 不基于比较
二、如何分析一个排序算法？
1.学习排序算法的思路？明确原理、掌握实现以及分析性能。
2.如何分析排序算法性能？从执行效率、内存消耗以及稳定性3个方面分析排序算法的性能。
3.执行效率：从以下3个方面来衡量
1）最好情况、最坏情况、平均情况时间复杂度
2）时间复杂度的系数、常数、低阶：排序的数据量比较小时考虑
3）比较次数和交换（或移动）次数
4.内存消耗：通过空间复杂度来衡量。针对排序算法的空间复杂度，引入原地排序的概念，原地排序算法就是指空间复杂度为O(1)的排序算法。
5.稳定性：如果待排序的序列中存在值等的元素，经过排序之后，相等元素之间原有的先后顺序不变，就说明这个排序算法时稳定的。
三、冒泡排序
1.排序原理
1）冒泡排序只会操作相邻的两个数据。
2）对相邻两个数据进行比较，看是否满足大小关系要求，若不满足让它俩互换。
3）一次冒泡会让至少一个元素移动到它应该在的位置，重复n次，就完成了n个数据的排序工作。
4）优化：若某次冒泡不存在数据交换，则说明已经达到完全有序，所以终止冒泡。
2.代码实现（见下一条留言）
3.性能分析
1）执行效率：最小时间复杂度、最大时间复杂度、平均时间复杂度
最小时间复杂度：数据完全有序时，只需进行一次冒泡操作即可，时间复杂度是O(n)。
最大时间复杂度：数据倒序排序时，需要n次冒泡操作，时间复杂度是O(n^2)。
平均时间复杂度：通过有序度和逆序度来分析。
什么是有序度？
有序度是数组中具有有序关系的元素对的个数，比如[2,4,3,1,5,6]这组数据的有序度就是11，分别是[2,4][2,3][2,5][2,6][4,5][4,6][3,5][3,6][1,5][1,6][5,6]。同理，对于一个倒序数组，比如[6,5,4,3,2,1]，有序度是0；对于一个完全有序的数组，比如[1,2,3,4,5,6]，有序度为n*(n-1)/2，也就是15，完全有序的情况称为满有序度。
什么是逆序度？逆序度的定义正好和有序度相反。核心公式：逆序度=满有序度-有序度。
排序过程，就是有序度增加，逆序度减少的过程，最后达到满有序度，就说明排序完成了。
冒泡排序包含两个操作原子，即比较和交换，每交换一次，有序度加1。不管算法如何改进，交换的次数总是确定的，即逆序度。
对于包含n个数据的数组进行冒泡排序，平均交换次数是多少呢？最坏的情况初始有序度为0，所以要进行n*(n-1)/2交换。最好情况下，初始状态有序度是n*(n-1)/2，就不需要进行交互。我们可以取个中间值n*(n-1)/4，来表示初始有序度既不是很高也不是很低的平均情况。
换句话说，平均情况下，需要n*(n-1)/4次交换操作，比较操作可定比交换操作多，而复杂度的上限是O(n^2)，所以平均情况时间复杂度就是O(n^2)。
以上的分析并不严格，但很实用，这就够了。
2）空间复杂度：每次交换仅需1个临时变量，故空间复杂度为O(1)，是原地排序算法。
3）算法稳定性：如果两个值相等，就不会交换位置，故是稳定排序算法。
四、插入排序
1.算法原理
首先，我们将数组中的数据分为2个区间，即已排序区间和未排序区间。初始已排序区间只有一个元素，就是数组的第一个元素。插入算法的核心思想就是取未排序区间中的元素，在已排序区间中找到合适的插入位置将其插入，并保证已排序区间中的元素一直有序。重复这个过程，直到未排序中元素为空，算法结束。
2.代码实现（见下一条留言）
3.性能分析
1）时间复杂度：最好、最坏、平均情况
如果要排序的数组已经是有序的，我们并不需要搬移任何数据。只需要遍历一遍数组即可，所以时间复杂度是O(n)。如果数组是倒序的，每次插入都相当于在数组的第一个位置插入新的数据，所以需要移动大量的数据，因此时间复杂度是O(n^2)。而在一个数组中插入一个元素的平均时间复杂都是O(n)，插入排序需要n次插入，所以平均时间复杂度是O(n^2)。
2）空间复杂度：从上面的代码可以看出，插入排序算法的运行并不需要额外的存储空间，所以空间复杂度是O(1)，是原地排序算法。
3）算法稳定性：在插入排序中，对于值相同的元素，我们可以选择将后面出现的元素，插入到前面出现的元素的后面，这样就保持原有的顺序不变，所以是稳定的。


作者回复: 👍

2018-10-22


21

Smallfly
二刷了下排序，有了一些新的体会。

冒泡、插入、选择排序都有一个共同点，将待排序数列分为已排序和未排序两部分。在未排序的部分中查找一个最值，放到已排序数列的恰当位置。

具体到代码层面，外层循环的变量用于分割已排序和未排序数，内层循环的变量用于在未排序数中查找。从思路上看，这三种算法其实是一样的，所以时间复杂度也相同。
2019-03-02


15

流风之回雪
a[j+1] = value; // 插入数据，这条语句弄了好久才明白，一直以为 j的值最小为0，那么a[j+1]最小就是a[1]，不过这样赋值逻辑上就有问题，后来debug了一下，发现j是可以为-1的，a[j+1]最小为a[0]，这样逻辑上就通了，果然多敲代码才能弄明白勒
作者回复: 👍钻研精神

2018-11-02


14

醉比
大家多思考多吸收吧。。。。我得多吸收一会
2018-10-15


12

allean
每一次看文章都要至少看三遍，代码实现也至少写三遍，不是追求量，是真的感觉每一次的体会都更加不一样😁
作者回复: 👍

2018-11-13


11

oldman
我用python实现了冒泡排序，插入排序，选择排序。地址如下，欢迎大家一起探讨：
冒泡排序：https://github.com/lipeng1991/testdemo/blob/master/40_bubble_sort.py
插入排序：https://github.com/lipeng1991/testdemo/blob/master/41_insert_sort.py
选择排序： https://github.com/lipeng1991/testdemo/blob/master/42_select_sort.py
2018-10-16


9

峰
三种排序算法不涉及随机读取，所以链表是可以实现的，而且时间复杂度空间空间复杂度和数组一样，O(n*n),O(1).
2018-10-15


9

Jo
冒泡排序的外层循环次数只需要n-1次，此时第1个数字在上一次已经比较过，肯定比第2个小（或大），所以第n次没必要比较了
2018-10-15


8

姜威
五、选择排序
1.算法原理
选择排序算法也分已排序区间和未排序区间。但是选择排序每次会从未排序区间中找到最小的元素，并将其放置到已排序区间的末尾。
2.代码实现（见下一条留言）
3.性能分析
1）时间复杂度：最好、最坏、平均情况
选择排序的最好、最坏、平均情况时间复杂度都是O(n^2)。为什么？因为无论是否有序，每个循环都会完整执行，没得商量。
2）空间复杂度：
选择排序算法空间复杂度是O(1)，是一种原地排序算法。
3）算法稳定性：
选择排序算法不是一种稳定排序算法，比如[5,8,5,2,9]这个数组，使用选择排序算法第一次找到的最小元素就是2，与第一个位置的元素5交换位置，那第一个5和中间的5的顺序就变量，所以就不稳定了。正因如此，相对于冒泡排序和插入排序，选择排序就稍微逊色了。
六、思考
1.冒泡排序和插入排序的时间复杂度都是 O(n^2)，都是原地排序算法，为什么插入排序要比冒泡排序更受欢迎呢？
冒泡排序移动数据有3条赋值语句，而选择排序的交换位置的只有1条赋值语句，因此在有序度相同的情况下，冒泡排序时间复杂度是选择排序的3倍，所以，选择排序性能更好。
2.如果数据存储在链表中，这三种排序算法还能工作吗？如果能，那相应的时间、空间复杂度又是多少呢？

代码实现：
/**
 * 冒泡排序
 * @param a 待排序数组
 * @param n 数组长度
 */
public static void bubbleSort(int[] a, int n) {
        if(n<=0) return ;
for (int i = 0; i < n; i++) {
//标记一次冒泡是否存在数据交换，若存在，则改为true
boolean tag = false;
for (int j = 0; j < n-1-i; j++) {
if(a[j] > a[j+1]){
int temp = a[j];
a[j] = a[j+1];
a[j+1] = temp;
tag = true;
}
}
//若本次冒泡操作未发生数据交换，则终止冒泡操作
if (tag == false) break;
}
}

/**
 * 插入排序
 * @param a 待排序数组
 * @param n 表示数组大小
 */
public static void insertSort(int[] a, int n) {
       if(n<=1) return;
       for(int i=1;i<n;i++){
            int value=a[i];
            int j=i-1;
            //找到插入位置
            for(;j>0;j--){
            if(a[j]>value){
                  a[j+1]=a[j];//移动数据
            } else {
                  break;
            }
       }
       a[j+1]=value;//插入数据
       }
}

/**
 * 选择排序
 * @param a 待排序数组
 * @param n 数组长度
 */
public static void selectSort(int[] a, int n) {
if(n<=0) return;
        for(int i=0;i<n;i++){
             int min=i;
             for(int j=i;j<n;j++){
                  if(a[j] < a[min]) min=j;
             }
             if(min != i){
                  int temp=a[i];
                  a[i]=a[min];
                  a[min]=temp;
             }
        }
}
作者回复: 👍

2018-10-22

1

7

星
冒泡排序的应该重复n-1次就有序了
2018-12-22


4

安静
每天坐地铁看一节都有点坚持不下来了，加油。
2018-11-09


4

zj
订单那个题目为什么要先按照订单时间排序，再按照金额呢？我先按照金额，再按订单时间有什么不一样么
作者回复: 我不是解释了嘛 先金额再时间 代码写起来比较麻烦

2018-11-07


4

mago
对于选择排序，如果每次排序选择的最值为未排序区间的第一个值，这不就是稳定的排序方法了吗？
作者回复: 第一个？那不就是插入排序了嘛

2018-10-23

1

4

王木公
感觉有个问题始终没有解决。前人是如何想出的这些算法？或者说是在怎样的环境下，作者经历了怎样的心路历程想出了这个算法。我认为知道这个很重要，尽管现在学这些算法觉得理所应当，但当时间久了仍然会忘记，尤其是那些细节临界点，人的大脑适合记忆有关联性的东西，这些算法则属于不擅长记忆的创造性内容，如果没有历史那些前提，相信很难根本性掌握。
作者回复: 很难知道人家是怎么想到的，你要求有点高了，说不定灵机一动就想到了。

2019-08-08


3
收起评论

99+99+





# 12 | 排序（下）：如何用快排思想在O(n)内查找第K大元素？




数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



12 | 排序（下）：如何用快排思想在O(n)内查找第K大元素？
王争 2018-10-17



21:58
讲述：修阳 大小：8.81M
上一节我讲了冒泡排序、插入排序、选择排序这三种排序算法，它们的时间复杂度都是 O(n2)，比较高，适合小规模数据的排序。今天，我讲两种时间复杂度为 O(nlogn) 的排序算法，归并排序和快速排序。这两种排序算法适合大规模的数据排序，比上一节讲的那三种排序算法要更常用。

归并排序和快速排序都用到了分治思想，非常巧妙。我们可以借鉴这个思想，来解决非排序的问题，比如：如何在 O(n) 的时间复杂度内查找一个无序数组中的第 K 大元素？ 这就要用到我们今天要讲的内容。

归并排序的原理
我们先来看归并排序（Merge Sort）。

归并排序的核心思想还是蛮简单的。如果要排序一个数组，我们先把数组从中间分成前后两部分，然后对前后两部分分别排序，再将排好序的两部分合并在一起，这样整个数组就都有序了。



归并排序使用的就是分治思想。分治，顾名思义，就是分而治之，将一个大问题分解成小的子问题来解决。小的子问题解决了，大问题也就解决了。

从我刚才的描述，你有没有感觉到，分治思想跟我们前面讲的递归思想很像。是的，分治算法一般都是用递归来实现的。分治是一种解决问题的处理思想，递归是一种编程技巧，这两者并不冲突。分治算法的思想我后面会有专门的一节来讲，现在不展开讨论，我们今天的重点还是排序算法。

前面我通过举例让你对归并有了一个感性的认识，又告诉你，归并排序用的是分治思想，可以用递归来实现。我们现在就来看看如何用递归代码来实现归并排序。

我在第 10 节讲的递归代码的编写技巧你还记得吗？写递归代码的技巧就是，分析得出递推公式，然后找到终止条件，最后将递推公式翻译成递归代码。所以，要想写出归并排序的代码，我们先写出归并排序的递推公式。

递推公式：
merge_sort(p…r) = merge(merge_sort(p…q), merge_sort(q+1…r))
 
终止条件：
p >= r 不用再继续分解
我来解释一下这个递推公式。

merge_sort(p…r) 表示，给下标从 p 到 r 之间的数组排序。我们将这个排序问题转化为了两个子问题，merge_sort(p…q) 和 merge_sort(q+1…r)，其中下标 q 等于 p 和 r 的中间位置，也就是 (p+r)/2。当下标从 p 到 q 和从 q+1 到 r 这两个子数组都排好序之后，我们再将两个有序的子数组合并在一起，这样下标从 p 到 r 之间的数据就也排好序了。

有了递推公式，转化成代码就简单多了。为了阅读方便，我这里只给出伪代码，你可以翻译成你熟悉的编程语言。

// 归并排序算法, A 是数组，n 表示数组大小
merge_sort(A, n) {
  merge_sort_c(A, 0, n-1)
}
 
// 递归调用函数
merge_sort_c(A, p, r) {
  // 递归终止条件
  if p >= r  then return
 
  // 取 p 到 r 之间的中间位置 q
  q = (p+r) / 2
  // 分治递归
  merge_sort_c(A, p, q)
  merge_sort_c(A, q+1, r)
  // 将 A[p...q] 和 A[q+1...r] 合并为 A[p...r]
  merge(A[p...r], A[p...q], A[q+1...r])
}
你可能已经发现了，merge(A[p…r], A[p…q], A[q+1…r]) 这个函数的作用就是，将已经有序的 A[p…q] 和 A[q+1…r] 合并成一个有序的数组，并且放入 A[p…r]。那这个过程具体该如何做呢？

如图所示，我们申请一个临时数组 tmp，大小与 A[p…r] 相同。我们用两个游标 i 和 j，分别指向 A[p…q] 和 A[q+1…r] 的第一个元素。比较这两个元素 A[i] 和 A[j]，如果 A[i]<=A[j]，我们就把 A[i] 放入到临时数组 tmp，并且 i 后移一位，否则将 A[j] 放入到数组 tmp，j 后移一位。

继续上述比较过程，直到其中一个子数组中的所有数据都放入临时数组中，再把另一个数组中的数据依次加入到临时数组的末尾，这个时候，临时数组中存储的就是两个子数组合并之后的结果了。最后再把临时数组 tmp 中的数据拷贝到原数组 A[p…r] 中。



我们把 merge() 函数写成伪代码，就是下面这样：

merge(A[p...r], A[p...q], A[q+1...r]) {
  var i := p，j := q+1，k := 0 // 初始化变量 i, j, k
  var tmp := new array[0...r-p] // 申请一个大小跟 A[p...r] 一样的临时数组
  while i<=q AND j<=r do {
    if A[i] <= A[j] {
      tmp[k++] = A[i++] // i++ 等于 i:=i+1
    } else {
      tmp[k++] = A[j++]
    }
  }
  
  // 判断哪个子数组中有剩余的数据
  var start := i，end := q
  if j<=r then start := j, end:=r
  
  // 将剩余的数据拷贝到临时数组 tmp
  while start <= end do {
    tmp[k++] = A[start++]
  }
  
  // 将 tmp 中的数组拷贝回 A[p...r]
  for i:=0 to r-p do {
    A[p+i] = tmp[i]
  }
}
你还记得第 7 讲讲过的利用哨兵简化编程的处理技巧吗？merge() 合并函数如果借助哨兵，代码就会简洁很多，这个问题留给你思考。

归并排序的性能分析
这样跟着我一步一步分析，归并排序是不是没那么难啦？还记得上节课我们分析排序算法的三个问题吗？接下来，我们来看归并排序的三个问题。

第一，归并排序是稳定的排序算法吗？

结合我前面画的那张图和归并排序的伪代码，你应该能发现，归并排序稳不稳定关键要看 merge() 函数，也就是两个有序子数组合并成一个有序数组的那部分代码。

在合并的过程中，如果 A[p…q] 和 A[q+1…r] 之间有值相同的元素，那我们可以像伪代码中那样，先把 A[p…q] 中的元素放入 tmp 数组。这样就保证了值相同的元素，在合并前后的先后顺序不变。所以，归并排序是一个稳定的排序算法。

第二，归并排序的时间复杂度是多少？

归并排序涉及递归，时间复杂度的分析稍微有点复杂。我们正好借此机会来学习一下，如何分析递归代码的时间复杂度。

在递归那一节我们讲过，递归的适用场景是，一个问题 a 可以分解为多个子问题 b、c，那求解问题 a 就可以分解为求解问题 b、c。问题 b、c 解决之后，我们再把 b、c 的结果合并成 a 的结果。

如果我们定义求解问题 a 的时间是 T(a)，求解问题 b、c 的时间分别是 T(b) 和 T( c)，那我们就可以得到这样的递推关系式：

T(a) = T(b) + T(c) + K
其中 K 等于将两个子问题 b、c 的结果合并成问题 a 的结果所消耗的时间。

从刚刚的分析，我们可以得到一个重要的结论：不仅递归求解的问题可以写成递推公式，递归代码的时间复杂度也可以写成递推公式。

套用这个公式，我们来分析一下归并排序的时间复杂度。

我们假设对 n 个元素进行归并排序需要的时间是 T(n)，那分解成两个子数组排序的时间都是 T(n/2)。我们知道，merge() 函数合并两个有序子数组的时间复杂度是 O(n)。所以，套用前面的公式，归并排序的时间复杂度的计算公式就是：

T(1) = C；   n=1 时，只需要常量级的执行时间，所以表示为 C。
T(n) = 2*T(n/2) + n； n>1
通过这个公式，如何来求解 T(n) 呢？还不够直观？那我们再进一步分解一下计算过程。

T(n) = 2*T(n/2) + n
     = 2*(2*T(n/4) + n/2) + n = 4*T(n/4) + 2*n
     = 4*(2*T(n/8) + n/4) + 2*n = 8*T(n/8) + 3*n
     = 8*(2*T(n/16) + n/8) + 3*n = 16*T(n/16) + 4*n
     ......
     = 2^k * T(n/2^k) + k * n
     ......
通过这样一步一步分解推导，我们可以得到 T(n) = 2^kT(n/2^k)+kn。当 T(n/2^k)=T(1) 时，也就是 n/2^k=1，我们得到 k=log2n 。我们将 k 值代入上面的公式，得到 T(n)=Cn+nlog2n 。如果我们用大 O 标记法来表示的话，T(n) 就等于 O(nlogn)。所以归并排序的时间复杂度是 O(nlogn)。

从我们的原理分析和伪代码可以看出，归并排序的执行效率与要排序的原始数组的有序程度无关，所以其时间复杂度是非常稳定的，不管是最好情况、最坏情况，还是平均情况，时间复杂度都是 O(nlogn)。

第三，归并排序的空间复杂度是多少？

归并排序的时间复杂度任何情况下都是 O(nlogn)，看起来非常优秀。（待会儿你会发现，即便是快速排序，最坏情况下，时间复杂度也是 O(n2)。）但是，归并排序并没有像快排那样，应用广泛，这是为什么呢？因为它有一个致命的“弱点”，那就是归并排序不是原地排序算法。

这是因为归并排序的合并函数，在合并两个有序数组为一个有序数组时，需要借助额外的存储空间。这一点你应该很容易理解。那我现在问你，归并排序的空间复杂度到底是多少呢？是 O(n)，还是 O(nlogn)，应该如何分析呢？

如果我们继续按照分析递归时间复杂度的方法，通过递推公式来求解，那整个归并过程需要的空间复杂度就是 O(nlogn)。不过，类似分析时间复杂度那样来分析空间复杂度，这个思路对吗？

实际上，递归代码的空间复杂度并不能像时间复杂度那样累加。刚刚我们忘记了最重要的一点，那就是，尽管每次合并操作都需要申请额外的内存空间，但在合并完成之后，临时开辟的内存空间就被释放掉了。在任意时刻，CPU 只会有一个函数在执行，也就只会有一个临时的内存空间在使用。临时内存空间最大也不会超过 n 个数据的大小，所以空间复杂度是 O(n)。

快速排序的原理
我们再来看快速排序算法（Quicksort），我们习惯性把它简称为“快排”。快排利用的也是分治思想。乍看起来，它有点像归并排序，但是思路其实完全不一样。我们待会会讲两者的区别。现在，我们先来看下快排的核心思想。

快排的思想是这样的：如果要排序数组中下标从 p 到 r 之间的一组数据，我们选择 p 到 r 之间的任意一个数据作为 pivot（分区点）。

我们遍历 p 到 r 之间的数据，将小于 pivot 的放到左边，将大于 pivot 的放到右边，将 pivot 放到中间。经过这一步骤之后，数组 p 到 r 之间的数据就被分成了三个部分，前面 p 到 q-1 之间都是小于 pivot 的，中间是 pivot，后面的 q+1 到 r 之间是大于 pivot 的。



根据分治、递归的处理思想，我们可以用递归排序下标从 p 到 q-1 之间的数据和下标从 q+1 到 r 之间的数据，直到区间缩小为 1，就说明所有的数据都有序了。

如果我们用递推公式来将上面的过程写出来的话，就是这样：

递推公式：
quick_sort(p…r) = quick_sort(p…q-1) + quick_sort(q+1, r)
 
终止条件：
p >= r
我将递推公式转化成递归代码。跟归并排序一样，我还是用伪代码来实现，你可以翻译成你熟悉的任何语言。

// 快速排序，A 是数组，n 表示数组的大小
quick_sort(A, n) {
  quick_sort_c(A, 0, n-1)
}
// 快速排序递归函数，p,r 为下标
quick_sort_c(A, p, r) {
  if p >= r then return
  
  q = partition(A, p, r) // 获取分区点
  quick_sort_c(A, p, q-1)
  quick_sort_c(A, q+1, r)
}
归并排序中有一个 merge() 合并函数，我们这里有一个 partition() 分区函数。partition() 分区函数实际上我们前面已经讲过了，就是随机选择一个元素作为 pivot（一般情况下，可以选择 p 到 r 区间的最后一个元素），然后对 A[p…r] 分区，函数返回 pivot 的下标。

如果我们不考虑空间消耗的话，partition() 分区函数可以写得非常简单。我们申请两个临时数组 X 和 Y，遍历 A[p…r]，将小于 pivot 的元素都拷贝到临时数组 X，将大于 pivot 的元素都拷贝到临时数组 Y，最后再将数组 X 和数组 Y 中数据顺序拷贝到 A[p…r]。



但是，如果按照这种思路实现的话，partition() 函数就需要很多额外的内存空间，所以快排就不是原地排序算法了。如果我们希望快排是原地排序算法，那它的空间复杂度得是 O(1)，那 partition() 分区函数就不能占用太多额外的内存空间，我们就需要在 A[p…r] 的原地完成分区操作。

原地分区函数的实现思路非常巧妙，我写成了伪代码，我们一起来看一下。

partition(A, p, r) {
  pivot := A[r]
  i := p
  for j := p to r-1 do {
    if A[j] < pivot {
      swap A[i] with A[j]
      i := i+1
    }
  }
  swap A[i] with A[r]
  return i
 
这里的处理有点类似选择排序。我们通过游标 i 把 A[p…r-1] 分成两部分。A[p…i-1] 的元素都是小于 pivot 的，我们暂且叫它“已处理区间”，A[i…r-1] 是“未处理区间”。我们每次都从未处理的区间 A[i…r-1] 中取一个元素 A[j]，与 pivot 对比，如果小于 pivot，则将其加入到已处理区间的尾部，也就是 A[i] 的位置。

数组的插入操作还记得吗？在数组某个位置插入元素，需要搬移数据，非常耗时。当时我们也讲了一种处理技巧，就是交换，在 O(1) 的时间复杂度内完成插入操作。这里我们也借助这个思想，只需要将 A[i] 与 A[j] 交换，就可以在 O(1) 时间复杂度内将 A[j] 放到下标为 i 的位置。

文字不如图直观，所以我画了一张图来展示分区的整个过程。



因为分区的过程涉及交换操作，如果数组中有两个相同的元素，比如序列 6，8，7，6，3，5，9，4，在经过第一次分区操作之后，两个 6 的相对先后顺序就会改变。所以，快速排序并不是一个稳定的排序算法。

到此，快速排序的原理你应该也掌握了。现在，我再来看另外一个问题：快排和归并用的都是分治思想，递推公式和递归代码也非常相似，那它们的区别在哪里呢？



可以发现，归并排序的处理过程是由下到上的，先处理子问题，然后再合并。而快排正好相反，它的处理过程是由上到下的，先分区，然后再处理子问题。归并排序虽然是稳定的、时间复杂度为 O(nlogn) 的排序算法，但是它是非原地排序算法。我们前面讲过，归并之所以是非原地排序算法，主要原因是合并函数无法在原地执行。快速排序通过设计巧妙的原地分区函数，可以实现原地排序，解决了归并排序占用太多内存的问题。

快速排序的性能分析
现在，我们来分析一下快速排序的性能。我在讲解快排的实现原理的时候，已经分析了稳定性和空间复杂度。快排是一种原地、不稳定的排序算法。现在，我们集中精力来看快排的时间复杂度。

快排也是用递归来实现的。对于递归代码的时间复杂度，我前面总结的公式，这里也还是适用的。如果每次分区操作，都能正好把数组分成大小接近相等的两个小区间，那快排的时间复杂度递推求解公式跟归并是相同的。所以，快排的时间复杂度也是 O(nlogn)。

T(1) = C；   n=1 时，只需要常量级的执行时间，所以表示为 C。
T(n) = 2*T(n/2) + n； n>1
但是，公式成立的前提是每次分区操作，我们选择的 pivot 都很合适，正好能将大区间对等地一分为二。但实际上这种情况是很难实现的。

我举一个比较极端的例子。如果数组中的数据原来已经是有序的了，比如 1，3，5，6，8。如果我们每次选择最后一个元素作为 pivot，那每次分区得到的两个区间都是不均等的。我们需要进行大约 n 次分区操作，才能完成快排的整个过程。每次分区我们平均要扫描大约 n/2 个元素，这种情况下，快排的时间复杂度就从 O(nlogn) 退化成了 O(n2)。

我们刚刚讲了两个极端情况下的时间复杂度，一个是分区极其均衡，一个是分区极其不均衡。它们分别对应快排的最好情况时间复杂度和最坏情况时间复杂度。那快排的平均情况时间复杂度是多少呢？

我们假设每次分区操作都将区间分成大小为 9:1 的两个小区间。我们继续套用递归时间复杂度的递推公式，就会变成这样：

T(1) = C；   n=1 时，只需要常量级的执行时间，所以表示为 C。
 
T(n) = T(n/10) + T(9*n/10) + n； n>1
这个公式的递推求解的过程非常复杂，虽然可以求解，但我不推荐用这种方法。实际上，递归的时间复杂度的求解方法除了递推公式之外，还有递归树，在树那一节我再讲，这里暂时不说。我这里直接给你结论：T(n) 在大部分情况下的时间复杂度都可以做到 O(nlogn)，只有在极端情况下，才会退化到 O(n2)。而且，我们也有很多方法将这个概率降到很低，如何来做？我们后面章节再讲。

解答开篇
快排核心思想就是分治和分区，我们可以利用分区的思想，来解答开篇的问题：O(n) 时间复杂度内求无序数组中的第 K 大元素。比如，4， 2， 5， 12， 3 这样一组数据，第 3 大元素就是 4。

我们选择数组区间 A[0…n-1] 的最后一个元素 A[n-1] 作为 pivot，对数组 A[0…n-1] 原地分区，这样数组就分成了三部分，A[0…p-1]、A[p]、A[p+1…n-1]。

如果 p+1=K，那 A[p] 就是要求解的元素；如果 K>p+1, 说明第 K 大元素出现在 A[p+1…n-1] 区间，我们再按照上面的思路递归地在 A[p+1…n-1] 这个区间内查找。同理，如果 K<p+1，那我们就在 A[0…p-1] 区间查找。



我们再来看，为什么上述解决思路的时间复杂度是 O(n)？

第一次分区查找，我们需要对大小为 n 的数组执行分区操作，需要遍历 n 个元素。第二次分区查找，我们只需要对大小为 n/2 的数组执行分区操作，需要遍历 n/2 个元素。依次类推，分区遍历元素的个数分别为、n/2、n/4、n/8、n/16.……直到区间缩小为 1。

如果我们把每次分区遍历的元素个数加起来，就是：n+n/2+n/4+n/8+…+1。这是一个等比数列求和，最后的和等于 2n-1。所以，上述解决思路的时间复杂度就为 O(n)。

你可能会说，我有个很笨的办法，每次取数组中的最小值，将其移动到数组的最前面，然后在剩下的数组中继续找最小值，以此类推，执行 K 次，找到的数据不就是第 K 大元素了吗？

不过，时间复杂度就并不是 O(n) 了，而是 O(K * n)。你可能会说，时间复杂度前面的系数不是可以忽略吗？O(K * n) 不就等于 O(n) 吗？

这个可不能这么简单地划等号。当 K 是比较小的常量时，比如 1、2，那最好时间复杂度确实是 O(n)；但当 K 等于 n/2 或者 n 时，这种最坏情况下的时间复杂度就是 O(n2) 了。

内容小结
归并排序和快速排序是两种稍微复杂的排序算法，它们用的都是分治的思想，代码都通过递归来实现，过程非常相似。理解归并排序的重点是理解递推公式和 merge() 合并函数。同理，理解快排的重点也是理解递推公式，还有 partition() 分区函数。

归并排序算法是一种在任何情况下时间复杂度都比较稳定的排序算法，这也使它存在致命的缺点，即归并排序不是原地排序算法，空间复杂度比较高，是 O(n)。正因为此，它也没有快排应用广泛。

快速排序算法虽然最坏情况下的时间复杂度是 O(n2)，但是平均情况下时间复杂度都是 O(nlogn)。不仅如此，快速排序算法时间复杂度退化到 O(n2) 的概率非常小，我们可以通过合理地选择 pivot 来避免这种情况。

课后思考
现在你有 10 个接口访问日志文件，每个日志文件大小约 300MB，每个文件里的日志都是按照时间戳从小到大排序的。你希望将这 10 个较小的日志文件，合并为 1 个日志文件，合并之后的日志仍然按照时间戳从小到大排列。如果处理上述排序任务的机器内存只有 1GB，你有什么好的解决思路，能“快速”地将这 10 个日志文件合并吗？

欢迎留言和我分享，我会第一时间给你反馈。

我已将本节内容相关的详细代码更新到 GitHub，戳此即可查看。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(329)

峰 置顶
每次从各个文件中取一条数据，在内存中根据数据时间戳构建一个最小堆，然后每次把最小值给写入新文件，同时将最小值来自的那个文件再出来一个数据，加入到最小堆中。这个空间复杂度为常数，但没能很好利用1g内存，而且磁盘单个读取比较慢，所以考虑每次读取一批数据，没了再从磁盘中取，时间复杂度还是一样O(n)。
2018-10-17

1

77

Light Lin
伪代码反而看得费劲，可能还是对代码不够敏感吧
作者回复: 那我以后还是写代码吧

2018-10-17

4

254

李建辉
先构建十条io流，分别指向十个文件，每条io流读取对应文件的第一条数据，然后比较时间戳，选择出时间戳最小的那条数据，将其写入一个新的文件，然后指向该时间戳的io流读取下一行数据，然后继续刚才的操作，比较选出最小的时间戳数据，写入新文件，io流读取下一行数据，以此类推，完成文件的合并， 这种处理方式，日志文件有n个数据就要比较n次，每次比较选出一条数据来写入，时间复杂度是O（n），空间复杂度是O（1）,几乎不占用内存，这是我想出的认为最好的操作了，希望老师指出最佳的做法！！！
作者回复: 你回答的不错 思路是正确的

2018-10-28

7

158

你有资格吗？
建议还是写源码吧，伪代码不能体现细节，基础不好的同学看起来也费劲，还有一个问题课后思考能不能在下一节课开头讲一下，因为感觉您每次留的课后思考都很精辟，想知道以您的维度怎么来思考和解决这个问题
2018-10-18

1

153

王先统
可以为每个文件分配一个40M的数组，再另外分配一个400M的数组储存归并结果，每个文件每次读取40M，对十个数组做归并排序直到其中某个数组的数据被处理完，这时将归并结果写入磁盘，处理完的数组继续读入40M继续参与归并，以此类推，直到所有文件都处理完
2018-10-17

1

69

侯金彪
老师，有个问题没懂，在一个数组中找第k大的数这个问题中，为什么如果p+1=k，a[p]就是要查找的结果呢？
2018-10-17

6

44

我来也
我觉得最后的思考题，[曹源]同学的策略是较优的。
该策略的最大好处是充分利用了内存。
但是我还是会这么做：
1.申请10个40M的数组和一个400M的数组。
2.每个文件都读40M，取各数组中最大时间戳中的最小值。
3.然后利用二分查找，在其他数组中快速定位到小于/等于该时间戳的位置，并做标记。
4.再把各数组中标记位置之前的数据全部放在申请的400M内存中，
5.在原来的40M数组中清除已参加排序的数据。[可优化成不挪动数据，只是用两个索引标记有效数据的起始和截止位置]
6.对400M内存中的有效数据[没装满]做快排。
将排好序的直接写文件。
7.再把每个数组尽量填充满。从第2步开始继续，知道各个文件都读区完毕。
这么做的好处有：
1.每个文件的内容只读区一次，且是批量读区。比每次只取一条快得多。
2.充分利用了读区到内存中的数据。曹源 同学在文件中查找那个中间数是会比较困难的。
3.每个拷贝到400M大数组中参加快排的数据都被写到了文件中，这样每个数只参加了一次快排。
2018-10-21

4

31

www.xnsms.com小鸟接码
用java来写吧，估计这里90％都是java开发！伪代码看的蛋疼
2018-10-23

8

28

曹源
先取得十个文件时间戳的最小值数组的最小值a，和最大值数组的最大值b。然后取mid=(a+b)/2，然后把每个文件按照mid分割，取所有前面部分之和，如果小于1g就可以读入内存快排生成中间文件，否则继续取时间戳的中间值分割文件，直到区间内文件之和小于1g。同理对所有区间都做同样处理。最终把生成的中间文件按照分割的时间区间的次序直接连起来即可。
2018-10-18

1

28

陈华应
坚持初衷，死磕就行，不退缩，不放弃！
2018-10-17


24

周茜(Diane)
看了十几节课，第一次留言竟然是支持老师写伪代码。捂脸。不希望被代表。另外希望总结的同学，尽量少写一点吧，翻着太累了。我也写总结，在自己的笔记应用里。默写。写完再查漏补缺。感觉效果很好，也能检查自己到底学进去多少。
2018-10-26


23

sherry
还是觉得伪代码更好，理解思路然后可以写成自己写练练手，看完代码后就没啥想写的欲望了。
作者回复: 真是众口难调啊😢

2018-10-21


23

Lx
合并函数借助哨兵简化方法
传入的后两个数组各在尾部多放一个和原有最后值相同的值。
循环改为：
while i<=q or j<=r do{
    if A[i] <= A[j] and i<=q {
        tmp[k++] = A[i++]
    }
    else{
        tmp[k++] = A[j++]
    }
}
可以在while循环里完成两个数组的清空，不需要专用部分完成。
2018-10-23

4

21

见贤思齐
我测试出，伪代码中
'
partition(A, p, r) {
  pivot := A[r]
  i := p
  for j := p to r-1 do {
    if A[j] < pivot {
      swap A[i] with A[j]
      i := i+1
    }
  }
  swap A[i] with A[r]
  return i
'

' for j := p to r-1 do '

中的 r-1 应该是 r
2018-10-19

2

16

姜威
三、快速排序
1.算法原理
快排的思想是这样的：如果要排序数组中下标从p到r之间的一组数据，我们选择p到r之间的任意一个数据作为pivot（分区点）。然后遍历p到r之间的数据，将小于pivot的放到左边，将大于pivot的放到右边，将povit放到中间。经过这一步之后，数组p到r之间的数据就分成了3部分，前面p到q-1之间都是小于povit的，中间是povit，后面的q+1到r之间是大于povit的。根据分治、递归的处理思想，我们可以用递归排序下标从p到q-1之间的数据和下标从q+1到r之间的数据，直到区间缩小为1，就说明所有的数据都有序了。
递推公式：quick_sort(p…r) = quick_sort(p…q-1) + quick_sort(q+1, r)
终止条件：p >= r
2.代码实现（参见下一条留言）
3.性能分析
1）算法稳定性：
因为分区过程中涉及交换操作，如果数组中有两个8，其中一个是pivot，经过分区处理后，后面的8就有可能放到了另一个8的前面，先后顺序就颠倒了，所以快速排序是不稳定的排序算法。比如数组[1,2,3,9,8,11,8]，取后面的8作为pivot，那么分区后就会将后面的8与9进行交换。
2）时间复杂度：最好、最坏、平均情况
快排也是用递归实现的，所以时间复杂度也可以用递推公式表示。
如果每次分区操作都能正好把数组分成大小接近相等的两个小区间，那快排的时间复杂度递推求解公式跟归并的相同。
T(1) = C； n=1 时，只需要常量级的执行时间，所以表示为 C。
T(n) = 2*T(n/2) + n； n>1
所以，快排的时间复杂度也是O(nlogn)。
如果数组中的元素原来已经有序了，比如1，3，5，6，8，若每次选择最后一个元素作为pivot，那每次分区得到的两个区间都是不均等的，需要进行大约n次的分区，才能完成整个快排过程，而每次分区我们平均要扫描大约n/2个元素，这种情况下，快排的时间复杂度就是O(n^2)。
前面两种情况，一个是分区及其均衡，一个是分区极不均衡，它们分别对应了快排的最好情况时间复杂度和最坏情况时间复杂度。那快排的平均时间复杂度是多少呢？T(n)大部分情况下是O(nlogn)，只有在极端情况下才是退化到O(n^2)，而且我们也有很多方法将这个概率降低。
3）空间复杂度：快排是一种原地排序算法，空间复杂度是O(1)
四、归并排序与快速排序的区别
归并和快排用的都是分治思想，递推公式和递归代码也非常相似，那它们的区别在哪里呢？
1.归并排序，是先递归调用，再进行合并，合并的时候进行数据的交换。所以它是自下而上的排序方式。何为自下而上？就是先解决子问题，再解决父问题。
2.快速排序，是先分区，在递归调用，分区的时候进行数据的交换。所以它是自上而下的排序方式。何为自上而下？就是先解决父问题，再解决子问题。
五、思考
1.O(n)时间复杂度内求无序数组中第K大元素，比如4，2，5，12，3这样一组数据，第3大元素是4。
我们选择数组区间A[0...n-1]的最后一个元素作为pivot，对数组A[0...n-1]进行原地分区，这样数组就分成了3部分，A[0...p-1]、A[p]、A[p+1...n-1]。
如果如果p+1=K，那A[p]就是要求解的元素；如果K>p+1，说明第K大元素出现在A[p+1...n-1]区间，我们按照上面的思路递归地在A[p+1...n-1]这个区间查找。同理，如果K<p+1，那我们就在A[0...p-1]区间查找。
时间复杂度分析？
第一次分区查找，我们需要对大小为n的数组进行分区操作，需要遍历n个元素。第二次分区查找，我们需要对大小为n/2的数组执行分区操作，需要遍历n/2个元素。依次类推，分区遍历元素的个数分别为n、n/2、n/4、n/8、n/16......直到区间缩小为1。如果把每次分区遍历的元素个数累加起来，就是等比数列求和，结果为2n-1。所以，上述解决问题的思路为O(n)。
2.有10个访问日志文件，每个日志文件大小约为300MB，每个文件里的日志都是按照时间戳从小到大排序的。现在需要将这10个较小的日志文件合并为1个日志文件，合并之后的日志仍然按照时间戳从小到大排列。如果处理上述任务的机器内存只有1GB，你有什么好的解决思路能快速地将这10个日志文件合并？
2018-10-22


14

The Sword of Damocles
王道考研书上看到的快排算法，利用哨兵减少了交换两个元素的复杂步骤，效果更好一些
private static void quickSort(int[] a, int head, int tail) {

        int low = head;
        int high = tail;
        int pivot = a[low];
        if (low < high) {

            while (low<high) {
                while (low < high && pivot <= a[high]) high--;
                a[low] = a[high];
                while (low < high && pivot >= a[low]) low++;
                a[high]=a[low];
            }
            a[low] = pivot;

            if(low>head+1) quickSort(a,head,low-1);
            if(high<tail-1) quickSort(a,high+1,tail);
        }

    }
2018-11-01


13

oldman
我用python实现了归并排序和快速排序，代码如下：
归并排序：https://github.com/lipeng1991/testdemo/blob/master/45_merge_sort.py
快速排序： https://github.com/lipeng1991/testdemo/blob/master/23_quick_sort.py
欢迎一起探讨。今天又回想了一下上一节的三个排序和今天的两个排序，自己又动手画了一下图，实现了一下代码，确切来讲，要想很深的掌握这些东西是需要不断的回想，不断的训练来加深印象的，想想以前学习算法为什么会感觉那么的难，其实就是练的不够，不要太着急的一下子把所有的算法都实现一遍，温故而知新，跟着老师的这个专栏来，一点一点的啃，啃着现在的复习前面的，你会越来越有成就感，你会越来越自信，这就是建立在不断的训练的基础上的。
2018-10-22


13

冷笑的花猫
老师您好，最后的思考题思路基本都是先拆成小文件，然后取出topK，最后再合并。疑惑的是内存不够，怎么读到内存中。如果不读到内存中该怎么实现，读不读到内存中的标准是什么？如果每个文件都是3g，内存只有1g，思路类似。老师能提供下详细的代码吗？相信绝大部分同学都有疑惑，谢谢。
2018-10-17


13

yaya
以前写快排的时候总是喜欢用第一个元素作为k值，partion喜欢用找到左右不符合规则的元素再对调，第k大总是纠结于，下次递归应该是第几大，😂这些其实只要把最后一个元素作为key就可以简化代码了。这门课让我懂了以前好多不懂得小细节。应该说曾经认为自己懂了吧，尤其是排序这里。
思考题，由于本来十个部分就是有序的，利用十个index，把这十个读入内存比较，在里面选择最小的一个index增1，如果一个部分放完了，就继续放剩下的九个部分，直到只剩一个部分，再复制。
2018-10-17

1

12

煦暖
对于“为什么如果p+1=k，a[p]就是要查找的结果呢？”的问题感到不解的同学，我想你是从小到大排序的，所以不理解p+1=k，a[p]就是要查找的结果，如果你是从大到小排序的就不难理解了。
2018-10-18


10
收起评论

99+99+






# 13 | 线性排序：如何根据年龄给100万用户数据排序？




数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



13 | 线性排序：如何根据年龄给100万用户数据排序？
王争 2018-10-19



16:40
讲述：修阳 大小：7.65M
上两节中，我带你着重分析了几种常用排序算法的原理、时间复杂度、空间复杂度、稳定性等。今天，我会讲三种时间复杂度是 O(n) 的排序算法：桶排序、计数排序、基数排序。因为这些排序算法的时间复杂度是线性的，所以我们把这类排序算法叫作线性排序（Linear sort）。之所以能做到线性的时间复杂度，主要原因是，这三个算法是非基于比较的排序算法，都不涉及元素之间的比较操作。

这几种排序算法理解起来都不难，时间、空间复杂度分析起来也很简单，但是对要排序的数据要求很苛刻，所以我们今天学习重点的是掌握这些排序算法的适用场景。

按照惯例，我先给你出一道思考题：如何根据年龄给 100 万用户排序？ 你可能会说，我用上一节课讲的归并、快排就可以搞定啊！是的，它们也可以完成功能，但是时间复杂度最低也是 O(nlogn)。有没有更快的排序方法呢？让我们一起进入今天的内容！

桶排序（Bucket sort）
首先，我们来看桶排序。桶排序，顾名思义，会用到“桶”，核心思想是将要排序的数据分到几个有序的桶里，每个桶里的数据再单独进行排序。桶内排完序之后，再把每个桶里的数据按照顺序依次取出，组成的序列就是有序的了。



桶排序的时间复杂度为什么是 O(n) 呢？我们一块儿来分析一下。

如果要排序的数据有 n 个，我们把它们均匀地划分到 m 个桶内，每个桶里就有 k=n/m 个元素。每个桶内部使用快速排序，时间复杂度为 O(k * logk)。m 个桶排序的时间复杂度就是 O(m * k * logk)，因为 k=n/m，所以整个桶排序的时间复杂度就是 O(n*log(n/m))。当桶的个数 m 接近数据个数 n 时，log(n/m) 就是一个非常小的常量，这个时候桶排序的时间复杂度接近 O(n)。

桶排序看起来很优秀，那它是不是可以替代我们之前讲的排序算法呢？

答案当然是否定的。为了让你轻松理解桶排序的核心思想，我刚才做了很多假设。实际上，桶排序对要排序数据的要求是非常苛刻的。

首先，要排序的数据需要很容易就能划分成 m 个桶，并且，桶与桶之间有着天然的大小顺序。这样每个桶内的数据都排序完之后，桶与桶之间的数据不需要再进行排序。

其次，数据在各个桶之间的分布是比较均匀的。如果数据经过桶的划分之后，有些桶里的数据非常多，有些非常少，很不平均，那桶内数据排序的时间复杂度就不是常量级了。在极端情况下，如果数据都被划分到一个桶里，那就退化为 O(nlogn) 的排序算法了。

桶排序比较适合用在外部排序中。所谓的外部排序就是数据存储在外部磁盘中，数据量比较大，内存有限，无法将数据全部加载到内存中。

比如说我们有 10GB 的订单数据，我们希望按订单金额（假设金额都是正整数）进行排序，但是我们的内存有限，只有几百 MB，没办法一次性把 10GB 的数据都加载到内存中。这个时候该怎么办呢？

现在我来讲一下，如何借助桶排序的处理思想来解决这个问题。

我们可以先扫描一遍文件，看订单金额所处的数据范围。假设经过扫描之后我们得到，订单金额最小是 1 元，最大是 10 万元。我们将所有订单根据金额划分到 100 个桶里，第一个桶我们存储金额在 1 元到 1000 元之内的订单，第二桶存储金额在 1001 元到 2000 元之内的订单，以此类推。每一个桶对应一个文件，并且按照金额范围的大小顺序编号命名（00，01，02…99）。

理想的情况下，如果订单金额在 1 到 10 万之间均匀分布，那订单会被均匀划分到 100 个文件中，每个小文件中存储大约 100MB 的订单数据，我们就可以将这 100 个小文件依次放到内存中，用快排来排序。等所有文件都排好序之后，我们只需要按照文件编号，从小到大依次读取每个小文件中的订单数据，并将其写入到一个文件中，那这个文件中存储的就是按照金额从小到大排序的订单数据了。

不过，你可能也发现了，订单按照金额在 1 元到 10 万元之间并不一定是均匀分布的 ，所以 10GB 订单数据是无法均匀地被划分到 100 个文件中的。有可能某个金额区间的数据特别多，划分之后对应的文件就会很大，没法一次性读入内存。这又该怎么办呢？

针对这些划分之后还是比较大的文件，我们可以继续划分，比如，订单金额在 1 元到 1000 元之间的比较多，我们就将这个区间继续划分为 10 个小区间，1 元到 100 元，101 元到 200 元，201 元到 300 元…901 元到 1000 元。如果划分之后，101 元到 200 元之间的订单还是太多，无法一次性读入内存，那就继续再划分，直到所有的文件都能读入内存为止。

计数排序（Counting sort）
我个人觉得，计数排序其实是桶排序的一种特殊情况。当要排序的 n 个数据，所处的范围并不大的时候，比如最大值是 k，我们就可以把数据划分成 k 个桶。每个桶内的数据值都是相同的，省掉了桶内排序的时间。

我们都经历过高考，高考查分数系统你还记得吗？我们查分数的时候，系统会显示我们的成绩以及所在省的排名。如果你所在的省有 50 万考生，如何通过成绩快速排序得出名次呢？

考生的满分是 900 分，最小是 0 分，这个数据的范围很小，所以我们可以分成 901 个桶，对应分数从 0 分到 900 分。根据考生的成绩，我们将这 50 万考生划分到这 901 个桶里。桶内的数据都是分数相同的考生，所以并不需要再进行排序。我们只需要依次扫描每个桶，将桶内的考生依次输出到一个数组中，就实现了 50 万考生的排序。因为只涉及扫描遍历操作，所以时间复杂度是 O(n)。

计数排序的算法思想就是这么简单，跟桶排序非常类似，只是桶的大小粒度不一样。不过，为什么这个排序算法叫“计数”排序呢？“计数”的含义来自哪里呢？

想弄明白这个问题，我们就要来看计数排序算法的实现方法。我还拿考生那个例子来解释。为了方便说明，我对数据规模做了简化。假设只有 8 个考生，分数在 0 到 5 分之间。这 8 个考生的成绩我们放在一个数组 A[8] 中，它们分别是：2，5，3，0，2，3，0，3。

考生的成绩从 0 到 5 分，我们使用大小为 6 的数组 C[6] 表示桶，其中下标对应分数。不过，C[6] 内存储的并不是考生，而是对应的考生个数。像我刚刚举的那个例子，我们只需要遍历一遍考生分数，就可以得到 C[6] 的值。



从图中可以看出，分数为 3 分的考生有 3 个，小于 3 分的考生有 4 个，所以，成绩为 3 分的考生在排序之后的有序数组 R[8] 中，会保存下标 4，5，6 的位置。



那我们如何快速计算出，每个分数的考生在有序数组中对应的存储位置呢？这个处理方法非常巧妙，很不容易想到。

思路是这样的：我们对 C[6] 数组顺序求和，C[6] 存储的数据就变成了下面这样子。C[k] 里存储小于等于分数 k 的考生个数。



有了前面的数据准备之后，现在我就要讲计数排序中最复杂、最难理解的一部分了，请集中精力跟着我的思路！

我们从后到前依次扫描数组 A。比如，当扫描到 3 时，我们可以从数组 C 中取出下标为 3 的值 7，也就是说，到目前为止，包括自己在内，分数小于等于 3 的考生有 7 个，也就是说 3 是数组 R 中的第 7 个元素（也就是数组 R 中下标为 6 的位置）。当 3 放入到数组 R 中后，小于等于 3 的元素就只剩下了 6 个了，所以相应的 C[3] 要减 1，变成 6。

以此类推，当我们扫描到第 2 个分数为 3 的考生的时候，就会把它放入数组 R 中的第 6 个元素的位置（也就是下标为 5 的位置）。当我们扫描完整个数组 A 后，数组 R 内的数据就是按照分数从小到大有序排列的了。



上面的过程有点复杂，我写成了代码，你可以对照着看下。

// 计数排序，a 是数组，n 是数组大小。假设数组中存储的都是非负整数。
public void countingSort(int[] a, int n) {
  if (n <= 1) return;
 
  // 查找数组中数据的范围
  int max = a[0];
  for (int i = 1; i < n; ++i) {
    if (max < a[i]) {
      max = a[i];
    }
  }
 
  int[] c = new int[max + 1]; // 申请一个计数数组 c，下标大小 [0,max]
  for (int i = 0; i <= max; ++i) {
    c[i] = 0;
  }
 
  // 计算每个元素的个数，放入 c 中
  for (int i = 0; i < n; ++i) {
    c[a[i]]++;
  }
 
  // 依次累加
  for (int i = 1; i <= max; ++i) {
    c[i] = c[i-1] + c[i];
  }
 
  // 临时数组 r，存储排序之后的结果
  int[] r = new int[n];
  // 计算排序的关键步骤，有点难理解
  for (int i = n - 1; i >= 0; --i) {
    int index = c[a[i]]-1;
    r[index] = a[i];
    c[a[i]]--;
  }
 
  // 将结果拷贝给 a 数组
  for (int i = 0; i < n; ++i) {
    a[i] = r[i];
  }
}
这种利用另外一个数组来计数的实现方式是不是很巧妙呢？这也是为什么这种排序算法叫计数排序的原因。不过，你千万不要死记硬背上面的排序过程，重要的是理解和会用。

我总结一下，计数排序只能用在数据范围不大的场景中，如果数据范围 k 比要排序的数据 n 大很多，就不适合用计数排序了。而且，计数排序只能给非负整数排序，如果要排序的数据是其他类型的，要将其在不改变相对大小的情况下，转化为非负整数。

比如，还是拿考生这个例子。如果考生成绩精确到小数后一位，我们就需要将所有的分数都先乘以 10，转化成整数，然后再放到 9010 个桶内。再比如，如果要排序的数据中有负数，数据的范围是 [-1000, 1000]，那我们就需要先对每个数据都加 1000，转化成非负整数。

基数排序（Radix sort）
我们再来看这样一个排序问题。假设我们有 10 万个手机号码，希望将这 10 万个手机号码从小到大排序，你有什么比较快速的排序方法呢？

我们之前讲的快排，时间复杂度可以做到 O(nlogn)，还有更高效的排序算法吗？桶排序、计数排序能派上用场吗？手机号码有 11 位，范围太大，显然不适合用这两种排序算法。针对这个排序问题，有没有时间复杂度是 O(n) 的算法呢？现在我就来介绍一种新的排序算法，基数排序。

刚刚这个问题里有这样的规律：假设要比较两个手机号码 a，b 的大小，如果在前面几位中，a 手机号码已经比 b 手机号码大了，那后面的几位就不用看了。

借助稳定排序算法，这里有一个巧妙的实现思路。还记得我们第 11 节中，在阐述排序算法的稳定性的时候举的订单的例子吗？我们这里也可以借助相同的处理思路，先按照最后一位来排序手机号码，然后，再按照倒数第二位重新排序，以此类推，最后按照第一位重新排序。经过 11 次排序之后，手机号码就都有序了。

手机号码稍微有点长，画图比较不容易看清楚，我用字符串排序的例子，画了一张基数排序的过程分解图，你可以看下。



注意，这里按照每位来排序的排序算法要是稳定的，否则这个实现思路就是不正确的。因为如果是非稳定排序算法，那最后一次排序只会考虑最高位的大小顺序，完全不管其他位的大小关系，那么低位的排序就完全没有意义了。

根据每一位来排序，我们可以用刚讲过的桶排序或者计数排序，它们的时间复杂度可以做到 O(n)。如果要排序的数据有 k 位，那我们就需要 k 次桶排序或者计数排序，总的时间复杂度是 O(k*n)。当 k 不大的时候，比如手机号码排序的例子，k 最大就是 11，所以基数排序的时间复杂度就近似于 O(n)。

实际上，有时候要排序的数据并不都是等长的，比如我们排序牛津字典中的 20 万个英文单词，最短的只有 1 个字母，最长的我特意去查了下，有 45 个字母，中文翻译是尘肺病。对于这种不等长的数据，基数排序还适用吗？

实际上，我们可以把所有的单词补齐到相同长度，位数不够的可以在后面补“0”，因为根据ASCII 值，所有字母都大于“0”，所以补“0”不会影响到原有的大小顺序。这样就可以继续用基数排序了。

我来总结一下，基数排序对要排序的数据是有要求的，需要可以分割出独立的“位”来比较，而且位之间有递进的关系，如果 a 数据的高位比 b 数据大，那剩下的低位就不用比较了。除此之外，每一位的数据范围不能太大，要可以用线性排序算法来排序，否则，基数排序的时间复杂度就无法做到 O(n) 了。

解答开篇
今天的内容学完了。我们再回过头来看看开篇的思考题：如何根据年龄给 100 万用户排序？现在思考题是不是变得非常简单了呢？我来说一下我的解决思路。

实际上，根据年龄给 100 万用户排序，就类似按照成绩给 50 万考生排序。我们假设年龄的范围最小 1 岁，最大不超过 120 岁。我们可以遍历这 100 万用户，根据年龄将其划分到这 120 个桶里，然后依次顺序遍历这 120 个桶中的元素。这样就得到了按照年龄排序的 100 万用户数据。

内容小结
今天，我们学习了 3 种线性时间复杂度的排序算法，有桶排序、计数排序、基数排序。它们对要排序的数据都有比较苛刻的要求，应用不是非常广泛。但是如果数据特征比较符合这些排序算法的要求，应用这些算法，会非常高效，线性时间复杂度可以达到 O(n)。

桶排序和计数排序的排序思想是非常相似的，都是针对范围不大的数据，将数据划分成不同的桶来实现排序。基数排序要求数据可以划分成高低位，位之间有递进关系。比较两个数，我们只需要比较高位，高位相同的再比较低位。而且每一位的数据范围不能太大，因为基数排序算法需要借助桶排序或者计数排序来完成每一个位的排序工作。

课后思考
我们今天讲的都是针对特殊数据的排序算法。实际上，还有很多看似是排序但又不需要使用排序算法就能处理的排序问题。

假设我们现在需要对 D，a，F，B，c，A，z 这个字符串进行排序，要求将其中所有小写字母都排在大写字母的前面，但小写字母内部和大写字母内部不要求有序。比如经过排序之后为 a，c，z，D，F，B，A，这个如何来实现呢？如果字符串中存储的不仅有大小写字母，还有数字。要将小写字母的放到前面，大写字母放在最后，数字放在中间，不用排序算法，又该怎么解决呢？

欢迎留言和我分享，我会第一时间给你反馈。

我已将本节内容相关的详细代码更新到 GitHub，戳此即可查看。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(221)

wucj 置顶
用两个指针a、b：a指针从头开始往后遍历，遇到大写字母就停下，b从后往前遍历，遇到小写字母就停下，交换a、b指针对应的元素；重复如上过程，直到a、b指针相交。
对于小写字母放前面，数字放中间，大写字母放后面，可以先将数据分为小写字母和非小写字母两大类，进行如上交换后再在非小写字母区间内分为数字和大写字母做同样处理
2018-10-19

2

312

伟忠
课后思考，利用桶排序思想，弄小写，大写，数字三个桶，遍历一遍，都放进去，然后再从桶中取出来就行了。相当于遍历了两遍，复杂度O(n)
2018-10-19

5

306


渐渐有些掉队的趋势
2018-10-19

1

226

传说中的成大大
排序算法基本上算是学完了，昨天我在实践快排的时候 我就发现这样一个问题，虽然理解了原理 但是写起来还不是很顺畅，如果写出来的代码跟老师的一模一样 那就不叫理解了原理 那叫背代码，我昨天也去翻了大话数据结构里面的快排 发现代码又不一样，所以我觉得接下来的时间就应该根据思路多实现一下这些排序代码，不能死记硬背代码，多理解原理
2018-10-19


97

胡二
计数排序中，从数组A中取数，也是可以从头开始取的吧
作者回复: 可以的 只不过就不是稳定排序算法了

2018-10-19

4

38

在路上
我觉着可以把大小写字母根据对应的ASCII值转化成数字，然后遍历一遍就可以了吧。
2018-11-02


28

姜威
总结：桶排序、计数排序、基数排序
一、线性排序算法介绍
1.线性排序算法包括桶排序、计数排序、基数排序。
2.线性排序算法的时间复杂度为O(n)。
3.此3种排序算法都不涉及元素之间的比较操作，是非基于比较的排序算法。
4.对排序数据的要求很苛刻，重点掌握此3种排序算法的适用场景。
二、桶排序（Bucket sort）
1.算法原理：
1）将要排序的数据分到几个有序的桶里，每个桶里的数据再单独进行快速排序。
2）桶内排完序之后，再把每个桶里的数据按照顺序依次取出，组成的序列就是有序的了。
2.使用条件
1）要排序的数据需要很容易就能划分成m个桶，并且桶与桶之间有着天然的大小顺序。
2）数据在各个桶之间分布是均匀的。
3.适用场景
1）桶排序比较适合用在外部排序中。
2）外部排序就是数据存储在外部磁盘且数据量大，但内存有限无法将整个数据全部加载到内存中。
4.应用案例
1）需求描述：
有10GB的订单数据，需按订单金额（假设金额都是正整数）进行排序
但内存有限，仅几百MB
2）解决思路：
扫描一遍文件，看订单金额所处数据范围，比如1元-10万元，那么就分100个桶。
第一个桶存储金额1-1000元之内的订单，第二个桶存1001-2000元之内的订单，依次类推。
每个桶对应一个文件，并按照金额范围的大小顺序编号命名（00，01，02，…，99）。
将100个小文件依次放入内存并用快排排序。
所有文件排好序后，只需按照文件编号从小到大依次读取每个小文件并写到大文件中即可。
3）注意点：若单个文件无法全部载入内存，则针对该文件继续按照前面的思路进行处理即可。
三、计数排序（Counting sort）
1.算法原理
1）计数其实就是桶排序的一种特殊情况。
2）当要排序的n个数据所处范围并不大时，比如最大值为k，则分成k个桶
3）每个桶内的数据值都是相同的，就省掉了桶内排序的时间。
2.代码实现（参见下一条留言）
案例分析：
假设只有8个考生分数在0-5分之间，成绩存于数组A[8] = [2，5，3，0，2，3，0，3]。
使用大小为6的数组C[6]表示桶，下标对应分数，即0，1，2，3，4，5。
C[6]存储的是考生人数，只需遍历一边考生分数，就可以得到C[6] = [2，0，2，3，0，1]。
对C[6]数组顺序求和则C[6]=[2，2，4，7，7，8]，c[k]存储的是小于等于分数k的考生个数。
数组R[8] = [0，0，2，2，3，3，3，5]存储考生名次。那么如何得到R[8]的呢？
从后到前依次扫描数组A，比如扫描到3时，可以从数组C中取出下标为3的值7，也就是说，到目前为止，包括自己在内，分数小于等于3的考生有7个，也就是说3是数组R的第7个元素（也就是数组R中下标为6的位置）。当3放入数组R后，小于等于3的元素就剩下6个了，相应的C[3]要减1变成6。
以此类推，当扫描到第二个分数为3的考生时，就会把它放入数组R中第6个元素的位置（也就是下标为5的位置）。当扫描完数组A后，数组R内的数据就是按照分数从小到大排列的了。
3.使用条件
1）只能用在数据范围不大的场景中，若数据范围k比要排序的数据n大很多，就不适合用计数排序；
2）计数排序只能给非负整数排序，其他类型需要在不改变相对大小情况下，转换为非负整数；
3）比如如果考试成绩精确到小数后一位，就需要将所有分数乘以10，转换为整数。
四、基数排序（Radix sort）
1.算法原理（以排序10万个手机号为例来说明）
1）比较两个手机号码a，b的大小，如果在前面几位中a已经比b大了，那后面几位就不用看了。
2）借助稳定排序算法的思想，可以先按照最后一位来排序手机号码，然后再按照倒数第二位来重新排序，以此类推，最后按照第一个位重新排序。
3）经过11次排序后，手机号码就变为有序的了。
4）每次排序有序数据范围较小，可以使用桶排序或计数排序来完成。
2.使用条件
1）要求数据可以分割独立的“位”来比较；
2）位之间由递进关系，如果a数据的高位比b数据大，那么剩下的地位就不用比较了；
3）每一位的数据范围不能太大，要可以用线性排序，否则基数排序的时间复杂度无法做到O(n)。
五、思考
1.如何根据年龄给100万用户数据排序？
2.对D，a，F，B，c，A，z这几个字符串进行排序，要求将其中所有小写字母都排在大写字母前面，但是小写字母内部和大写字母内部不要求有序。比如经过排序后为a，c，z，D，F，B，A，这个如何实现呢？如果字符串中处理大小写，还有数字，将数字放在最前面，又该如何解决呢？
2018-10-22


25

Monday
老师，个人感觉这节没有以往章节的细致了，拿桶排序来举例：
1、自问的三个问题只有了时间复杂度分析，少了是否为稳定排序算法和空间复杂度两个问题。
1.1）稳定性，若单个桶内用归并排序，则可保证桶排序的稳定性；若使用快排则无法保证稳定性。
1.2）空间复杂度，桶都是额外的存储空间，只有确定了单个桶的大小才能确定空间复杂度；n个元素假设分为m个桶，每个桶分配n/m个元素的大小？个人觉得单个桶的大小不好确定，但是范围应该在n/m~n之间
2、没有伪代码实现，自己在代码实现中遇到了一些问题
2.1）桶个数的设置依据什么原则？
2.2）桶大小的设置，让桶的能动扩容？
望回复，谢谢！
作者回复: 1）这一节课的重点是应用场景
2）关于时间 空间 稳定性分析确实没有前面两节详细。不过通过前两节的学习 这三种排序算法的时间 空间 稳定性分析应该简单多了
3）你说的对 要用归并
4）桶的大小设置的原则 权衡空间 时间复杂度 在你能接受的执行时间和内存占用下完成就可以 并没有一个标准答案
5）是的 要么用链表 要么用动态扩容的数组

2018-10-22


21

seniusen
计数排序中可以从头向后取数据吗？个人感觉似乎是一样的过程。
作者回复: 可以的 但就不是稳定排序算法了

2018-10-19


16

伟忠
以前了解桶排序，以为计数排序就是桶排序的优化，很简单，没想到里面用"顺序求和"快速得出值对应的原排序对象位置(有多个相同值的时候是这个值在排序后的数组中的最后位置，用一次以后减少1)，这样就可以用对象属性来将对象进行排序了，这波操作666

基数排序用了排序算法的稳定性，排多次
2018-10-19


16

徐凯
包含数字的话。其实就是一个荷兰国旗问题 思路与第一题类似 一个指针控制左边界 一个指针控制右边界 左边界控制小写字母 右边界控制大写字母 另外一个指针扫描 遇到小写字母跳过 遇到大写字母则将右边界-1的元素交换过来 此时q指针应保持原位置不动 因为右边还未扫描过 交换过来的元素无法保证就是小写字母
2018-10-19


13

Kudo
关于思考题：
如果分为三个桶（大写、小写、数字），那么时间复杂度应该不会达到O(n)，因为O(nlog(n/m))中的m只有3，时间复杂度会退化到O(nlogn)。如果要达到O(n)的复杂度，我认为应该使用计数排序，将A-Za-z0-9作为62个桶，这样遍历一次就可以完成排序。（如果上述理解有偏差，请作者务必指出，多谢！）
2018-10-19

1

7

烈冬冰夏
老师 您好。您说的手机号码排序伪代码向下面这样
sort(array,comparator)//对比第11位
sort(array,comparator)//对比第10位
sort(array,comparator)//对比第9位
sort(array,comparator)//对比第8位
sort(array,comparator)//对比第7位
sort(array,comparator)//对比第6位
sort(array,comparator)//对比第5位
sort(array,comparator)//对比第4位
sort(array,comparator)//对比第3位
sort(array,comparator)//对比第2位
sort(array,comparator)//对比第1位

我不太明白这和直接对比手机号码大小有什么区别
sort(array,comparator)//对比手机号码
作者回复: 每一位排序用的是O（n）时间复杂度的桶排序或者计数排序

2018-11-06


6

coulson
老师，你讲的一会数组C,一会数组R，一会数组A，已经被绕晕了，咋办？跟不上节奏了
作者回复: 多看几遍 确实不好理解

2018-10-30


6

峰
思考题，快排划分的思想分成两半，分成三份(双轴)，只不过固定选取一个合适的pivot就ok。
2018-10-19


5

叶明
老师，你好，有个疑问：
在计数排序中，第一次得到数组int[] c = new int[]{2,0,2,3,0,1}之后，
能不能直接遍历数组c，

int j=0;
for(int i=0; i<c.length; i++){
    int count = c[i];
    for(int k=0;k<count;k++){
        a[j++] = i;
    }
}
这样不是也对所有的分数进行排序了吗？这个不知道可以不？第一次发言，希望能回复下
作者回复: 如果你排序的不是单纯的数字 而是一个对象呢

2018-12-17

1

4

kakasi
桶排序:
1. 原理: 根据数据范围，分成若干个数据段的桶，通过遍历讲数据放到对应的桶中。每个桶里都进行快排或归并。
2. 时间复杂度: 最好o(n), 最坏o(nlogn), 平均o(n)，一般桶分的越细越多复杂度就会最好。
3. 内存消耗: o(n)
4. 稳定性: 取决于每个桶的排序方式，快排就不稳定，归并就稳定。
5. 适用场景: 数据范围不大的。内存吃紧的，如磁盘的读写可以分成多个小文件并对每个小文件排序，然后直接写到大文件里，这个时候内存消耗不再是o(n)了。

计数排序:
1. 原理: 特殊的桶排序，即每个下标代表一个数据范围，其值就是这个数据的个数。
2. 时间复杂度: 都是o(n)
3. 内存消耗: o(n)
4. 稳定性: 稳定，只要整理最后结果时从后开始遍历即可。
5. 适用场景: 数据范围不大的，如年龄排序。

基数排序:
1. 原理: 对数据的每一位进行桶排序或计数排序，对每位排序后结果就是有序的。
2. 时间复杂度: 最好o(n), 最坏o(nlogn), 平均o(n)
3. 内存消耗: o(n)
4. 稳定性: 稳定。否则就排不成的。
5. 适用场景: 是在桶排序和计数排序基础上进行的，保证每位数据范围不大，并且位数也不是很多。
2018-11-04


4

Ant
看了俩小时
作者回复: 如果之前没基础 想掌握牢固 起码看一个礼拜吧😄

2018-11-02


4

刘強
根据acill码的天然顺序，分三个桶就可以把
2018-10-19


4

林贻民
老师你好,觉得计数排序可以完全被桶排序取代,由于计数排序对数据的要求是范围不大,不妨设为k,那完全可以分为k个桶,遍历一遍待排序列,将对应元素放入相关桶中,最后在按顺序遍历一次,即可得到顺序序列.在时间复杂度,空间复杂度上与计数排序一样,但是在代码编写上要比计数排序要简单的多.
作者回复: 👍 你说的没错，在实践中，桶排序可能更实用些：）

2019-03-04


3
收起评论

99+99+




# 14 | 排序优化：如何实现一个通用的、高性能的排序函数？



数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



14 | 排序优化：如何实现一个通用的、高性能的排序函数？
王争 2018-10-22



10:17
讲述：修阳 大小：4.72M
几乎所有的编程语言都会提供排序函数，比如 C 语言中 qsort()，C++ STL 中的 sort()、stable_sort()，还有 Java 语言中的 Collections.sort()。在平时的开发中，我们也都是直接使用这些现成的函数来实现业务逻辑中的排序功能。那你知道这些排序函数是如何实现的吗？底层都利用了哪种排序算法呢？

基于这些问题，今天我们就来看排序这部分的最后一块内容：如何实现一个通用的、高性能的排序函数？

如何选择合适的排序算法？
如果要实现一个通用的、高效率的排序函数，我们应该选择哪种排序算法？我们先回顾一下前面讲过的几种排序算法。



我们前面讲过，线性排序算法的时间复杂度比较低，适用场景比较特殊。所以如果要写一个通用的排序函数，不能选择线性排序算法。

如果对小规模数据进行排序，可以选择时间复杂度是 O(n2) 的算法；如果对大规模数据进行排序，时间复杂度是 O(nlogn) 的算法更加高效。所以，为了兼顾任意规模数据的排序，一般都会首选时间复杂度是 O(nlogn) 的排序算法来实现排序函数。

时间复杂度是 O(nlogn) 的排序算法不止一个，我们已经讲过的有归并排序、快速排序，后面讲堆的时候我们还会讲到堆排序。堆排序和快速排序都有比较多的应用，比如 Java 语言采用堆排序实现排序函数，C 语言使用快速排序实现排序函数。

不知道你有没有发现，使用归并排序的情况其实并不多。我们知道，快排在最坏情况下的时间复杂度是 O(n2)，而归并排序可以做到平均情况、最坏情况下的时间复杂度都是 O(nlogn)，从这点上看起来很诱人，那为什么它还是没能得到“宠信”呢？

还记得我们上一节讲的归并排序的空间复杂度吗？归并排序并不是原地排序算法，空间复杂度是 O(n)。所以，粗略点、夸张点讲，如果要排序 100MB 的数据，除了数据本身占用的内存之外，排序算法还要额外再占用 100MB 的内存空间，空间耗费就翻倍了。

前面我们讲到，快速排序比较适合来实现排序函数，但是，我们也知道，快速排序在最坏情况下的时间复杂度是 O(n2)，如何来解决这个“复杂度恶化”的问题呢？

如何优化快速排序？
我们先来看下，为什么最坏情况下快速排序的时间复杂度是 O(n2) 呢？我们前面讲过，如果数据原来就是有序的或者接近有序的，每次分区点都选择最后一个数据，那快速排序算法就会变得非常糟糕，时间复杂度就会退化为 O(n2)。实际上，这种 O(n2) 时间复杂度出现的主要原因还是因为我们分区点选的不够合理。

那什么样的分区点是好的分区点呢？或者说如何来选择分区点呢？

最理想的分区点是：被分区点分开的两个分区中，数据的数量差不多。

如果很粗暴地直接选择第一个或者最后一个数据作为分区点，不考虑数据的特点，肯定会出现之前讲的那样，在某些情况下，排序的最坏情况时间复杂度是 O(n2)。为了提高排序算法的性能，我们也要尽可能地让每次分区都比较平均。

我这里介绍两个比较常用、比较简单的分区算法，你可以直观地感受一下。

1. 三数取中法
我们从区间的首、尾、中间，分别取出一个数，然后对比大小，取这 3 个数的中间值作为分区点。这样每间隔某个固定的长度，取数据出来比较，将中间值作为分区点的分区算法，肯定要比单纯取某一个数据更好。但是，如果要排序的数组比较大，那“三数取中”可能就不够了，可能要“五数取中”或者“十数取中”。

2. 随机法
随机法就是每次从要排序的区间中，随机选择一个元素作为分区点。这种方法并不能保证每次分区点都选的比较好，但是从概率的角度来看，也不大可能会出现每次分区点都选的很差的情况，所以平均情况下，这样选的分区点是比较好的。时间复杂度退化为最糟糕的 O(n2) 的情况，出现的可能性不大。

好了，我这里也只是抛砖引玉，如果想了解更多寻找分区点的方法，你可以自己课下深入去学习一下。

我们知道，快速排序是用递归来实现的。我们在递归那一节讲过，递归要警惕堆栈溢出。为了避免快速排序里，递归过深而堆栈过小，导致堆栈溢出，我们有两种解决办法：第一种是限制递归深度。一旦递归过深，超过了我们事先设定的阈值，就停止递归。第二种是通过在堆上模拟实现一个函数调用栈，手动模拟递归压栈、出栈的过程，这样就没有了系统栈大小的限制。

举例分析排序函数
为了让你对如何实现一个排序函数有一个更直观的感受，我拿 Glibc 中的 qsort() 函数举例说明一下。虽说 qsort() 从名字上看，很像是基于快速排序算法实现的，实际上它并不仅仅用了快排这一种算法。

如果你去看源码，你就会发现，qsort() 会优先使用归并排序来排序输入数据，因为归并排序的空间复杂度是 O(n)，所以对于小数据量的排序，比如 1KB、2KB 等，归并排序额外需要 1KB、2KB 的内存空间，这个问题不大。现在计算机的内存都挺大的，我们很多时候追求的是速度。还记得我们前面讲过的用空间换时间的技巧吗？这就是一个典型的应用。

但如果数据量太大，就跟我们前面提到的，排序 100MB 的数据，这个时候我们再用归并排序就不合适了。所以，要排序的数据量比较大的时候，qsort() 会改为用快速排序算法来排序。

那 qsort() 是如何选择快速排序算法的分区点的呢？如果去看源码，你就会发现，qsort() 选择分区点的方法就是“三数取中法”。是不是也并不复杂？

还有我们前面提到的递归太深会导致堆栈溢出的问题，qsort() 是通过自己实现一个堆上的栈，手动模拟递归来解决的。我们之前在讲递归那一节也讲过，不知道你还有没有印象？

实际上，qsort() 并不仅仅用到了归并排序和快速排序，它还用到了插入排序。在快速排序的过程中，当要排序的区间中，元素的个数小于等于 4 时，qsort() 就退化为插入排序，不再继续用递归来做快速排序，因为我们前面也讲过，在小规模数据面前，O(n2) 时间复杂度的算法并不一定比 O(nlogn) 的算法执行时间长。我们现在就来分析下这个说法。

我们在讲复杂度分析的时候讲过，算法的性能可以通过时间复杂度来分析，但是，这种复杂度分析是比较偏理论的，如果我们深究的话，实际上时间复杂度并不等于代码实际的运行时间。

时间复杂度代表的是一个增长趋势，如果画成增长曲线图，你会发现 O(n2) 比 O(nlogn) 要陡峭，也就是说增长趋势要更猛一些。但是，我们前面讲过，在大 O 复杂度表示法中，我们会省略低阶、系数和常数，也就是说，O(nlogn) 在没有省略低阶、系数、常数之前可能是 O(knlogn + c)，而且 k 和 c 有可能还是一个比较大的数。

假设 k=1000，c=200，当我们对小规模数据（比如 n=100）排序时，n2的值实际上比 knlogn+c 还要小。

knlogn+c = 1000 * 100 * log100 + 200 远大于 10000
 
n^2 = 100*100 = 10000
所以，对于小规模数据的排序，O(n2) 的排序算法并不一定比 O(nlogn) 排序算法执行的时间长。对于小数据量的排序，我们选择比较简单、不需要递归的插入排序算法。

还记得我们之前讲到的哨兵来简化代码，提高执行效率吗？在 qsort() 插入排序的算法实现中，也利用了这种编程技巧。虽然哨兵可能只是少做一次判断，但是毕竟排序函数是非常常用、非常基础的函数，性能的优化要做到极致。

好了，C 语言的 qsort() 我已经分析完了，你有没有觉得其实也不是很难？基本上都是用了我们前面讲到的知识点，有了前面的知识积累，看一些底层的类库的时候是不是也更容易了呢？

内容小结
今天我带你分析了一下如何来实现一个工业级的通用的、高效的排序函数，内容比较偏实战，而且贯穿了一些前面几节的内容，你要多看几遍。我们大部分排序函数都是采用 O(nlogn) 排序算法来实现，但是为了尽可能地提高性能，会做很多优化。

我还着重讲了快速排序的一些优化策略，比如合理选择分区点、避免递归太深等等。最后，我还带你分析了一个 C 语言中 qsort() 的底层实现原理，希望你对此能有一个更加直观的感受。

课后思考
在今天的内容中，我分析了 C 语言的中的 qsort() 的底层排序算法，你能否分析一下你所熟悉的语言中的排序函数都是用什么排序算法实现的呢？都有哪些优化技巧？

欢迎留言和我分享，我会第一时间给你反馈。

特别说明：

专栏已经更新一月有余，我在留言区看到很多同学说，希望给出课后思考题的标准答案。鉴于留言区里本身就有很多非常好的答案，之后我会将我认为比较好的答案置顶在留言区，供需要的同学参考。

如果文章发布一周后，留言里依旧没有比较好的答案，我会把我的答案写出来置顶在留言区。

最后，希望你把思考的过程看得比标准答案更重要。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(74)

刘強
我们的教育让我们对标准答案的依赖太深了，让我们失去了独立思考的能力。深深的感受到了这一点。思考的过程比标准答案更重要，这句话才是关键。
2018-10-22

1

221

Liam
查看了下Arrays.sort的源码，主要采用TimSort算法, 大致思路是这样的：

1 元素个数 < 32, 采用二分查找插入排序(Binary Sort)
2 元素个数 >= 32, 采用归并排序，归并的核心是分区(Run)
3 找连续升或降的序列作为分区，分区最终被调整为升序后压入栈
4 如果分区长度太小，通过二分插入排序扩充分区长度到分区最小阙值
5 每次压入栈，都要检查栈内已存在的分区是否满足合并条件，满足则进行合并
6 最终栈内的分区被全部合并，得到一个排序好的数组

Timsort的合并算法非常巧妙：

1 找出左分区最后一个元素(最大)及在右分区的位置
2 找出右分区第一个元素(最小)及在左分区的位置
3 仅对这两个位置之间的元素进行合并，之外的元素本身就是有序的
2018-10-22


123

杨伟
思考过程比答案重要这句话是不假，但是有答案来验证自己的思考是否准确在初学时期也很重要。

学习知识每个人的理解会不同，有的人可能这么理解有的人可能那样理解。如果没有一个标杆，有些同学就会按照自己错误的理解继续学习下去。

有了标准答案，同学就可以对照答案来反思自己的理解是否正确。也能够从别人的答案中看到更好的解答也是一种学习。

当然自己偷懒不思考，依赖标准答案，那肯定是学不好的
2018-10-22


88

小确幸
数据库里面的Order BY，用的是什么排序呢？
2018-10-22


46

峰
java1.8中的排序，在元素小于47的时候用插入排序，大于47小于286用双轴快排，大于286用timsort归并排序，并在timesort中记录数据的连续的有序段的的位置，若有序段太多，也就是说数据近乎乱序，则用双轴快排，当然快排的递归调用的过程中，若排序的子数组数据数量小，用插入排序。
2018-10-22


28

姜威
总结：如何实现一个通用的高性能的排序函数？
一、如何选择合适的排序算法？
1.排序算法一览表
                 时间复杂度 是稳定排序？ 是原地排序？
冒泡排序 O(n^2) 是 是
插入排序 O(n^2) 是 是
选择排序 O(n^2) 否 是
快速排序 O(nlogn) 否 是
归并排序 O(nlogn) 是 否
桶排序 O(n) 是 否
计数排序 O(n+k)，k是数据范围 是 否
基数排序 O(dn)，d是纬度 是 否
2.为什选择快速排序？
1）线性排序时间复杂度很低但使用场景特殊，如果要写一个通用排序函数，不能选择线性排序。
2）为了兼顾任意规模数据的排序，一般会首选时间复杂度为O(nlogn)的排序算法来实现排序函数。
3）同为O(nlogn)的快排和归并排序相比，归并排序不是原地排序算法，所以最优的选择是快排。
二、如何优化快速排序？
导致快排时间复杂度降为O(n)的原因是分区点选择不合理，最理想的分区点是：被分区点分开的两个分区中，数据的数量差不多。如何优化分区点的选择？有2种常用方法，如下：
1.三数取中法
①从区间的首、中、尾分别取一个数，然后比较大小，取中间值作为分区点。
②如果要排序的数组比较大，那“三数取中”可能就不够用了，可能要“5数取中”或者“10数取中”。
2.随机法：每次从要排序的区间中，随机选择一个元素作为分区点。
3.警惕快排的递归发生堆栈溢出，有2中解决方法，如下：
①限制递归深度，一旦递归超过了设置的阈值就停止递归。
②在堆上模拟实现一个函数调用栈，手动模拟递归压栈、出栈过程，这样就没有系统栈大小的限制。
三、通用排序函数实现技巧
1.数据量不大时，可以采取用时间换空间的思路
2.数据量大时，优化快排分区点的选择
3.防止堆栈溢出，可以选择在堆上手动模拟调用栈解决
4.在排序区间中，当元素个数小于某个常数是，可以考虑使用O(n^2)级别的插入排序
5.用哨兵简化代码，每次排序都减少一次判断，尽可能把性能优化到极致
四、思考
1.Java中的排序函数都是用什么排序算法实现的？有有哪些技巧？
2018-10-22

2

21

Andrew 陈震
老师，我有一个问题，关于递归太深导致堆栈溢出的问题。对于这个问题，您说一般有两种解决方法，一是设置最深的层数，如果超过层数了，就报错。对于这样的问题，我想排序一个数列，超过了层数，难道就不排了么？我看有留言说，stl中的sort默认是使用快排的，但当递归深度过大时 会转为使用归并排序。但是归并排序也是递归排序啊，如果两种排序都达到了最深层数怎么处理？另外，在排序之前，能否估算出排序是否超过最深层数呢？如果估算不出，那岂不是要先排一遍，发现超过层数，再换用别的。我的想法是设个阈值，不超过阈值，用一种，超过了，用另一种。

第二种应对堆栈溢出的方法是通过在堆上模拟实现一个函数调用栈，手动模拟递归压栈、出栈的过程。这个方法在您的几篇教程里都提到过，但是不详细，您能否稍微详细讲解一下。

谢谢老师
作者回复: 太深报错也没问题 不过不建议这么处理
归并排序比较稳定 栈的深度是logn 非常小 所以不会堆栈溢出
关于手动模拟栈 你可以看看qsort（）函数的实现

2018-10-22


16

李靖峰
golang标准库中的Sort用的是快排+希尔排序+插排，数据量大于12时用快排，小于等于12时用6作为gap做一次希尔排序，然后走一遍普通的插排（插排对有序度高的序列效率高）。其中快排pivot的选择做了很多工作不是一两句话可以描述出来，是基于首中尾中值的很复杂的变种
2018-10-29


14

蛐鸣
看了一下，.NET里面的Array排序实现:
1. 三个以内的，直接比较，交换进行实现
2.大于3个小于16个的，用的是插入排序进行的实现
3.对于大于16，并且深度限制是0的，用的是堆排序实现的
4.对于大于15，并且深度限制不是0的，使用的是快速排序；然后快速排序分区使用的也是三数取中法
作者回复: 👍

2018-11-02


11

Jerry银银
说说我觉得文章可能存在的一个问题，再借此问题，正好回答下思考题！
----------------------
文章中有一段话，如下：
"时间复杂度是 O(nlogn) 的排序算法不止一个，我们已经讲过的有归并排序、快速排序，后面讲堆的时候我们还会讲到堆排序。堆排序和快速排序都有比较多的应用，比如 Java 语言采用堆排序实现排序函数，C 语言使用快速排序实现排序函数。"
这里说，”Java语言采用堆排序实现排序函数“，这句话是不是错误的？

在JDK中，排序相关的主要是两个工具类：Arrays.java 和 Collections.java，具体的排序方法是sort()。这里要注意的是，Collections.java中的sort()方法是将List转为数组，然后调用Arrays.sort()方法进行排序，具体代码如下(留言中代码格式可能有点混乱，讲究看看，也可以自行参看List.sort())：
default void sort(Comparator<? super E> c) {
        Object[] a = this.toArray();
        Arrays.sort(a, (Comparator) c);
        ListIterator<E> i = this.listIterator();
        for (Object e : a) {
            i.next();
            i.set((E) e);
        }
    }

在Arrays类中，sort()有一系列的重载方法，罗列几个典型的Arrays.sort()方法如下:
public static void sort(int[] a) {
     DualPivotQuicksort.sort(a, 0, a.length - 1, null, 0, 0);
 }

public static void sort(long[] a) {
     DualPivotQuicksort.sort(a, 0, a.length - 1, null, 0, 0);
}

public static void sort(Object[] a) {
        if (LegacyMergeSort.userRequested)
            legacyMergeSort(a);
        else
            ComparableTimSort.sort(a, 0, a.length, null, 0, 0);
}
重载方法虽然多，但是从“被排序的数组所存储的内容”这个维度可以将其分为两类：
1. 存储的数据类型是基本数据类型
2. 存储的数据类型是Object
第一种情况使用的是快排，在数据量很小的时候，使用的插入排序；
第二种情况使用的是归并排序，在数据量很小的时候，使用的也是插入排序
 
以上两种场景所用到的排序都是「混合式的排序」，也都是为了追求极致的性能而设计的。另外，第二种排序有个专业的名称，叫：TimSort(可以自行Wikipedia)

作者回复: 👍 细心，新版本的jdk估计有优化吧，可以从代码中发现：
        if (LegacyMergeSort.userRequested)
            legacyMergeSort(a);

legacy的实现确实是堆排序！

2019-03-02


9

leo
排序的思维导图链接：https://share.weiyun.com/5X17MG3
2018-10-29


9

等风来
使用快排如何解决不稳定排序的问题?
作者回复: 并没解决 所以qsort不稳定

2018-10-22


8

Random.nextName()
Google v8中对QuickSort的实现是:
数据规模在10以内的话使用快排;
数据规模在10到1000之间时选择中点作为pivot进行快排;
数据规模在1000以上时，每隔200到215个数选一个数，将选出来的数排序，选择中间值作为pivot进行快排；
而且还有几个细节：
1是折半的时候用的是位运算；
2是每一次遍历都会分成小于pivot，等于pivot，大于pivot的三个区间；
3是小于pivot和大于pivot这两个区间中数据规模比较小的会递归执行QuickSort，数据规模大的会先通过while循环减小数据规模。
附上源码链接: https://github.com/v8/v8/blob/master/src/js/array.js
2018-10-30


6

Liam
关于快排递归过深的处理的疑惑，以及关于 STL 里的 std::sort 是怎么实现的，可以看我这篇博客：https://liam.page/2018/09/18/std-sort-in-STL/
2018-10-22


6

城
qsort中为避免递归调用过深，所以在堆上模拟了栈。不知道是否是将递归调用，改写为循环非递归方式呢？
作者回复: 是的

2018-10-22


6

学习爱好者
王老师，总结8种排序算法的那个图，桶排序不一定是稳定排序吧？比如桶内排序用快排的时候
作者回复: 嗯嗯 用归并或者插入排序就稳定了

2018-11-05


5

T神
归并排序空间复杂度应该没那么高，因为实际存储的都是指针或者引用。
作者回复: 是的

2018-12-14


3

落叶飞逝的恋
老师，你好，我终于认真消化完了前面的知识，没有半点马虎，也给自己打个卡记录。
关于思考题：
查看了Java的Arrays.sort
1.若数组元素个数总数小于47，使用插入排序
2.若数据元素个数总数在47~286之间，使用快速排序。应该是使用的优化版本的三值取中的优化版本。
3.若大于286的个数，使用归并排序。
底层实现的代码比之前示范写的代码校验多，所以目前只能看到这，下面继续加油吧！
作者回复: 👍

2018-12-04

1

3

懒猫
简单说下go语言的，大致是两个限制条件：数据长度和递归深度，如果长度大于或等于12，且递归深度大于0时，使用快排，快排在选择分区点数字时用了三数取中法，如果长度大于12且递归深度限制为0时，使用堆排序，如果数据长度小于或等于12时，用的希尔排序，间隔用是6
2018-11-12


3

favorlm
虽然说思考很重要，但是面试还是需要你实现一种算法。
作者回复: 留言区点赞最高的就是答案

2018-11-04


3
收起评论

7499+





# 15 | 二分查找（上）：如何用最省内存的方式实现快速查找功能？



数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



15 | 二分查找（上）：如何用最省内存的方式实现快速查找功能？
王争 2018-10-24



14:56
讲述：修阳 大小：6.85M
今天我们讲一种针对有序数据集合的查找算法：二分查找（Binary Search）算法，也叫折半查找算法。二分查找的思想非常简单，很多非计算机专业的同学很容易就能理解，但是看似越简单的东西往往越难掌握好，想要灵活应用就更加困难。

老规矩，我们还是来看一道思考题。

假设我们有 1000 万个整数数据，每个数据占 8 个字节，如何设计数据结构和算法，快速判断某个整数是否出现在这 1000 万数据中？ 我们希望这个功能不要占用太多的内存空间，最多不要超过 100MB，你会怎么做呢？带着这个问题，让我们进入今天的内容吧！

无处不在的二分思想
二分查找是一种非常简单易懂的快速查找算法，生活中到处可见。比如说，我们现在来做一个猜字游戏。我随机写一个 0 到 99 之间的数字，然后你来猜我写的是什么。猜的过程中，你每猜一次，我就会告诉你猜的大了还是小了，直到猜中为止。你来想想，如何快速猜中我写的数字呢？

假设我写的数字是 23，你可以按照下面的步骤来试一试。（如果猜测范围的数字有偶数个，中间数有两个，就选择较小的那个。）



7 次就猜出来了，是不是很快？这个例子用的就是二分思想，按照这个思想，即便我让你猜的是 0 到 999 的数字，最多也只要 10 次就能猜中。不信的话，你可以试一试。

这是一个生活中的例子，我们现在回到实际的开发场景中。假设有 1000 条订单数据，已经按照订单金额从小到大排序，每个订单金额都不同，并且最小单位是元。我们现在想知道是否存在金额等于 19 元的订单。如果存在，则返回订单数据，如果不存在则返回 null。

最简单的办法当然是从第一个订单开始，一个一个遍历这 1000 个订单，直到找到金额等于 19 元的订单为止。但这样查找会比较慢，最坏情况下，可能要遍历完这 1000 条记录才能找到。那用二分查找能不能更快速地解决呢？

为了方便讲解，我们假设只有 10 个订单，订单金额分别是：8，11，19，23，27，33，45，55，67，98。

还是利用二分思想，每次都与区间的中间数据比对大小，缩小查找区间的范围。为了更加直观，我画了一张查找过程的图。其中，low 和 high 表示待查找区间的下标，mid 表示待查找区间的中间元素下标。



看懂这两个例子，你现在对二分的思想应该掌握得妥妥的了。我这里稍微总结升华一下，二分查找针对的是一个有序的数据集合，查找思想有点类似分治思想。每次都通过跟区间的中间元素对比，将待查找的区间缩小为之前的一半，直到找到要查找的元素，或者区间被缩小为 0。

O(logn) 惊人的查找速度
二分查找是一种非常高效的查找算法，高效到什么程度呢？我们来分析一下它的时间复杂度。

我们假设数据大小是 n，每次查找后数据都会缩小为原来的一半，也就是会除以 2。最坏情况下，直到查找区间被缩小为空，才停止。



可以看出来，这是一个等比数列。其中 n/2k=1 时，k 的值就是总共缩小的次数。而每一次缩小操作只涉及两个数据的大小比较，所以，经过了 k 次区间缩小操作，时间复杂度就是 O(k)。通过 n/2k=1，我们可以求得 k=log2n，所以时间复杂度就是 O(logn)。

二分查找是我们目前为止遇到的第一个时间复杂度为 O(logn) 的算法。后面章节我们还会讲堆、二叉树的操作等等，它们的时间复杂度也是 O(logn)。我这里就再深入地讲讲 O(logn) 这种对数时间复杂度。这是一种极其高效的时间复杂度，有的时候甚至比时间复杂度是常量级 O(1) 的算法还要高效。为什么这么说呢？

因为 logn 是一个非常“恐怖”的数量级，即便 n 非常非常大，对应的 logn 也很小。比如 n 等于 2 的 32 次方，这个数很大了吧？大约是 42 亿。也就是说，如果我们在 42 亿个数据中用二分查找一个数据，最多需要比较 32 次。

我们前面讲过，用大 O 标记法表示时间复杂度的时候，会省略掉常数、系数和低阶。对于常量级时间复杂度的算法来说，O(1) 有可能表示的是一个非常大的常量值，比如 O(1000)、O(10000)。所以，常量级时间复杂度的算法有时候可能还没有 O(logn) 的算法执行效率高。

反过来，对数对应的就是指数。有一个非常著名的“阿基米德与国王下棋的故事”，你可以自行搜索一下，感受一下指数的“恐怖”。这也是为什么我们说，指数时间复杂度的算法在大规模数据面前是无效的。

二分查找的递归与非递归实现
实际上，简单的二分查找并不难写，注意我这里的“简单”二字。下一节，我们会讲到二分查找的变体问题，那才是真正烧脑的。今天，我们来看如何来写最简单的二分查找。

最简单的情况就是有序数组中不存在重复元素，我们在其中用二分查找值等于给定值的数据。我用 Java 代码实现了一个最简单的二分查找算法。

public int bsearch(int[] a, int n, int value) {
  int low = 0;
  int high = n - 1;
 
  while (low <= high) {
    int mid = (low + high) / 2;
    if (a[mid] == value) {
      return mid;
    } else if (a[mid] < value) {
      low = mid + 1;
    } else {
      high = mid - 1;
    }
  }
 
  return -1;
}
这个代码我稍微解释一下，low、high、mid 都是指数组下标，其中 low 和 high 表示当前查找的区间范围，初始 low=0， high=n-1。mid 表示 [low, high] 的中间位置。我们通过对比 a[mid] 与 value 的大小，来更新接下来要查找的区间范围，直到找到或者区间缩小为 0，就退出。如果你有一些编程基础，看懂这些应该不成问题。现在，我就着重强调一下容易出错的 3 个地方。

1. 循环退出条件
注意是 low<=high，而不是 low<high。

2.mid 的取值
实际上，mid=(low+high)/2 这种写法是有问题的。因为如果 low 和 high 比较大的话，两者之和就有可能会溢出。改进的方法是将 mid 的计算方式写成 low+(high-low)/2。更进一步，如果要将性能优化到极致的话，我们可以将这里的除以 2 操作转化成位运算 low+((high-low)>>1)。因为相比除法运算来说，计算机处理位运算要快得多。

3.low 和 high 的更新
low=mid+1，high=mid-1。注意这里的 +1 和 -1，如果直接写成 low=mid 或者 high=mid，就可能会发生死循环。比如，当 high=3，low=3 时，如果 a[3] 不等于 value，就会导致一直循环不退出。

如果你留意我刚讲的这三点，我想一个简单的二分查找你已经可以实现了。实际上，二分查找除了用循环来实现，还可以用递归来实现，过程也非常简单。

我用 Java 语言实现了一下这个过程，正好你可以借此机会回顾一下写递归代码的技巧。

// 二分查找的递归实现
public int bsearch(int[] a, int n, int val) {
  return bsearchInternally(a, 0, n - 1, val);
}
 
private int bsearchInternally(int[] a, int low, int high, int value) {
  if (low > high) return -1;
 
  int mid =  low + ((high - low) >> 1);
  if (a[mid] == value) {
    return mid;
  } else if (a[mid] < value) {
    return bsearchInternally(a, mid+1, high, value);
  } else {
    return bsearchInternally(a, low, mid-1, value);
  }
}
二分查找应用场景的局限性
前面我们分析过，二分查找的时间复杂度是 O(logn)，查找数据的效率非常高。不过，并不是什么情况下都可以用二分查找，它的应用场景是有很大局限性的。那什么情况下适合用二分查找，什么情况下不适合呢？

首先，二分查找依赖的是顺序表结构，简单点说就是数组。

那二分查找能否依赖其他数据结构呢？比如链表。答案是不可以的，主要原因是二分查找算法需要按照下标随机访问元素。我们在数组和链表那两节讲过，数组按照下标随机访问数据的时间复杂度是 O(1)，而链表随机访问的时间复杂度是 O(n)。所以，如果数据使用链表存储，二分查找的时间复杂就会变得很高。

二分查找只能用在数据是通过顺序表来存储的数据结构上。如果你的数据是通过其他数据结构存储的，则无法应用二分查找。

其次，二分查找针对的是有序数据。

二分查找对这一点的要求比较苛刻，数据必须是有序的。如果数据没有序，我们需要先排序。前面章节里我们讲到，排序的时间复杂度最低是 O(nlogn)。所以，如果我们针对的是一组静态的数据，没有频繁地插入、删除，我们可以进行一次排序，多次二分查找。这样排序的成本可被均摊，二分查找的边际成本就会比较低。

但是，如果我们的数据集合有频繁的插入和删除操作，要想用二分查找，要么每次插入、删除操作之后保证数据仍然有序，要么在每次二分查找之前都先进行排序。针对这种动态数据集合，无论哪种方法，维护有序的成本都是很高的。

所以，二分查找只能用在插入、删除操作不频繁，一次排序多次查找的场景中。针对动态变化的数据集合，二分查找将不再适用。那针对动态数据集合，如何在其中快速查找某个数据呢？别急，等到二叉树那一节我会详细讲。

再次，数据量太小不适合二分查找。

如果要处理的数据量很小，完全没有必要用二分查找，顺序遍历就足够了。比如我们在一个大小为 10 的数组中查找一个元素，不管用二分查找还是顺序遍历，查找速度都差不多。只有数据量比较大的时候，二分查找的优势才会比较明显。

不过，这里有一个例外。如果数据之间的比较操作非常耗时，不管数据量大小，我都推荐使用二分查找。比如，数组中存储的都是长度超过 300 的字符串，如此长的两个字符串之间比对大小，就会非常耗时。我们需要尽可能地减少比较次数，而比较次数的减少会大大提高性能，这个时候二分查找就比顺序遍历更有优势。

最后，数据量太大也不适合二分查找。

二分查找的底层需要依赖数组这种数据结构，而数组为了支持随机访问的特性，要求内存空间连续，对内存的要求比较苛刻。比如，我们有 1GB 大小的数据，如果希望用数组来存储，那就需要 1GB 的连续内存空间。

注意这里的“连续”二字，也就是说，即便有 2GB 的内存空间剩余，但是如果这剩余的 2GB 内存空间都是零散的，没有连续的 1GB 大小的内存空间，那照样无法申请一个 1GB 大小的数组。而我们的二分查找是作用在数组这种数据结构之上的，所以太大的数据用数组存储就比较吃力了，也就不能用二分查找了。

解答开篇
二分查找的理论知识你应该已经掌握了。我们来看下开篇的思考题：如何在 1000 万个整数中快速查找某个整数？

这个问题并不难。我们的内存限制是 100MB，每个数据大小是 8 字节，最简单的办法就是将数据存储在数组中，内存占用差不多是 80MB，符合内存的限制。借助今天讲的内容，我们可以先对这 1000 万数据从小到大排序，然后再利用二分查找算法，就可以快速地查找想要的数据了。

看起来这个问题并不难，很轻松就能解决。实际上，它暗藏了“玄机”。如果你对数据结构和算法有一定了解，知道散列表、二叉树这些支持快速查找的动态数据结构。你可能会觉得，用散列表和二叉树也可以解决这个问题。实际上是不行的。

虽然大部分情况下，用二分查找可以解决的问题，用散列表、二叉树都可以解决。但是，我们后面会讲，不管是散列表还是二叉树，都会需要比较多的额外的内存空间。如果用散列表或者二叉树来存储这 1000 万的数据，用 100MB 的内存肯定是存不下的。而二分查找底层依赖的是数组，除了数据本身之外，不需要额外存储其他信息，是最省内存空间的存储方式，所以刚好能在限定的内存大小下解决这个问题。

内容小结
今天我们学习了一种针对有序数据的高效查找算法，二分查找，它的时间复杂度是 O(logn)。

二分查找的核心思想理解起来非常简单，有点类似分治思想。即每次都通过跟区间中的中间元素对比，将待查找的区间缩小为一半，直到找到要查找的元素，或者区间被缩小为 0。但是二分查找的代码实现比较容易写错。你需要着重掌握它的三个容易出错的地方：循环退出条件、mid 的取值，low 和 high 的更新。

二分查找虽然性能比较优秀，但应用场景也比较有限。底层必须依赖数组，并且还要求数据是有序的。对于较小规模的数据查找，我们直接使用顺序遍历就可以了，二分查找的优势并不明显。二分查找更适合处理静态数据，也就是没有频繁的数据插入、删除操作。

课后思考
如何编程实现“求一个数的平方根”？要求精确到小数点后 6 位。

我刚才说了，如果数据使用链表存储，二分查找的时间复杂就会变得很高，那查找的时间复杂度究竟是多少呢？如果你自己推导一下，你就会深刻地认识到，为何我们会选择用数组而不是链表来实现二分查找了。

欢迎留言和我分享，我会第一时间给你反馈。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(111)

Jerry银银 置顶
说说第二题吧，感觉争议比较大:
假设链表长度为n，二分查找每次都要找到中间点(计算中忽略奇偶数差异):
第一次查找中间点，需要移动指针n/2次；
第二次，需要移动指针n/4次；
第三次需要移动指针n/8次；
......
以此类推，一直到1次为值

总共指针移动次数(查找次数) = n/2 + n/4 + n/8 + ...+ 1，这显然是个等比数列，根据等比数列求和公式：Sum = n - 1.

最后算法时间复杂度是：O(n-1)，忽略常数，记为O(n)，时间复杂度和顺序查找时间复杂度相同

但是稍微思考下，在二分查找的时候，由于要进行多余的运算，严格来说，会比顺序查找时间慢


-----------------
以上分析，不知道是否准确，还请老师解答
作者回复: 分析的很好 👍 同学们可以把这条顶上去了

2018-10-25

1

401

蒋礼锐 置顶
因为要精确到后六位，可以先用二分查找出整数位，然后再二分查找小数第一位，第二位，到第六位。

整数查找很简单，判断当前数小于+1后大于即可找到，

小数查找举查找小数后第一位来说，从x.0到(x+1).0，查找终止条件与整数一样，当前数小于，加0.1大于，

后面的位数以此类推，可以用x*10^(-i)通项来循环或者递归，终止条件是i>6，

想了一下复杂度，每次二分是logn，包括整数位会查找7次，所以时间复杂度为7logn。空间复杂度没有开辟新的储存空间，空间复杂度为1。

没有具体用代码实现，只是思路，还请多多指正。之后会用js去实际实现。
2018-10-24


30

Jerry银银
个人觉得二分查找进行优化时，还个细节注意：
将mid = lo + (hi - lo) /2，将除法优化成移位运算时，得注意运算符的优先级，千万不能写成这样：mid = lo + (hi - lo) >> 1
作者回复: 👍

2018-10-26

2

95

朱凯
二分法求一个数x的平方根y？
解答：根据x的值，判断求解值y的取值范围。假设求解值范围min < y < max。若0<x<1，则min=x，max=1；若x=1，则y=1；x>1，则min=1，max=x；在确定了求解范围之后，利用二分法在求解值的范围中取一个中间值middle=(min+max)÷2，判断middle是否是x的平方根？若(middle+0.000001)*(middle+0.000001)＞x且(middle-0.000001)*(middle-0.000001)<x，根据介值定理，可知middle既是求解值;若middle*middle > x，表示middle＞实际求解值，max=middle; 若middle*middle ＜ x，表示middle＜实际求解值，min =middle;之后递归求解！
备注：因为是保留6位小数，所以middle上下浮动0.000001用于介值定理的判断
2018-10-25


57

Alexis何春光
现在在cmu读研，正在上terry lee的data structure，惊喜的发现不少他讲的点你都涵盖了，个别他没讲到的你也涵盖了.... （当然可能因为那门课只有6学时，时间不足，但还是给这个专栏赞一个！）
作者回复: 读cmu 太厉害了 仰慕

2018-11-12

2

53

锐雨
求平方根，可以参考0到99之间猜数字的思路，99换成x, 循环到误差允许内即可，注意1这个分界线。欢迎交流，Java如下
public static double sqrt(double x, double precision) {
if (x < 0) {
return Double.NaN;
}
double low = 0;
double up = x;
if (x < 1 && x > 0) {
/** 小于1的时候*/
low = x;
up = 1;
}
double mid = low + (up - low)/2;
while(up - low > precision) {
if (mid * mid > x ) {//TODO mid可能会溢出
up = mid;
} else if (mid * mid < x) {
low = mid;
} else {
return mid;
}
mid = low + (up - low)/2;
}
return mid;
}
2018-10-24


22

三忌
def sqrt(x):
    '''
    求平方根，精确到小数点后6位
    '''
    low = 0
    mid = x / 2
    high = x
    while abs(mid ** 2 - x) > 0.000001:
        if mid ** 2 < x:
            low = mid
        else:
            high = mid
        mid = (low + high) / 2
    return mid
2018-10-24


18

Dwyane
1、low=mid+1，high=mid-1 学习了比较严谨条件


2、二分法求根号5

a:折半：       5/2=2.5

b:平方校验:  2.5*2.5=6.25>5，并且得到当前上限2.5

c:再次向下折半:2.5/2=1.25

d:平方校验：1.25*1.25=1.5625<5,得到当前下限1.25

e:再次折半:2.5-(2.5-1.25)/2=1.875

f:平方校验：1.875*1.875=3.515625<5,得到当前下限1.875

每次得到当前值和5进行比较，并且记下下下限和上限，依次迭代，逐渐逼近平方根：
2018-12-21


16

姜威
总结：二分查找（上）
一、什么是二分查找？
二分查找针对的是一个有序的数据集合，每次通过跟区间中间的元素对比，将待查找的区间缩小为之前的一半，直到找到要查找的元素，或者区间缩小为0。
二、时间复杂度分析？
1.时间复杂度
假设数据大小是n，每次查找后数据都会缩小为原来的一半，最坏的情况下，直到查找区间被缩小为空，才停止。所以，每次查找的数据大小是：n，n/2，n/4，…，n/(2^k)，…，这是一个等比数列。当n/(2^k)=1时，k的值就是总共缩小的次数，也是查找的总次数。而每次缩小操作只涉及两个数据的大小比较，所以，经过k次区间缩小操作，时间复杂度就是O(k)。通过n/(2^k)=1，可求得k=log2n，所以时间复杂度是O(logn)。
2.认识O(logn)
①这是一种极其高效的时间复杂度，有时甚至比O(1)的算法还要高效。为什么？
②因为logn是一个非常“恐怖“的数量级，即便n非常大，对应的logn也很小。比如n等于2的32次方，也就是42亿，而logn才32。
③由此可见，O(logn)有时就是比O(1000)，O(10000)快很多。
三、如何实现二分查找？
1.循环实现
代码实现：
public int binarySearch1(int[] a, int val){
int start = 0;
int end = a.length - 1;
while(start <= end){
int mid = start + (end - start) / 2;
if(a[mid] > val) end = mid - 1;
else if(a[mid] < val) start = mid + 1;
else return mid;
}
return -1;
}
注意事项：
①循环退出条件是：start<=end，而不是start<end。
②mid的取值，使用mid=start + (end - start) / 2，而不用mid=(start + end)/2，因为如果start和end比较大的话，求和可能会发生int类型的值超出最大范围。为了把性能优化到极致，可以将除以2转换成位运算，即start + ((end - start) >> 1)，因为相比除法运算来说，计算机处理位运算要快得多。
③start和end的更新：start = mid - 1，end = mid + 1，若直接写成start = mid，end=mid，就可能会发生死循环。
2.递归实现
public int binarySearch(int[] a, int val){
return bSear(a, val, 0, a.length-1);
}
private int bSear(int[] a, int val, int start, int end) {
if(start > end) return -1;
int mid = start + (end - start) / 2;
if(a[mid] == val) return mid;
else if(a[mid] > val) end = mid - 1;
else start = mid + 1;
return bSear(a, val, start, end);
}
四、使用条件（应用场景的局限性）
1.二分查找依赖的是顺序表结构，即数组。
2.二分查找针对的是有序数据，因此只能用在插入、删除操作不频繁，一次排序多次查找的场景中。
3.数据量太小不适合二分查找，与直接遍历相比效率提升不明显。但有一个例外，就是数据之间的比较操作非常费时，比如数组中存储的都是长度超过300的字符串，那这是还是尽量减少比较操作使用二分查找吧。
4.数据量太大也不是适合用二分查找，因为数组需要连续的空间，若数据量太大，往往找不到存储如此大规模数据的连续内存空间。
五、思考
1.如何在1000万个整数中快速查找某个整数？
①1000万个整数占用存储空间为40MB，占用空间不大，所以可以全部加载到内存中进行处理；
②用一个1000万个元素的数组存储，然后使用快排进行升序排序，时间复杂度为O(nlogn)
③在有序数组中使用二分查找算法进行查找，时间复杂度为O(logn)
2.如何编程实现“求一个数的平方根”？要求精确到小数点后6位？
2018-10-31

1

16

Smallfly
1. 求平方根可以用二分查找或牛顿迭代法;
2. 有序链表的二分查找时间复杂度为 O(n)。
2018-10-24


16

TWO STRINGS
1000w数据查找这个，在排序的时候不就可以找到了么？
作者回复: 如果是多次查找操作呢

2018-10-24


14

Victor
开篇的问题：1000w 个 8字节整数的中查找某个整数是否存在，且内存占用不超过100M ？ 我尝试延伸了一些解决方案：
1、由于内存限制，存储一个整数需要8字节，也就是 64 bit。此时是否可以考虑bitmap这样的数据结构，也就是每个整数就是一个索引下标，对于每一个索引bit，1 表示存在，0 表示不存在。同时考虑到整数的数据范围，8字节整数的范围太大，这是需要考虑压缩的问题，压缩方案可以参考 RoaringBitmap 的压缩方式。
2、我们要解决的问题，也就是判断某个元素是否属于某个集合的问题。这里是否可以和出题方探讨是否严格要求100%判断正确。在允许很小误差概率的情景下（比如判断是否在垃圾邮件地址黑名单中），可以考虑 BloomFilter 。
BloomFilter 存储空间更加高效。1000w数据、0.1%的误差下需要的内存仅为 17.14M
时间复杂度上，上面两种都是 hashmap的变种，因此为 o(1)。
2018-10-27


9

kaka
关于求平方根的题，我知道一种比较巧妙的方法，那就是利用魔数，时间复杂度是 O(1)，根据我测试，精度大概能精确到 5 位小数，也还不错。下面是 c 语言代码

float q_rsqrt(float number) {
    int i;
    float x2, y;
    const float threehalfs = 1.5;
    x2 = number * 0.5;
    y = number;
    i = *(int*)&y;
    i = 0x5f3759df - (i >> 1);
    y = *(float*)&i;
    y = y * (threehalfs - (x2 * y * y));
    y = y * (threehalfs - (x2 * y * y));
    y = y * (threehalfs - (x2 * y * y));

    return 1.0 / y;
}
2018-10-29


5

啊波次的额佛哥～
平方根C代码，precision位数，小数点后6位是0.000001
double squareRoot(double a , double precision){
    double low,high,mid,tmp;
    if (a>1){
        low = 1;
        high = a;
    }else{
        low = 1;
        high = a;
    }
    while (low<=high) {
        mid = (low+high)/2.000;
        tmp = mid*mid;
        if (tmp-a <= precision && tmp-a >= precision*-1){
            return mid;
        }else if (tmp>a){
            high = mid;
        }else{
            low = mid;
        }
    }
    return -1.000;
}
int main(int argc, const char * argv[]) {
    double num = squareRoot(2, 0.000001);
    printf("%f",num);
    return 0;
}
2018-10-29

2

5

Liam
链表的二分查找，每次查找的时间复杂度都为当前数据规模的一半，所以最坏情况下：
查找次数f(n) = n + n/2 + n/4 + n/8 + ... + 1 = n(1 + 1/2 + 1/4 + ... 1/n)

情况1： n = 2^k, 根据等比数列公式 f(n) = 2^k * ( 1 - (1/2) ^k) / (1 - 1/2) = 2n - 1
情况2：n != 2^k, 假设k无穷大，则limf(n) = n ( 1 / (1 - 1/2)) = 2n, 实际上k < +∞， 所以
f(n) < lim f(n) = 2n => f(n) = 2n-1

综上所述，f(n) = 2n - 1, 时间复杂度为O(n)
2018-10-26


4

追风者
王老师，考研的话可以以这个课程作为数据结构第一轮的基础复习吗。如果可以，还需要补充其他概念知识吗
作者回复: 概念知识应该全了 考研的话还要看看考纲吧

2018-10-24


4

王小李
平方根可以用牛顿迭代实现。
作者回复: 哈哈 同学的回答超纲了 👍

2018-10-24


4

yu🐟
/**
     * 求一个数的平方根
     *
     * @param n：待求的数
     * @param deltaThreshold 误差的阈值
     * @return
     */
    public static double getSqureRoot(int n, double deltaThreshold) {
        double low = 1.0;
        double high = (double) n;
        while (low <= high) {
            double mid = low + ((high - low) / 2);
            double square = mid * mid;
            double delta = Math.abs(square / n - 1);
            if (delta < deltaThreshold) {
                return mid;
            } else if (square < n) {
                low = mid;
            } else {
                high = mid;
            }
        }
        return -1.0;
    }
2019-01-03

1

3

Kudo
二分查找Python实现：
1、非递归方式
def bsearch(ls, value):
    low, high = 0, len(ls)-1
    while low <= high:
        mid = low + (high - low) // 2
        if ls[mid] == value:
            return mid
        elif ls[mid] < value:
            low = mid + 1
        else:
            high = mid - 1
    return -1

2、递归方式
def bsearch(ls, value):
    return bsearch_recursively(ls, 0, len(ls)-1, value)
    
def bsearch_recursively(ls, low, high, value):
    if low > high:
        return -1
    mid = low + (high - low) // 2
    if ls[mid] == value:
        return mid
    elif ls[mid] < value:
        return bsearch_recursively(ls, mid+1, high, value)
    else:
        return bsearch_recursively(ls, low, mid-1, value)
2018-10-25


3

C家族铁粉
二分法一直在用，知道太小的、非数组、非有序的确实不适合用，不过确实没有注意到太大的局限性！get√了~
2018-10-24


3
收起评论

99+99+





# 16 | 二分查找（下）：如何快速定位IP对应的省份地址？



数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



16 | 二分查找（下）：如何快速定位IP对应的省份地址？
王争 2018-10-26



11:47
讲述：修阳 大小：5.40M
通过 IP 地址来查找 IP 归属地的功能，不知道你有没有用过？没用过也没关系，你现在可以打开百度，在搜索框里随便输一个 IP 地址，就会看到它的归属地。



这个功能并不复杂，它是通过维护一个很大的 IP 地址库来实现的。地址库中包括 IP 地址范围和归属地的对应关系。

当我们想要查询 202.102.133.13 这个 IP 地址的归属地时，我们就在地址库中搜索，发现这个 IP 地址落在 [202.102.133.0, 202.102.133.255] 这个地址范围内，那我们就可以将这个 IP 地址范围对应的归属地“山东东营市”显示给用户了。

[202.102.133.0, 202.102.133.255]  山东东营市 
[202.102.135.0, 202.102.136.255]  山东烟台 
[202.102.156.34, 202.102.157.255] 山东青岛 
[202.102.48.0, 202.102.48.255] 江苏宿迁 
[202.102.49.15, 202.102.51.251] 江苏泰州 
[202.102.56.0, 202.102.56.255] 江苏连云港
现在我的问题是，在庞大的地址库中逐一比对 IP 地址所在的区间，是非常耗时的。假设我们有 12 万条这样的 IP 区间与归属地的对应关系，如何快速定位出一个 IP 地址的归属地呢？

是不是觉得比较难？不要紧，等学完今天的内容，你就会发现这个问题其实很简单。

上一节我讲了二分查找的原理，并且介绍了最简单的一种二分查找的代码实现。今天我们来讲几种二分查找的变形问题。

不知道你有没有听过这样一个说法：“十个二分九个错”。二分查找虽然原理极其简单，但是想要写出没有 Bug 的二分查找并不容易。

唐纳德·克努特（Donald E.Knuth）在《计算机程序设计艺术》的第 3 卷《排序和查找》中说到：“尽管第一个二分查找算法于 1946 年出现，然而第一个完全正确的二分查找算法实现直到 1962 年才出现。”

你可能会说，我们上一节学的二分查找的代码实现并不难写啊。那是因为上一节讲的只是二分查找中最简单的一种情况，在不存在重复元素的有序数组中，查找值等于给定值的元素。最简单的二分查找写起来确实不难，但是，二分查找的变形问题就没那么好写了。

二分查找的变形问题很多，我只选择几个典型的来讲解，其他的你可以借助我今天讲的思路自己来分析。



需要特别说明一点，为了简化讲解，今天的内容，我都以数据是从小到大排列为前提，如果你要处理的数据是从大到小排列的，解决思路也是一样的。同时，我希望你最好先自己动手试着写一下这 4 个变形问题，然后再看我的讲述，这样你就会对我说的“二分查找比较难写”有更加深的体会了。

变体一：查找第一个值等于给定值的元素
上一节中的二分查找是最简单的一种，即有序数据集合中不存在重复的数据，我们在其中查找值等于某个给定值的数据。如果我们将这个问题稍微修改下，有序数据集合中存在重复的数据，我们希望找到第一个值等于给定值的数据，这样之前的二分查找代码还能继续工作吗？

比如下面这样一个有序数组，其中，a[5]，a[6]，a[7] 的值都等于 8，是重复的数据。我们希望查找第一个等于 8 的数据，也就是下标是 5 的元素。



如果我们用上一节课讲的二分查找的代码实现，首先拿 8 与区间的中间值 a[4] 比较，8 比 6 大，于是在下标 5 到 9 之间继续查找。下标 5 和 9 的中间位置是下标 7，a[7] 正好等于 8，所以代码就返回了。

尽管 a[7] 也等于 8，但它并不是我们想要找的第一个等于 8 的元素，因为第一个值等于 8 的元素是数组下标为 5 的元素。我们上一节讲的二分查找代码就无法处理这种情况了。所以，针对这个变形问题，我们可以稍微改造一下上一节的代码。

100 个人写二分查找就会有 100 种写法。网上有很多关于变形二分查找的实现方法，有很多写得非常简洁，比如下面这个写法。但是，尽管简洁，理解起来却非常烧脑，也很容易写错。

public int bsearch(int[] a, int n, int value) {
  int low = 0;
  int high = n - 1;
  while (low <= high) {
    int mid = low + ((high - low) >> 1);
    if (a[mid] >= value) {
      high = mid - 1;
    } else {
      low = mid + 1;
    }
  }
 
  if (low < n && a[low]==value) return low;
  else return -1;
}
看完这个实现之后，你是不是觉得很不好理解？如果你只是死记硬背这个写法，我敢保证，过不了几天，你就会全都忘光，再让你写，90% 的可能会写错。所以，我换了一种实现方法，你看看是不是更容易理解呢？

public int bsearch(int[] a, int n, int value) {
  int low = 0;
  int high = n - 1;
  while (low <= high) {
    int mid =  low + ((high - low) >> 1);
    if (a[mid] > value) {
      high = mid - 1;
    } else if (a[mid] < value) {
      low = mid + 1;
    } else {
      if ((mid == 0) || (a[mid - 1] != value)) return mid;
      else high = mid - 1;
    }
  }
  return -1;
}
我来稍微解释一下这段代码。a[mid] 跟要查找的 value 的大小关系有三种情况：大于、小于、等于。对于 a[mid]>value 的情况，我们需要更新 high= mid-1；对于 a[mid]<value 的情况，我们需要更新 low=mid+1。这两点都很好理解。那当 a[mid]=value 的时候应该如何处理呢？

如果我们查找的是任意一个值等于给定值的元素，当 a[mid] 等于要查找的值时，a[mid] 就是我们要找的元素。但是，如果我们求解的是第一个值等于给定值的元素，当 a[mid] 等于要查找的值时，我们就需要确认一下这个 a[mid] 是不是第一个值等于给定值的元素。

我们重点看第 11 行代码。如果 mid 等于 0，那这个元素已经是数组的第一个元素，那它肯定是我们要找的；如果 mid 不等于 0，但 a[mid] 的前一个元素 a[mid-1] 不等于 value，那也说明 a[mid] 就是我们要找的第一个值等于给定值的元素。

如果经过检查之后发现 a[mid] 前面的一个元素 a[mid-1] 也等于 value，那说明此时的 a[mid] 肯定不是我们要查找的第一个值等于给定值的元素。那我们就更新 high=mid-1，因为要找的元素肯定出现在 [low, mid-1] 之间。

对比上面的两段代码，是不是下面那种更好理解？实际上，很多人都觉得变形的二分查找很难写，主要原因是太追求第一种那样完美、简洁的写法。而对于我们做工程开发的人来说，代码易读懂、没 Bug，其实更重要，所以我觉得第二种写法更好。

变体二：查找最后一个值等于给定值的元素
前面的问题是查找第一个值等于给定值的元素，我现在把问题稍微改一下，查找最后一个值等于给定值的元素，又该如何做呢？

如果你掌握了前面的写法，那这个问题你应该很轻松就能解决。你可以先试着实现一下，然后跟我写的对比一下。

public int bsearch(int[] a, int n, int value) {
  int low = 0;
  int high = n - 1;
  while (low <= high) {
    int mid =  low + ((high - low) >> 1);
    if (a[mid] > value) {
      high = mid - 1;
    } else if (a[mid] < value) {
      low = mid + 1;
    } else {
      if ((mid == n - 1) || (a[mid + 1] != value)) return mid;
      else low = mid + 1;
    }
  }
  return -1;
}
我们还是重点看第 11 行代码。如果 a[mid] 这个元素已经是数组中的最后一个元素了，那它肯定是我们要找的；如果 a[mid] 的后一个元素 a[mid+1] 不等于 value，那也说明 a[mid] 就是我们要找的最后一个值等于给定值的元素。

如果我们经过检查之后，发现 a[mid] 后面的一个元素 a[mid+1] 也等于 value，那说明当前的这个 a[mid] 并不是最后一个值等于给定值的元素。我们就更新 low=mid+1，因为要找的元素肯定出现在 [mid+1, high] 之间。

变体三：查找第一个大于等于给定值的元素
现在我们再来看另外一类变形问题。在有序数组中，查找第一个大于等于给定值的元素。比如，数组中存储的这样一个序列：3，4，6，7，10。如果查找第一个大于等于 5 的元素，那就是 6。

实际上，实现的思路跟前面的那两种变形问题的实现思路类似，代码写起来甚至更简洁。

public int bsearch(int[] a, int n, int value) {
  int low = 0;
  int high = n - 1;
  while (low <= high) {
    int mid =  low + ((high - low) >> 1);
    if (a[mid] >= value) {
      if ((mid == 0) || (a[mid - 1] < value)) return mid;
      else high = mid - 1;
    } else {
      low = mid + 1;
    }
  }
  return -1;
}
如果 a[mid] 小于要查找的值 value，那要查找的值肯定在 [mid+1, high] 之间，所以，我们更新 low=mid+1。

对于 a[mid] 大于等于给定值 value 的情况，我们要先看下这个 a[mid] 是不是我们要找的第一个值大于等于给定值的元素。如果 a[mid] 前面已经没有元素，或者前面一个元素小于要查找的值 value，那 a[mid] 就是我们要找的元素。这段逻辑对应的代码是第 7 行。

如果 a[mid-1] 也大于等于要查找的值 value，那说明要查找的元素在 [low, mid-1] 之间，所以，我们将 high 更新为 mid-1。

变体四：查找最后一个小于等于给定值的元素
现在，我们来看最后一种二分查找的变形问题，查找最后一个小于等于给定值的元素。比如，数组中存储了这样一组数据：3，5，6，8，9，10。最后一个小于等于 7 的元素就是 6。是不是有点类似上面那一种？实际上，实现思路也是一样的。

有了前面的基础，你完全可以自己写出来了，所以我就不详细分析了。我把代码贴出来，你可以写完之后对比一下。

public int bsearch7(int[] a, int n, int value) {
  int low = 0;
  int high = n - 1;
  while (low <= high) {
    int mid =  low + ((high - low) >> 1);
    if (a[mid] > value) {
      high = mid - 1;
    } else {
      if ((mid == n - 1) || (a[mid + 1] > value)) return mid;
      else low = mid + 1;
    }
  }
  return -1;
}
解答开篇
好了，现在我们回头来看开篇的问题：如何快速定位出一个 IP 地址的归属地？

现在这个问题应该很简单了。如果 IP 区间与归属地的对应关系不经常更新，我们可以先预处理这 12 万条数据，让其按照起始 IP 从小到大排序。如何来排序呢？我们知道，IP 地址可以转化为 32 位的整型数。所以，我们可以将起始地址，按照对应的整型值的大小关系，从小到大进行排序。

然后，这个问题就可以转化为我刚讲的第四种变形问题“在有序数组中，查找最后一个小于等于某个给定值的元素”了。

当我们要查询某个 IP 归属地时，我们可以先通过二分查找，找到最后一个起始 IP 小于等于这个 IP 的 IP 区间，然后，检查这个 IP 是否在这个 IP 区间内，如果在，我们就取出对应的归属地显示；如果不在，就返回未查找到。

内容小结
上一节我说过，凡是用二分查找能解决的，绝大部分我们更倾向于用散列表或者二叉查找树。即便是二分查找在内存使用上更节省，但是毕竟内存如此紧缺的情况并不多。那二分查找真的没什么用处了吗？

实际上，上一节讲的求“值等于给定值”的二分查找确实不怎么会被用到，二分查找更适合用在“近似”查找问题，在这类问题上，二分查找的优势更加明显。比如今天讲的这几种变体问题，用其他数据结构，比如散列表、二叉树，就比较难实现了。

变体的二分查找算法写起来非常烧脑，很容易因为细节处理不好而产生 Bug，这些容易出错的细节有：终止条件、区间上下界更新方法、返回值选择。所以今天的内容你最好能用自己实现一遍，对锻炼编码能力、逻辑思维、写出 Bug free 代码，会很有帮助。

课后思考
我们今天讲的都是非常规的二分查找问题，今天的思考题也是一个非常规的二分查找问题。如果有序数组是一个循环有序数组，比如 4，5，6，1，2，3。针对这种情况，如何实现一个求“值等于给定值”的二分查找算法呢？

欢迎留言和我分享，我会第一时间给你反馈。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(128)

Smallfly 置顶
有三种方法查找循环有序数组
 
 一、
 1. 找到分界下标，分成两个有序数组
 2. 判断目标值在哪个有序数据范围内，做二分查找
 
 二、
 1. 找到最大值的下标 x;
 2. 所有元素下标 +x 偏移，超过数组范围值的取模;
 3. 利用偏移后的下标做二分查找；
 4. 如果找到目标下标，再作 -x 偏移，就是目标值实际下标。
 
 两种情况最高时耗都在查找分界点上，所以时间复杂度是 O(N）。
 
 复杂度有点高，能否优化呢？
 
 三、
我们发现循环数组存在一个性质：以数组中间点为分区，会将数组分成一个有序数组和一个循环有序数组。
 
 如果首元素小于 mid，说明前半部分是有序的，后半部分是循环有序数组；
 如果首元素大于 mid，说明后半部分是有序的，前半部分是循环有序的数组；
 如果目标元素在有序数组范围中，使用二分查找；
 如果目标元素在循环有序数组中，设定数组边界后，使用以上方法继续查找。
 
 时间复杂度为 O(logN)。
2018-10-27

5

188

zixuan
思考题对应leetcode 33题，大家可以去练习
2018-10-31


60

Victor
今天的IP地址归属地问题，从工程实现的角度考虑，我更偏向于直接使用关系型数据库实现。
也就是将12w条归属地与IP区间的开始、结束存入数据库中。
数据库表ip_table有如下字段：area_name | start_ip | end_ip ，start_ip及end_ip 均建立索引
SQL语句：
select area_name from ip_table where input_ip >= start_ip and input_ip <= end_ip;
学习算法的课程常常和自己工程开发的实际结合在一起，感觉两者是相互促进理解的过程。
作者回复: 数据库可以 单性能会受限

2018-10-27

1

13

舍得
第一段代码有漏洞，且不说int能不能表示数组的下标问题，毕竟这个数组能越界说明相当庞大了；
主要问题在于，如果我给定的数大于任何一个数组元素，low就会等于n，n是数组越界后的第一个元素，如果它刚好是要查找的值呢？？
作者回复: 谢谢指正 我稍后改下

2018-10-27


13

王艳红
王老师，有一个疑惑不太明白
int mid = low + ((high - low)>>1)
这句，为什么要用这种写法呢？我看之前的简单的额二分查找是
int mid = (low + high)/2

作者回复: 下面的写法有可能会导致溢出，比如low很大，high也很大，之和就溢出了。

2019-03-05

1

10

charon
用JavaScript实现的最基本的思考题：
array是传入的数组，value是要查找的值
思路是通过对比low,high的值来判断value所在的区间，不用多循环一遍找偏移量了~
    function search(array,value){
        let low = 0;
        let high = array.length - 1;
        
        while(low <= high){
            let mid = low + ((high - low) >> 1);
            if(value == array[low]) return low;
            if(value == array[high]) return high;
            if(value == array[mid]) return mid;

            if(value > array[mid] && value > array[high] && array[mid] < array[low]){
                high = mid - 1;
            }else if(value < array[mid] && value < array[low] && array[mid] < array[low]){
                high = mid - 1;
            }else if(value < array[mid] && value > array[low]){
                high = mid - 1;
            }else{
                low = mid + 1;
            }
        }

        return -1
    }
2018-10-26


10

菜鸡程序员

1.如果不知道分界点，找寻分界点没有意义，不如直接遍历。
2.如果知道分界点，查看在哪一边，然后二分法，或者偏移量计算,二分法

老师,我今天这种可以吗:
/**
* 功能描述:查找第一个大于等于给定值的元素
*
* @param null
* @return
* @author xiongfan
* @date 2018/12/7 9:43:00
*/
public static int getFirstGreaterValue(int[] array,int value) {
int low = 0;
int high = array.length - 1;

while (low <= high) {
int mid = low + (high - low) >> 1;
if (array[mid] < value) {
low = mid + 1;
} else if (array[mid] > value) {
high = mid - 1;
} else {

if (mid == 0 || array[mid - 1] < array[mid]) {
return mid;
}
high = mid - 1;

}
}

return low>array.length-1?-1:low;
}

/**
* 功能描述:查找最后一个小于等于给定值的元素
*
* @param null
* @return
* @author xiongfan
* @date 2018/12/7 10:03:00
*/
public static int getLastLessValue(int[] array,int value) {
int low = 0;
int high = array.length - 1;

while (low <= high) {
int mid = low + (high - low) >> 1;
if (array[mid] > value) {
high = mid - 1;
} else if (array[mid] < value) {
low = mid + 1;
} else {
if (mid > array.length-1 || array[mid] < array[mid + 1]) {
return mid;
}
low = mid + 1;
}
}

return high<0?-1:high;
}
2018-12-07


6

姜威
总结：二分查找（下）
一、四种常见的二分查找变形问题
1.查找第一个值等于给定值的元素
2.查找最后一个值等于给定值的元素
3.查找第一个大于等于给定值的元素
4.查找最后一个小于等于给定值的元素
二、适用性分析
1.凡事能用二分查找解决的，绝大部分我们更倾向于用散列表或者二叉查找树，即便二分查找在内存上更节省，但是毕竟内存如此紧缺的情况并不多。
2.求“值等于给定值”的二分查找确实不怎么用到，二分查找更适合用在”近似“查找问题上。比如上面讲几种变体。
三、思考
1.如何快速定位出一个IP地址的归属地？
[202.102.133.0, 202.102.133.255] 山东东营市
[202.102.135.0, 202.102.136.255] 山东烟台
[202.102.156.34, 202.102.157.255] 山东青岛
[202.102.48.0, 202.102.48.255] 江苏宿迁
[202.102.49.15, 202.102.51.251] 江苏泰州
[202.102.56.0, 202.102.56.255] 江苏连云港
假设我们有 12 万条这样的 IP 区间与归属地的对应关系，如何快速定位出一个IP地址的归属地呢？
2.如果有一个有序循环数组，比如4，5，6，1，2，3。针对这种情况，如何实现一个求“值等于给定值”的二分查找算法？
2018-11-03


5

狼的诱惑
@老师，请老师或其他高人回复指教
/**
     * 例如： 4 5 6 1 2 3
     * 循环数组的二分查找 总体时间复杂度O(n)
     */
    public static int forEqualsThan(int[] arr, int num) {
        if (arr[0] == num) {
            return 0;
        }
        int length = arr.length;
        int low = 0;
        int high = length - 1;
        //找到循环节点
        for (int i = 0; i < length; i++) {
            if (i == length - 1) {
                if (arr[i] > arr[0]) {
                    low = i;
                    high = 0;
                    break;
                }
            } else {
                if (arr[i] > arr[i + 1]) {
                    low = i;
                    high = low + 1;
                    break;
                }
            }
        }
        //判断第一个节点的大小位置，确定low和high的值，转变为正常有序的二分查找
        if (arr[0] < num) {
            high = low;
            low = 0;
        }
        if (arr[0] > num) {
            low = high;
            high = length - 1;
        }
        while (low <= high) {
            int index = low + ((high - low) >> 1);
            if (arr[index] > num) {
                high = index - 1;
            }
            if (arr[index] < num) {
                low = index + 1;
            }
            if (arr[index] == num) {
                return index;
            }
        }
        return -1;
    }
2018-10-31

3

5

朱坤
置顶的同学的思路一，即先找分界再判断在哪个数组，再二分，其实是可以做到O(Log N)的，找分界的点的规则就是找到首个小于a[0]的元素，思路用老师4个转换问题的解法就可以。按评论做了下leetcode33题，感觉会比较老师给的思考题描述清晰。。因为老师说的找问题，没有明确有几组循环数组。。
2019-02-25


3

晓杉
老师，我有一个疑问。
使用二分查找的前提是有序数组。
对于本节IP地址问题，我们先进行排序再进行查找，我理解应该时间复杂度是排序平均O(nLogn)再加上二分查找O(logn)
比单纯的顺序遍历O(n)要慢许多了。
是不是实际中，这种无序情况直接使用了顺序遍历查找呢？
2018-11-16

1

3

勤劳的小胖子-libo
1. 先二分遍历找到分隔点index，特征是<pre, >=next;
2. 把数组分成二个部分，[0,index-1], [index,length-1];
3. 分别使用二分查找，找到给定的值。
时间复杂度为2*log(n). 不确定有什么更好的办法。
2018-10-27


3

komo0104
给原来的index加上偏移量。
比如原来的二分查找代码从0开始到n-1结束，现在为x到x - 1 (即n-1+x-n)。
x为开始循环处的索引，例子里为3 （1所在索引）。需要扫描一遍数组找到x，复杂度O(n)。其余和普通二分查找一样，需要多判断index not out of bound。如果索引超过n了要减n。
总的复杂度还是O(n)
2018-10-26


3

低调人生
我觉得查找第一个符合给定的值得那两种写法 第一种更好理解 没看懂作者的写法
2019-05-28

1

2

牛顿的苹果啦
思考题：
可以考虑将数组分为N个有序数组，分别进行二分查找。
代码实现：
 public int circleBinarySearch(int[] a, int value){
        int low = 0, high=0;
        for(int i=0;i<a.length-1;i++){
            //找到有序数组的下标
            if(a[i]<a[i+1]){
                high=i+1;
            }else{
                //有序数组到顶，二分查找
                int i1 = binarySearch(low, high, a, value);
                if(-1 != i1){
                    return i1;
                }else{
                    low = high+1;
                }
            }
            //high已经到最后一个位置
            if(a.length-1 == high){
                return binarySearch(low, high, a, value);
            }
        }
        return -1;
    }

    private int binarySearch(int low, int high, int[] a, int value){
        for(;low<=high;){
            int middle = low+((high-low)>>1);
            if(a[middle] == value){
                return middle;
            }
            if(a[middle] > value){
                high = middle -1;
            }else{
                low = middle +1;
            }
        }
        return -1;
    }
2019-01-31


2

毅仔
第一次见到逻辑这么清晰的二分查找代码，已经被老师俘获了，太优雅了
2018-12-23


2

QFann
public int search(int[] nums, int target) {
        if(nums.length ==0) return -1;
        if(nums.length ==1){
            if(nums[0] == target) return 0;
            else return -1;
        }
        int low = 0;
        int high = nums.length - 1;
        int index = subIndex(nums,low,high);
        if(index != -1){
            int val = binarySearch(nums,low,index,target);
            if (val != -1) return val;
            return binarySearch(nums,index+1,high,target);
        }
        return binarySearch(nums,low,high,target);
    }
    
    public static int subIndex(int [] nums,int low,int high){
        while (low <= high){
            int mid = low + ((high - low )>> 1);
            if(nums.length < 1) return -1;
            if(nums[mid] > nums[mid+1]) return mid;
            else if( nums[mid] < nums[low] ) high = mid ;
            else if (nums[mid] > nums[high]) low = mid ;
            else return -1;
        }
        return -1;
    }
    
    public static int binarySearch(int[] nums,int low,int high,int target){
        while (low <= high){
            int mid = low + ((high - low)>>1);
            if(nums[mid] == target) return mid;
            else if (nums[mid] < target) low = mid + 1;
            else high = mid -1;
        }
        return -1;
    }
2018-12-18


2

Monday
二分的四种变种写法。个人觉得都是分三种情况进行讨论，再多注意判断边界值，三种情况为：
a[mid]<value
a[mid]=value
a[mid]>value；
思考题：自己思考了一小段时间没有好的思路，就各学友的留言，亲自实现了Smallfly的方法三，感觉比较好！谢谢！
2018-10-29


2

疾风狂草
老师，你说二分查找更适合用在“近似”查找问题，在这类问题上，二分查找的优势更加明显。这种问题链式哈希表不是更擅长吗？
作者回复: 哈希表是精准查找

2018-12-10


1

Laughing_Lz
/**
* 循环数组中使用二分查找获取value所在位置
*
* @param arr arr
* @param value value
* @return
*/
public static int loopBinarySearch(int[] arr, int value) {
if (arr.length == 1) {
if (arr[0] == value) {
return 0;
} else {
return -1;
}
}
int low = 0, high = arr.length, middle = 0;
// 首先获取首末位置
for (int i = 0; i < arr.length - 1; i++) {
if (arr[i] > arr[i + 1]) {
high = i;
low = i + 1;
}
}
if (arr[arr.length - 1] > arr[0]) {
low = 0;
high = arr.length - 1;
}
// 经过和arr[0]判断后筛选出可能包含value的子数组
if (arr[0] == value) {
return 0;
} else if (arr[0] < value) {
low = 1;
} else if (arr[0] > value) {
high = arr.length - 1;
}
// 使用简单二分查找获取value位置
while (low <= high) {
middle = low + ((high - low) >> 1);
if (arr[middle] > value) {
high = middle - 1;
} else if (arr[middle] < value) {
low = middle + 1;
} else {
return middle;
}
}
return -1;
}
2018-11-24


1
收起评论

99+99+







# 17 | 跳表：为什么Redis一定要用跳表来实现有序集合？




数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



17 | 跳表：为什么Redis一定要用跳表来实现有序集合？
王争 2018-10-29



15:08
讲述：修阳 大小：6.94M
上两节我们讲了二分查找算法。当时我讲到，因为二分查找底层依赖的是数组随机访问的特性，所以只能用数组来实现。如果数据存储在链表中，就真的没法用二分查找算法了吗？

实际上，我们只需要对链表稍加改造，就可以支持类似“二分”的查找算法。我们把改造之后的数据结构叫作跳表（Skip list），也就是今天要讲的内容。

跳表这种数据结构对你来说，可能会比较陌生，因为一般的数据结构和算法书籍里都不怎么会讲。但是它确实是一种各方面性能都比较优秀的动态数据结构，可以支持快速的插入、删除、查找操作，写起来也不复杂，甚至可以替代红黑树（Red-black tree）。

Redis 中的有序集合（Sorted Set）就是用跳表来实现的。如果你有一定基础，应该知道红黑树也可以实现快速的插入、删除和查找操作。那 Redis 为什么会选择用跳表来实现有序集合呢？ 为什么不用红黑树呢？学完今天的内容，你就知道答案了。

如何理解“跳表”？
对于一个单链表来讲，即便链表中存储的数据是有序的，如果我们要想在其中查找某个数据，也只能从头到尾遍历链表。这样查找效率就会很低，时间复杂度会很高，是 O(n)。



那怎么来提高查找效率呢？如果像图中那样，对链表建立一级“索引”，查找起来是不是就会更快一些呢？每两个结点提取一个结点到上一级，我们把抽出来的那一级叫作索引或索引层。你可以看我画的图。图中的 down 表示 down 指针，指向下一级结点。



如果我们现在要查找某个结点，比如 16。我们可以先在索引层遍历，当遍历到索引层中值为 13 的结点时，我们发现下一个结点是 17，那要查找的结点 16 肯定就在这两个结点之间。然后我们通过索引层结点的 down 指针，下降到原始链表这一层，继续遍历。这个时候，我们只需要再遍历 2 个结点，就可以找到值等于 16 的这个结点了。这样，原来如果要查找 16，需要遍历 10 个结点，现在只需要遍历 7 个结点。

从这个例子里，我们看出，加来一层索引之后，查找一个结点需要遍历的结点个数减少了，也就是说查找效率提高了。那如果我们再加一级索引呢？效率会不会提升更多呢？

跟前面建立第一级索引的方式相似，我们在第一级索引的基础之上，每两个结点就抽出一个结点到第二级索引。现在我们再来查找 16，只需要遍历 6 个结点了，需要遍历的结点数量又减少了。



我举的例子数据量不大，所以即便加了两级索引，查找效率的提升也并不明显。为了让你能真切地感受索引提升查询效率。我画了一个包含 64 个结点的链表，按照前面讲的这种思路，建立了五级索引。



从图中我们可以看出，原来没有索引的时候，查找 62 需要遍历 62 个结点，现在只需要遍历 11 个结点，速度是不是提高了很多？所以，当链表的长度 n 比较大时，比如 1000、10000 的时候，在构建索引之后，查找效率的提升就会非常明显。

前面讲的这种链表加多级索引的结构，就是跳表。我通过例子给你展示了跳表是如何减少查询次数的，现在你应该比较清晰地知道，跳表确实是可以提高查询效率的。接下来，我会定量地分析一下，用跳表查询到底有多快。

用跳表查询到底有多快？
前面我讲过，算法的执行效率可以通过时间复杂度来度量，这里依旧可以用。我们知道，在一个单链表中查询某个数据的时间复杂度是 O(n)。那在一个具有多级索引的跳表中，查询某个数据的时间复杂度是多少呢？

这个时间复杂度的分析方法比较难想到。我把问题分解一下，先来看这样一个问题，如果链表里有 n 个结点，会有多少级索引呢？

按照我们刚才讲的，每两个结点会抽出一个结点作为上一级索引的结点，那第一级索引的结点个数大约就是 n/2，第二级索引的结点个数大约就是 n/4，第三级索引的结点个数大约就是 n/8，依次类推，也就是说，第 k 级索引的结点个数是第 k-1 级索引的结点个数的 1/2，那第 k级索引结点的个数就是 n/(2k)。

假设索引有 h 级，最高级的索引有 2 个结点。通过上面的公式，我们可以得到 n/(2h)=2，从而求得 h=log2n-1。如果包含原始链表这一层，整个跳表的高度就是 log2n。我们在跳表中查询某个数据的时候，如果每一层都要遍历 m 个结点，那在跳表中查询一个数据的时间复杂度就是 O(m*logn)。

那这个 m 的值是多少呢？按照前面这种索引结构，我们每一级索引都最多只需要遍历 3 个结点，也就是说 m=3，为什么是 3 呢？我来解释一下。

假设我们要查找的数据是 x，在第 k 级索引中，我们遍历到 y 结点之后，发现 x 大于 y，小于后面的结点 z，所以我们通过 y 的 down 指针，从第 k 级索引下降到第 k-1 级索引。在第 k-1 级索引中，y 和 z 之间只有 3 个结点（包含 y 和 z），所以，我们在 K-1 级索引中最多只需要遍历 3 个结点，依次类推，每一级索引都最多只需要遍历 3 个结点。



通过上面的分析，我们得到 m=3，所以在跳表中查询任意数据的时间复杂度就是 O(logn)。这个查找的时间复杂度跟二分查找是一样的。换句话说，我们其实是基于单链表实现了二分查找，是不是很神奇？不过，天下没有免费的午餐，这种查询效率的提升，前提是建立了很多级索引，也就是我们在第 6 节讲过的空间换时间的设计思路。

跳表是不是很浪费内存？
比起单纯的单链表，跳表需要存储多级索引，肯定要消耗更多的存储空间。那到底需要消耗多少额外的存储空间呢？我们来分析一下跳表的空间复杂度。

跳表的空间复杂度分析并不难，我在前面说了，假设原始链表大小为 n，那第一级索引大约有 n/2 个结点，第二级索引大约有 n/4 个结点，以此类推，每上升一级就减少一半，直到剩下 2 个结点。如果我们把每层索引的结点数写出来，就是一个等比数列。



这几级索引的结点总和就是 n/2+n/4+n/8…+8+4+2=n-2。所以，跳表的空间复杂度是 O(n)。也就是说，如果将包含 n 个结点的单链表构造成跳表，我们需要额外再用接近 n 个结点的存储空间。那我们有没有办法降低索引占用的内存空间呢？

我们前面都是每两个结点抽一个结点到上级索引，如果我们每三个结点或五个结点，抽一个结点到上级索引，是不是就不用那么多索引结点了呢？我画了一个每三个结点抽一个的示意图，你可以看下。



从图中可以看出，第一级索引需要大约 n/3 个结点，第二级索引需要大约 n/9 个结点。每往上一级，索引结点个数都除以 3。为了方便计算，我们假设最高一级的索引结点个数是 1。我们把每级索引的结点个数都写下来，也是一个等比数列。



通过等比数列求和公式，总的索引结点大约就是 n/3+n/9+n/27+…+9+3+1=n/2。尽管空间复杂度还是 O(n)，但比上面的每两个结点抽一个结点的索引构建方法，要减少了一半的索引结点存储空间。

实际上，在软件开发中，我们不必太在意索引占用的额外空间。在讲数据结构和算法时，我们习惯性地把要处理的数据看成整数，但是在实际的软件开发中，原始链表中存储的有可能是很大的对象，而索引结点只需要存储关键值和几个指针，并不需要存储对象，所以当对象比索引结点大很多时，那索引占用的额外空间就可以忽略了。

高效的动态插入和删除
跳表长什么样子我想你应该已经很清楚了，它的查找操作我们刚才也讲过了。实际上，跳表这个动态数据结构，不仅支持查找操作，还支持动态的插入、删除操作，而且插入、删除操作的时间复杂度也是 O(logn)。

我们现在来看下， 如何在跳表中插入一个数据，以及它是如何做到 O(logn) 的时间复杂度的？

我们知道，在单链表中，一旦定位好要插入的位置，插入结点的时间复杂度是很低的，就是 O(1)。但是，这里为了保证原始链表中数据的有序性，我们需要先找到要插入的位置，这个查找操作就会比较耗时。

对于纯粹的单链表，需要遍历每个结点，来找到插入的位置。但是，对于跳表来说，我们讲过查找某个结点的的时间复杂度是 O(logn)，所以这里查找某个数据应该插入的位置，方法也是类似的，时间复杂度也是 O(logn)。我画了一张图，你可以很清晰地看到插入的过程。



好了，我们再来看删除操作。

如果这个结点在索引中也有出现，我们除了要删除原始链表中的结点，还要删除索引中的。因为单链表中的删除操作需要拿到要删除结点的前驱结点，然后通过指针操作完成删除。所以在查找要删除的结点的时候，一定要获取前驱结点。当然，如果我们用的是双向链表，就不需要考虑这个问题了。

跳表索引动态更新
当我们不停地往跳表中插入数据时，如果我们不更新索引，就有可能出现某 2 个索引结点之间数据非常多的情况。极端情况下，跳表还会退化成单链表。



作为一种动态数据结构，我们需要某种手段来维护索引与原始链表大小之间的平衡，也就是说，如果链表中结点多了，索引结点就相应地增加一些，避免复杂度退化，以及查找、插入、删除操作性能下降。

如果你了解红黑树、AVL 树这样平衡二叉树，你就知道它们是通过左右旋的方式保持左右子树的大小平衡（如果不了解也没关系，我们后面会讲），而跳表是通过随机函数来维护前面提到的“平衡性”。

当我们往跳表中插入数据的时候，我们可以选择同时将这个数据插入到部分索引层中。如何选择加入哪些索引层呢？

我们通过一个随机函数，来决定将这个结点插入到哪几级索引中，比如随机函数生成了值 K，那我们就将这个结点添加到第一级到第 K 级这 K 级索引中。



随机函数的选择很有讲究，从概率上来讲，能够保证跳表的索引大小和数据大小平衡性，不至于性能过度退化。至于随机函数的选择，我就不展开讲解了。如果你感兴趣的话，可以看看我在 GitHub 上的代码或者 Redis 中关于有序集合的跳表实现。

跳表的实现还是稍微有点复杂的，我将 Java 实现的代码放到了 GitHub 中，你可以根据我刚刚的讲解，对照着代码仔细思考一下。你不用死记硬背代码，跳表的实现并不是我们这节的重点。

解答开篇
今天的内容到此就讲完了。现在，我来讲解一下开篇的思考题：为什么 Redis 要用跳表来实现有序集合，而不是红黑树？

Redis 中的有序集合是通过跳表来实现的，严格点讲，其实还用到了散列表。不过散列表我们后面才会讲到，所以我们现在暂且忽略这部分。如果你去查看 Redis 的开发手册，就会发现，Redis 中的有序集合支持的核心操作主要有下面这几个：

插入一个数据；

删除一个数据；

查找一个数据；

按照区间查找数据（比如查找值在 [100, 356] 之间的数据）；

迭代输出有序序列。

其中，插入、删除、查找以及迭代输出有序序列这几个操作，红黑树也可以完成，时间复杂度跟跳表是一样的。但是，按照区间来查找数据这个操作，红黑树的效率没有跳表高。

对于按照区间查找数据这个操作，跳表可以做到 O(logn) 的时间复杂度定位区间的起点，然后在原始链表中顺序往后遍历就可以了。这样做非常高效。

当然，Redis 之所以用跳表来实现有序集合，还有其他原因，比如，跳表更容易代码实现。虽然跳表的实现也不简单，但比起红黑树来说还是好懂、好写多了，而简单就意味着可读性好，不容易出错。还有，跳表更加灵活，它可以通过改变索引构建策略，有效平衡执行效率和内存消耗。

不过，跳表也不能完全替代红黑树。因为红黑树比跳表的出现要早一些，很多编程语言中的 Map 类型都是通过红黑树来实现的。我们做业务开发的时候，直接拿来用就可以了，不用费劲自己去实现一个红黑树，但是跳表并没有一个现成的实现，所以在开发中，如果你想使用跳表，必须要自己实现。

内容小结
今天我们讲了跳表这种数据结构。跳表使用空间换时间的设计思路，通过构建多级索引来提高查询的效率，实现了基于链表的“二分查找”。跳表是一种动态数据结构，支持快速的插入、删除、查找操作，时间复杂度都是 O(logn)。

跳表的空间复杂度是 O(n)。不过，跳表的实现非常灵活，可以通过改变索引构建策略，有效平衡执行效率和内存消耗。虽然跳表的代码实现并不简单，但是作为一种动态数据结构，比起红黑树来说，实现要简单多了。所以很多时候，我们为了代码的简单、易读，比起红黑树，我们更倾向用跳表。

课后思考
在今天的内容中，对于跳表的时间复杂度分析，我分析了每两个结点提取一个结点作为索引的时间复杂度。如果每三个或者五个结点提取一个结点作为上级索引，对应的在跳表中查询数据的时间复杂度是多少呢？

欢迎留言和我分享，我会第一时间给你反馈。

我已将本节内容相关的详细代码更新到 GitHub，戳此即可查看。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(133)

张先生
为什么评论区的都这么优秀，为什么我这么菜，我该怎么办😱
2018-11-26

2

146

leo
跳表是我非常喜欢的数据结构，之前写过一篇文章，希望大家斧正（https://cloud.tencent.com/developer/article/1353762）。另外，严格来讲，Redis的对象系统中的每种对象实际上都是基于使用场景选择多种底层数据结构实现的，比如ZSET就是基于【压缩列表】或者【跳跃表+字典】（这也跟之前排序中提到的Sort包实现的思想一样，基于数据规模选择合适的排序算法），体现了Redis对于性能极致的追求。
作者回复: 👍

2018-10-29


115

Liam
看了下老师github上的实现(java版本)，不是很理解，尤其是数组Node forward[]的作用，能多加些注释或讲解一下吗
2018-10-29

1

72

董航
redis有序集合是跳跃表实现的，直接这么说有失偏驳，他是复合数据结构，准确说应该是由一个双hashmap构成的字典和跳跃表实现的，不知道我说的有问题吗😊
作者回复: 后面还会讲 你说的没错 👍

2018-10-29


41

escray
如果每三个或者五个节点提取一个节点作为上级索引，那么对应的查询数据时间复杂度，应该也还是 O(logn)。

假设每 5 个节点提取，那么最高一层有 5 个节点，而跳表高度为 log5n，每层最多需要查找 5 个节点，即 O(mlogn) 中的 m = 5，最终，时间复杂度为 O(logn)。

空间复杂度也还是 O(logn)，虽然省去了一部分索引节点，但是似乎意义不大。

不知道在一般的生产系统，跳表的提取是按照多少个节点来实现？还是每个系统根据实际情况，都不一样。

看了跳表的 Java 实现，查找部分的代码真是漂亮，插入部分看了半天才看明白。
作者回复: 👍

2018-10-29

1

32

姜威
总结：
一、什么是跳表？
为一个值有序的链表建立多级索引，比如每2个节点提取一个节点到上一级，我们把抽出来的那一级叫做索引或索引层。如下图所示，其中down表示down指针，指向下一级节点。以此类推，对于节点数为n的链表，大约可以建立log2n-1级索引。像这种为链表建立多级索引的数据结构就称为跳表。
二、跳表的时间复杂度？
1.计算跳表的高度
如果链表有n个节点，每2个节点抽取抽出一个节点作为上一级索引的节点，那第1级索引的节点个数大约是n/2，第2级索引的节点个数大约是n/4，依次类推，第k级索引的节点个数就是n/(2^k)。假设索引有h级别，最高级的索引有2个节点，则有n/(2^h)=2，得出h=log2n-1，包含原始链表这一层，整个跳表的高度就是log2n。
2.计算跳表的时间复杂度
假设我们在跳表中查询某个数据的时候，如果每一层都遍历m个节点，那在跳表中查询一个数据的时间复杂度就是O(m*logn)。那这个m是多少呢？如下图所示，假设我们要查找的数据是x，在第k级索引中，我们遍历到y节点之后，发现x大于y，小于后面的节点z，所以我们通过y的down指针，从第k级下降到第k-1级索引。在第k-1级索引中，y和z之间只有3个节点（包含y和z），所以，我们在k-1级索引中最多只需要遍历3个节点，以此类推，每一级索引都最多只需要遍历3个节点。所以m=3。因此在跳表中查询某个数据的时间复杂度就是O(logn)。
三、跳表的空间复杂度及如何优化？
1.计算索引的节点总数
如果链表有n个节点，每2个节点抽取抽出一个节点作为上一级索引的节点，那每一级索引的节点数分别为：n/2，n/4，n/8，…，8，4，2，等比数列求和n-1，所以跳表的空间复杂度为O(n)。
2.如何优化时间复杂度
如果链表有n个节点，每3或5个节点抽取抽出一个节点作为上一级索引的节点，那每一级索引的节点数分别为（以3为例）：n/3，n/9，n/27，…，27，9，3，1，等比数列求和n/2，所以跳表的空间复杂度为O(n)，和每2个节点抽取一次相比，时间复杂度要低不少呢。
四、高效的动态插入和删除？
跳表本质上就是链表，所以仅插作，插入和删除操时间复杂度就为O(1)，但在实际情况中，要插入或删除某个节点，需要先查找到指定位置，而这个查找操作比较费时，但在跳表中这个查找操作的时间复杂度是O(logn)，所以，跳表的插入和删除操作的是时间复杂度也是O(logn)。
五、跳表索引动态更新？
当往跳表中插入数据的时候，可以选择同时将这个数据插入到部分索引层中，那么如何选择这个索引层呢？可以通过随机函数来决定将这个节点插入到哪几级索引中，比如随机函数生成了值K，那就可以把这个节点添加到第1级到第K级索引中。
2018-10-31


22

小情绪
王老师：跳表的思想讲的非常好，但是我总觉得应该把跳表的具体实现讲一下吧，毕竟来这里的大部分算法能力不是很强，而跳表的实现还是有一定难度的。
2018-11-29

1

20

德尼
看评论很多人说对github的代码不理解，我来说下自己的理解吧。整个代码的实现思想就是老师说的那样。每个节点的forward里存的是当前节点的所有索引层的下一跳，forward[ 0 ]对应的是原链表里的下一跳，forward[ 1 ]是最后一层节点的下一跳位置，以此类推，也就是说访问head的forward[ levelCount-1 ]表示第一层索引的头结点。head是一个头结点，它的forward里存的是原链表以及索引层的头结点。
2018-12-09


17

MG
王老师的Java实现版本，有几个关键点理解到了，基本上就明白是怎么实现的了：
1.每次插入数据的时候随机产生的level:决定了新节点的层数；
2.数组update的作用：用以存储新节点所有层数上，各自的前一个节点的信息；
3.节点内的forwards数组：用以存储该节点所有层的下一个节点的信息；
4.当所有节点的最大层级变量maxlevel=1的时候，跳表退化成一个普通链表
2018-12-25


13

許敲敲
我是机械行业打算换行的，不知道应该怎么把这些知识掌握的扎实一点，今天课里面的红黑树不了解.
作者回复: 后面会讲 不急

2018-10-29


8

k
看了下留言 好像有人对等比数列求和有想法 老师的n-2并不是估算解 是精确解
n/2, n/4, .., 2 这个数列中一共有log2(n/2)项
套进等比数列求和公式
S = a0(1-q^n)/(1-q), 其中a0表示首项，n表示项数
这里的a0=n/2, 项数=log2(n/2), q=1/2
S = n/2(1-2/n)/(1-1/2) = n-2
2018-11-20

1

7

Smallfly
老师想问下文章中出现的等比数列求和怎么算的，因为整数除法是取整的，所以公式好像不好使……，用数据代入老师的公式又是正确的，希望能指点一下。
作者回复: 整数除法是取取整的是什么意思啊

2018-10-29


5

Uper
仍然是logn 不过底数是间隔结点个数
2018-10-29


5

CathyLin
思考题：
每 3 个结点提取一个结点作为上级索引，时间复杂度是 4log3N ，用大 O 表示法为 O(logn)
同理，每 5 个结点提取一个结点作为上级索引的时间复杂度是 6log5N，用大 O 表示法为 O(logn)。

github 上的代码看的有点没太看懂，还得慢慢啃，加油💪
2018-12-30


4

kakasi
感觉github上的实现好难理解，希望老师有时间能解释下。
我有一个思路：定义两个数据结构，一个是普通的单链表Node，一个索引类Index。索引类中两个域：单链表节点Node， 下一个Index引用。用Index数组表示1 - level索引层。
这样数据结构里就不会出现数组了，不知这样的思路是否正确。
作者回复: 你的方法也可以 我的实现思路比较有技巧 是不容易看懂 建议不要纠结实现了

2018-11-12


4

刘涛涛
github上的代码，我理解的p=p.forwars[i]代表第i层的下一结点，不知道对不对
作者回复: 对的！👍

2019-02-17


3

安南寸暖🤕
talk is cheap, show your code
2019-01-30


3

Pluto
学到了，这个厉害了，不过实现还是没有看的太懂
作者回复: 实现确实不好看懂 我也看了很久

2018-11-05


3

andavid
关于 GitHub 上跳表的 Java 代码实现，本人仔细研读后，按自己的理解加上了注释，并写了一个测试程序打印跳表每一层的结点，以及每个结点在各层的下一跳结点。希望对大家理解跳表有所帮助。如果理解有不恰当的地方，还请指正，多谢~

https://github.com/andavid/ds-algo-java/blob/master/src/main/java/com/github/andavid/ds/datastructure/skiplist/SkipList.java

https://github.com/andavid/ds-algo-java/blob/master/src/test/java/com/github/andavid/ds/datastructure/skiplist/SkipListTest.java

2019-08-17

1

2

晓龙
跳表就是告诉链表中查找从什么地方开始比较快
2019-02-18


2
收起评论

99+99+






# 18 | 散列表（上）：Word文档中的单词拼写检查功能是如何实现的？




数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



18 | 散列表（上）：Word文档中的单词拼写检查功能是如何实现的？
王争 2018-10-31



13:39
讲述：修阳 大小：6.26M
Word 这种文本编辑器你平时应该经常用吧，那你有没有留意过它的拼写检查功能呢？一旦我们在 Word 里输入一个错误的英文单词，它就会用标红的方式提示“拼写错误”。Word 的这个单词拼写检查功能，虽然很小但却非常实用。你有没有想过，这个功能是如何实现的呢？

其实啊，一点儿都不难。只要你学完今天的内容，散列表（Hash Table）。你就能像微软 Office 的工程师一样，轻松实现这个功能。

散列思想
散列表的英文叫“Hash Table”，我们平时也叫它“哈希表”或者“Hash 表”，你一定也经常听过它，我在前面的文章里，也不止一次提到过，但是你是不是真的理解这种数据结构呢？

散列表用的是数组支持按照下标随机访问数据的特性，所以散列表其实就是数组的一种扩展，由数组演化而来。可以说，如果没有数组，就没有散列表。

我用一个例子来解释一下。假如我们有 89 名选手参加学校运动会。为了方便记录成绩，每个选手胸前都会贴上自己的参赛号码。这 89 名选手的编号依次是 1 到 89。现在我们希望编程实现这样一个功能，通过编号快速找到对应的选手信息。你会怎么做呢？

我们可以把这 89 名选手的信息放在数组里。编号为 1 的选手，我们放到数组中下标为 1 的位置；编号为 2 的选手，我们放到数组中下标为 2 的位置。以此类推，编号为 k 的选手放到数组中下标为 k 的位置。

因为参赛编号跟数组下标一一对应，当我们需要查询参赛编号为 x 的选手的时候，我们只需要将下标为 x 的数组元素取出来就可以了，时间复杂度就是 O(1)。这样按照编号查找选手信息，效率是不是很高？

实际上，这个例子已经用到了散列的思想。在这个例子里，参赛编号是自然数，并且与数组的下标形成一一映射，所以利用数组支持根据下标随机访问的时候，时间复杂度是 O(1) 这一特性，就可以实现快速查找编号对应的选手信息。

你可能要说了，这个例子中蕴含的散列思想还不够明显，那我来改造一下这个例子。

假设校长说，参赛编号不能设置得这么简单，要加上年级、班级这些更详细的信息，所以我们把编号的规则稍微修改了一下，用 6 位数字来表示。比如 051167，其中，前两位 05 表示年级，中间两位 11 表示班级，最后两位还是原来的编号 1 到 89。这个时候我们该如何存储选手信息，才能够支持通过编号来快速查找选手信息呢？

思路还是跟前面类似。尽管我们不能直接把编号作为数组下标，但我们可以截取参赛编号的后两位作为数组下标，来存取选手信息数据。当通过参赛编号查询选手信息的时候，我们用同样的方法，取参赛编号的后两位，作为数组下标，来读取数组中的数据。

这就是典型的散列思想。其中，参赛选手的编号我们叫作键（key）或者关键字。我们用它来标识一个选手。我们把参赛编号转化为数组下标的映射方法就叫作散列函数（或“Hash 函数”“哈希函数”），而散列函数计算得到的值就叫作散列值（或“Hash 值”“哈希值”）。



通过这个例子，我们可以总结出这样的规律：散列表用的就是数组支持按照下标随机访问的时候，时间复杂度是 O(1) 的特性。我们通过散列函数把元素的键值映射为下标，然后将数据存储在数组中对应下标的位置。当我们按照键值查询元素时，我们用同样的散列函数，将键值转化数组下标，从对应的数组下标的位置取数据。

散列函数
从上面的例子我们可以看到，散列函数在散列表中起着非常关键的作用。现在我们就来学习下散列函数。

散列函数，顾名思义，它是一个函数。我们可以把它定义成hash(key)，其中 key 表示元素的键值，hash(key) 的值表示经过散列函数计算得到的散列值。

那第一个例子中，编号就是数组下标，所以 hash(key) 就等于 key。改造后的例子，写成散列函数稍微有点复杂。我用伪代码将它写成函数就是下面这样：

int hash(String key) {
  // 获取后两位字符
  string lastTwoChars = key.substr(length-2, length);
  // 将后两位字符转换为整数
  int hashValue = convert lastTwoChas to int-type;
  return hashValue;
}
刚刚举的学校运动会的例子，散列函数比较简单，也比较容易想到。但是，如果参赛选手的编号是随机生成的 6 位数字，又或者用的是 a 到 z 之间的字符串，该如何构造散列函数呢？我总结了三点散列函数设计的基本要求：

散列函数计算得到的散列值是一个非负整数；

如果 key1 = key2，那 hash(key1) == hash(key2)；

如果 key1 ≠ key2，那 hash(key1) ≠ hash(key2)。

我来解释一下这三点。其中，第一点理解起来应该没有任何问题。因为数组下标是从 0 开始的，所以散列函数生成的散列值也要是非负整数。第二点也很好理解。相同的 key，经过散列函数得到的散列值也应该是相同的。

第三点理解起来可能会有问题，我着重说一下。这个要求看起来合情合理，但是在真实的情况下，要想找到一个不同的 key 对应的散列值都不一样的散列函数，几乎是不可能的。即便像业界著名的MD5、SHA、CRC等哈希算法，也无法完全避免这种散列冲突。而且，因为数组的存储空间有限，也会加大散列冲突的概率。

所以我们几乎无法找到一个完美的无冲突的散列函数，即便能找到，付出的时间成本、计算成本也是很大的，所以针对散列冲突问题，我们需要通过其他途径来解决。

散列冲突
再好的散列函数也无法避免散列冲突。那究竟该如何解决散列冲突问题呢？我们常用的散列冲突解决方法有两类，开放寻址法（open addressing）和链表法（chaining）。

1. 开放寻址法
开放寻址法的核心思想是，如果出现了散列冲突，我们就重新探测一个空闲位置，将其插入。那如何重新探测新的位置呢？我先讲一个比较简单的探测方法，线性探测（Linear Probing）。

当我们往散列表中插入数据时，如果某个数据经过散列函数散列之后，存储位置已经被占用了，我们就从当前位置开始，依次往后查找，看是否有空闲位置，直到找到为止。

我说的可能比较抽象，我举一个例子具体给你说明一下。这里面黄色的色块表示空闲位置，橙色的色块表示已经存储了数据。



从图中可以看出，散列表的大小为 10，在元素 x 插入散列表之前，已经 6 个元素插入到散列表中。x 经过 Hash 算法之后，被散列到位置下标为 7 的位置，但是这个位置已经有数据了，所以就产生了冲突。于是我们就顺序地往后一个一个找，看有没有空闲的位置，遍历到尾部都没有找到空闲的位置，于是我们再从表头开始找，直到找到空闲位置 2，于是将其插入到这个位置。

在散列表中查找元素的过程有点儿类似插入过程。我们通过散列函数求出要查找元素的键值对应的散列值，然后比较数组中下标为散列值的元素和要查找的元素。如果相等，则说明就是我们要找的元素；否则就顺序往后依次查找。如果遍历到数组中的空闲位置，还没有找到，就说明要查找的元素并没有在散列表中。



散列表跟数组一样，不仅支持插入、查找操作，还支持删除操作。对于使用线性探测法解决冲突的散列表，删除操作稍微有些特别。我们不能单纯地把要删除的元素设置为空。这是为什么呢？

还记得我们刚讲的查找操作吗？在查找的时候，一旦我们通过线性探测方法，找到一个空闲位置，我们就可以认定散列表中不存在这个数据。但是，如果这个空闲位置是我们后来删除的，就会导致原来的查找算法失效。本来存在的数据，会被认定为不存在。这个问题如何解决呢？

我们可以将删除的元素，特殊标记为 deleted。当线性探测查找的时候，遇到标记为 deleted 的空间，并不是停下来，而是继续往下探测。



你可能已经发现了，线性探测法其实存在很大问题。当散列表中插入的数据越来越多时，散列冲突发生的可能性就会越来越大，空闲位置会越来越少，线性探测的时间就会越来越久。极端情况下，我们可能需要探测整个散列表，所以最坏情况下的时间复杂度为 O(n)。同理，在删除和查找时，也有可能会线性探测整张散列表，才能找到要查找或者删除的数据。

对于开放寻址冲突解决方法，除了线性探测方法之外，还有另外两种比较经典的探测方法，二次探测（Quadratic probing）和双重散列（Double hashing）。

所谓二次探测，跟线性探测很像，线性探测每次探测的步长是 1，那它探测的下标序列就是 hash(key)+0，hash(key)+1，hash(key)+2……而二次探测探测的步长就变成了原来的“二次方”，也就是说，它探测的下标序列就是 hash(key)+0，hash(key)+12，hash(key)+22……

所谓双重散列，意思就是不仅要使用一个散列函数。我们使用一组散列函数 hash1(key)，hash2(key)，hash3(key)……我们先用第一个散列函数，如果计算得到的存储位置已经被占用，再用第二个散列函数，依次类推，直到找到空闲的存储位置。

不管采用哪种探测方法，当散列表中空闲位置不多的时候，散列冲突的概率就会大大提高。为了尽可能保证散列表的操作效率，一般情况下，我们会尽可能保证散列表中有一定比例的空闲槽位。我们用装载因子（load factor）来表示空位的多少。

装载因子的计算公式是：

散列表的装载因子 = 填入表中的元素个数 / 散列表的长度
装载因子越大，说明空闲位置越少，冲突越多，散列表的性能会下降。

2. 链表法
链表法是一种更加常用的散列冲突解决办法，相比开放寻址法，它要简单很多。我们来看这个图，在散列表中，每个“桶（bucket）”或者“槽（slot）”会对应一条链表，所有散列值相同的元素我们都放到相同槽位对应的链表中。



当插入的时候，我们只需要通过散列函数计算出对应的散列槽位，将其插入到对应链表中即可，所以插入的时间复杂度是 O(1)。当查找、删除一个元素时，我们同样通过散列函数计算出对应的槽，然后遍历链表查找或者删除。那查找或删除操作的时间复杂度是多少呢？

实际上，这两个操作的时间复杂度跟链表的长度 k 成正比，也就是 O(k)。对于散列比较均匀的散列函数来说，理论上讲，k=n/m，其中 n 表示散列中数据的个数，m 表示散列表中“槽”的个数。

解答开篇
有了前面这些基本知识储备，我们来看一下开篇的思考题：Word 文档中单词拼写检查功能是如何实现的？

常用的英文单词有 20 万个左右，假设单词的平均长度是 10 个字母，平均一个单词占用 10 个字节的内存空间，那 20 万英文单词大约占 2MB 的存储空间，就算放大 10 倍也就是 20MB。对于现在的计算机来说，这个大小完全可以放在内存里面。所以我们可以用散列表来存储整个英文单词词典。

当用户输入某个英文单词时，我们拿用户输入的单词去散列表中查找。如果查到，则说明拼写正确；如果没有查到，则说明拼写可能有误，给予提示。借助散列表这种数据结构，我们就可以轻松实现快速判断是否存在拼写错误。

内容小结
今天我讲了一些比较基础、比较偏理论的散列表知识，包括散列表的由来、散列函数、散列冲突的解决方法。

散列表来源于数组，它借助散列函数对数组这种数据结构进行扩展，利用的是数组支持按照下标随机访问元素的特性。散列表两个核心问题是散列函数设计和散列冲突解决。散列冲突有两种常用的解决方法，开放寻址法和链表法。散列函数设计的好坏决定了散列冲突的概率，也就决定散列表的性能。

针对散列函数和散列冲突，今天我只讲了一些基础的概念、方法，下一节我会更贴近实战、更加深入探讨这两个问题。

课后思考
假设我们有 10 万条 URL 访问日志，如何按照访问次数给 URL 排序？

有两个字符串数组，每个数组大约有 10 万条字符串，如何快速找出两个数组中相同的字符串？

欢迎留言和我分享，我会第一时间给你反馈。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(154)

Smallfly

1. 假设我们有 10 万条 URL 访问日志，如何按照访问次数给 URL 排序？

遍历 10 万条数据，以 URL 为 key，访问次数为 value，存入散列表，同时记录下访问次数的最大值 K，时间复杂度 O(N)。

如果 K 不是很大，可以使用桶排序，时间复杂度 O(N)。如果 K 非常大（比如大于 10 万），就使用快速排序，复杂度 O(NlogN)。

2. 有两个字符串数组，每个数组大约有 10 万条字符串，如何快速找出两个数组中相同的字符串？

以第一个字符串数组构建散列表，key 为字符串，value 为出现次数。再遍历第二个字符串数组，以字符串为 key 在散列表中查找，如果 value 大于零，说明存在相同字符串。时间复杂度 O(N)。
作者回复: 👍 这条留言可以顶上去了 其他同学都看看吧

2018-10-31

10

606

K战神
今天在新公司转正述职上提到了一些基础的编程原理类的学习计划。被领导和同事嗤之以鼻，现在都怀疑学习深度理论有必要么？我是一个开发6年的程序员。同事在追着最近的技术跑，而我最近阶段总觉得技术原理理论方面基础薄弱。不知道这样的坚持对不对。比如我说学习数据结构算法，他们抛开异样的眼光，觉得在说有什么用。
作者回复: 你的领导 同事也有可能是水货 别局限于身边的人的观点 多上网看看大牛们都咋说

2018-11-20

9

82

五岳寻仙
今天学习了散列表的原理，以及两种解决hash冲突的方法：开放地址法和链表法。
课后思考题第一题，我觉得可以用hash表的链表法解决。访问次数作为slot，访问次数相同的URL放入同一个slot所对应的一条链表中，这样只需要扫一遍所有的URL就排好序了，时间复杂度为O(n)
第二题跟老师讲的word拼写检查有点像，我觉得可以将一个字符串数组做成hash表，然后扫描另一个字符串数组，就能找到重复的字符串。制作和扫描hash表的算法复杂度都是O(n)
2018-10-31

1

42

姜威
总结：
一、散列表的由来？
1.散列表来源于数组，它借助散列函数对数组这种数据结构进行扩展，利用的是数组支持按照下标随机访问元素的特性。
2.需要存储在散列表中的数据我们称为键，将键转化为数组下标的方法称为散列函数，散列函数的计算结果称为散列值。
3.将数据存储在散列值对应的数组下标位置。
二、如何设计散列函数？
总结3点设计散列函数的基本要求
1.散列函数计算得到的散列值是一个非负整数。
2.若key1=key2，则hash(key1)=hash(key2)
3.若key≠key2，则hash(key1)≠hash(key2)
正是由于第3点要求，所以产生了几乎无法避免的散列冲突问题。
三、散列冲突的解放方法？
1.常用的散列冲突解决方法有2类：开放寻址法（open addressing）和链表法（chaining）
2.开放寻址法
①核心思想：如果出现散列冲突，就重新探测一个空闲位置，将其插入。
②线性探测法（Linear Probing）：
插入数据：当我们往散列表中插入数据时，如果某个数据经过散列函数之后，存储的位置已经被占用了，我们就从当前位置开始，依次往后查找，看是否有空闲位置，直到找到为止。
查找数据：我们通过散列函数求出要查找元素的键值对应的散列值，然后比较数组中下标为散列值的元素和要查找的元素是否相等，若相等，则说明就是我们要查找的元素；否则，就顺序往后依次查找。如果遍历到数组的空闲位置还未找到，就说明要查找的元素并没有在散列表中。
删除数据：为了不让查找算法失效，可以将删除的元素特殊标记为deleted，当线性探测查找的时候，遇到标记为deleted的空间，并不是停下来，而是继续往下探测。
结论：最坏时间复杂度为O(n)
③二次探测（Quadratic probing）：线性探测每次探测的步长为1，即在数组中一个一个探测，而二次探测的步长变为原来的平方。
④双重散列（Double hashing）：使用一组散列函数，直到找到空闲位置为止。
⑤线性探测法的性能描述：
用“装载因子”来表示空位多少，公式：散列表装载因子=填入表中的个数/散列表的长度。
装载因子越大，说明空闲位置越少，冲突越多，散列表的性能会下降。
3.链表法（更常用）
插入数据：当插入的时候，我们需要通过散列函数计算出对应的散列槽位，将其插入到对应的链表中即可，所以插入的时间复杂度为O(1)。
查找或删除数据：当查找、删除一个元素时，通过散列函数计算对应的槽，然后遍历链表查找或删除。对于散列比较均匀的散列函数，链表的节点个数k=n/m，其中n表示散列表中数据的个数，m表示散列表中槽的个数，所以是时间复杂度为O(k)。
四、思考
1.Word文档中单词拼写检查功能是如何实现的？
字符串占用内存大小为8字节，20万单词占用内存大小不超过20MB，所以用散列表存储20万英文词典单词，然后对每个编辑进文档的单词进行查找，若未找到，则提示拼写错误。
2.假设我们有10万条URL访问日志，如何按照访问次数给URL排序？
字符串占用内存大小为8字节，10万条URL访问日志占用内存不超过10MB，通过散列表统计url访问次数，然后用TreeMap存储散列表的元素值（作为key）和数组下标值（作为value）
3.有两个字符串数组，每个数组大约有10万条字符串，如何快速找出两个数组中相同的字符串？
分别将2个数组的字符串通过散列函数映射到散列表，散列表中的元素值为次数。注意，先存储的数组中的相同元素值不进行次数累加。最后，统计散列表中元素值大于等于2的散列值对应的字符串就是两个数组中相同的字符串。
2018-10-31

2

28

leo
Redis的字典是使用链式法来解决散列冲突的，并且使用了渐进式rehash的方式来进行哈希表的弹性扩容（https://cloud.tencent.com/developer/article/1353754，请大家斧正）。
两道思考题使用哈希表都可以解决，第二道题也可以对字符串数组进行排序后使用双指针判断，但字符串的比较成本较高，如果是整数类型更加适用。另外，哈希表比较经典的应用还有bitmap和布隆过滤器，其中布隆过滤器也可以用于文本判重，但是有一定的误判概率，可以根据场景使用。
2018-10-31


24

黄金的太阳
请教老师，当我在查找元素时候，在相同散列值的链表中遍历如何区分哪个是我要找的元素？毕竟查找时查询条件只包含KEY的信息吧
作者回复: 相同散列值 但是key不同的 可以再对比key

2018-10-31

4

18

醉比
看到链表那一块感觉是hashmap的实现原理呀
2018-10-31


17

追风者
关于100万URL排序问题？
我看了半天置顶的回答，没太明白。
url为key，出现次数count为value。数组的下标为hash(key)得到的值，保存的内容为count。
排序阶段根据count排序，不是只是改变count的位置么，对应的地址没有改变啊。
如果说散列表是链表法的形式，难道排序的时候也会改变链表的头指针地址？那再要查找对应url的访问次数不就不行了。
2018-11-10


16

他城之途
关于课后习题，基于某种语言的sdk实现起来可能比较容易，显然老师问的是思想，下面是我的理解，望老师和大家指正。
习题1，先分组累加次数再排序: 遍历10万数据，通过hash把相同url分组到同一个bucket下，如果bucket已存在，则取出已有次数+当前次数后再set进去，遍历完了整体再排序。
习题2，显然不是循环嵌套循环，那样时间复杂度不可接受。应该分别独立遍历两个数组，通过hash把相同的字符串扔到同一个bucket, 完了之后统计bucket长度＞1的就行了。
2018-10-31


14

这么写的闫
当散列冲突，表中存储了多个相同散列值时，查询数据怎么确定查询到的是我想要的那个？
这一点很疑惑，求指点
作者回复: 再全量对比 因为散列表中存储的不仅仅是哈希值 还有全量的数据信息

2018-11-05


7

万里晴空
可以写代码进行分析讲解不，这样更能感受到
2018-10-31


7

回家
假设我们有 10 万条 URL 访问日志，如何按照访问次数给 URL 排序？
1.访问次数作为key，URL和访问次数作为存储对象，存在散列表中。解决冲突的方法使用链表法，相当于实现了对URL根据访问次数进行了分组。
2.将信息存储在散列表中的过程中，构造数组，数组元素是访问次数。在存入散列表的过程中，如果出现散列冲突，就不将该次数放入到数组中。
3.使用快速排序对数组进行排序。排序后的数组相当于是排序后的URL，即利用次数可以索引到该访问次数对应的URL。
2019-01-01

1

6

王荣慧
有个疑问，如果在冲突的位置的下一个空闲位置存储数据，文中提到，根据key算出的位置存储的值和要查询的数据进行对比，确定是否是要查询的数据，如果我已经知道了要查询的数据，应该就不用查询了吧，这个地方不大理解。
作者回复: 表述的不准确 我的意思是散列表中存储对象 对象包含key和附属字段 根据key构建散列表 查询的时候也是根据key 但是同一个散列值可能对应多个key 在查询的时候不能仅仅通过key的散列值 还要对比key

2018-11-19

1

6

唐朝农民
Word 单词验证 是不是用 Trie 树更好，大神讲讲这个数据结构，尤其是编码这块
作者回复: 马上就要讲了 别急

2018-11-02


6

张三丰
在查找的时候，一旦我们通过线性探测方法，找到一个空闲位置，我们就可以认定散列表中不存在这个数据。但是，如果这个空闲位置是我们后来删除的，就会导致原来的查找算法失效。本来存在的数据，会被认定为不存在。这个问题如何解决呢？

这句话不理解，这不正是删除的效果么。。。设置为空，下次查找的时候当然不在了啊，已经删除了啊。。。
2018-11-23

2

5

肖小强
老师，关于置顶的那个回答有些疑问。
比如第一题的解答说到“url为key，出现次数为value”
我的疑问是，hash(key)=VALUE，这个VALUE经过处理后不应该是一个随机的数组的下标吗？然后把出现次数value存入到这个位置中并不断更新。我对上面那句话的理解是hash(url)=value，所以为什么可以把出现次数作为value，value不应该是一个随机值吗？还是这个value本来就不是那个VALUE？
作者回复: value并不是hash函数的值。更好的表述应该是声明一个count字段

2018-11-04


4

ALAN
老师，有个问题请教下。开放寻址法查询的时候，碰到散列表为空的位置后，就不继续往后找了吗？这样设计不合理吧，因为存储的时候，存数据的散列表的位置是随机的，空的位置后面也许存了数据呢？如果是继续找的话，那为什么删除数据后，要进行特殊标记，这样标记也没意义啊，反正碰到空的位置，还是会继续找，这样标不标记都无所谓啊？
2018-11-02


4

Ionizing
个人的疑问：
1. 关于开放空间的散列冲突：既然存在散列冲突问题，插入时可以通过分配新的 key 来插入存在散列冲突的元素，那么在访问时又是如何解决散列冲突的呢？比如有两个键值对 {key1: val1}, {key2: val2} 它们的 key 在生成时是冲突的，key2 经过重新分配，现在访问 {key2: val2} 时应该如何通过hash函数得到正确的 key2 呢？假如删除 {key1: val1}，现在要访问 {key2: val2} ，那么执行 hash(string) 后得到的 key1 并不存在，应该怎么实现对 {key2: val2} 的正确访问呢？
2018-11-01


4

Monday
思考题1：
1、先计算出每个URL访问次数
    思路最好是使用Java的HashMap<String,Integer>这个结果，key为URL，value为访问次数； 每次put之前先get一把，若不存在value为1，若存在value=value+1。若直接用hash(URL)获取散列值做为数组下标，如若出现哈希冲突，会使得URL的访问次数统计不正确，当然可以使用链表法来解决冲突，也就是Java中HashMap一样解决方法。
2、再通过桶排序进行排序（使用访问次数做为桶编号）
思考题2：
假设两个数组为A和B，快速查找相同字符串的思路如下
1）遍历A并将元素存入散列表HA中
2）遍历B中每个元素并在散列表HA进行查找，查找得到表示相同元素

谢谢！
2018-10-31


4

吴彪
为什么数组的存储空间有限，也会加大散列冲突的概率呢？hash函数得出来的散列值相同的概率应该是很低的，比如git hash-object，几乎不可能有碰撞，为啥在散列表里碰撞的可能性就这么大
作者回复: 我们还要把散列值转化为数组下标的 单纯散列值是没法直接拿来当下标的

2018-10-31


3
收起评论

99+99+






# 19 | 散列表（中）：如何打造一个工业级水平的散列表？



数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



19 | 散列表（中）：如何打造一个工业级水平的散列表？
王争 2018-11-02



17:57
讲述：修阳 大小：8.23M
通过上一节的学习，我们知道，散列表的查询效率并不能笼统地说成是 O(1)。它跟散列函数、装载因子、散列冲突等都有关系。如果散列函数设计得不好，或者装载因子过高，都可能导致散列冲突发生的概率升高，查询效率下降。

在极端情况下，有些恶意的攻击者，还有可能通过精心构造的数据，使得所有的数据经过散列函数之后，都散列到同一个槽里。如果我们使用的是基于链表的冲突解决方法，那这个时候，散列表就会退化为链表，查询的时间复杂度就从 O(1) 急剧退化为 O(n)。

如果散列表中有 10 万个数据，退化后的散列表查询的效率就下降了 10 万倍。更直接点说，如果之前运行 100 次查询只需要 0.1 秒，那现在就需要 1 万秒。这样就有可能因为查询操作消耗大量 CPU 或者线程资源，导致系统无法响应其他请求，从而达到拒绝服务攻击（DoS）的目的。这也就是散列表碰撞攻击的基本原理。

今天，我们就来学习一下，如何设计一个可以应对各种异常情况的工业级散列表，来避免在散列冲突的情况下，散列表性能的急剧下降，并且能抵抗散列碰撞攻击？

如何设计散列函数？
散列函数设计的好坏，决定了散列表冲突的概率大小，也直接决定了散列表的性能。那什么才是好的散列函数呢？

首先，散列函数的设计不能太复杂。过于复杂的散列函数，势必会消耗很多计算时间，也就间接的影响到散列表的性能。其次，散列函数生成的值要尽可能随机并且均匀分布，这样才能避免或者最小化散列冲突，而且即便出现冲突，散列到每个槽里的数据也会比较平均，不会出现某个槽内数据特别多的情况。

实际工作中，我们还需要综合考虑各种因素。这些因素有关键字的长度、特点、分布、还有散列表的大小等。散列函数各式各样，我举几个常用的、简单的散列函数的设计方法，让你有个直观的感受。

第一个例子就是我们上一节的学生运动会的例子，我们通过分析参赛编号的特征，把编号中的后两位作为散列值。我们还可以用类似的散列函数处理手机号码，因为手机号码前几位重复的可能性很大，但是后面几位就比较随机，我们可以取手机号的后四位作为散列值。这种散列函数的设计方法，我们一般叫作“数据分析法”。

第二个例子就是上一节的开篇思考题，如何实现 Word 拼写检查功能。这里面的散列函数，我们就可以这样设计：将单词中每个字母的ASCll 码值“进位”相加，然后再跟散列表的大小求余、取模，作为散列值。比如，英文单词 nice，我们转化出来的散列值就是下面这样：

hash("nice")=(("n" - "a") * 26*26*26 + ("i" - "a")*26*26 + ("c" - "a")*26+ ("e"-"a")) / 78978
实际上，散列函数的设计方法还有很多，比如直接寻址法、平方取中法、折叠法、随机数法等，这些你只要了解就行了，不需要全都掌握。

装载因子过大了怎么办？
我们上一节讲到散列表的装载因子的时候说过，装载因子越大，说明散列表中的元素越多，空闲位置越少，散列冲突的概率就越大。不仅插入数据的过程要多次寻址或者拉很长的链，查找的过程也会因此变得很慢。

对于没有频繁插入和删除的静态数据集合来说，我们很容易根据数据的特点、分布等，设计出完美的、极少冲突的散列函数，因为毕竟之前数据都是已知的。

对于动态散列表来说，数据集合是频繁变动的，我们事先无法预估将要加入的数据个数，所以我们也无法事先申请一个足够大的散列表。随着数据慢慢加入，装载因子就会慢慢变大。当装载因子大到一定程度之后，散列冲突就会变得不可接受。这个时候，我们该如何处理呢？

还记得我们前面多次讲的“动态扩容”吗？你可以回想一下，我们是如何做数组、栈、队列的动态扩容的。

针对散列表，当装载因子过大时，我们也可以进行动态扩容，重新申请一个更大的散列表，将数据搬移到这个新散列表中。假设每次扩容我们都申请一个原来散列表大小两倍的空间。如果原来散列表的装载因子是 0.8，那经过扩容之后，新散列表的装载因子就下降为原来的一半，变成了 0.4。

针对数组的扩容，数据搬移操作比较简单。但是，针对散列表的扩容，数据搬移操作要复杂很多。因为散列表的大小变了，数据的存储位置也变了，所以我们需要通过散列函数重新计算每个数据的存储位置。

你可以看我图里这个例子。在原来的散列表中，21 这个元素原来存储在下标为 0 的位置，搬移到新的散列表中，存储在下标为 7 的位置。



对于支持动态扩容的散列表，插入操作的时间复杂度是多少呢？前面章节我已经多次分析过支持动态扩容的数组、栈等数据结构的时间复杂度了。所以，这里我就不啰嗦了，你要是还不清楚的话，可以回去复习一下。

插入一个数据，最好情况下，不需要扩容，最好时间复杂度是 O(1)。最坏情况下，散列表装载因子过高，启动扩容，我们需要重新申请内存空间，重新计算哈希位置，并且搬移数据，所以时间复杂度是 O(n)。用摊还分析法，均摊情况下，时间复杂度接近最好情况，就是 O(1)。

实际上，对于动态散列表，随着数据的删除，散列表中的数据会越来越少，空闲空间会越来越多。如果我们对空间消耗非常敏感，我们可以在装载因子小于某个值之后，启动动态缩容。当然，如果我们更加在意执行效率，能够容忍多消耗一点内存空间，那就可以不用费劲来缩容了。

我们前面讲到，当散列表的装载因子超过某个阈值时，就需要进行扩容。装载因子阈值需要选择得当。如果太大，会导致冲突过多；如果太小，会导致内存浪费严重。

装载因子阈值的设置要权衡时间、空间复杂度。如果内存空间不紧张，对执行效率要求很高，可以降低负载因子的阈值；相反，如果内存空间紧张，对执行效率要求又不高，可以增加负载因子的值，甚至可以大于 1。

如何避免低效地扩容？
我们刚刚分析得到，大部分情况下，动态扩容的散列表插入一个数据都很快，但是在特殊情况下，当装载因子已经到达阈值，需要先进行扩容，再插入数据。这个时候，插入数据就会变得很慢，甚至会无法接受。

我举一个极端的例子，如果散列表当前大小为 1GB，要想扩容为原来的两倍大小，那就需要对 1GB 的数据重新计算哈希值，并且从原来的散列表搬移到新的散列表，听起来就很耗时，是不是？

如果我们的业务代码直接服务于用户，尽管大部分情况下，插入一个数据的操作都很快，但是，极个别非常慢的插入操作，也会让用户崩溃。这个时候，“一次性”扩容的机制就不合适了。

为了解决一次性扩容耗时过多的情况，我们可以将扩容操作穿插在插入操作的过程中，分批完成。当装载因子触达阈值之后，我们只申请新空间，但并不将老的数据搬移到新散列表中。

当有新数据要插入时，我们将新数据插入新散列表中，并且从老的散列表中拿出一个数据放入到新散列表。每次插入一个数据到散列表，我们都重复上面的过程。经过多次插入操作之后，老的散列表中的数据就一点一点全部搬移到新散列表中了。这样没有了集中的一次性数据搬移，插入操作就都变得很快了。



这期间的查询操作怎么来做呢？对于查询操作，为了兼容了新、老散列表中的数据，我们先从新散列表中查找，如果没有找到，再去老的散列表中查找。

通过这样均摊的方法，将一次性扩容的代价，均摊到多次插入操作中，就避免了一次性扩容耗时过多的情况。这种实现方式，任何情况下，插入一个数据的时间复杂度都是 O(1)。

如何选择冲突解决方法？
上一节我们讲了两种主要的散列冲突的解决办法，开放寻址法和链表法。这两种冲突解决办法在实际的软件开发中都非常常用。比如，Java 中 LinkedHashMap 就采用了链表法解决冲突，ThreadLocalMap 是通过线性探测的开放寻址法来解决冲突。那你知道，这两种冲突解决方法各有什么优势和劣势，又各自适用哪些场景吗？

1. 开放寻址法
我们先来看看，开放寻址法的优点有哪些。

开放寻址法不像链表法，需要拉很多链表。散列表中的数据都存储在数组中，可以有效地利用 CPU 缓存加快查询速度。而且，这种方法实现的散列表，序列化起来比较简单。链表法包含指针，序列化起来就没那么容易。你可不要小看序列化，很多场合都会用到的。我们后面就有一节会讲什么是数据结构序列化、如何序列化，以及为什么要序列化。

我们再来看下，开放寻址法有哪些缺点。

上一节我们讲到，用开放寻址法解决冲突的散列表，删除数据的时候比较麻烦，需要特殊标记已经删除掉的数据。而且，在开放寻址法中，所有的数据都存储在一个数组中，比起链表法来说，冲突的代价更高。所以，使用开放寻址法解决冲突的散列表，装载因子的上限不能太大。这也导致这种方法比链表法更浪费内存空间。

所以，我总结一下，当数据量比较小、装载因子小的时候，适合采用开放寻址法。这也是 Java 中的ThreadLocalMap使用开放寻址法解决散列冲突的原因。

2. 链表法
首先，链表法对内存的利用率比开放寻址法要高。因为链表结点可以在需要的时候再创建，并不需要像开放寻址法那样事先申请好。实际上，这一点也是我们前面讲过的链表优于数组的地方。

链表法比起开放寻址法，对大装载因子的容忍度更高。开放寻址法只能适用装载因子小于 1 的情况。接近 1 时，就可能会有大量的散列冲突，导致大量的探测、再散列等，性能会下降很多。但是对于链表法来说，只要散列函数的值随机均匀，即便装载因子变成 10，也就是链表的长度变长了而已，虽然查找效率有所下降，但是比起顺序查找还是快很多。

还记得我们之前在链表那一节讲的吗？链表因为要存储指针，所以对于比较小的对象的存储，是比较消耗内存的，还有可能会让内存的消耗翻倍。而且，因为链表中的结点是零散分布在内存中的，不是连续的，所以对 CPU 缓存是不友好的，这方面对于执行效率也有一定的影响。

当然，如果我们存储的是大对象，也就是说要存储的对象的大小远远大于一个指针的大小（4 个字节或者 8 个字节），那链表中指针的内存消耗在大对象面前就可以忽略了。

实际上，我们对链表法稍加改造，可以实现一个更加高效的散列表。那就是，我们将链表法中的链表改造为其他高效的动态数据结构，比如跳表、红黑树。这样，即便出现散列冲突，极端情况下，所有的数据都散列到同一个桶内，那最终退化成的散列表的查找时间也只不过是 O(logn)。这样也就有效避免了前面讲到的散列碰撞攻击。



所以，我总结一下，基于链表的散列冲突处理方法比较适合存储大对象、大数据量的散列表，而且，比起开放寻址法，它更加灵活，支持更多的优化策略，比如用红黑树代替链表。

工业级散列表举例分析
刚刚我讲了实现一个工业级散列表需要涉及的一些关键技术，现在，我就拿一个具体的例子，Java 中的 HashMap 这样一个工业级的散列表，来具体看下，这些技术是怎么应用的。

1. 初始大小
HashMap 默认的初始大小是 16，当然这个默认值是可以设置的，如果事先知道大概的数据量有多大，可以通过修改默认初始大小，减少动态扩容的次数，这样会大大提高 HashMap 的性能。

2. 装载因子和动态扩容
最大装载因子默认是 0.75，当 HashMap 中元素个数超过 0.75*capacity（capacity 表示散列表的容量）的时候，就会启动扩容，每次扩容都会扩容为原来的两倍大小。

3. 散列冲突解决方法
HashMap 底层采用链表法来解决冲突。即使负载因子和散列函数设计得再合理，也免不了会出现拉链过长的情况，一旦出现拉链过长，则会严重影响 HashMap 的性能。

于是，在 JDK1.8 版本中，为了对 HashMap 做进一步优化，我们引入了红黑树。而当链表长度太长（默认超过 8）时，链表就转换为红黑树。我们可以利用红黑树快速增删改查的特点，提高 HashMap 的性能。当红黑树结点个数少于 8 个的时候，又会将红黑树转化为链表。因为在数据量较小的情况下，红黑树要维护平衡，比起链表来，性能上的优势并不明显。

4. 散列函数
散列函数的设计并不复杂，追求的是简单高效、分布均匀。我把它摘抄出来，你可以看看。

int hash(Object key) {
    int h = key.hashCode()；
    return (h ^ (h >>> 16)) & (capitity -1); //capicity 表示散列表的大小
}
其中，hashCode() 返回的是 Java 对象的 hash code。比如 String 类型的对象的 hashCode() 就是下面这样：

public int hashCode() {
  int var1 = this.hash;
  if(var1 == 0 && this.value.length > 0) {
    char[] var2 = this.value;
    for(int var3 = 0; var3 < this.value.length; ++var3) {
      var1 = 31 * var1 + var2[var3];
    }
    this.hash = var1;
  }
  return var1;
}
解答开篇
今天的内容就讲完了，我现在来分析一下开篇的问题：如何设计的一个工业级的散列函数？如果这是一道面试题或者是摆在你面前的实际开发问题，你会从哪几个方面思考呢？

首先，我会思考，何为一个工业级的散列表？工业级的散列表应该具有哪些特性？

结合已经学习过的散列知识，我觉得应该有这样几点要求：

支持快速的查询、插入、删除操作；

内存占用合理，不能浪费过多的内存空间；

性能稳定，极端情况下，散列表的性能也不会退化到无法接受的情况。

如何实现这样一个散列表呢？根据前面讲到的知识，我会从这三个方面来考虑设计思路：

设计一个合适的散列函数；

定义装载因子阈值，并且设计动态扩容策略；

选择合适的散列冲突解决方法。

关于散列函数、装载因子、动态扩容策略，还有散列冲突的解决办法，我们前面都讲过了，具体如何选择，还要结合具体的业务场景、具体的业务数据来具体分析。不过只要我们朝这三个方向努力，就离设计出工业级的散列表不远了。

内容小结
上一节的内容比较偏理论，今天的内容侧重实战。我主要讲了如何设计一个工业级的散列表，以及如何应对各种异常情况，防止在极端情况下，散列表的性能退化过于严重。我分了三部分来讲解这些内容，分别是：如何设计散列函数，如何根据装载因子动态扩容，以及如何选择散列冲突解决方法。

关于散列函数的设计，我们要尽可能让散列后的值随机且均匀分布，这样会尽可能地减少散列冲突，即便冲突之后，分配到每个槽内的数据也比较均匀。除此之外，散列函数的设计也不能太复杂，太复杂就会太耗时间，也会影响散列表的性能。

关于散列冲突解决方法的选择，我对比了开放寻址法和链表法两种方法的优劣和适应的场景。大部分情况下，链表法更加普适。而且，我们还可以通过将链表法中的链表改造成其他动态查找数据结构，比如红黑树，来避免散列表时间复杂度退化成 O(n)，抵御散列碰撞攻击。但是，对于小规模数据、装载因子不高的散列表，比较适合用开放寻址法。

对于动态散列表来说，不管我们如何设计散列函数，选择什么样的散列冲突解决方法。随着数据的不断增加，散列表总会出现装载因子过高的情况。这个时候，我们就需要启动动态扩容。

课后思考
在你熟悉的编程语言中，哪些数据类型底层是基于散列表实现的？散列函数是如何设计的？散列冲突是通过哪种方法解决的？是否支持动态扩容呢？

欢迎留言和我分享，我会第一时间给你反馈。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(103)

Jerry银银
int hash(Object key) {
    int h = key.hashCode()；
    return (h ^ (h >>> 16)) & (capitity -1); //capicity 表示散列表的大小
}

先补充下老师使用的这段代码的一些问题：在JDK HashMap源码中，是分两步走的：
1. hash值的计算，源码如下：
static final int hash(Object key) {
        int hash;
        return key == null ? 0 : (hash = key.hashCode()) ^ hash >>> 16;
 }

2. 在插入或查找的时候，计算Key被映射到桶的位置：
int index = hash(key) & (capacity - 1)

----------------------------
JDK HashMap中hash函数的设计，确实很巧妙：

首先hashcode本身是个32位整型值，在系统中，这个值对于不同的对象必须保证唯一（JAVA规范），这也是大家常说的，重写equals必须重写hashcode的重要原因。

获取对象的hashcode以后，先进行移位运算，然后再和自己做异或运算，即：hashcode ^ (hashcode >>> 16)，这一步甚是巧妙，是将高16位移到低16位，这样计算出来的整型值将“具有”高位和低位的性质

最后，用hash表当前的容量减去一，再和刚刚计算出来的整型值做位与运算。进行位与运算，很好理解，是为了计算出数组中的位置。但这里有个问题：
为什么要用容量减去一？
因为 A % B = A & (B - 1)，所以，(h ^ (h >>> 16)) & (capitity -1) = (h ^ (h >>> 16)) % capitity，可以看出这里本质上是使用了「除留余数法」

综上，可以看出，hashcode的随机性，加上移位异或算法，得到一个非常随机的hash值，再通过「除留余数法」，得到index，整体的设计过程与老师所说的“散列函数”设计原则非常吻合！

---------
有分析不准确的地方，请指正！
作者回复: 👍

2018-11-04

3

235

SCu
可能会有同学对那个mod （capacity-1）有疑问 这个很正常，因为缺少前置描述条件 即当且仅当 capacity是2的整数倍的时候该公式才成立 当capacity为2的整数倍时（无符号）仅有一位是1其余位为0 减1后 后续为为1当前位为0 做与运算等于取后面的所有位的值 比如capacity=8 即00001000 减1为00000111 如has code=5 即00000101 此时5%8=00000101&00000111=00000101=5 其他大家举一反三即可
2018-11-16


54

Flash
经过一番资料查阅理解之后，说说我的理解：
JDK hashMap源码，hash表中数组位置的计算分两步：
1.计算hash值：
 hash(Object key) {
        int h;
        return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
}
这一步有一种说法，叫它扰动函数，为什么要右移16位再与本身异或呢？
1.1 首先hashCode()返回值int最高是32位，如果直接拿hashCode()返回值作为下标，大概40亿的映射空间，只要哈希函数映射得比较均匀松散，一般是很难出现碰撞的。
问题是一个40亿长度的数组，内存是放不下的。
1.2 所以，用自己的高半区和低半区做异或，混合原始哈希码的高位和低位，关键是以此来加大低位的随机性。为后续计算index截取低位，保证低位的随机性。
1.3 这样设计保证了对象的hashCode的32位值只要有一位发生改变，整个hash()返回值就会改变，高位的变化会反应到低位里，保证了hash值的随机性。

2.在插入或查找的时候，计算Key被映射到桶的位置：
int index = hash(key) & (capacity - 1)
hash()扰动函数计算的值和hash表当前的容量减一，做按位与运算。
这一步，为什么要减一，又为什么要按位与运算？
因为A % B = A & (B - 1)，当B是2的指数时，等式成立。
本质上是使用了「除留余数法」，保证了index的位置分布均匀。

为什么HashMap的数组长度必须是2的整次幂？
数组长度是2的整次幂时，（数组长度-1）正好相当于一个**“低位掩码”**，“与”操作的结果就是散列值的高位全部归零，只保留低位值，用来做数组下标访问。

以初始长度16为例，16-1=15。2进制表示是00000000 00000000 00001111。“与”操作的结果就是截取了最低的四位值。也就相当于取模操作。
2019-01-07

2

52

拉欧
比如Redis中的hash,set,hset,都是散列表实现，他们的动态扩容策略是同时维护两个散列表，然后一点点搬移数据
2018-11-02

1

43

天王
能否每节讲完都有个代码的demo?
作者回复: 是个好建议 我考虑下

2018-11-02


43

姜威
总结：散列表（中）
面试题目：如何设计一个工业级的散列函数？
思路：
何为一个工业级的散列表？工业级的散列表应该具有哪些特性？结合学过的知识，我觉的应该有这样的要求：
1.支持快速的查询、插入、删除操作；
2.内存占用合理，不能浪费过多空间；
3.性能稳定，在极端情况下，散列表的性能也不会退化到无法接受的情况。
方案：
如何设计这样一个散列表呢？根据前面讲到的知识，我会从3个方面来考虑设计思路：
1.设计一个合适的散列函数；
2.定义装载因子阈值，并且设计动态扩容策略；
3.选择合适的散列冲突解决方法。
知识总结：
一、如何设计散列函数？
1.要尽可能让散列后的值随机且均匀分布，这样会尽可能减少散列冲突，即便冲突之后，分配到每个槽内的数据也比较均匀。
2.除此之外，散列函数的设计也不能太复杂，太复杂就会太耗时间，也会影响到散列表的性能。
3.常见的散列函数设计方法：直接寻址法、平方取中法、折叠法、随机数法等。
二、如何根据装载因子动态扩容？
1.如何设置装载因子阈值？
①可以通过设置装载因子的阈值来控制是扩容还是缩容，支持动态扩容的散列表，插入数据的时间复杂度使用摊还分析法。
②装载因子的阈值设置需要权衡时间复杂度和空间复杂度。如何权衡？如果内存空间不紧张，对执行效率要求很高，可以降低装载因子的阈值；相反，如果内存空间紧张，对执行效率要求又不高，可以增加装载因子的阈值。
2.如何避免低效扩容？分批扩容
①分批扩容的插入操作：当有新数据要插入时，我们将数据插入新的散列表，并且从老的散列表中拿出一个数据放入新散列表。每次插入都重复上面的过程。这样插入操作就变得很快了。
②分批扩容的查询操作：先查新散列表，再查老散列表。
③通过分批扩容的方式，任何情况下，插入一个数据的时间复杂度都是O(1)。
三、如何选择散列冲突解决方法？
①常见的2中方法：开放寻址法和链表法。
②大部分情况下，链表法更加普适。而且，我们还可以通过将链表法中的链表改造成其他动态查找数据结构，比如红黑树、跳表，来避免散列表时间复杂度退化成O(n)，抵御散列冲突攻击。
③但是，对于小规模数据、装载因子不高的散列表，比较适合用开放寻址法。
2018-11-03


17

w1sl1y
看了下，的确是TREEFY_THRESHOLD等于8
UNTREEFY_THRESHOLD等于6
2018-11-05


12


老师能不能就具体的题，讲讲数据结构呀。这种高大上的，对我来说有点难😔
作者回复: 我后面还打算把所有的课后题集中写一写答案 那个时候会具体分析题目对应的就解决思路

2018-11-02


12

kakasi
对于回答点赞第一的 @Jerry银银 有疑问：首先hashcode本身是个32位整型值，在系统中，这个值对于不同的对象必须保证唯一（JAVA规范），这也是大家常说的，重写equals必须重写hashcode的重要原因。
hashcode不一定是唯一的，重写equals必须重写hashcode的原因是：java中有很多集合类是基于散列工作的，如果不重写hashcode， 两只值相等的对象就无法相等，因为object的hashcode是32位内存地址。
2018-11-16


8

Infinite_gao
老师可以分享一下，你对hashmap的默认负载因子是0.75的理解吗？是与泊松分布有关吗？
作者回复: 大牛 能否详细说说

2018-11-02


8

w1sl1y
我怎么hashmap记得红黑树树化的阈值是8，退化的阈值是6，回头看看源码确认下
作者回复: 确认好留言给我啊

2018-11-03


7

喜欢你的笑
能分析一下HashMap的散列函数吗？
作者回复: 不建议搞得这么详细 ：）你就看一眼 有个印象就好了

2018-11-02


7

猫头鹰爱拿铁
集合类的带hash的，例如hashmap、hashset、hashtable等。hashmap中散列函数是key的hashcode与key的hashcode右移16位异或，这是为了把key的高位考虑进去，如果key是0，hash值为0。在put的时候，如果表没有初始化，需要初始化下，在计算key的位置的时候很巧妙，使用表的length-1和key的hash值与计算的，实际上就是对key的hash值对表长取模，基于hashmap是2的幂次方特性，这种位运算速度更快。如果put后hashmap的数据容量超过了表的容量*负载因子，就会自动扩容，默认是两倍，自动扩容方法是将key的hash与表长直接与判断是否有高位，有高位就把这个node放到新表里旧表对应位置加旧表长的地方。没有高位就直接是新表旧位置。这是hashmap1.8的处理方法。hashmap1.7还是对key的hash取模。如果是个非常大的数，赋值为integer.max。hashmap采用的是链地址法结合红黑树解决hash冲突，当桶中链表长度大于8就会将桶中数据结构转化为红黑树。hashtable默认的初使容量11，负载因子也是0.75，如果要指定初始化hashtable容量最好是给一个素数。这是因为放入table的时候需要对表长取模，尽量分散地映射。hashtable通过链地址法解决hash冲突，当数据容量大于数据容量*负载因子自动扩容，扩容原表长两倍+1。
2018-11-02


6

辰陌
python的字典就是封装好的散列吧
作者回复: 嗯嗯

2018-11-05


5

Zhangwh
链表和哈希表结合成lru 缓存，老师能讲讲不，记得老师在链表那块说过
作者回复: 下一节课就要讲了

2018-11-02


5

强哥
X % 2^n = X & (2^n - 1)
2^n表示2的n次方，也就是说，一个数对2^n取模 == 一个数和(2^n - 1)做按位与运算 。
所以说评论第一个说A%B=A&(B-1)，并不成立。
2019-03-07


4

Allen Zou
老师，开放寻址法如果冲突了，占用其它hash code对应的位置，那该位置真正的数据来的时候怎么办，接着往后放么？删除的时候是否要搬回来？
作者回复: 不存在真正的数据的说法 都是先来先占坑

2018-11-03


4

Ruhm
NOTE 这节课给我的启发太大了，以前去阅读go的源码，总是感觉异常吃力，看完这节课之后去读了go关于map这个内置类型的源码，发现思路一下就清晰起来了，阅读效率高了很多，做到了有的放矢。那么以后阅读代码之前，先了解相关知识的方法论是很有必要的，这样比拿到源码就开始读，实际从长远看是节省了时间的。
2018-12-29


3

Yishem
关于HashMap的loadFactor为什么是0.75？已经有网友整理好了(https://www.jianshu.com/p/64f6de3ffcc1)，可以看看，很详细
2018-12-14


3

左胜利
JAVA中使用散列表的数据类型：
HashTable:
1、默认初始大小：11
2、装载因子：0.75
3、散列函数：int hash = key.hashCode();
                      int index = (hash & 0x7FFFFFFF) % tab.length;
4、当装载因子大于0.75时，启动扩容机制
4、冲突解决方法：使用单链表解决hash冲突
HashMap:
1、默认初始大小：16
2、装载因子：0.75
3、散列函数：
        hash(Object key) {
            int h;
            return (key == null) ? 0 : (h = key.hashCode()) ^ (h >>> 16);
        }
4、当装载因子大于0.75时，启动扩容机制
5、使用单链表解决hash冲突，当链表长度大于8，将单链表转换成红黑树
ThreadLocalMap
1、初始容量：16
2、装载因子：2/3
3、散列函数：
    hash(Object key) {
        int HASH_INCREMENT = 0x61c88647;
        AtomicInteger nextHashCode = new AtomicInteger();
        nextHashCode.getAndAdd(HASH_INCREMENT)
        int threadLocalHashCode = nextHashCode()
        int i = threadLocalHashCode & (table.length - 1);
    }
4、当装载因子大于2/3时，启动扩容机制
5、使用线性探测的开放地址法解决hash冲突
2018-12-21


2
收起评论

99+99+






# 20 | 散列表（下）：为什么散列表和链表经常会一起使用？



数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



20 | 散列表（下）：为什么散列表和链表经常会一起使用？
王争 2018-11-05



11:39
讲述：修阳 大小：5.34M
我们已经学习了 20 节内容，你有没有发现，有两种数据结构，散列表和链表，经常会被放在一起使用。你还记得，前面的章节中都有哪些地方讲到散列表和链表的组合使用吗？我带你一起回忆一下。

在链表那一节，我讲到如何用链表来实现 LRU 缓存淘汰算法，但是链表实现的 LRU 缓存淘汰算法的时间复杂度是 O(n)，当时我也提到了，通过散列表可以将这个时间复杂度降低到 O(1)。

在跳表那一节，我提到 Redis 的有序集合是使用跳表来实现的，跳表可以看作一种改进版的链表。当时我们也提到，Redis 有序集合不仅使用了跳表，还用到了散列表。

除此之外，如果你熟悉 Java 编程语言，你会发现 LinkedHashMap 这样一个常用的容器，也用到了散列表和链表两种数据结构。

今天，我们就来看看，在这几个问题中，散列表和链表都是如何组合起来使用的，以及为什么散列表和链表会经常放到一块使用。

LRU 缓存淘汰算法
在链表那一节中，我提到，借助散列表，我们可以把 LRU 缓存淘汰算法的时间复杂度降低为 O(1)。现在，我们就来看看它是如何做到的。

首先，我们来回顾一下当时我们是如何通过链表实现 LRU 缓存淘汰算法的。

我们需要维护一个按照访问时间从大到小有序排列的链表结构。因为缓存大小有限，当缓存空间不够，需要淘汰一个数据的时候，我们就直接将链表头部的结点删除。

当要缓存某个数据的时候，先在链表中查找这个数据。如果没有找到，则直接将数据放到链表的尾部；如果找到了，我们就把它移动到链表的尾部。因为查找数据需要遍历链表，所以单纯用链表实现的 LRU 缓存淘汰算法的时间复杂很高，是 O(n)。

实际上，我总结一下，一个缓存（cache）系统主要包含下面这几个操作：

往缓存中添加一个数据；

从缓存中删除一个数据；

在缓存中查找一个数据。

这三个操作都要涉及“查找”操作，如果单纯地采用链表的话，时间复杂度只能是 O(n)。如果我们将散列表和链表两种数据结构组合使用，可以将这三个操作的时间复杂度都降低到 O(1)。具体的结构就是下面这个样子：



我们使用双向链表存储数据，链表中的每个结点处理存储数据（data）、前驱指针（prev）、后继指针（next）之外，还新增了一个特殊的字段 hnext。这个 hnext 有什么作用呢？

因为我们的散列表是通过链表法解决散列冲突的，所以每个结点会在两条链中。一个链是刚刚我们提到的双向链表，另一个链是散列表中的拉链。前驱和后继指针是为了将结点串在双向链表中，hnext 指针是为了将结点串在散列表的拉链中。

了解了这个散列表和双向链表的组合存储结构之后，我们再来看，前面讲到的缓存的三个操作，是如何做到时间复杂度是 O(1) 的？

首先，我们来看如何查找一个数据。我们前面讲过，散列表中查找数据的时间复杂度接近 O(1)，所以通过散列表，我们可以很快地在缓存中找到一个数据。当找到数据之后，我们还需要将它移动到双向链表的尾部。

其次，我们来看如何删除一个数据。我们需要找到数据所在的结点，然后将结点删除。借助散列表，我们可以在 O(1) 时间复杂度里找到要删除的结点。因为我们的链表是双向链表，双向链表可以通过前驱指针 O(1) 时间复杂度获取前驱结点，所以在双向链表中，删除结点只需要 O(1) 的时间复杂度。

最后，我们来看如何添加一个数据。添加数据到缓存稍微有点麻烦，我们需要先看这个数据是否已经在缓存中。如果已经在其中，需要将其移动到双向链表的尾部；如果不在其中，还要看缓存有没有满。如果满了，则将双向链表头部的结点删除，然后再将数据放到链表的尾部；如果没有满，就直接将数据放到链表的尾部。

这整个过程涉及的查找操作都可以通过散列表来完成。其他的操作，比如删除头结点、链表尾部插入数据等，都可以在 O(1) 的时间复杂度内完成。所以，这三个操作的时间复杂度都是 O(1)。至此，我们就通过散列表和双向链表的组合使用，实现了一个高效的、支持 LRU 缓存淘汰算法的缓存系统原型。

Redis 有序集合
在跳表那一节，讲到有序集合的操作时，我稍微做了些简化。实际上，在有序集合中，每个成员对象有两个重要的属性，key（键值）和score（分值）。我们不仅会通过 score 来查找数据，还会通过 key 来查找数据。

举个例子，比如用户积分排行榜有这样一个功能：我们可以通过用户的 ID 来查找积分信息，也可以通过积分区间来查找用户 ID 或者姓名信息。这里包含 ID、姓名和积分的用户信息，就是成员对象，用户 ID 就是 key，积分就是 score。

所以，如果我们细化一下 Redis 有序集合的操作，那就是下面这样：

添加一个成员对象；

按照键值来删除一个成员对象；

按照键值来查找一个成员对象；

按照分值区间查找数据，比如查找积分在 [100, 356] 之间的成员对象；

按照分值从小到大排序成员变量；

如果我们仅仅按照分值将成员对象组织成跳表的结构，那按照键值来删除、查询成员对象就会很慢，解决方法与 LRU 缓存淘汰算法的解决方法类似。我们可以再按照键值构建一个散列表，这样按照 key 来删除、查找一个成员对象的时间复杂度就变成了 O(1)。同时，借助跳表结构，其他操作也非常高效。

实际上，Redis 有序集合的操作还有另外一类，也就是查找成员对象的排名（Rank）或者根据排名区间查找成员对象。这个功能单纯用刚刚讲的这种组合结构就无法高效实现了。这块内容我后面的章节再讲。

Java LinkedHashMap
前面我们讲了两个散列表和链表结合的例子，现在我们再来看另外一个，Java 中的 LinkedHashMap 这种容器。

如果你熟悉 Java，那你几乎天天会用到这个容器。我们之前讲过，HashMap 底层是通过散列表这种数据结构实现的。而 LinkedHashMap 前面比 HashMap 多了一个“Linked”，这里的“Linked”是不是说，LinkedHashMap 是一个通过链表法解决散列冲突的散列表呢？

实际上，LinkedHashMap 并没有这么简单，其中的“Linked”也并不仅仅代表它是通过链表法解决散列冲突的。关于这一点，在我是初学者的时候，也误解了很久。

我们先来看一段代码。你觉得这段代码会以什么样的顺序打印 3，1，5，2 这几个 key 呢？原因又是什么呢？

HashMap<Integer, Integer> m = new LinkedHashMap<>();
m.put(3, 11);
m.put(1, 12);
m.put(5, 23);
m.put(2, 22);
 
for (Map.Entry e : m.entrySet()) {
  System.out.println(e.getKey());
}
我先告诉你答案，上面的代码会按照数据插入的顺序依次来打印，也就是说，打印的顺序就是 3，1，5，2。你有没有觉得奇怪？散列表中数据是经过散列函数打乱之后无规律存储的，这里是如何实现按照数据的插入顺序来遍历打印的呢？

你可能已经猜到了，LinkedHashMap 也是通过散列表和链表组合在一起实现的。实际上，它不仅支持按照插入顺序遍历数据，还支持按照访问顺序来遍历数据。你可以看下面这段代码：

// 10 是初始大小，0.75 是装载因子，true 是表示按照访问时间排序
HashMap<Integer, Integer> m = new LinkedHashMap<>(10, 0.75f, true);
m.put(3, 11);
m.put(1, 12);
m.put(5, 23);
m.put(2, 22);
 
m.put(3, 26);
m.get(5);
 
for (Map.Entry e : m.entrySet()) {
  System.out.println(e.getKey());
}
这段代码打印的结果是 1，2，3，5。我来具体分析一下，为什么这段代码会按照这样顺序来打印。

每次调用 put() 函数，往 LinkedHashMap 中添加数据的时候，都会将数据添加到链表的尾部，所以，在前四个操作完成之后，链表中的数据是下面这样：



在第 8 行代码中，再次将键值为 3 的数据放入到 LinkedHashMap 的时候，会先查找这个键值是否已经有了，然后，再将已经存在的 (3,11) 删除，并且将新的 (3,26) 放到链表的尾部。所以，这个时候链表中的数据就是下面这样：



当第 9 行代码访问到 key 为 5 的数据的时候，我们将被访问到的数据移动到链表的尾部。所以，第 9 行代码之后，链表中的数据是下面这样：



所以，最后打印出来的数据是 1，2，3，5。从上面的分析，你有没有发现，按照访问时间排序的 LinkedHashMap 本身就是一个支持 LRU 缓存淘汰策略的缓存系统？实际上，它们两个的实现原理也是一模一样的。我也就不再啰嗦了。

我现在来总结一下，实际上，LinkedHashMap 是通过双向链表和散列表这两种数据结构组合实现的。LinkedHashMap 中的“Linked”实际上是指的是双向链表，并非指用链表法解决散列冲突。

解答开篇 & 内容小结
弄懂刚刚我讲的这三个例子，开篇的问题也就不言而喻了。我这里总结一下，为什么散列表和链表经常一块使用？

散列表这种数据结构虽然支持非常高效的数据插入、删除、查找操作，但是散列表中的数据都是通过散列函数打乱之后无规律存储的。也就说，它无法支持按照某种顺序快速地遍历数据。如果希望按照顺序遍历散列表中的数据，那我们需要将散列表中的数据拷贝到数组中，然后排序，再遍历。

因为散列表是动态数据结构，不停地有数据的插入、删除，所以每当我们希望按顺序遍历散列表中的数据的时候，都需要先排序，那效率势必会很低。为了解决这个问题，我们将散列表和链表（或者跳表）结合在一起使用。

课后思考
今天讲的几个散列表和链表结合使用的例子里，我们用的都是双向链表。如果把双向链表改成单链表，还能否正常工作呢？为什么呢？

假设猎聘网有 10 万名猎头，每个猎头都可以通过做任务（比如发布职位）来积累积分，然后通过积分来下载简历。假设你是猎聘网的一名工程师，如何在内存中存储这 10 万个猎头 ID 和积分信息，让它能够支持这样几个操作：

根据猎头的 ID 快速查找、删除、更新这个猎头的积分信息；

查找积分在某个区间的猎头 ID 列表；

查找按照积分从小到大排名在第 x 位到第 y 位之间的猎头 ID 列表。

欢迎留言和我分享，我会第一时间给你反馈。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(130)

Smallfly
通过这 20 节课学习下来，个人感觉其实就两种数据结构，链表和数组。

数组占据随机访问的优势，却有需要连续内存的缺点。

链表具有可不连续存储的优势，但访问查找是线性的。

散列表和链表、跳表的混合使用，是为了结合数组和链表的优势，规避它们的不足。

我们可以得出数据结构和算法的重要性排行榜：连续空间 > 时间 > 碎片空间。

PS：跟专业的书籍相比，老师讲的真的是通俗易懂不废话，篇篇是干货。如果这个课程学不下去，学其它的会更加困难。暂时不懂的话反复阅读复习，外加查阅，一定可以的！
作者回复: 👍 大牛

2018-11-05

1

340

Smallfly
1.

在删除一个元素时，虽然能 O(1) 的找到目标结点，但是要删除该结点需要拿到前一个结点的指针，遍历到前一个结点复杂度会变为 O(N），所以用双链表实现比较合适。

（但其实硬要操作的话，单链表也是可以实现 O(1) 时间复杂度删除结点的）。

iOS 的同学可能知道，YYMemoryCache 就是结合散列表和双向链表来实现的。

2.

以积分排序构建一个跳表，再以猎头 ID 构建一个散列表。

1）ID 在散列表中所以可以 O(1) 查找到这个猎头；
2）积分以跳表存储，跳表支持区间查询；
3）这点根据目前学习的知识暂时无法实现，老师文中也提到了。
作者回复: 👍 其他同学可以看看这条留言

2018-11-05

4

144

姜威
带着问题去学习：
1.为什么散列表和链表经常放在一起使用？
2.散列表和链表如何组合起来使用？
一、为什么散列表和链表经常放在一起使用？
1.散列表的优点：支持高效的数据插入、删除和查找操作
2.散列表的缺点：不支持快速顺序遍历散列表中的数据
3.如何按照顺序快速遍历散列表的数据？只能将数据转移到数组，然后排序，最后再遍历数据。
4.我们知道散列表是动态的数据结构，需要频繁的插入和删除数据，那么每次顺序遍历之前都需要先排序，这势必会造成效率非常低下。
5.如何解决上面的问题呢？就是将散列表和链表（或跳表）结合起来使用。
二、散列表和链表如何组合起来使用？
1.LRU（Least Recently Used）缓存淘汰算法
1.1.LRU缓存淘汰算法主要操作有哪些？主要包含3个操作：
①往缓存中添加一个数据；
②从缓存中删除一个数据；
③在缓存中查找一个数据；
④总结：上面3个都涉及到查找。
1.2.如何用链表实现LRU缓存淘汰算法？
①需要维护一个按照访问时间从大到小的有序排列的链表结构。
②缓冲空间有限，当空间不足需要淘汰一个数据时直接删除链表头部的节点。
③当要缓存某个数据时，先在链表中查找这个数据。若未找到，则直接将数据放到链表的尾部。若找到，就把它移动到链表尾部。
④前面说了，LRU缓存的3个主要操作都涉及到查找，若单纯由链表实现，查找的时间复杂度很高为O(n)。若将链表和散列表结合使用，查找的时间复杂度会降低到O(1)。
1.3.如何使用散列表和链表实现LRU缓存淘汰算法？
①使用双向链表存储数据，链表中每个节点存储数据（data）、前驱指针（prev）、后继指针（next）和hnext指针（解决散列冲突的链表指针）。
②散列表通过链表法解决散列冲突，所以每个节点都会在两条链中。一条链是双向链表，另一条链是散列表中的拉链。前驱和后继指针是为了将节点串在双向链表中，hnext指针是为了将节点串在散列表的拉链中。
③LRU缓存淘汰算法的3个主要操作如何做到时间复杂度为O(1)呢？
首先，我们明确一点就是链表本身插入和删除一个节点的时间复杂度为O(1)，因为只需更改几个指针指向即可。
接着，来分析查找操作的时间复杂度。当要查找一个数据时，通过散列表可实现在O(1)时间复杂度找到该数据，再加上前面说的插入或删除的时间复杂度是O(1)，所以我们总操作的时间复杂度就是O(1)。
2.Redis有序集合
2.1.什么是有序集合？
①在有序集合中，每个成员对象有2个重要的属性，即key（键值）和score（分值）。
②不仅会通过score来查找数据，还会通过key来查找数据。
2.2.有序集合的操作有哪些？
举个例子，比如用户积分排行榜有这样一个功能：可以通过用户ID来查找积分信息，也可以通过积分区间来查找用户ID。这里用户ID就是key，积分就是score。所以，有序集合的操作如下：
①添加一个对象；
②根据键值删除一个对象；
③根据键值查找一个成员对象；
④根据分值区间查找数据，比如查找积分在[100.356]之间的成员对象；
⑤按照分值从小到大排序成员变量。
这时可以按照分值将成员对象组织成跳表结构，按照键值构建一个散列表。那么上面的所有操作都非常高效。
3.Java LinkedHashMap
和LRU缓存淘汰策略实现一模一样。支持按照插入顺序遍历数据，也支持按照访问顺序遍历数据。
三、课后思考
1.上面所讲的几个散列表和链表组合的例子里，我们都是使用双向链表。如果把双向链表改成单链表，还能否正常工作？为什么呢？
2.假设猎聘网有10万名猎头，每个猎头可以通过做任务（比如发布职位）来积累积分，然后通过积分来下载简历。假设你是猎聘网的一名工程师，如何在内存中存储这10万个猎头的ID和积分信息，让它能够支持这样几个操作：
1）根据猎头ID查收查找、删除、更新这个猎头的积分信息；
2）查找积分在某个区间的猎头ID列表；
3）查找按照积分从小到大排名在第x位到第y位之间的猎头ID列表。
2018-11-16

1

29

Keep-Moving
LRU查找数据，查找到之后，不是应该把数据放到链表的头部吗？为什么这里说是尾部？
作者回复: 两种方式都可以的

2018-11-05


20

莫问流年
怎么判断缓存已满，是要维护一个计数变量吗
作者回复: 是的

2018-11-05


14

Zeng Shine
“一个节点会存在两条拉链中，一条是双向链表，另一条是散列表中的拉链”，这句话描述的结构，怎么都想不明白。。
作者回复: 图能不能看懂呢 你结合图看下

2018-11-06

2

11

微秒
通过散列表遍历后不用在遍历双向链表了，那怎么以o(1)的时间查找定位链表中的节点？？？除非，散列表的尺寸很大，使得散列表的节点中只有少量数据的链表？？？？
作者回复: 是的 理论上散列表查找数据的时间复杂度是O（1）

2018-11-06


9

hot
一个链是刚刚我们提到的双向链表，另一个链是散列表中的拉链
就是结合你的图也看不懂啊 ，老铁
2018-11-13

2

8

HunterYuan
看好些人询问LRU中设计的到pre，next和hnext的具体含义，将自己的理解说下，pre和next组成双向链表，这个链表是按照缓存的时间由大到小，组成的一个缓存队列；对于hnext作用是，在最新时间插入缓存数据时，通过哈希函数得出的冲突，用其连接。
总结：在双向链表中，时间是从大到小；在hnext组成的拉链中，时间从左到右依次变小。
核心：数据结构的设计，一定是建立应用场景之上，根据最新时间加入缓存。
这是自己的见解，若是有错误，希望争哥不吝赐教，thanks
作者回复: 对的 👍

2019-04-15

1

7

虢白
看到很多人都在问，为什么老师说的，一条链是双向链表的链，一条链是拉链没看明白。
其实就是散列表为了解决散列冲突，所以得到同一个hash值的时候，将同一个hash值的用一个链表来存放了，而在图上面就是双链表中的hnext所串连起来的链表。个人是这么理解的。
2019-01-31


5

P@tricK
老师我想问下，散列表和双向链表结构中的散列值，是用链表中的data哈希的吗？因为这样才能用O(1)查找…
那问题来了，那我要在链表尾部插入数据时，根据什么方法用O(1)定位到尾部呢？
作者回复: 需要维护一个尾指针的

2018-11-07

1

5

牧民牛仔
1.双联表改成单链表，依然可以工作。可以用一个变量存储遍历到的节点的前驱指针。
2.可以把猎聘网的猎头的信息存储在 散列表和链表（跳表）组合使用的容器中，其中按照猎头id建立散列表，按照猎头的积分建立一个跳表。这样，无论是按照id查用户，还是按照积分进行排序和区间查找都会很高效。
2018-11-05


5

MrTrans
老师，hnext是解决散列冲突的链表，而双向链表是维护插入元素顺序的表。两条链是不一样的，一个hnext是维护散列冲突的，一个双向链表是维护插入元素的顺序的。那么查找，删除，添加就要维护这两个链表。老师这样理解是不是很对。
2018-12-21


4

小智e
想请问一下，如何使用跳表来解决哈希冲突呢？没想通
作者回复: 就是把散列表中的链表换成跳表 其他不变

2018-12-07


4

Tensor
老师，您好，你讲的那个LRU算法中的，散列表加上双向链表的图没有看懂，能不能再讲详细点儿啊（不好意思，基础太差了）？还有不理解的是为什么查找哈希表中双向链表某一节点的时间复杂度是o(1)？？？首先在哈希表中遍历为1，但确定了哈希表的位置后，还要遍及节点，这个跟链表的规模有关吧？？？
2018-11-11


4

猫头鹰爱拿铁
1.可以通过单链表和散列表实现，但是删除和添加的时间复杂度就变成了O(n)，因为需要遍历一次链表将前驱节点找到，再进行删除。
2.猎头问题：每个猎头对象由node构成（pre，next，hnext，data）将id作为键值建立类似hashmap的结构来存放猎头的对象，同时再将每个节点使用双向链表按照积分大小（快排排序）链接起来。根据id查找、删除、添加时间复杂度为O(1)，查找排名的时间复杂度为O(n),如果想提高查找排名的时间复杂度，可以再和跳表结合一块，根据积分建立索引，查找排名的时间复杂度将提升为O(logn)
2018-11-05


4

我能走多远
https://github.com/jin13417/algo/tree/master/c-cpp/19_Dlisthash C语言 哈希表+双向循环链表 实现LRU功能，请指正。
2018-11-09


3

等风来
1.改成单链表,删除/插入的时候需要O(n)去找前驱节点;
2.如文中第一个列子,按ID顺序存储双向链表;在双向链表按积分hash和按ID跳表;
2018-11-05


3

chenlong321
lru算法，缓存中，如果能查找到节点a，那么需要先删除a，再将a移动到双向链表的尾端，那这不就改变了节点a的hash bucket，下次怎么还能通过hash快速查找到节点a，请老师指教，谢谢
作者回复: 双向链表，跟散列表没有任何关系。这里的双向链表不是散列表中的链表。

不管是双向链表还是散列表，你都可以把它当做一种索引结构。里面存储的都是指向真实缓存对象的内存地址。

改变双向链表的结点结构，并不会影响散列表。

2019-04-16

1

2

Lucus
老师我有一点不明白，双向链表中节点要移动到尾部还有找到链表头节点应该都需要遍历链表吧，平均时间复杂度应该是O（n）啊？
作者回复: 链表头、尾指针是已经记录好的了。移动到尾部，就是先删除，再添加的过程。

2019-04-08


2
收起评论

99+99+






# 21 | 哈希算法（上）：如何防止数据库中的用户信息被脱库？



数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



21 | 哈希算法（上）：如何防止数据库中的用户信息被脱库？
王争 2018-11-07



14:29
讲述：修阳 大小：6.64M
还记得 2011 年 CSDN 的“脱库”事件吗？当时，CSDN 网站被黑客攻击，超过 600 万用户的注册邮箱和密码明文被泄露，很多网友对 CSDN 明文保存用户密码行为产生了不满。如果你是 CSDN 的一名工程师，你会如何存储用户密码这么重要的数据吗？仅仅 MD5 加密一下存储就够了吗？ 要想搞清楚这个问题，就要先弄明白哈希算法。

哈希算法历史悠久，业界著名的哈希算法也有很多，比如 MD5、SHA 等。在我们平时的开发中，基本上都是拿现成的直接用。所以，我今天不会重点剖析哈希算法的原理，也不会教你如何设计一个哈希算法，而是从实战的角度告诉你，在实际的开发中，我们该如何用哈希算法解决问题。

什么是哈希算法？
我们前面几节讲到“散列表”“散列函数”，这里又讲到“哈希算法”，你是不是有点一头雾水？实际上，不管是“散列”还是“哈希”，这都是中文翻译的差别，英文其实就是“Hash”。所以，我们常听到有人把“散列表”叫作“哈希表”“Hash 表”，把“哈希算法”叫作“Hash 算法”或者“散列算法”。那到底什么是哈希算法呢？

哈希算法的定义和原理非常简单，基本上一句话就可以概括了。将任意长度的二进制值串映射为固定长度的二进制值串，这个映射的规则就是哈希算法，而通过原始数据映射之后得到的二进制值串就是哈希值。但是，要想设计一个优秀的哈希算法并不容易，根据我的经验，我总结了需要满足的几点要求：

从哈希值不能反向推导出原始数据（所以哈希算法也叫单向哈希算法）；

对输入数据非常敏感，哪怕原始数据只修改了一个 Bit，最后得到的哈希值也大不相同；

散列冲突的概率要很小，对于不同的原始数据，哈希值相同的概率非常小；

哈希算法的执行效率要尽量高效，针对较长的文本，也能快速地计算出哈希值。

这些定义和要求都比较理论，可能还是不好理解，我拿 MD5 这种哈希算法来具体说明一下。

我们分别对“今天我来讲哈希算法”和“jiajia”这两个文本，计算 MD5 哈希值，得到两串看起来毫无规律的字符串（MD5 的哈希值是 128 位的 Bit 长度，为了方便表示，我把它们转化成了 16 进制编码）。可以看出来，无论要哈希的文本有多长、多短，通过 MD5 哈希之后，得到的哈希值的长度都是相同的，而且得到的哈希值看起来像一堆随机数，完全没有规律。

MD5(" 今天我来讲哈希算法 ") = bb4767201ad42c74e650c1b6c03d78fa
MD5("jiajia") = cd611a31ea969b908932d44d126d195b
我们再来看两个非常相似的文本，“我今天讲哈希算法！”和“我今天讲哈希算法”。这两个文本只有一个感叹号的区别。如果用 MD5 哈希算法分别计算它们的哈希值，你会发现，尽管只有一字之差，得到的哈希值也是完全不同的。

MD5(" 我今天讲哈希算法！") = 425f0d5a917188d2c3c3dc85b5e4f2cb
MD5(" 我今天讲哈希算法 ") = a1fb91ac128e6aa37fe42c663971ac3d
我在前面也说了，通过哈希算法得到的哈希值，很难反向推导出原始数据。比如上面的例子中，我们就很难通过哈希值“a1fb91ac128e6aa37fe42c663971ac3d”反推出对应的文本“我今天讲哈希算法”。

哈希算法要处理的文本可能是各种各样的。比如，对于非常长的文本，如果哈希算法的计算时间很长，那就只能停留在理论研究的层面，很难应用到实际的软件开发中。比如，我们把今天这篇包含 4000 多个汉字的文章，用 MD5 计算哈希值，用不了 1ms 的时间。

哈希算法的应用非常非常多，我选了最常见的七个，分别是安全加密、唯一标识、数据校验、散列函数、负载均衡、数据分片、分布式存储。这节我们先来看前四个应用。

应用一：安全加密
说到哈希算法的应用，最先想到的应该就是安全加密。最常用于加密的哈希算法是MD5（MD5 Message-Digest Algorithm，MD5 消息摘要算法）和SHA（Secure Hash Algorithm，安全散列算法）。

除了这两个之外，当然还有很多其他加密算法，比如DES（Data Encryption Standard，数据加密标准）、AES（Advanced Encryption Standard，高级加密标准）。

前面我讲到的哈希算法四点要求，对用于加密的哈希算法来说，有两点格外重要。第一点是很难根据哈希值反向推导出原始数据，第二点是散列冲突的概率要很小。

第一点很好理解，加密的目的就是防止原始数据泄露，所以很难通过哈希值反向推导原始数据，这是一个最基本的要求。所以我着重讲一下第二点。实际上，不管是什么哈希算法，我们只能尽量减少碰撞冲突的概率，理论上是没办法做到完全不冲突的。为什么这么说呢？

这里就基于组合数学中一个非常基础的理论，鸽巢原理（也叫抽屉原理）。这个原理本身很简单，它是说，如果有 10 个鸽巢，有 11 只鸽子，那肯定有 1 个鸽巢中的鸽子数量多于 1 个，换句话说就是，肯定有 2 只鸽子在 1 个鸽巢内。

有了鸽巢原理的铺垫之后，我们再来看，为什么哈希算法无法做到零冲突？

我们知道，哈希算法产生的哈希值的长度是固定且有限的。比如前面举的 MD5 的例子，哈希值是固定的 128 位二进制串，能表示的数据是有限的，最多能表示 2^128 个数据，而我们要哈希的数据是无穷的。基于鸽巢原理，如果我们对 2^128+1 个数据求哈希值，就必然会存在哈希值相同的情况。这里你应该能想到，一般情况下，哈希值越长的哈希算法，散列冲突的概率越低。

2^128=340282366920938463463374607431768211456
为了让你能有个更加直观的感受，我找了两段字符串放在这里。这两段字符串经过 MD5 哈希算法加密之后，产生的哈希值是相同的。





不过，即便哈希算法存在散列冲突的情况，但是因为哈希值的范围很大，冲突的概率极低，所以相对来说还是很难破解的。像 MD5，有 2^128 个不同的哈希值，这个数据已经是一个天文数字了，所以散列冲突的概率要小于 1/2^128。

如果我们拿到一个 MD5 哈希值，希望通过毫无规律的穷举的方法，找到跟这个 MD5 值相同的另一个数据，那耗费的时间应该是个天文数字。所以，即便哈希算法存在冲突，但是在有限的时间和资源下，哈希算法还是被很难破解的。

除此之外，没有绝对安全的加密。越复杂、越难破解的加密算法，需要的计算时间也越长。比如 SHA-256 比 SHA-1 要更复杂、更安全，相应的计算时间就会比较长。密码学界也一直致力于找到一种快速并且很难被破解的哈希算法。我们在实际的开发过程中，也需要权衡破解难度和计算时间，来决定究竟使用哪种加密算法。

应用二：唯一标识
我先来举一个例子。如果要在海量的图库中，搜索一张图是否存在，我们不能单纯地用图片的元信息（比如图片名称）来比对，因为有可能存在名称相同但图片内容不同，或者名称不同图片内容相同的情况。那我们该如何搜索呢？

我们知道，任何文件在计算中都可以表示成二进制码串，所以，比较笨的办法就是，拿要查找的图片的二进制码串与图库中所有图片的二进制码串一一比对。如果相同，则说明图片在图库中存在。但是，每个图片小则几十 KB、大则几 MB，转化成二进制是一个非常长的串，比对起来非常耗时。有没有比较快的方法呢？

我们可以给每一个图片取一个唯一标识，或者说信息摘要。比如，我们可以从图片的二进制码串开头取 100 个字节，从中间取 100 个字节，从最后再取 100 个字节，然后将这 300 个字节放到一块，通过哈希算法（比如 MD5），得到一个哈希字符串，用它作为图片的唯一标识。通过这个唯一标识来判定图片是否在图库中，这样就可以减少很多工作量。

如果还想继续提高效率，我们可以把每个图片的唯一标识，和相应的图片文件在图库中的路径信息，都存储在散列表中。当要查看某个图片是不是在图库中的时候，我们先通过哈希算法对这个图片取唯一标识，然后在散列表中查找是否存在这个唯一标识。

如果不存在，那就说明这个图片不在图库中；如果存在，我们再通过散列表中存储的文件路径，获取到这个已经存在的图片，跟现在要插入的图片做全量的比对，看是否完全一样。如果一样，就说明已经存在；如果不一样，说明两张图片尽管唯一标识相同，但是并不是相同的图片。

应用三：数据校验
电驴这样的 BT 下载软件你肯定用过吧？我们知道，BT 下载的原理是基于 P2P 协议的。我们从多个机器上并行下载一个 2GB 的电影，这个电影文件可能会被分割成很多文件块（比如可以分成 100 块，每块大约 20MB）。等所有的文件块都下载完成之后，再组装成一个完整的电影文件就行了。

我们知道，网络传输是不安全的，下载的文件块有可能是被宿主机器恶意修改过的，又或者下载过程中出现了错误，所以下载的文件块可能不是完整的。如果我们没有能力检测这种恶意修改或者文件下载出错，就会导致最终合并后的电影无法观看，甚至导致电脑中毒。现在的问题是，如何来校验文件块的安全、正确、完整呢？

具体的 BT 协议很复杂，校验方法也有很多，我来说其中的一种思路。

我们通过哈希算法，对 100 个文件块分别取哈希值，并且保存在种子文件中。我们在前面讲过，哈希算法有一个特点，对数据很敏感。只要文件块的内容有一丁点儿的改变，最后计算出的哈希值就会完全不同。所以，当文件块下载完成之后，我们可以通过相同的哈希算法，对下载好的文件块逐一求哈希值，然后跟种子文件中保存的哈希值比对。如果不同，说明这个文件块不完整或者被篡改了，需要再重新从其他宿主机器上下载这个文件块。

应用四：散列函数
前面讲了很多哈希算法的应用，实际上，散列函数也是哈希算法的一种应用。

我们前两节讲到，散列函数是设计一个散列表的关键。它直接决定了散列冲突的概率和散列表的性能。不过，相对哈希算法的其他应用，散列函数对于散列算法冲突的要求要低很多。即便出现个别散列冲突，只要不是过于严重，我们都可以通过开放寻址法或者链表法解决。

不仅如此，散列函数对于散列算法计算得到的值，是否能反向解密也并不关心。散列函数中用到的散列算法，更加关注散列后的值是否能平均分布，也就是，一组数据是否能均匀地散列在各个槽中。除此之外，散列函数执行的快慢，也会影响散列表的性能，所以，散列函数用的散列算法一般都比较简单，比较追求效率。

解答开篇
好了，有了前面的基础，现在你有没有发现开篇的问题其实很好解决？

我们可以通过哈希算法，对用户密码进行加密之后再存储，不过最好选择相对安全的加密算法，比如 SHA 等（因为 MD5 已经号称被破解了）。不过仅仅这样加密之后存储就万事大吉了吗？

字典攻击你听说过吗？如果用户信息被“脱库”，黑客虽然拿到是加密之后的密文，但可以通过“猜”的方式来破解密码，这是因为，有些用户的密码太简单。比如很多人习惯用 00000、123456 这样的简单数字组合做密码，很容易就被猜中。

那我们就需要维护一个常用密码的字典表，把字典中的每个密码用哈希算法计算哈希值，然后拿哈希值跟脱库后的密文比对。如果相同，基本上就可以认为，这个加密之后的密码对应的明文就是字典中的这个密码。（注意，这里说是的是“基本上可以认为”，因为根据我们前面的学习，哈希算法存在散列冲突，也有可能出现，尽管密文一样，但是明文并不一样的情况。）

针对字典攻击，我们可以引入一个盐（salt），跟用户的密码组合在一起，增加密码的复杂度。我们拿组合之后的字符串来做哈希算法加密，将它存储到数据库中，进一步增加破解的难度。不过我这里想多说一句，我认为安全和攻击是一种博弈关系，不存在绝对的安全。所有的安全措施，只是增加攻击的成本而已。

内容小结
今天的内容比较偏实战，我讲到了哈希算法的四个应用场景。我带你来回顾一下。

第一个应用是唯一标识，哈希算法可以对大数据做信息摘要，通过一个较短的二进制编码来表示很大的数据。

第二个应用是用于校验数据的完整性和正确性。

第三个应用是安全加密，我们讲到任何哈希算法都会出现散列冲突，但是这个冲突概率非常小。越是复杂哈希算法越难破解，但同样计算时间也就越长。所以，选择哈希算法的时候，要权衡安全性和计算时间来决定用哪种哈希算法。

第四个应用是散列函数，这个我们前面讲散列表的时候已经详细地讲过，它对哈希算法的要求非常特别，更加看重的是散列的平均性和哈希算法的执行效率。

课后思考
现在，区块链是一个很火的领域，它被很多人神秘化，不过其底层的实现原理并不复杂。其中，哈希算法就是它的一个非常重要的理论基础。你能讲一讲区块链使用的是哪种哈希算法吗？是为了解决什么问题而使用的呢？

欢迎留言和我分享，我会第一时间给你反馈。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(70)

Smallfly
课后思考：

区块链是一块块区块组成的，每个区块分为两部分：区块头和区块体。

区块头保存着 自己区块体 和 上一个区块头 的哈希值。

因为这种链式关系和哈希值的唯一性，只要区块链上任意一个区块被修改过，后面所有区块保存的哈希值就不对了。

区块链使用的是 SHA256 哈希算法，计算哈希值非常耗时，如果要篡改一个区块，就必须重新计算该区块后面所有的区块的哈希值，短时间内几乎不可能做到。
作者回复: 👍

2018-11-07

2

182

雪无痕
除了hash+salt，现在大多公司都采用无论密码长度多少，计算字符串hash时间都固定或者足够慢的算法如PBKDF2WithHmacSHA1，来降低硬件计算hash速度，减少不同长度字符串计算hash所需时间不一样而泄漏字符串长度信息，进一步减少风险。
2018-11-07

1

72

oyt
加salt，也可理解为为密码加点佐料后再进行hash运算。比如原密码是123456，不加盐的情况加密后假设是是xyz。 黑客拿到脱机的数据后，通过彩虹表匹配可以轻松破解常用密码。如果加盐，密码123456加盐后可能是12ng34qq56zz，再对加盐后的密码进行hash后值就与原密码hash后的值完全不同了。而且加盐的方式有很多种，可以是在头部加，可以在尾部加，还可在内容中间加，甚至加的盐还可以是随机的。这样即使用户使用的是最常用的密码，黑客拿到密文后破解的难度也很高。
作者回复: 👍

2018-11-13

2

43

Jerry银银
原来“散列冲突”的数学原理是鸽巢原理，为啥大部分算法书上讲解散列表的时候，不提一下呢。搞得我平时向朋友解释为什么存在冲突的时候，用得都是“鸽巢原理的白话版”，而且在讲解的时候还不知道那就是鸽巢原理，很尬!

离散数学的课必须得好好补完
作者回复: 👍

2018-11-07


35

小龙的城堡
老师您好，我有一个疑问就是hash算法用于加密数据，但是我理解的加密是需要对应解密的，但是hash算法并不能解密，这用应用更像是数字签名，不知道我理解是不是有问题，感谢！
作者回复: 没错 可以理解为数字签名

2018-11-07

2

23

FLYING
越是复杂哈希算法越难破解，但同样计算时间也就越少。这句话应该是越多吧？
作者回复: 谢谢指出 笔误 本来是想写“长”的 写成了“少”

2018-11-07


18

姜威
带着问题来学习：
1.如何防止数据库中的用户信息被脱库？
2.你会如何存储用户密码这么重要的数据吗？仅仅 MD5 加密一下存储就够了吗？
3.在实际开发中，我们应该如何用哈希算法解决问题？
一、什么是哈希算法？
1.定义
将任意长度的二进制值串映射成固定长度的二进制值串，这个映射的规则就是哈希算法，而通过原始数据映射之后得到的二进制值串就是哈希值。
2.如何设计一个优秀的哈希算法？
①单向哈希：
从哈希值不能反向推导出哈希值（所以哈希算法也叫单向哈希算法）。
②篡改无效：
对输入敏感，哪怕原始数据只修改一个Bit，最后得到的哈希值也大不相同。
③散列冲突：
散列冲突的概率要很小，对于不同的原始数据，哈希值相同的概率非常小。
④执行效率：
哈希算法的执行效率要尽量高效，针对较长的文本，也能快速计算哈希值。
二、哈希算法的常见应用有哪些？
7个常见应用：安全加密、唯一标识、数据校验、散列函数、负载均衡、数据分片、分布式存储。
1.安全加密
①常用于加密的哈希算法：
MD5：MD5 Message-Digest Algorithm，MD5消息摘要算法
SHA：Secure Hash Algorithm，安全散列算法
DES：Data Encryption Standard，数据加密标准
AES：Advanced Encryption Standard，高级加密标准
②对用于加密的哈希算法，有两点格外重要，第一点是很难根据哈希值反向推导出原始数据，第二点是散列冲突的概率要小。
③在实际开发中要权衡破解难度和计算时间来决定究竟使用哪种加密算法。
2.唯一标识
通过哈希算法计算出数据的唯一标识，从而用于高效检索数据。
3.数据校验
利用哈希算法对输入数据敏感的特点，可以对数据取哈希值，从而高效校验数据是否被篡改过。
4.散列函数
散列函数中用到的哈希算法更加关注散列后的值能不能平均分布，以及散列函数的执行快慢。
三、思考
1.如何防止数据库中的用户信息被脱库？你会如何存储用户密码这么重要的数据吗？
①使用MD5进行加密
②字典攻击：如果用户信息被“脱库”，黑客虽然拿到的是加密之后的密文，但可以通过“猜”的方式来破解密码，这是因为，有些用户的密码太简单。
③针对字典攻击，我们可以引入一个盐（salt），跟用户密码组合在一起，增加密码的复杂度。
2.现在，区块链是一个很火的领域，它被很多人神秘化，不过其底层的实现原理并不复杂。其中，哈希算法就是它的一个非常重要的理论基础。你能讲一讲区块链使用的是哪种哈希算法吗？是为了解决什么问题而使用的呢？
2018-11-16


16

🐱您的好友William🐱
其实我感觉hash不可能做到无冲突的原理可以用机器学习里面的免费午餐理论解释，因为hash追求的其实就是机器学习中的best seperate，就是mapping之后，不只是把两个不一样的东西分开，还要保证两者足够远（最大margin），因为hash函数是要面对所有类型的数据分布，而免费午餐理论告诉我们：不存在一种完美的算法对所有类型的数据分布都能做到完美的分离，最好的算法一定是根据特定的数据分布特定设计出来的。所以像hash函数这种需要应对不特定数据分布的，需要广泛使用的，是一定不会将数据完美seperate的。
作者回复: 👍

2018-11-08


13

王鸿运
md5不应该称之为加密算法，所谓加密，肯定对应有解密，不管是简单的异或加密，还是对称加密算法（aes，des）或者是非对称加密（rsa，ecc），都有加密和解密方式
而md5是不可逆的，因此不能称为加密算法，从名字来看，md5就算一个摘要算法，用于生成字符串的摘要信息以及签名校验信息
2018-12-18


10

0.618
所有的安全措施，只是增加攻击的成本而已！！！
2018-11-08


6

大张
加盐之后，盐是随机的，但对一个用户来讲，盐是固定的，而且肯定是存储的，那同样找到盐之后可以轻易计算hash了
2018-11-26

1

5

伯安
哈希算法的特点有一条：从哈希值不能反向推导出原始数据（所以哈希算法也叫单向哈希算法）。

可是JAVA中的MD5类不是有加密和解密方法吗？解密的过程，是不是代表哈希算法能够反向推导出原始数据呢？就这块比较困惑。。
作者回复: 应该没有吧。有破解方法 但也是基于碰撞的。但它也只是最近才被破解的

2018-11-07


5

chengzise
1. hash不可能做到无冲突的原理，可以用数学中的函数映射来理解。hash函数本质就是明文空间到密文空间的映射，以md5为例，它的密文空间是2^128，明文空间是无穷大的，所以存在多个明文映射到同一个密文，不存在无冲突的hash。
2. 同时，为什么说可以设计出md5等碰撞概率小的hash函数：虽然刚才说的明文空间是无穷大的，但是实际人类使用的明文空间没有想象中的那么大，例如：大量的文章都是相对于有意义的，随机的乱码文章，人类根本不会使用到。因此还是可以设计出在人类使用的明文空间的hash函数的
2019-05-25


3

落叶飞逝的恋
老师有个问题：
我们可以从图片的二进制码串开头取 100 个字节，从中间取 100 个字节，从最后再取 100 个字节，然后将这 300 个字节放到一块，通过哈希算法（比如 MD5），得到一个哈希字符串，用它作为图片的唯一标识。
这里说的取图片的二进制码串头部、中部、尾部的100个字节，这样图片在第一次计算的时候，还是需要完全读取图片的流。第一次就很耗时呀？
2018-12-20


3

学习爱好者
王老师好，关于哈希加密，我查了一些资料，但是有几个点不太明白，希望老师能指点一下：
1、网上说，固定盐值硬编码到程序里不安全，推荐把哈希值和随机盐一起存储到数据库里，这种做法是否可行？如果盐存在库里，脱库后也轻松拿到盐，用彩虹表也能比较容易破解吧？感觉这样做也不行啊
2、这节里说到的哈希加密应该属于存储范畴，那web传输的账号密码怎么加密呢？直接在客户端求哈希值？还是把密码传到服务端再算哈希值？
3、这节的举例子aes，des应该属于对称加密吧？感觉放到哈希加密好像不太合适。
4、以MD5为例，有2^128个哈希值，但是我们可取的值有无数个，那按照鸽巢理论，碰撞的可能肯定大于1；相反，如果数据库里存原始密码，命中的可能只有1种，就是完全等于原始密码，从这个角度讲，如果不脱库，存储原始密码是不是更安全？
2018-11-15

1

2

MrTin
个人认为hash算法不能做加密用，因为解密不出来，文中说的不是准确
作者回复: 我再去研究下 有没有要求说加密算法必须能解密才叫加密算法。这里你看以理解为数字签名

2018-11-11


2

bro.
java中是没有MD5的解密的,一个很简单的例子,一部电影可以加密成128为的MD5值存储,那么能将这128位的md5值还原成相对应的一部高清电影吗,如果可以的话,以后就不用拍电影了,直接写128位密码值还原一下就好了吗,网上的破解,只是维护一个密码表,暴力的一一对应,根据密码生成的MD5到表中查询是否存在,如果存在对应的密码值是?一般小公司要求不高的话会在密码前后加上特定的字符串在生成md5在上传保存的.有效避免常用密码被破解
2018-11-07


2

Hesher
比特币是两重hash，先做hash160或sha256，然后RIPEMD160，得到160位的hash串。主要用于Pow工作量证明。使用这两种散列算法应该主要是考虑安全性，但至于为什么是这两种就不太清楚了。
2018-11-07


2

小喵喵
Rsa加密呢？
作者回复: 是非对称加密算法吧 跟现在讲的哈希算法 有点扯远了

2018-11-12


1

Nior
老师，那两个示例的字符串不应该以图片的形式放出来啊，还要自己识别一下才能使用，稍有些不便。
作者回复: 不好意思 你可以谷歌一下 网上有关于md5冲突的例子

2018-11-08


1
收起评论

7099+





# 22 | 哈希算法（下）：哈希算法在分布式系统中有哪些应用？




数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



22 | 哈希算法（下）：哈希算法在分布式系统中有哪些应用？
王争 2018-11-09



09:20
讲述：修阳 大小：4.29M
上一节，我讲了哈希算法的四个应用，它们分别是：安全加密、数据校验、唯一标识、散列函数。今天，我们再来看剩余三种应用：负载均衡、数据分片、分布式存储。

你可能已经发现，这三个应用都跟分布式系统有关。没错，今天我就带你看下，哈希算法是如何解决这些分布式问题的。

应用五：负载均衡
我们知道，负载均衡算法有很多，比如轮询、随机、加权轮询等。那如何才能实现一个会话粘滞（session sticky）的负载均衡算法呢？也就是说，我们需要在同一个客户端上，在一次会话中的所有请求都路由到同一个服务器上。

最直接的方法就是，维护一张映射关系表，这张表的内容是客户端 IP 地址或者会话 ID 与服务器编号的映射关系。客户端发出的每次请求，都要先在映射表中查找应该路由到的服务器编号，然后再请求编号对应的服务器。这种方法简单直观，但也有几个弊端：

如果客户端很多，映射表可能会很大，比较浪费内存空间；

客户端下线、上线，服务器扩容、缩容都会导致映射失效，这样维护映射表的成本就会很大；

如果借助哈希算法，这些问题都可以非常完美地解决。我们可以通过哈希算法，对客户端 IP 地址或者会话 ID 计算哈希值，将取得的哈希值与服务器列表的大小进行取模运算，最终得到的值就是应该被路由到的服务器编号。 这样，我们就可以把同一个 IP 过来的所有请求，都路由到同一个后端服务器上。

应用六：数据分片
哈希算法还可以用于数据的分片。我这里有两个例子。

1. 如何统计“搜索关键词”出现的次数？
假如我们有 1T 的日志文件，这里面记录了用户的搜索关键词，我们想要快速统计出每个关键词被搜索的次数，该怎么做呢？

我们来分析一下。这个问题有两个难点，第一个是搜索日志很大，没办法放到一台机器的内存中。第二个难点是，如果只用一台机器来处理这么巨大的数据，处理时间会很长。

针对这两个难点，我们可以先对数据进行分片，然后采用多台机器处理的方法，来提高处理速度。具体的思路是这样的：为了提高处理的速度，我们用 n 台机器并行处理。我们从搜索记录的日志文件中，依次读出每个搜索关键词，并且通过哈希函数计算哈希值，然后再跟 n 取模，最终得到的值，就是应该被分配到的机器编号。

这样，哈希值相同的搜索关键词就被分配到了同一个机器上。也就是说，同一个搜索关键词会被分配到同一个机器上。每个机器会分别计算关键词出现的次数，最后合并起来就是最终的结果。

实际上，这里的处理过程也是 MapReduce 的基本设计思想。

2. 如何快速判断图片是否在图库中？
如何快速判断图片是否在图库中？上一节我们讲过这个例子，不知道你还记得吗？当时我介绍了一种方法，即给每个图片取唯一标识（或者信息摘要），然后构建散列表。

假设现在我们的图库中有 1 亿张图片，很显然，在单台机器上构建散列表是行不通的。因为单台机器的内存有限，而 1 亿张图片构建散列表显然远远超过了单台机器的内存上限。

我们同样可以对数据进行分片，然后采用多机处理。我们准备 n 台机器，让每台机器只维护某一部分图片对应的散列表。我们每次从图库中读取一个图片，计算唯一标识，然后与机器个数 n 求余取模，得到的值就对应要分配的机器编号，然后将这个图片的唯一标识和图片路径发往对应的机器构建散列表。

当我们要判断一个图片是否在图库中的时候，我们通过同样的哈希算法，计算这个图片的唯一标识，然后与机器个数 n 求余取模。假设得到的值是 k，那就去编号 k 的机器构建的散列表中查找。

现在，我们来估算一下，给这 1 亿张图片构建散列表大约需要多少台机器。

散列表中每个数据单元包含两个信息，哈希值和图片文件的路径。假设我们通过 MD5 来计算哈希值，那长度就是 128 比特，也就是 16 字节。文件路径长度的上限是 256 字节，我们可以假设平均长度是 128 字节。如果我们用链表法来解决冲突，那还需要存储指针，指针只占用 8 字节。所以，散列表中每个数据单元就占用 152 字节（这里只是估算，并不准确）。

假设一台机器的内存大小为 2GB，散列表的装载因子为 0.75，那一台机器可以给大约 1000 万（2GB*0.75/152）张图片构建散列表。所以，如果要对 1 亿张图片构建索引，需要大约十几台机器。在工程中，这种估算还是很重要的，能让我们事先对需要投入的资源、资金有个大概的了解，能更好地评估解决方案的可行性。

实际上，针对这种海量数据的处理问题，我们都可以采用多机分布式处理。借助这种分片的思路，可以突破单机内存、CPU 等资源的限制。

应用七：分布式存储
现在互联网面对的都是海量的数据、海量的用户。我们为了提高数据的读取、写入能力，一般都采用分布式的方式来存储数据，比如分布式缓存。我们有海量的数据需要缓存，所以一个缓存机器肯定是不够的。于是，我们就需要将数据分布在多台机器上。

该如何决定将哪个数据放到哪个机器上呢？我们可以借用前面数据分片的思想，即通过哈希算法对数据取哈希值，然后对机器个数取模，这个最终值就是应该存储的缓存机器编号。

但是，如果数据增多，原来的 10 个机器已经无法承受了，我们就需要扩容了，比如扩到 11 个机器，这时候麻烦就来了。因为，这里并不是简单地加个机器就可以了。

原来的数据是通过与 10 来取模的。比如 13 这个数据，存储在编号为 3 这台机器上。但是新加了一台机器中，我们对数据按照 11 取模，原来 13 这个数据就被分配到 2 号这台机器上了。



因此，所有的数据都要重新计算哈希值，然后重新搬移到正确的机器上。这样就相当于，缓存中的数据一下子就都失效了。所有的数据请求都会穿透缓存，直接去请求数据库。这样就可能发生雪崩效应，压垮数据库。

所以，我们需要一种方法，使得在新加入一个机器后，并不需要做大量的数据搬移。这时候，一致性哈希算法就要登场了。

假设我们有 k 个机器，数据的哈希值的范围是 [0, MAX]。我们将整个范围划分成 m 个小区间（m 远大于 k），每个机器负责 m/k 个小区间。当有新机器加入的时候，我们就将某几个小区间的数据，从原来的机器中搬移到新的机器中。这样，既不用全部重新哈希、搬移数据，也保持了各个机器上数据数量的均衡。

一致性哈希算法的基本思想就是这么简单。除此之外，它还会借助一个虚拟的环和虚拟结点，更加优美地实现出来。这里我就不展开讲了，如果感兴趣，你可以看下这个介绍。

除了我们上面讲到的分布式缓存，实际上，一致性哈希算法的应用非常广泛，在很多分布式存储系统中，都可以见到一致性哈希算法的影子。

解答开篇 & 内容小结
这两节的内容理论不多，比较贴近具体的开发。今天我讲了三种哈希算法在分布式系统中的应用，它们分别是：负载均衡、数据分片、分布式存储。

在负载均衡应用中，利用哈希算法替代映射表，可以实现一个会话粘滞的负载均衡策略。在数据分片应用中，通过哈希算法对处理的海量数据进行分片，多机分布式处理，可以突破单机资源的限制。在分布式存储应用中，利用一致性哈希算法，可以解决缓存等分布式系统的扩容、缩容导致数据大量搬移的难题。

课后思考
这两节我总共讲了七个哈希算法的应用。实际上，我讲的也只是冰山一角，哈希算法还有很多其他的应用，比如网络协议中的 CRC 校验、Git commit id 等等。除了这些，你还能想到其他用到哈希算法的地方吗？

欢迎留言和我分享，我会第一时间给你反馈。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(81)

ban
一致性算法讲的有的有点抽象，不够详细。我网上找到一个漫画图解，各位可以参考一下：https://www.sohu.com/a/158141377_479559
2018-11-09

4

198

null
一致性哈希算法，举个栗子：
我们钟表有 60 分钟，从 0 开始到 59，共 60 个点。
现在我们将机器往这 60 个点分配，规则如下：
hash(ip) % 60。

假设有 3 台机器 A，B 和 C，分别被分配到了 14，37 和 46 这三个点上。

图片的分配规则类似：
hash(image_id) % 60。
现有 3 张图片 x， y， z，分别被分配到 5，30，50 这三个点。

很明示，图片都没被分配到机器的节点上，怎么办呢?在钟表上顺时钟往前寻找，第一台遇到的机器，就是它的归属。

--- 我是分割线 ---

现在很不凑巧，A B C 三台机器分别分配到 5，10，15 这三个点。这样对 A 是很不公平的吖，要负责存储绝大多数的图片，那这怎么办呢?我们社会主义核心价值观基本内容：和谐、平等、公正。为建设和谐社会努力奋斗！！

为了避免不必要的争端，我们引入“虚拟节点”，每台机器都可以拔一根汗毛，变成若干台，把虚拟节点分散到 60 个点上，归属“虚拟节点”的图片，均保存到它的真身。这样就能解决分配不均匀的问题。

------

应用时，将 60 替换下即可，如替换为 2的 32 次方。
2018-11-09


91

Geek_fbe6fe
跟着作者学习整个数据结构和算法，感觉如醍醐灌顶，好像整个世界被重新打开了，最近也想学习go所以用go实现了到目前为止的所有算法和数据结构，用于自己学习和理解希望对大家有帮助
https://github.com/xiangdong1987/studyAlgorithm
对于一致性算法：我理解是先从整体上将hash 分好区间m 在通过自己维护一套在K台机器上m区间的分布来实现不需要rehash 的扩容方式
2018-11-09


25

Hesher
一致性哈希算法没看懂，只能说看完文章知道了有这么个概念可以解决扩容rehash问题
作者回复: 主要是展开讲内容会很多 网上关于一致性哈希算法的文章很多 你可以看下我给的那个链接。这个算法的核心思想非常简单，网上讲的都很复杂 只是为了实现起来优美。

2018-11-09


22

姜威
总结：哈希算法在分布式系统中的应用
1.负载均衡
1.1.需求
如何实现一个会话粘滞（session sticky）的负载均衡算法？也就是说，在一次会话中的所有请求都路由到同一个服务器上。
1.2.解决方案
通过哈希算法对客户端IP或会话ID计算哈希值，将取得的哈希值与服务器列表的大小进行取模运算，最终得到的值就是应该被路由到的服务器编号。这样，就可以把同一个IP过来的请求都路由到同一个后端服务器上。
2.数据分片
2.1.如何统计“搜索关键词”出现的次数？
①需求描述
假如我们有1T的日志文件，这里面记录了用户的搜索关键词，我们想要快速统计出每个关键词被搜索的次数，该怎么做呢？
②问题分析
这个问题有两个难点，第一个是搜索的日子很大，没办法放到一台机器的内存中。第二个是只用一台机器来处理这么巨大的数据，处理时间会很长。
③解决方案
先对数据进行分片，然后采用多台（比如n台）机器进行处理。具体做法：从搜索记录的日志文件中依次读取每个关键词，并通过哈希函数计算该关键词的哈希值，然后跟机器的台数n取模，最终得到值就是该关键词应该被分到的机器编号，这样相同的关键词一定会被分配到同一台机器上，数据分配完成后，由多台机器并行进行统计，最后合并起来就是最终结果。
实际上，这里的处理过程也是 MapReduce 的基本设计思想。
2.2.如何快速判断图片是否存在图库中？
①需求描述
假设现在我们的图库中有1亿张图片，如何快速判断图片是否在图库中？基本方式是给每个图片去唯一表示（或者信息摘要），然后构建散列表。
②问题分析
很显然，在单台机器上构建散列表示行不通的，因为单台机器的内存有限，而1亿张图片构建散列表远远超过了单台机器的内存上限。
②解决方案
准备n台机器，让每台机器只维护一部分图片对应的散列表。我们每次从图库中读取一个图片，计算唯一标识，然后与机器个数n求余取模，得到的值就对应要分配的机器编号，然后将这个图片的唯一表示和图片路径发往对应的机器构建散列表。
当我们要判断一个图片是否在图库中时，我们通过同样的哈希算法，计算这个图片的唯一表示，然后与机器个数n求余取模。假设得到的值是k，那就去编号为k的机器构建的散列表中查找。
如何估算给1亿张图片构建散列表大约需要多少台机器？
散列表中每个数据单元包含两个信息，哈希值和图片文件的路径。假设我们通过 MD5 来计算哈希值，那长度就是 128 比特，也就是 16 字节。文件路径长度的上限是 256 字节，我们可以假设平均长度是 128 字节。如果我们用链表法来解决冲突，那还需要存储指针，指针只占用 8 字节。所以，散列表中每个数据单元就占用 152 字节（这里只是估算，并不准确）。
假设一台机器的内存大小为 2GB，散列表的装载因子为 0.75，那一台机器可以给大约 1000 万（2GB*0.75/152）张图片构建散列表。所以，如果要对 1 亿张图片构建索引，需要大约十几台机器。在工程中，这种估算还是很重要的，能让我们事先对需要投入的资源、资金有个大概的了解，能更好地评估解决方案的可行性。
实际上，针对这种海量数据的处理问题，我们都可以采用多机分布式处理。借助这种分片的思路，可以突破单机内存、CPU 等资源的限制。
3.分布式存储
3.1.什么是分布式存储？
分布式存储就是将数据存储在多台机器上并提供高效的读取、写入支持。那如何决定将哪个数据放到哪个机器上呢？可以利用数据分片的思想，即通过哈希算法对数据取哈希值，然后对机器个数取模，这个最终值就是应该存储的缓存机器编号。
3.2.遇到的问题是什么？
如果数据持续增多，原来的机器数量已经不能满足需求，就需要增加机器，这时就麻烦了，因为所有的数据都需要重新哈希值进行再次分配。这就相当于，缓存中的数据一下子都失效了，所有的数据请求都会穿透缓存，直接去请求数据库。这样就可能发生雪崩效应，压垮数据库。
3.3.解决方案是什么？
①这时，需要一种方法，使得新加入一个机器后，并不需要做大量的数据搬移。那就是在分布式系统中应用非常广泛的一致性哈希算法。
②一致性哈希算法的基本思想是什么呢？为了说清楚这个问题，我们假设有k个机器，数据的哈希值范围是[0-MAX]，我们将整个范围划分成m个小区间（m远大于k），每个机器复杂m/k个小区间。当有新机器加入的时候，我们就将某几个小区间的数据，从原来的机器中搬移到新的机器中。这样，既不用全部重新哈希、搬移数据，也保持了各个机器上数据量的均衡。
2018-11-16


12

鹏飞天下
一致性hash算法http://www.zsythink.net/archives/1182
2019-01-03

2

11

会网络的老鼠
上几节讲过扩容冗余算法，可以避免搬移数据，如果对当前n取模未中再对扩容前的m取模，直到都未中再返回值是不是也可以？
作者回复: 👍 也是可以的

2018-11-09


11

jiaobuchongจุ๊บ
一致性 hash 算法，这篇文章讲得挺好的：http://www.zsythink.net/archives/1182
2018-12-15

1

8

CCC
Redis集群就是应用的一致性哈希算法
2018-11-09

1

7

虎虎❤️
您在计算1亿张图片的散列表占用内存的部分提到，每个数据单元都包含16字节的md5哈希值。加上文件路径和指针，一共152字节。这里为什么要存哈希值呢？谢谢
2018-11-13


5

若星
数据分片“搜索关键词”出现的次数，依次读出每个搜索关键词，的时候就可以计数了吧？
2018-11-26


4

www.xnsms.com小鸟接码
感觉评论里好多技术大佬，如果老师能附上一致性哈希算法代码案例就更好了
作者回复: 嗯嗯 感谢给出的意见

2018-11-09


4

道
希望对一致性哈希有深入的讲解。
2018-11-09


4

Lucus
git status应该也是利用文件的hash值判断文件是否有修改的
2019-04-09


3

晓龙
一致性hash算法感觉不是利用hash取模分配的，而是规定好哪些内容分配到哪些机器中，如果扩容就讲某些内容移植到新机器中，具体选择哪些内容移植到新机器，也不是用的hash去做的
2019-02-20

1

2

蓝艺
自己用go写的，一致性hash算法，https://github.com/lanyilee/ConsistentHash
2018-11-30


2

ZX
采用一致性hash算法，在增加节点的时候，是不是仍然要遍历数据，进行部分迁移，只是改变存储数据比较少啊
作者回复: 对于缓存来说 可以不用 直接让要搬移的数据失效就好了

2018-11-18


2

NeverMore
我了解的，某些互联网大厂Redis，使用的不是Redis的集群，而是主从的模式，客户端通过Hash映射到相应的机器上，使用的也是自己的hash算法。
2018-11-12


2

远方夕阳
一致性哈希也会存在映射差异的问题， A ,C节点中插入B节点，那么A B之间原先映射到C的请求都会B，这样的情况，是要C分割一些数据给B吗
作者回复: 是的

2018-11-11


2

cyf
哈希值相同的搜索关键词就被分配到了同一个机器上，这里数据是分片存储到不同的机器上的，而同一个机器只搜索固定的关键词，最后的结果会不会不完整？可能我没get到老师的点。
2018-11-09


2
收起评论

8199+





# 23 | 二叉树基础（上）：什么样的二叉树适合用数组来存储？




数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



23 | 二叉树基础（上）：什么样的二叉树适合用数组来存储？
王争 2018-11-12



10:11
讲述：修阳 大小：4.67M
前面我们讲的都是线性表结构，栈、队列等等。今天我们讲一种非线性表结构，树。树这种数据结构比线性表的数据结构要复杂得多，内容也比较多，所以我会分四节来讲解。



我反复强调过，带着问题学习，是最有效的学习方式之一，所以在正式的内容开始之前，我还是给你出一道思考题：二叉树有哪几种存储方式？什么样的二叉树适合用数组来存储？

带着这些问题，我们就来学习今天的内容，树！

树（Tree）
我们首先来看，什么是“树”？再完备的定义，都没有图直观。所以我在图中画了几棵“树”。你来看看，这些“树”都有什么特征？



你有没有发现，“树”这种数据结构真的很像我们现实生活中的“树”，这里面每个元素我们叫作“节点”；用来连线相邻节点之间的关系，我们叫作“父子关系”。

比如下面这幅图，A 节点就是 B 节点的父节点，B 节点是 A 节点的子节点。B、C、D 这三个节点的父节点是同一个节点，所以它们之间互称为兄弟节点。我们把没有父节点的节点叫作根节点，也就是图中的节点 E。我们把没有子节点的节点叫作叶子节点或者叶节点，比如图中的 G、H、I、J、K、L 都是叶子节点。



除此之外，关于“树”，还有三个比较相似的概念：高度（Height）、深度（Depth）、层（Level）。它们的定义是这样的：



这三个概念的定义比较容易混淆，描述起来也比较空洞。我举个例子说明一下，你一看应该就能明白。



记这几个概念，我还有一个小窍门，就是类比“高度”“深度”“层”这几个名词在生活中的含义。

在我们的生活中，“高度”这个概念，其实就是从下往上度量，比如我们要度量第 10 层楼的高度、第 13 层楼的高度，起点都是地面。所以，树这种数据结构的高度也是一样，从最底层开始计数，并且计数的起点是 0。

“深度”这个概念在生活中是从上往下度量的，比如水中鱼的深度，是从水平面开始度量的。所以，树这种数据结构的深度也是类似的，从根结点开始度量，并且计数起点也是 0。

“层数”跟深度的计算类似，不过，计数起点是 1，也就是说根节点的位于第 1 层。

二叉树（Binary Tree）
树结构多种多样，不过我们最常用还是二叉树。

二叉树，顾名思义，每个节点最多有两个“叉”，也就是两个子节点，分别是左子节点和右子节点。不过，二叉树并不要求每个节点都有两个子节点，有的节点只有左子节点，有的节点只有右子节点。我画的这几个都是二叉树。以此类推，你可以想象一下四叉树、八叉树长什么样子。



这个图里面，有两个比较特殊的二叉树，分别是编号 2 和编号 3 这两个。

其中，编号 2 的二叉树中，叶子节点全都在最底层，除了叶子节点之外，每个节点都有左右两个子节点，这种二叉树就叫作满二叉树。

编号 3 的二叉树中，叶子节点都在最底下两层，最后一层的叶子节点都靠左排列，并且除了最后一层，其他层的节点个数都要达到最大，这种二叉树叫作完全二叉树。

满二叉树很好理解，也很好识别，但是完全二叉树，有的人可能就分不清了。我画了几个完全二叉树和非完全二叉树的例子，你可以对比着看看。



你可能会说，满二叉树的特征非常明显，我们把它单独拎出来讲，这个可以理解。但是完全二叉树的特征不怎么明显啊，单从长相上来看，完全二叉树并没有特别特殊的地方啊，更像是“芸芸众树”中的一种。

那我们为什么还要特意把它拎出来讲呢？为什么偏偏把最后一层的叶子节点靠左排列的叫完全二叉树？如果靠右排列就不能叫完全二叉树了吗？这个定义的由来或者说目的在哪里？

要理解完全二叉树定义的由来，我们需要先了解，如何表示（或者存储）一棵二叉树？

想要存储一棵二叉树，我们有两种方法，一种是基于指针或者引用的二叉链式存储法，一种是基于数组的顺序存储法。

我们先来看比较简单、直观的链式存储法。从图中你应该可以很清楚地看到，每个节点有三个字段，其中一个存储数据，另外两个是指向左右子节点的指针。我们只要拎住根节点，就可以通过左右子节点的指针，把整棵树都串起来。这种存储方式我们比较常用。大部分二叉树代码都是通过这种结构来实现的。



我们再来看，基于数组的顺序存储法。我们把根节点存储在下标 i = 1 的位置，那左子节点存储在下标 2 * i = 2 的位置，右子节点存储在 2 * i + 1 = 3 的位置。以此类推，B 节点的左子节点存储在 2 * i = 2 * 2 = 4 的位置，右子节点存储在 2 * i + 1 = 2 * 2 + 1 = 5 的位置。



我来总结一下，如果节点 X 存储在数组中下标为 i 的位置，下标为 2 * i 的位置存储的就是左子节点，下标为 2 * i + 1 的位置存储的就是右子节点。反过来，下标为 i/2 的位置存储就是它的父节点。通过这种方式，我们只要知道根节点存储的位置（一般情况下，为了方便计算子节点，根节点会存储在下标为 1 的位置），这样就可以通过下标计算，把整棵树都串起来。

不过，我刚刚举的例子是一棵完全二叉树，所以仅仅“浪费”了一个下标为 0 的存储位置。如果是非完全二叉树，其实会浪费比较多的数组存储空间。你可以看我举的下面这个例子。



所以，如果某棵二叉树是一棵完全二叉树，那用数组存储无疑是最节省内存的一种方式。因为数组的存储方式并不需要像链式存储法那样，要存储额外的左右子节点的指针。这也是为什么完全二叉树会单独拎出来的原因，也是为什么完全二叉树要求最后一层的子节点都靠左的原因。

当我们讲到堆和堆排序的时候，你会发现，堆其实就是一种完全二叉树，最常用的存储方式就是数组。

二叉树的遍历
前面我讲了二叉树的基本定义和存储方法，现在我们来看二叉树中非常重要的操作，二叉树的遍历。这也是非常常见的面试题。

如何将所有节点都遍历打印出来呢？经典的方法有三种，前序遍历、中序遍历和后序遍历。其中，前、中、后序，表示的是节点与它的左右子树节点遍历打印的先后顺序。

前序遍历是指，对于树中的任意节点来说，先打印这个节点，然后再打印它的左子树，最后打印它的右子树。

中序遍历是指，对于树中的任意节点来说，先打印它的左子树，然后再打印它本身，最后打印它的右子树。

后序遍历是指，对于树中的任意节点来说，先打印它的左子树，然后再打印它的右子树，最后打印这个节点本身。



实际上，二叉树的前、中、后序遍历就是一个递归的过程。比如，前序遍历，其实就是先打印根节点，然后再递归地打印左子树，最后递归地打印右子树。

写递归代码的关键，就是看能不能写出递推公式，而写递推公式的关键就是，如果要解决问题 A，就假设子问题 B、C 已经解决，然后再来看如何利用 B、C 来解决 A。所以，我们可以把前、中、后序遍历的递推公式都写出来。

前序遍历的递推公式：
preOrder(r) = print r->preOrder(r->left)->preOrder(r->right)
 
中序遍历的递推公式：
inOrder(r) = inOrder(r->left)->print r->inOrder(r->right)
 
后序遍历的递推公式：
postOrder(r) = postOrder(r->left)->postOrder(r->right)->print r
有了递推公式，代码写起来就简单多了。这三种遍历方式的代码，我都写出来了，你可以看看。

void preOrder(Node* root) {
  if (root == null) return;
  print root // 此处为伪代码，表示打印 root 节点
  preOrder(root->left);
  preOrder(root->right);
}
 
void inOrder(Node* root) {
  if (root == null) return;
  inOrder(root->left);
  print root // 此处为伪代码，表示打印 root 节点
  inOrder(root->right);
}
 
void postOrder(Node* root) {
  if (root == null) return;
  postOrder(root->left);
  postOrder(root->right);
  print root // 此处为伪代码，表示打印 root 节点
}
二叉树的前、中、后序遍历的递归实现是不是很简单？你知道二叉树遍历的时间复杂度是多少吗？我们一起来看看。

从我前面画的前、中、后序遍历的顺序图，可以看出来，每个节点最多会被访问两次，所以遍历操作的时间复杂度，跟节点的个数 n 成正比，也就是说二叉树遍历的时间复杂度是 O(n)。

解答开篇 & 内容小结
今天，我讲了一种非线性表数据结构，树。关于树，有几个比较常用的概念你需要掌握，那就是：根节点、叶子节点、父节点、子节点、兄弟节点，还有节点的高度、深度、层数，以及树的高度。

我们平时最常用的树就是二叉树。二叉树的每个节点最多有两个子节点，分别是左子节点和右子节点。二叉树中，有两种比较特殊的树，分别是满二叉树和完全二叉树。满二叉树又是完全二叉树的一种特殊情况。

二叉树既可以用链式存储，也可以用数组顺序存储。数组顺序存储的方式比较适合完全二叉树，其他类型的二叉树用数组存储会比较浪费存储空间。除此之外，二叉树里非常重要的操作就是前、中、后序遍历操作，遍历的时间复杂度是 O(n)，你需要理解并能用递归代码来实现。

课后思考
给定一组数据，比如 1，3，5，6，9，10。你来算算，可以构建出多少种不同的二叉树？

我们讲了三种二叉树的遍历方式，前、中、后序。实际上，还有另外一种遍历方式，也就是按层遍历，你知道如何实现吗？

欢迎留言和我分享，我会第一时间给你反馈。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(109)

meng
关于问题1，如果是完全二叉树，老师说过可以放在数组里面，那么问题是否 可以简化为数组内的元素有多少种组合方式，这样的话，就是 n!，不知是否可以这样理解 ？
作者回复: 👍

2018-11-18


116

失火的夏天
1.是卡特兰数，是C[n,2n] / (n+1)种形状，c是组合数，节点的不同又是一个全排列，一共就是n!*C[n,2n] / (n+1)个二叉树。可以通过数学归纳法推导得出。
2.层次遍历需要借助队列这样一个辅助数据结构。（其实也可以不用，这样就要自己手动去处理节点的关系，代码不太好理解，好处就是空间复杂度是o(1)。不过用队列比较好理解，缺点就是空间复杂度是o(n)）。根节点先入队列，然后队列不空，取出对头元素，如果左孩子存在就入列队，否则什么也不做，右孩子同理。直到队列为空，则表示树层次遍历结束。树的层次遍历，其实也是一个广度优先的遍历算法。
2018-11-12


102

言志
1、既然是数组了，说明是完全二叉树，应该有n的阶乘个组合。
2、二叉树按层遍历，可以看作以根结点为起点，图的广度优先遍历的问题。
作者回复: 👍

2018-11-21


37

Jerry银银
第一题：
确定两点：
1）n个数，即n个节点，能构造出多少种不同形态的树？
2）n个数，有多少种不同的排列？
当确定以上两点，将【1)的结果】乘以 【2)的结果】，即为最终的结果。
但是有一个注意的点： 如果n中有相等的数，产生的总排列数就不是n！了哟

通过这一题，我学到了【卡塔兰数】：https://en.wikipedia.org/wiki/Catalan_number

第二题：
层序遍历，借用队列辅助即可，根节点先入队列，然后循环从队列中pop节点，将pop出来的节点的左子节点先入队列，右节点后入队列，依次循环，直到队列为空，遍历结束。

leetcode上有个类似的题目，链接为：https://leetcode.com/problems/binary-tree-level-order-traversal/
Java代码如下：
/**
 * Definition for a binary tree node.
 * public class TreeNode {
 * int val;
 * TreeNode left;
 * TreeNode right;
 * TreeNode(int x) { val = x; }
 * }
 */
class Solution {
    public List<List<Integer>> levelOrder(TreeNode root) {
        if (root == null) return new ArrayList<>(0);
        
        List<List<Integer>> result = new ArrayList<>();
        
        Queue<TreeNode> queue = new LinkedList<TreeNode>();
        queue.offer(root);
        
        Queue<TreeNode> curLevelNodes = new LinkedList<TreeNode>();
        
        while (!queue.isEmpty()) {
            TreeNode node = queue.poll();
            curLevelNodes.offer(node);
            
            if (queue.isEmpty()) {
                List<Integer> list = new ArrayList<>(curLevelNodes.size());
                while (!curLevelNodes.isEmpty()) {
                    TreeNode curNode = curLevelNodes.poll();
                    list.add(curNode.val);
                    
                    if (curNode.left != null) {
                        queue.offer(curNode.left);
                    }
                    
                    if (curNode.right != null) {
                        queue.offer(curNode.right);
                    }
                    
                }
                result.add(list);
            }
        }
        
        
        return result;
    }
    
}
2018-11-18

1

35

姜威
树，总共包含4节内容。具体如下：
1.树、二叉树
2.二叉查找树
3.平衡二叉树、红黑树
4.递归树

一、树
1.树的常用概念
根节点、叶子节点、父节点、子节点、兄弟节点，还有节点的高度、深度以及层数，树的高度。
2.概念解释
节点：树中的每个元素称为节点
父子关系：相邻两节点的连线，称为父子关系
根节点：没有父节点的节点
叶子节点：没有子节点的节点
父节点：指向子节点的节点
子节点：被父节点指向的节点
兄弟节点：具有相同父节点的多个节点称为兄弟节点关系
节点的高度：节点到叶子节点的最长路径所包含的边数
节点的深度：根节点到节点的路径所包含的边数
节点的层数：节点的深度+1（根节点的层数是1）
树的高度：等于根节点的高度
二、二叉树
1.概念
①什么是二叉树？
每个节点最多只有2个子节点的树，这两个节点分别是左子节点和右子节点。
②什么是满二叉树？
有一种二叉树，除了叶子节点外，每个节点都有左右两个子节点，这种二叉树叫做满二叉树。
③什么是完全二叉树？
有一种二叉树，叶子节点都在最底下两层，最后一层叶子节都靠左排列，并且除了最后一层，其他层的节点个数都要达到最大，这种二叉树叫做完全二叉树。
2.完全二叉树的存储
①链式存储
每个节点由3个字段，其中一个存储数据，另外两个是指向左右子节点的指针。我们只要拎住根节点，就可以通过左右子节点的指针，把整棵树都串起来。这种存储方式比较常用，大部分二叉树代码都是通过这种方式实现的。
②顺序存储
用数组来存储，对于完全二叉树，如果节点X存储在数组中的下标为i，那么它的左子节点的存储下标为2*i，右子节点的下标为2*i+1，反过来，下标i/2位置存储的就是该节点的父节点。注意，根节点存储在下标为1的位置。完全二叉树用数组来存储时最省内存的方式。
3.二叉树的遍历
①前序遍历：对于树中的任意节点来说，先打印这个节点，然后再打印它的左子树，最后打印它的右子树。
②中序遍历：对于树中的任意节点来说，先打印它的左子树，然后再打印它的本身，最后打印它的右子树。
③后序遍历：对于树中的任意节点来说，先打印它的左子树，然后再打印它的右子树，最后打印它本身。
前序遍历的递推公式：
preOrder(r) = print r->preOrder(r->left)->preOrder(r->right)
中序遍历的递推公式：
inOrder(r) = inOrder(r->left)->print r->inOrder(r->right)
后序遍历的递推公式：
postOrder(r) = postOrder(r->left)->postOrder(r->right)->print r
时间复杂度：3种遍历方式中，每个节点最多会被访问2次，所以时间复杂度是O(n)。
三、思考
1.二叉树有哪几种存储方式？什么样的二叉树适合用数组来存储？
2.给定一组数据，比如1，3，5，6，9，10.你来算算，可以构建出多少种不同的二叉树？
3.我们讲了三种二叉树的遍历方式，前、中、后序。实际上，还有另一种遍历方式，也就是按层遍历，你知道如何实现吗？
4.如何用循环实现二叉树的遍历？
2018-11-24

1

33

Renext
我看评论有人误解 文章所说的 完全二叉树--“最后一层的叶子节点都靠左排列。”然而图例中 I 节点明明是右节点，怎么就被称作完全二叉树？其实刚开始我也理解错了。这里说的 “最后一层的叶子节点都靠左排列”不是最后一层的子节点是左节点，而是指最后一层的子节点，从 左数到右是连续，中间没有断开，缺少节点（如图例H、I、J是连续的）。结合下文所说的基于数组的顺序存储法，可以知道完全二叉树是不会浪费内存的。其实简单理解，完全是为了省内存而提出这样的概念
2019-04-28


18

LeoBing
恕我愚钝。完全二叉树最后一层叶节点都靠左。可是图上节点9是靠右的，是不是我理解有什么问题，请教老师
2018-11-17

1

16

Laughing_Lz
/**
* 层次遍历二叉树
*
* @param root
*/
public static void levelOrder(Node root) {
if (root == null) {
return;
}
LinkedList<Node> queue = new LinkedList<Node>();
queue.add(root);
while (!queue.isEmpty()) {
Node currentNode = queue.poll();
System.out.print(currentNode.getValue() + " ");
if (currentNode.getLeft() != null) {
queue.add(currentNode.getLeft());
}
if (currentNode.getRight() != null) {
queue.add(currentNode.getRight());
}
}
}
2018-11-30

1

12

明翼
我看很多人计算第一题都按照完全二叉树计算的，实际上并没有说完全二叉树，所以n阶乘肯定不对吧，只要是二叉树按照文中规则肯定可以按照数组存储，六个数字，前面五个数字最多浪费四个位置加上本身存储五个就是九个位置，然后六可以浪费一个，那就是一共十个位置，六个数字，有多少种放法就有多少种二叉树。
2018-12-16

1

10

Liam
1 递归地理解一下：按住根节点，如果有k个左节点，则有n-k-1个右节点，分步乘法，f(n) = f(k) * f(n - k - 1) ，k可能性从0 到 n - 1 ,分步加法： f(n) = f(0)f(n-1) + ... + f(n-1)f(0) ，怎么计算该递推公式呢？参考Catalon数
2018-11-12


10

涂
前、中、后序遍历，主要是针对父节点的打印顺序。父左右为前序，左父右为中序，左右父为后序
2019-03-15


7

天二
老师 你在计算便利二叉树时间复杂度的时候说，“从我前面画的前、中、后序遍历的顺序图，可以看出来，每个节点最多会被访问两次”， 我想知道都是哪两次呢？ 可否帮忙解惑，从图中没看出来
作者回复: 第一次遍历到的时候算一次。递归返回的时候再一次。不过，这些说法都很笼统，你只要知道每个节点都被访问了一次，并且被访问的次数是常数次就可以了。

2019-01-21


7

Rephontil
现在评论的小伙伴少了好多，坚持学习的小伙伴是不是越来越少了？大家的热情呢？💪
作者回复: 有些人学得慢 或者工作耽搁了。一直追着最新的看的不多

2018-11-21


7

极明
感谢老师让我明白了为什么需要完全二叉树
2019-02-05


4

kakasi
思考题：
1. 一组数能构建多少个二叉树？
第一时间想到只要排列位置有改变，那么就应该是新的二叉树。组合排列的公式有点忘记了。。。那么用笨方法：
当只有1个数的时候，能构建1个二叉树；2个数时是2个二叉树；3个数有6个二叉树；再看下4个数，原来是24个；最后得出n!
2. 层序遍历二叉树：
数组和链表的方式都一样。先打印本身的数据，然后将左右节点塞到一个队列中；从队列里取第一个节点打印数据，并将其左右节点再塞到队列，以此类推。
2018-11-26


3

传说中的成大大
刚刚思考了完全二叉树的定义 叶子结点必须要在最后两层 如果不在最后两层的话通过数组顺序存储也会浪费空间吧
作者回复: 是的

2018-11-12


3

D→_→M
老师是否可以在您专栏的github上传一下二叉树这几节的相关代码，还有除了递归遍历二叉树，循环遍历是否也可以讲一下，或者在github上上传一下相关代码，自行研究学习。
作者回复: 非递归遍历比较复杂 不建议非得给自己制造学习难度 除非是为了面试。其他的二叉树的代码我会放到github上

2018-11-12


3

nothing
后序遍历节点不是最多被访问三次嘛， 还有那个深度我们学的深度和层次是一样的哇
作者回复: 1 从图上看是两次
2 从生活中的理解来说 应该没有第0层之说 但是有深度为0的说法

2018-11-12


3

往事随风，顺其自然
按照蹭便利使用队列，广度优先搜索
2018-11-12


3

朱龙凯
通过数组存储二叉树，可以从0开始，左右子节点下标分别是2*i+1和2*i+2
2019-06-05


2
收起评论

99+99+





# 24 | 二叉树基础（下）：有了如此高效的散列表，为什么还需要二叉树？




数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



24 | 二叉树基础（下）：有了如此高效的散列表，为什么还需要二叉树？
王争 2018-11-14



12:21
讲述：修阳 大小：5.66M
上一节我们学习了树、二叉树以及二叉树的遍历，今天我们再来学习一种特殊的的二叉树，二叉查找树。二叉查找树最大的特点就是，支持动态数据集合的快速插入、删除、查找操作。

我们之前说过，散列表也是支持这些操作的，并且散列表的这些操作比二叉查找树更高效，时间复杂度是 O(1)。既然有了这么高效的散列表，使用二叉树的地方是不是都可以替换成散列表呢？有没有哪些地方是散列表做不了，必须要用二叉树来做的呢？

带着这些问题，我们就来学习今天的内容，二叉查找树！

二叉查找树（Binary Search Tree）
二叉查找树是二叉树中最常用的一种类型，也叫二叉搜索树。顾名思义，二叉查找树是为了实现快速查找而生的。不过，它不仅仅支持快速查找一个数据，还支持快速插入、删除一个数据。它是怎么做到这些的呢？

这些都依赖于二叉查找树的特殊结构。二叉查找树要求，在树中的任意一个节点，其左子树中的每个节点的值，都要小于这个节点的值，而右子树节点的值都大于这个节点的值。 我画了几个二叉查找树的例子，你一看应该就清楚了。



前面我们讲到，二叉查找树支持快速查找、插入、删除操作，现在我们就依次来看下，这三个操作是如何实现的。

1. 二叉查找树的查找操作
首先，我们看如何在二叉查找树中查找一个节点。我们先取根节点，如果它等于我们要查找的数据，那就返回。如果要查找的数据比根节点的值小，那就在左子树中递归查找；如果要查找的数据比根节点的值大，那就在右子树中递归查找。



这里我把查找的代码实现了一下，贴在下面了，结合代码，理解起来会更加容易。

public class BinarySearchTree {
  private Node tree;
 
  public Node find(int data) {
    Node p = tree;
    while (p != null) {
      if (data < p.data) p = p.left;
      else if (data > p.data) p = p.right;
      else return p;
    }
    return null;
  }
 
  public static class Node {
    private int data;
    private Node left;
    private Node right;
 
    public Node(int data) {
      this.data = data;
    }
  }
}
2. 二叉查找树的插入操作
二叉查找树的插入过程有点类似查找操作。新插入的数据一般都是在叶子节点上，所以我们只需要从根节点开始，依次比较要插入的数据和节点的大小关系。

如果要插入的数据比节点的数据大，并且节点的右子树为空，就将新数据直接插到右子节点的位置；如果不为空，就再递归遍历右子树，查找插入位置。同理，如果要插入的数据比节点数值小，并且节点的左子树为空，就将新数据插入到左子节点的位置；如果不为空，就再递归遍历左子树，查找插入位置。



同样，插入的代码我也实现了一下，贴在下面，你可以看看。

public void insert(int data) {
  if (tree == null) {
    tree = new Node(data);
    return;
  }
 
  Node p = tree;
  while (p != null) {
    if (data > p.data) {
      if (p.right == null) {
        p.right = new Node(data);
        return;
      }
      p = p.right;
    } else { // data < p.data
      if (p.left == null) {
        p.left = new Node(data);
        return;
      }
      p = p.left;
    }
  }
}
3. 二叉查找树的删除操作
二叉查找树的查找、插入操作都比较简单易懂，但是它的删除操作就比较复杂了 。针对要删除节点的子节点个数的不同，我们需要分三种情况来处理。

第一种情况是，如果要删除的节点没有子节点，我们只需要直接将父节点中，指向要删除节点的指针置为 null。比如图中的删除节点 55。

第二种情况是，如果要删除的节点只有一个子节点（只有左子节点或者右子节点），我们只需要更新父节点中，指向要删除节点的指针，让它指向要删除节点的子节点就可以了。比如图中的删除节点 13。

第三种情况是，如果要删除的节点有两个子节点，这就比较复杂了。我们需要找到这个节点的右子树中的最小节点，把它替换到要删除的节点上。然后再删除掉这个最小节点，因为最小节点肯定没有左子节点（如果有左子结点，那就不是最小节点了），所以，我们可以应用上面两条规则来删除这个最小节点。比如图中的删除节点 18。



老规矩，我还是把删除的代码贴在这里。

public void delete(int data) {
  Node p = tree; // p 指向要删除的节点，初始化指向根节点
  Node pp = null; // pp 记录的是 p 的父节点
  while (p != null && p.data != data) {
    pp = p;
    if (data > p.data) p = p.right;
    else p = p.left;
  }
  if (p == null) return; // 没有找到
 
  // 要删除的节点有两个子节点
  if (p.left != null && p.right != null) { // 查找右子树中最小节点
    Node minP = p.right;
    Node minPP = p; // minPP 表示 minP 的父节点
    while (minP.left != null) {
      minPP = minP;
      minP = minP.left;
    }
    p.data = minP.data; // 将 minP 的数据替换到 p 中
    p = minP; // 下面就变成了删除 minP 了
    pp = minPP;
  }
 
  // 删除节点是叶子节点或者仅有一个子节点
  Node child; // p 的子节点
  if (p.left != null) child = p.left;
  else if (p.right != null) child = p.right;
  else child = null;
 
  if (pp == null) tree = child; // 删除的是根节点
  else if (pp.left == p) pp.left = child;
  else pp.right = child;
}
实际上，关于二叉查找树的删除操作，还有个非常简单、取巧的方法，就是单纯将要删除的节点标记为“已删除”，但是并不真正从树中将这个节点去掉。这样原本删除的节点还需要存储在内存中，比较浪费内存空间，但是删除操作就变得简单了很多。而且，这种处理方法也并没有增加插入、查找操作代码实现的难度。

4. 二叉查找树的其他操作
除了插入、删除、查找操作之外，二叉查找树中还可以支持快速地查找最大节点和最小节点、前驱节点和后继节点。这些操作我就不一一展示了。我会将相应的代码放到 GitHub 上，你可以自己先实现一下，然后再去上面看。

二叉查找树除了支持上面几个操作之外，还有一个重要的特性，就是中序遍历二叉查找树，可以输出有序的数据序列，时间复杂度是 O(n)，非常高效。因此，二叉查找树也叫作二叉排序树。

支持重复数据的二叉查找树
前面讲二叉查找树的时候，我们默认树中节点存储的都是数字。很多时候，在实际的软件开发中，我们在二叉查找树中存储的，是一个包含很多字段的对象。我们利用对象的某个字段作为键值（key）来构建二叉查找树。我们把对象中的其他字段叫作卫星数据。

前面我们讲的二叉查找树的操作，针对的都是不存在键值相同的情况。那如果存储的两个对象键值相同，这种情况该怎么处理呢？我这里有两种解决方法。

第一种方法比较容易。二叉查找树中每一个节点不仅会存储一个数据，因此我们通过链表和支持动态扩容的数组等数据结构，把值相同的数据都存储在同一个节点上。

第二种方法比较不好理解，不过更加优雅。

每个节点仍然只存储一个数据。在查找插入位置的过程中，如果碰到一个节点的值，与要插入数据的值相同，我们就将这个要插入的数据放到这个节点的右子树，也就是说，把这个新插入的数据当作大于这个节点的值来处理。



当要查找数据的时候，遇到值相同的节点，我们并不停止查找操作，而是继续在右子树中查找，直到遇到叶子节点，才停止。这样就可以把键值等于要查找值的所有节点都找出来。



对于删除操作，我们也需要先查找到每个要删除的节点，然后再按前面讲的删除操作的方法，依次删除。



二叉查找树的时间复杂度分析
好了，对于二叉查找树常用操作的实现方式，你应该掌握得差不多了。现在，我们来分析一下，二叉查找树的插入、删除、查找操作的时间复杂度。

实际上，二叉查找树的形态各式各样。比如这个图中，对于同一组数据，我们构造了三种二叉查找树。它们的查找、插入、删除操作的执行效率都是不一样的。图中第一种二叉查找树，根节点的左右子树极度不平衡，已经退化成了链表，所以查找的时间复杂度就变成了 O(n)。



我刚刚其实分析了一种最糟糕的情况，我们现在来分析一个最理想的情况，二叉查找树是一棵完全二叉树（或满二叉树）。这个时候，插入、删除、查找的时间复杂度是多少呢？

从我前面的例子、图，以及还有代码来看，不管操作是插入、删除还是查找，时间复杂度其实都跟树的高度成正比，也就是 O(height)。既然这样，现在问题就转变成另外一个了，也就是，如何求一棵包含 n 个节点的完全二叉树的高度？

树的高度就等于最大层数减一，为了方便计算，我们转换成层来表示。从图中可以看出，包含 n 个节点的完全二叉树中，第一层包含 1 个节点，第二层包含 2 个节点，第三层包含 4 个节点，依次类推，下面一层节点个数是上一层的 2 倍，第 K 层包含的节点个数就是 2^(K-1)。

不过，对于完全二叉树来说，最后一层的节点个数有点儿不遵守上面的规律了。它包含的节点个数在 1 个到 2^(L-1) 个之间（我们假设最大层数是 L）。如果我们把每一层的节点个数加起来就是总的节点个数 n。也就是说，如果节点的个数是 n，那么 n 满足这样一个关系：

n >= 1+2+4+8+...+2^(L-2)+1
n <= 1+2+4+8+...+2^(L-2)+2^(L-1)
借助等比数列的求和公式，我们可以计算出，L 的范围是 [log2(n+1), log2n +1]。完全二叉树的层数小于等于 log2n +1，也就是说，完全二叉树的高度小于等于 log2n。

显然，极度不平衡的二叉查找树，它的查找性能肯定不能满足我们的需求。我们需要构建一种不管怎么删除、插入数据，在任何时候，都能保持任意节点左右子树都比较平衡的二叉查找树，这就是我们下一节课要详细讲的，一种特殊的二叉查找树，平衡二叉查找树。平衡二叉查找树的高度接近 logn，所以插入、删除、查找操作的时间复杂度也比较稳定，是 O(logn)。

解答开篇
我们在散列表那节中讲过，散列表的插入、删除、查找操作的时间复杂度可以做到常量级的 O(1)，非常高效。而二叉查找树在比较平衡的情况下，插入、删除、查找操作时间复杂度才是 O(logn)，相对散列表，好像并没有什么优势，那我们为什么还要用二叉查找树呢？

我认为有下面几个原因：

第一，散列表中的数据是无序存储的，如果要输出有序的数据，需要先进行排序。而对于二叉查找树来说，我们只需要中序遍历，就可以在 O(n) 的时间复杂度内，输出有序的数据序列。

第二，散列表扩容耗时很多，而且当遇到散列冲突时，性能不稳定，尽管二叉查找树的性能不稳定，但是在工程中，我们最常用的平衡二叉查找树的性能非常稳定，时间复杂度稳定在 O(logn)。

第三，笼统地来说，尽管散列表的查找等操作的时间复杂度是常量级的，但因为哈希冲突的存在，这个常量不一定比 logn 小，所以实际的查找速度可能不一定比 O(logn) 快。加上哈希函数的耗时，也不一定就比平衡二叉查找树的效率高。

第四，散列表的构造比二叉查找树要复杂，需要考虑的东西很多。比如散列函数的设计、冲突解决办法、扩容、缩容等。平衡二叉查找树只需要考虑平衡性这一个问题，而且这个问题的解决方案比较成熟、固定。

最后，为了避免过多的散列冲突，散列表装载因子不能太大，特别是基于开放寻址法解决冲突的散列表，不然会浪费一定的存储空间。

综合这几点，平衡二叉查找树在某些方面还是优于散列表的，所以，这两者的存在并不冲突。我们在实际的开发过程中，需要结合具体的需求来选择使用哪一个。

内容小结
今天我们学习了一种特殊的二叉树，二叉查找树。它支持快速地查找、插入、删除操作。

二叉查找树中，每个节点的值都大于左子树节点的值，小于右子树节点的值。不过，这只是针对没有重复数据的情况。对于存在重复数据的二叉查找树，我介绍了两种构建方法，一种是让每个节点存储多个值相同的数据；另一种是，每个节点中存储一个数据。针对这种情况，我们只需要稍加改造原来的插入、删除、查找操作即可。

在二叉查找树中，查找、插入、删除等很多操作的时间复杂度都跟树的高度成正比。两个极端情况的时间复杂度分别是 O(n) 和 O(logn)，分别对应二叉树退化成链表的情况和完全二叉树。

为了避免时间复杂度的退化，针对二叉查找树，我们又设计了一种更加复杂的树，平衡二叉查找树，时间复杂度可以做到稳定的 O(logn)，下一节我们具体来讲。

课后思考
今天我讲了二叉树高度的理论分析方法，给出了粗略的数量级。如何通过编程，求出一棵给定二叉树的确切高度呢？

欢迎留言和我分享，我会第一时间给你反馈。

我已将本节内容相关的详细代码更新到 GitHub，戳此即可查看。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(119)

失火的夏天
确定二叉树高度有两种思路：第一种是深度优先思想的递归，分别求左右子树的高度。当前节点的高度就是左右子树中较大的那个+1；第二种可以采用层次遍历的方式，每一层记录都记录下当前队列的长度，这个是队尾，每一层队头从0开始。然后每遍历一个元素，队头下标+1。直到队头下标等于队尾下标。这个时候表示当前层遍历完成。每一层刚开始遍历的时候，树的高度+1。最后队列为空，就能得到树的高度。
作者回复: 👍 大家可以看看这条留言

2018-11-14


195

拉欧
递归法，根节点高度=max(左子树高度，右子树高度)+1
作者回复: 👍 精髓

2018-11-14


78

Smallfly
老师我有一个疑问，二叉树删除时，如果待删除节点有两个子节点，能否用左子树中的最大值来替换待删除节点呢？
作者回复: 好像也可以 👍

2018-11-15

3

39

一般社员
老师，不理解删除有两个子节点那段代码，最后删除minp，不是minpp.left =null,minp =null吗
2018-11-14

2

38

Monday
1、思考题：leetcode 104 题，可以使用递归法。
递归公式： depth =Math.max(maxDepth(node.left), maxDepth(node.right) )+ 1;
递归出口： depth = 0 (node == null)
2、二叉查找树的删除操作（无重复的数据）leetcode 450。
根据老师的思路，先不看代码，自己写了好长段时间，写出来都跑过leetcode的所有案例。回过头来再看老师的删除的代码，感觉到了巧妙之处就是：当删除节点有两个子节点的情况，很巧得一起套用了删除结点子节点个数小于1的两种场景。
作者回复: 是的 钻研精神值得称赞👍

2018-11-17


24

🌟
姜威老大没写总结笔记了吗？我是个算法菜鸟萌新，一直看着姜大佬的笔记总结学习。。。
2018-11-26


20

www.xnsms.com小鸟接码
p.data = minP.data; // 将 minP 的数据替换到 p 中
p = minP; // 下面就变成了删除 minP 了
pp = minPP;


总于看明白这段代码了……各位老铁，单纯看这3行代码是看不出是删除后继节点的，是要结合后面的代码来看的……不过说实话这种代码是不好看的懂……
作者回复: 😄 是不好看懂

2018-11-15


13

莫弹弹
在sf的微信公众号上刚好看到二叉树相关的文章，二叉树常规操作都有了，基本思路是：

- 只有一个根结点时，二叉树深度为 1
- 只有左子树时，二叉树深度为左子树深度加 1
- 只有右子树时，二叉树深度为右子树深度加 1
- 同时存在左右子树时，二叉树深度为左右子树中深度最大者加 1

https://mp.weixin.qq.com/s/ONKJyusGCIE2ctwT9uLv9g
作者回复: 👍

2018-11-14


9

一个慢慢爬行的普通人
p = minP; // 下面就变成了删除 minP 了...
pp = minPP;
老师，对这里不太搞懂，似乎也有些人对这里感到困惑，老师可以对这两句集中解释下嘛
作者回复: 好的。我们用后继节点替换到要删除节点的位置。 然后就变成删除后继节点的问题了。为了逻辑统一 代码书写简洁。我们把后继节点赋给了p

2018-11-14


7

追风者
更新二十多篇了，王老师把前面文章的课后思考题都总结回答一下吧。
作者回复: 好的 基础篇完了后会集中答疑一下

2018-11-15


6

陆老师
有一种更容易理解复杂度的思路，二叉查找树类似二分法搜索，每次缩小一半的区间，而二分查找法时间复杂度就是logN
作者回复: 是的，👍

2019-03-13


4

Ryan-Hou
平衡树相比于哈希表，保存了节点数据间的顺序信息，所以操作的时间复杂度上会比哈希表大(因为额外的提供了顺序性，对应的会有代价)。也正因为保存了顺序性，平衡树可以方便的实现min, max, ceil, floor 等操作，所以个人认为这两种数据结构最大的不同在于这里，有不同的取舍
2018-11-14


4

李沁
这两句代码一开始看得很晕
p = minP; // 下面就变成了删除 minP 了
pp = minPP;

后面想到其实代码还没有终结，如果minP是右子树的最左节点，那么这个节点肯定是没有左子树的。
这步操作其实可以理解为把这个节点标记要删除，用后面的删除只有一个子树或没有子树的节点的逻辑去做
2019-05-01


3

allean
连续看好几遍，每一次的感受都更深刻，谢谢老师。可是有一点要吐槽下，老师给变量命名也有点太随意了啊，二叉树删除节点那个，好多p啊，看的晕了都
2019-01-14


3

kakasi
老师，看了二叉树的优点和适用场景，跳表不是都满足吗？
2018-11-28


3

james
散列表装载因子不能太大，特别是基于开放寻址法解决冲突的散列表，不然会浪费内存空间。
修改：应该是装在因子不能太小吧
2018-11-22


3

李建辉
看了下老师显示的代码，发现老师的删除二叉查找树节点的代码写的有点问题，为此自己实现了一下，希望老师指正：
先说老师代码问题所在：
    p.data = minP.data; // 将 minP 的数据替换到 p 中
    p = minP; // 下面就变成了删除 minP 了
    pp = minPP;
这里是有问题的，感觉正确的应该是
findNode.setData(minP.getData());//覆盖原来的值
minPP.setLeftNode(minP.getRightNode());//替代删除节点的父节点的左节点指向替代删除节点的右节点

贴上自己的删除代码：
/**
* 删除查找二叉树的一个节点
* @param root
* @param value
*/
public static void delete(Node root,int value) {
Node findNode = root; //记录当前要删除的节点
Node fatherNode = null; //记录删除节点的父节点
while (findNode != null && findNode.getData() != value) {
fatherNode = findNode;
if (findNode.getData() < value) {
findNode = findNode.getRightNode();
} else if (findNode.getData() > value) {
findNode = findNode.getLeftNode();
}
}
if (findNode != null) {
if (findNode.getLeftNode() != null && findNode.getRightNode() != null) {//要删除节点 左节点和右节点都存在
Node minP = findNode.getRightNode(); //minP是获取右节点下面的最小节点
Node minPP = findNode; //minPP是minP的父节点
while (minP.getLeftNode() != null) {
minPP = minP;
minP = minP.getLeftNode();
}
findNode.setData(minP.getData());//覆盖原来的值
minPP.setLeftNode(minP.getRightNode());//替代删除节点的父节点的左节点指向替代删除节点的右节点
}else{//要删除节点 左节点和右节点有一个存在 或全部都不存在
Node tidai = null;
if (findNode.getLeftNode() == null && findNode.getRightNode() != null) {
tidai = findNode.getRightNode();
}
if (findNode.getLeftNode() != null && findNode.getRightNode() == null) {
tidai = findNode.getLeftNode();
}
if (fatherNode == null) { //父节点为空 即为根节点
root = tidai;
} else if (fatherNode.getRightNode().getData() == value) {
fatherNode.setRightNode(tidai);
} else {
fatherNode.setLeftNode(tidai);
}
}
}

}
2018-11-15


3

等风来
老师:删除示例的25节点的右节点[21]错误;
删除节点有两个节点
p = minP; // 下面就变成了删除 minP 了...
pp = minPP;
是不是应该改成: minPP.Left = minP.Right;
作者回复: 图已经改正 多谢指出。
代码应该没错

2018-11-14


3

PhilZhang
对于二叉搜索树各种操作的复杂度，有更容易理解的解释方法:每次操作后数据量都减少了一半，所以复杂度自然是logN。
作者回复: 👍

2018-11-18


2

feifei

  /**
   * 计算层级的重点于在写出递推公式
   *
   * count(level) = max(count(level.left),count(level.right))
   *
   * @param root
   * @param index
   * @return
   */
  public int getBinaryLevel(treeNode root, int index) {
    if (null == root) {
      return index;
    }

    int maxleftLevel = 0;
    if (root.left != null) {
      maxleftLevel = getBinaryLevel(root.left, index + 1);
    }

    int maxRightLevel = 0;

    if (root.right != null) {
      maxRightLevel = getBinaryLevel(root.right, index + 1);
    }

    return Math.max(maxleftLevel, maxRightLevel) + 1;
  }
2018-11-15


2
收起评论

99+99+





# 25 | 红黑树（上）：为什么工程中都用红黑树这种二叉树？



数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



25 | 红黑树（上）：为什么工程中都用红黑树这种二叉树？
王争 2018-11-16



10:00
讲述：修阳 大小：4.59M
上两节，我们依次讲了树、二叉树、二叉查找树。二叉查找树是最常用的一种二叉树，它支持快速插入、删除、查找操作，各个操作的时间复杂度跟树的高度成正比，理想情况下，时间复杂度是 O(logn)。

不过，二叉查找树在频繁的动态更新过程中，可能会出现树的高度远大于 log2n 的情况，从而导致各个操作的效率下降。极端情况下，二叉树会退化为链表，时间复杂度会退化到 O(n)。我上一节说了，要解决这个复杂度退化的问题，我们需要设计一种平衡二叉查找树，也就是今天要讲的这种数据结构。

很多书籍里，但凡讲到平衡二叉查找树，就会拿红黑树作为例子。不仅如此，如果你有一定的开发经验，你会发现，在工程中，很多用到平衡二叉查找树的地方都会用红黑树。你有没有想过，为什么工程中都喜欢用红黑树，而不是其他平衡二叉查找树呢？

带着这个问题，让我们一起来学习今天的内容吧！

什么是“平衡二叉查找树”？
平衡二叉树的严格定义是这样的：二叉树中任意一个节点的左右子树的高度相差不能大于 1。从这个定义来看，上一节我们讲的完全二叉树、满二叉树其实都是平衡二叉树，但是非完全二叉树也有可能是平衡二叉树。



平衡二叉查找树不仅满足上面平衡二叉树的定义，还满足二叉查找树的特点。最先被发明的平衡二叉查找树是AVL 树，它严格符合我刚讲到的平衡二叉查找树的定义，即任何节点的左右子树高度相差不超过 1，是一种高度平衡的二叉查找树。

但是很多平衡二叉查找树其实并没有严格符合上面的定义（树中任意一个节点的左右子树的高度相差不能大于 1），比如我们下面要讲的红黑树，它从根节点到各个叶子节点的最长路径，有可能会比最短路径大一倍。

我们学习数据结构和算法是为了应用到实际的开发中的，所以，我觉得没必去死抠定义。对于平衡二叉查找树这个概念，我觉得我们要从这个数据结构的由来，去理解“平衡”的意思。

发明平衡二叉查找树这类数据结构的初衷是，解决普通二叉查找树在频繁的插入、删除等动态更新的情况下，出现时间复杂度退化的问题。

所以，平衡二叉查找树中“平衡”的意思，其实就是让整棵树左右看起来比较“对称”、比较“平衡”，不要出现左子树很高、右子树很矮的情况。这样就能让整棵树的高度相对来说低一些，相应的插入、删除、查找等操作的效率高一些。

所以，如果我们现在设计一个新的平衡二叉查找树，只要树的高度不比 log2n 大很多（比如树的高度仍然是对数量级的），尽管它不符合我们前面讲的严格的平衡二叉查找树的定义，但我们仍然可以说，这是一个合格的平衡二叉查找树。

如何定义一棵“红黑树”？
平衡二叉查找树其实有很多，比如，Splay Tree（伸展树）、Treap（树堆）等，但是我们提到平衡二叉查找树，听到的基本都是红黑树。它的出镜率甚至要高于“平衡二叉查找树”这几个字，有时候，我们甚至默认平衡二叉查找树就是红黑树，那我们现在就来看看这个“明星树”。

红黑树的英文是“Red-Black Tree”，简称 R-B Tree。它是一种不严格的平衡二叉查找树，我前面说了，它的定义是不严格符合平衡二叉查找树的定义的。那红黑树究竟是怎么定义的呢？

顾名思义，红黑树中的节点，一类被标记为黑色，一类被标记为红色。除此之外，一棵红黑树还需要满足这样几个要求：

根节点是黑色的；

每个叶子节点都是黑色的空节点（NIL），也就是说，叶子节点不存储数据；

任何相邻的节点都不能同时为红色，也就是说，红色节点是被黑色节点隔开的；

每个节点，从该节点到达其可达叶子节点的所有路径，都包含相同数目的黑色节点；

这里的第二点要求“叶子节点都是黑色的空节点”，稍微有些奇怪，它主要是为了简化红黑树的代码实现而设置的，下一节我们讲红黑树的实现的时候会讲到。这节我们暂时不考虑这一点，所以，在画图和讲解的时候，我将黑色的、空的叶子节点都省略掉了。

为了让你更好地理解上面的定义，我画了两个红黑树的图例，你可以对照着看下。



为什么说红黑树是“近似平衡”的？
我们前面也讲到，平衡二叉查找树的初衷，是为了解决二叉查找树因为动态更新导致的性能退化问题。所以，“平衡”的意思可以等价为性能不退化。“近似平衡”就等价为性能不会退化的太严重。

我们在上一节讲过，二叉查找树很多操作的性能都跟树的高度成正比。一棵极其平衡的二叉树（满二叉树或完全二叉树）的高度大约是 log2n，所以如果要证明红黑树是近似平衡的，我们只需要分析，红黑树的高度是否比较稳定地趋近 log2n 就好了。

红黑树的高度不是很好分析，我带你一步一步来推导。

首先，我们来看，如果我们将红色节点从红黑树中去掉，那单纯包含黑色节点的红黑树的高度是多少呢？

红色节点删除之后，有些节点就没有父节点了，它们会直接拿这些节点的祖父节点（父节点的父节点）作为父节点。所以，之前的二叉树就变成了四叉树。



前面红黑树的定义里有这么一条：从任意节点到可达的叶子节点的每个路径包含相同数目的黑色节点。我们从四叉树中取出某些节点，放到叶节点位置，四叉树就变成了完全二叉树。所以，仅包含黑色节点的四叉树的高度，比包含相同节点个数的完全二叉树的高度还要小。

上一节我们说，完全二叉树的高度近似 log2n，这里的四叉“黑树”的高度要低于完全二叉树，所以去掉红色节点的“黑树”的高度也不会超过 log2n。

我们现在知道只包含黑色节点的“黑树”的高度，那我们现在把红色节点加回去，高度会变成多少呢？

从上面我画的红黑树的例子和定义看，在红黑树中，红色节点不能相邻，也就是说，有一个红色节点就要至少有一个黑色节点，将它跟其他红色节点隔开。红黑树中包含最多黑色节点的路径不会超过 log2n，所以加入红色节点之后，最长路径不会超过 2log2n，也就是说，红黑树的高度近似 2log2n。

所以，红黑树的高度只比高度平衡的 AVL 树的高度（log2n）仅仅大了一倍，在性能上，下降得并不多。这样推导出来的结果不够精确，实际上红黑树的性能更好。

解答开篇
我们刚刚提到了很多平衡二叉查找树，现在我们就来看下，为什么在工程中大家都喜欢用红黑树这种平衡二叉查找树？

我们前面提到 Treap、Splay Tree，绝大部分情况下，它们操作的效率都很高，但是也无法避免极端情况下时间复杂度的退化。尽管这种情况出现的概率不大，但是对于单次操作时间非常敏感的场景来说，它们并不适用。

AVL 树是一种高度平衡的二叉树，所以查找的效率非常高，但是，有利就有弊，AVL 树为了维持这种高度的平衡，就要付出更多的代价。每次插入、删除都要做调整，就比较复杂、耗时。所以，对于有频繁的插入、删除操作的数据集合，使用 AVL 树的代价就有点高了。

红黑树只是做到了近似平衡，并不是严格的平衡，所以在维护平衡的成本上，要比 AVL 树要低。

所以，红黑树的插入、删除、查找各种操作性能都比较稳定。对于工程应用来说，要面对各种异常情况，为了支撑这种工业级的应用，我们更倾向于这种性能稳定的平衡二叉查找树。

内容小结
很多同学都觉得红黑树很难，的确，它算是最难掌握的一种数据结构。其实红黑树最难的地方是它的实现，我们今天还没有涉及，下一节我会专门来讲。

不过呢，我认为，我们其实不应该把学习的侧重点，放到它的实现上。那你可能要问了，关于红黑树，我们究竟需要掌握哪些东西呢？

还记得我多次说过的观点吗？我们学习数据结构和算法，要学习它的由来、特性、适用的场景以及它能解决的问题。对于红黑树，也不例外。你如果能搞懂这几个问题，其实就已经足够了。

红黑树是一种平衡二叉查找树。它是为了解决普通二叉查找树在数据更新的过程中，复杂度退化的问题而产生的。红黑树的高度近似 log2n，所以它是近似平衡，插入、删除、查找操作的时间复杂度都是 O(logn)。

因为红黑树是一种性能非常稳定的二叉查找树，所以，在工程中，但凡是用到动态插入、删除、查找数据的场景，都可以用到它。不过，它实现起来比较复杂，如果自己写代码实现，难度会有些高，这个时候，我们其实更倾向用跳表来替代它。

课后思考
动态数据结构支持动态地数据插入、删除、查找操作，除了红黑树，我们前面还学习过哪些呢？能对比一下各自的优势、劣势，以及应用场景吗？

欢迎留言和我分享，我会第一时间给你反馈。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(68)

🐱您的好友William🐱
老师做图的软件用的是什么啊？我看了不少的极客时间的blog，感觉老师这个是最好看的哈哈。
2018-11-16


127

kakasi
散列表：插入删除查找都是O(1), 是最常用的，但其缺点是不能顺序遍历以及扩容缩容的性能损耗。适用于那些不需要顺序遍历，数据更新不那么频繁的。

跳表：插入删除查找都是O(logn), 并且能顺序遍历。缺点是空间复杂度O(n)。适用于不那么在意内存空间的，其顺序遍历和区间查找非常方便。

红黑树：插入删除查找都是O(logn), 中序遍历即是顺序遍历，稳定。缺点是难以实现，去查找不方便。其实跳表更佳，但红黑树已经用于很多地方了。
2018-12-02

3

80

Smallfly
动态数据结构的动态是什么意思？

动态是指在运行时该数据结构所占的内存会扩大或缩小。

数组是一种静态的数据结构，在创建时内存大小已经确定，不管有没有插入数据。而链表是动态的数据结构，插入数据 alloc 内存，删除数据 release 内存。

栈、队列、散列表、跳表、树都是抽象的数据结构，它们在内存中存在的形式都要依赖于数组或者链表。

如果用链表实现，很明显它们是动态的数据结构；如果用数组实现，那么在扩容的时候会创建更大内存的数组，原数组被废弃，从抽象角度看，它们仍旧是动态的。
作者回复: 我看smallfly大牛好像对动态数据结构有些误解，可能其他同学也会有。所以，我解释一下：动态数据结构是支持动态的更新操作，里面存储的数据是时刻在变化的，通俗一点讲，它不仅仅支持查询，还支持删除、插入数据。而且，这些操作都非常高效。如果不高效，也就算不上是有效的动态数据结构了。所以，这里的红黑树算一个，支持动态的插入、删除、查找，而且效率都很高。链表、队列、栈实际上算不上，因为操作非常有限，查询效率不高。那现在你再想一下还有哪些支持动态插入、删除、查找数据并且效率都很高的的数据结构呢？？

2018-11-16


59

allan
看了这篇文章还是有很多疑惑，主要是 不理解红黑树满足的几个性质，为什么要那样要求？
2018-12-02


45

fy
老师，可以教我们刷下leetcode上的算法，毕竟讲了这么多，还是练习的。这样的提升才有巨大的帮助
2018-11-18


36

王争
我看smallfly大牛好像对动态数据结构有些误解，可能其他同学也会有。所以，我解释一下：动态数据结构是支持动态的更新操作，里面存储的数据是时刻在变化的，通俗一点讲，它不仅仅支持查询，还支持删除、插入数据。而且，这些操作都非常高效。如果不高效，也就算不上是有效的动态数据结构了。所以，这里的红黑树算一个，支持动态的插入、删除、查找，而且效率都很高。链表、队列、栈实际上算不上，因为操作非常有限，查询效率不高。那现在你再想一下还有哪些支持动态插入、删除、查找数据并且效率都很高的的数据结构呢？？
2018-11-16


36

失火的夏天
动态数据结构有链表，栈，队列，哈希表等等。链表适合遍历的场景，插入和删除操作方便，栈和队列可以算一种特殊的链表，分别适用先进后出和先进先出的场景。哈希表适合插入和删除比较少（尽量少的扩容和缩容），查找比较多的时候。红黑树对数据要求有序，对数据增删查都有一定要求的时候。（个人看法，欢迎老师指正）
作者回复: 👍 刚看错了。写的不错

2018-11-16


16

蜗牛行天下
我觉得红黑树对于我们初学者来说最大的疑惑是，红黑节点有什么区别，是怎么演化来的？老师讲的很好，但是这个问题并没有在文中解决，所以不能深刻地理解红黑树的存在价值。我找到一篇文章，在这方面讲的很清楚，可以作为这篇讲义的补充：https://www.cnblogs.com/tiancai/p/9072813.html
2019-01-31

2

15

null
红黑树的节点颜色，是如何确定的，如何知道在新增一个节点时，该节点是什么颜色？

从红黑树需要满足的四个要求来看：
1. 根节点为黑色
2. 所有叶子节点为黑色，且不存储数据
3. 相邻两个节点不能都为红色
4. 从某节点到其所有叶子节点的路径中，黑色节点数相同

从这四点要求，好像我一根树全是黑色，也是满足其定义的。这里用红黑两色区分各节点，意义是啥？

谢谢老师
作者回复: 新插入的节点都是红色的。全黑不可能的。红黑区分的意义你等下一节课看看能懂不

2018-11-16


9

不似旧日
没明白红节点与黑节点的存在意义
2019-01-03


7

有铭
我除了看懂红黑树是一种“性能上比较均衡”的二叉树这个结论外，完全没搞懂它为啥能获得这个“比较平衡”的结果
2018-11-16


7

朱月俊
动态数据结构比如本篇的平衡二叉查找树，还有就是跳表，跳表也支持动态插入，删除，查询，也很快，不同点是跳表还能支持快速的范围查询。比如leveldb中的memtable，redis都是使用跳表实现的，而也有用红黑树实现的memtable。
除此之外，跳表还支持多写多读，而红黑树不可以，这些场景下显然用跳表合适。
2018-11-17


5

increasingly
请问什么是单次操作时间非常敏感的场景呢
作者回复: 比如有些系统只关注操作的平均执行时间，大部分操作都很快，比如1s，极个别操作可能花费很多时间10s，但平均下来，整体上都很快，所以也能接受。

但是有的系统不仅仅关注平均执行时间，对单次操作的时间非常敏感，极个别的10s操作也是无法接受的。

2019-02-21


3

！null
没太看懂去掉红色节点生成全黑四叉树，又把红色节点加进去的目的是什么？感觉不懂这个整个红黑树就没学懂。
2018-11-21


3

wean
“我们从四叉树中取出某些节点，放到叶节点位置，四叉树就变成了完全二叉树”

老师，这里的某些节点应该怎么取，才能让四叉树变成二叉树，不是很明白，希望老师讲解一下，谢谢
2018-11-16


3

建强
动态数据结构还包括以下几种：
1.链表：
优势：高效地数据插入、删除。
缺点：随机查找元素效率较低。
适用场景：适用于顺序访问数据，数据维护较频繁的场合。

2.哈希链表
优势：高效地数据插入、删除、随机查找元素。
缺点：需要设计一个好的散列函数，把元素均匀分散到散列表中。
适用场景：适用于在海量数据中随机访问数据的场合。

3.跳表
优势：高效地查找、插入、删除数据。
缺点：需要额外的空间来构建索引链表
适用场景：适用于需要高效查找数据的场合。

4.二叉查找树
优势：高效地查找、插入、删除数据，实现简单。
缺点：需要动态地维护左右子树的高度平衡，否则数据查找会退化成链表的顺序查找。
适用场景：适用于需要高效查找数据的场合。
2019-07-07


2

S.S Mr Lin
很多讲红黑树的地方都没讲2-3-4树，其实如果看懂了2-3-4树，再来看红黑树就特别好理解了。我一般会问别人，红黑树的黑节点代表了什么？如果理解了，就会知道黑节点代表了近似平衡高度，所有黑节点的定义都是为了保证这一点。
2019-03-22


2

Laughing_Lz
老师，你这里提到：我画了两个红黑树的图例，你可以对照着看下。
这下面的两张图，左边第一个，四个叶子节点都是红色呀？我有点看不懂。。
规则不是说叶子节点都是不存储数据的黑色空节点吗？这里是不是画错了？
如果你是说省略了黑色叶子节点，那就是说这四个红色节点下其实还有叶子节点？但是这样又不能满足规则四：每个节点，从该节点到达其可达叶子节点的所有路径，都包含相同数目的黑色节点...除非第三层的第三个黑色子节点下也有叶子节点？
作者回复: 是的 都会有nil的黑色叶子节点的

2018-12-02


2

丁卯兔
动态的数据结构可能跳跃链表算一个，实现比红黑树简单，查询，删除，插入都可以；大顶堆，小顶堆应该也还行。
2018-11-28


2

farFlight
老师好，请问之后讲到heap sort这些的时候会提到斐波那契堆吗？最近在看相关但是觉得网上的资料讲得都不太清楚。
2018-11-16


2
收起评论

6899+






# 26 | 红黑树（下）：掌握这些技巧，你也可以实现一个红黑树




数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



26 | 红黑树（下）：掌握这些技巧，你也可以实现一个红黑树
王争 2018-11-19



15:03
讲述：修阳 大小：6.90M
红黑树是一个让我又爱又恨的数据结构，“爱”是因为它稳定、高效的性能，“恨”是因为实现起来实在太难了。我今天讲的红黑树的实现，对于基础不太好的同学，理解起来可能会有些困难。但是，我觉得没必要去死磕它。

我为什么这么说呢？因为，即便你将左右旋背得滚瓜烂熟，我保证你过不几天就忘光了。因为，学习红黑树的代码实现，对于你平时做项目开发没有太大帮助。对于绝大部分开发工程师来说，这辈子你可能都用不着亲手写一个红黑树。除此之外，它对于算法面试也几乎没什么用，一般情况下，靠谱的面试官也不会让你手写红黑树的。

如果你对数据结构和算法很感兴趣，想要开拓眼界、训练思维，我还是很推荐你看一看这节的内容。但是如果学完今天的内容你还觉得懵懵懂懂的话，也不要纠结。我们要有的放矢去学习。你先把平时要用的、基础的东西都搞会了，如果有余力了，再来深入地研究这节内容。

好，我们现在就进入正式的内容。上一节，我们讲到红黑树定义的时候，提到红黑树的叶子节点都是黑色的空节点。当时我只是粗略地解释了，这是为了代码实现方便，那更加确切的原因是什么呢？ 我们这节就来说一说。

实现红黑树的基本思想
不知道你有没有玩过魔方？其实魔方的复原解法是有固定算法的：遇到哪几面是什么样子，对应就怎么转几下。你只要跟着这个复原步骤，就肯定能将魔方复原。

实际上，红黑树的平衡过程跟魔方复原非常神似，大致过程就是：遇到什么样的节点排布，我们就对应怎么去调整。只要按照这些固定的调整规则来操作，就能将一个非平衡的红黑树调整成平衡的。

还记得我们前面讲过的红黑树的定义吗？今天的内容里，我们会频繁用到它，所以，我们现在再来回顾一下。一棵合格的红黑树需要满足这样几个要求：

根节点是黑色的；

每个叶子节点都是黑色的空节点（NIL），也就是说，叶子节点不存储数据；

任何相邻的节点都不能同时为红色，也就是说，红色节点是被黑色节点隔开的；

每个节点，从该节点到达其可达叶子节点的所有路径，都包含相同数目的黑色节点。

在插入、删除节点的过程中，第三、第四点要求可能会被破坏，而我们今天要讲的“平衡调整”，实际上就是要把被破坏的第三、第四点恢复过来。

在正式开始之前，我先介绍两个非常重要的操作，左旋（rotate left）、右旋（rotate right）。左旋全称其实是叫围绕某个节点的左旋，那右旋的全称估计你已经猜到了，就叫围绕某个节点的右旋。

我们下面的平衡调整中，会一直用到这两个操作，所以我这里画了个示意图，帮助你彻底理解这两个操作。图中的 a，b，r 表示子树，可以为空。



前面我说了，红黑树的插入、删除操作会破坏红黑树的定义，具体来说就是会破坏红黑树的平衡，所以，我们现在就来看下，红黑树在插入、删除数据之后，如何调整平衡，继续当一棵合格的红黑树的。

插入操作的平衡调整
首先，我们来看插入操作。

红黑树规定，插入的节点必须是红色的。而且，二叉查找树中新插入的节点都是放在叶子节点上。所以，关于插入操作的平衡调整，有这样两种特殊情况，但是也都非常好处理。

如果插入节点的父节点是黑色的，那我们什么都不用做，它仍然满足红黑树的定义。

如果插入的节点是根节点，那我们直接改变它的颜色，把它变成黑色就可以了。

除此之外，其他情况都会违背红黑树的定义，于是我们就需要进行调整，调整的过程包含两种基础的操作：左右旋转和改变颜色。

红黑树的平衡调整过程是一个迭代的过程。我们把正在处理的节点叫作关注节点。关注节点会随着不停地迭代处理，而不断发生变化。最开始的关注节点就是新插入的节点。

新节点插入之后，如果红黑树的平衡被打破，那一般会有下面三种情况。我们只需要根据每种情况的特点，不停地调整，就可以让红黑树继续符合定义，也就是继续保持平衡。

我们下面依次来看每种情况的调整过程。提醒你注意下，为了简化描述，我把父节点的兄弟节点叫作叔叔节点，父节点的父节点叫作祖父节点。

CASE 1：如果关注节点是 a，它的叔叔节点 d 是红色，我们就依次执行下面的操作：

将关注节点 a 的父节点 b、叔叔节点 d 的颜色都设置成黑色；

将关注节点 a 的祖父节点 c 的颜色设置成红色；

关注节点变成 a 的祖父节点 c；

跳到 CASE 2 或者 CASE 3。



CASE 2：如果关注节点是 a，它的叔叔节点 d 是黑色，关注节点 a 是其父节点 b 的右子节点，我们就依次执行下面的操作：

关注节点变成节点 a 的父节点 b；

围绕新的关注节点b 左旋；

跳到 CASE 3。



CASE 3：如果关注节点是 a，它的叔叔节点 d 是黑色，关注节点 a 是其父节点 b 的左子节点，我们就依次执行下面的操作：

围绕关注节点 a 的祖父节点 c 右旋；

将关注节点 a 的父节点 b、兄弟节点 c 的颜色互换。

调整结束。



删除操作的平衡调整
红黑树插入操作的平衡调整还不是很难，但是它的删除操作的平衡调整相对就要难多了。不过原理都是类似的，我们依旧只需要根据关注节点与周围节点的排布特点，按照一定的规则去调整就行了。

删除操作的平衡调整分为两步，第一步是针对删除节点初步调整。初步调整只是保证整棵红黑树在一个节点删除之后，仍然满足最后一条定义的要求，也就是说，每个节点，从该节点到达其可达叶子节点的所有路径，都包含相同数目的黑色节点；第二步是针对关注节点进行二次调整，让它满足红黑树的第三条定义，即不存在相邻的两个红色节点。

1. 针对删除节点初步调整
这里需要注意一下，红黑树的定义中“只包含红色节点和黑色节点”，经过初步调整之后，为了保证满足红黑树定义的最后一条要求，有些节点会被标记成两种颜色，“红 - 黑”或者“黑 - 黑”。如果一个节点被标记为了“黑 - 黑”，那在计算黑色节点个数的时候，要算成两个黑色节点。

在下面的讲解中，如果一个节点既可以是红色，也可以是黑色，在画图的时候，我会用一半红色一半黑色来表示。如果一个节点是“红 - 黑”或者“黑 - 黑”，我会用左上角的一个小黑点来表示额外的黑色。

CASE 1：如果要删除的节点是 a，它只有一个子节点 b，那我们就依次进行下面的操作：

删除节点 a，并且把节点 b 替换到节点 a 的位置，这一部分操作跟普通的二叉查找树的删除操作一样；

节点 a 只能是黑色，节点 b 也只能是红色，其他情况均不符合红黑树的定义。这种情况下，我们把节点 b 改为黑色；

调整结束，不需要进行二次调整。



CASE 2：如果要删除的节点 a 有两个非空子节点，并且它的后继节点就是节点 a 的右子节点 c。我们就依次进行下面的操作：

如果节点 a 的后继节点就是右子节点 c，那右子节点 c 肯定没有左子树。我们把节点 a 删除，并且将节点 c 替换到节点 a 的位置。这一部分操作跟普通的二叉查找树的删除操作无异；

然后把节点 c 的颜色设置为跟节点 a 相同的颜色；

如果节点 c 是黑色，为了不违反红黑树的最后一条定义，我们给节点 c 的右子节点 d 多加一个黑色，这个时候节点 d 就成了“红 - 黑”或者“黑 - 黑”；

这个时候，关注节点变成了节点 d，第二步的调整操作就会针对关注节点来做。



CASE 3：如果要删除的是节点 a，它有两个非空子节点，并且节点 a 的后继节点不是右子节点，我们就依次进行下面的操作：

找到后继节点 d，并将它删除，删除后继节点 d 的过程参照 CASE 1；

将节点 a 替换成后继节点 d；

把节点 d 的颜色设置为跟节点 a 相同的颜色；

如果节点 d 是黑色，为了不违反红黑树的最后一条定义，我们给节点 d 的右子节点 c 多加一个黑色，这个时候节点 c 就成了“红 - 黑”或者“黑 - 黑”；

这个时候，关注节点变成了节点 c，第二步的调整操作就会针对关注节点来做。



2. 针对关注节点进行二次调整
经过初步调整之后，关注节点变成了“红 - 黑”或者“黑 - 黑”节点。针对这个关注节点，我们再分四种情况来进行二次调整。二次调整是为了让红黑树中不存在相邻的红色节点。

CASE 1：如果关注节点是 a，它的兄弟节点 c 是红色的，我们就依次进行下面的操作：

围绕关注节点 a 的父节点 b 左旋；

关注节点 a 的父节点 b 和祖父节点 c 交换颜色；

关注节点不变；

继续从四种情况中选择适合的规则来调整。



CASE 2：如果关注节点是 a，它的兄弟节点 c 是黑色的，并且节点 c 的左右子节点 d、e 都是黑色的，我们就依次进行下面的操作：

将关注节点 a 的兄弟节点 c 的颜色变成红色；

从关注节点 a 中去掉一个黑色，这个时候节点 a 就是单纯的红色或者黑色；

给关注节点 a 的父节点 b 添加一个黑色，这个时候节点 b 就变成了“红 - 黑”或者“黑 - 黑”；

关注节点从 a 变成其父节点 b；

继续从四种情况中选择符合的规则来调整。



CASE 3：如果关注节点是 a，它的兄弟节点 c 是黑色，c 的左子节点 d 是红色，c 的右子节点 e 是黑色，我们就依次进行下面的操作：

围绕关注节点 a 的兄弟节点 c 右旋；

节点 c 和节点 d 交换颜色；

关注节点不变；

跳转到 CASE 4，继续调整。



CASE 4：如果关注节点 a 的兄弟节点 c 是黑色的，并且 c 的右子节点是红色的，我们就依次进行下面的操作：

围绕关注节点 a 的父节点 b 左旋；

将关注节点 a 的兄弟节点 c 的颜色，跟关注节点 a 的父节点 b 设置成相同的颜色；

将关注节点 a 的父节点 b 的颜色设置为黑色；

从关注节点 a 中去掉一个黑色，节点 a 就变成了单纯的红色或者黑色；

将关注节点 a 的叔叔节点 e 设置为黑色；

调整结束。



解答开篇
红黑树的平衡调整就讲完了，现在，你能回答开篇的问题了吗？为什么红黑树的定义中，要求叶子节点是黑色的空节点？

要我说，之所以有这么奇怪的要求，其实就是为了实现起来方便。只要满足这一条要求，那在任何时刻，红黑树的平衡操作都可以归结为我们刚刚讲的那几种情况。

还是有点不好理解，我通过一个例子来解释一下。假设红黑树的定义中不包含刚刚提到的那一条“叶子节点必须是黑色的空节点”，我们往一棵红黑树中插入一个数据，新插入节点的父节点也是红色的，两个红色的节点相邻，这个时候，红黑树的定义就被破坏了。那我们应该如何调整呢？



你会发现，这个时候，我们前面讲的插入时，三种情况下的平衡调整规则，没有一种是适用的。但是，如果我们把黑色的空节点都给它加上，变成下面这样，你会发现，它满足 CASE 2 了。



你可能会说，你可以调整一下平衡调整规则啊。比如把 CASE 2 改为“如果关注节点 a 的叔叔节点 b 是黑色或者不存在，a 是父节点的右子节点，就进行某某操作”。当然可以，但是这样的话规则就没有原来简洁了。

你可能还会说，这样给红黑树添加黑色的空的叶子节点，会不会比较浪费存储空间呢？答案是不会的。虽然我们在讲解或者画图的时候，每个黑色的、空的叶子节点都是独立画出来的。实际上，在具体实现的时候，我们只需要像下面这样，共用一个黑色的、空的叶子节点就行了。



内容小结
“红黑树一向都很难学”，有这种想法的人很多。但是我感觉，其实主要原因是，很多人试图去记忆它的平衡调整策略。实际上，你只需要能看懂我讲的过程，没有知识盲点，就算是掌握了这部分内容了。毕竟实际的软件开发并不是闭卷考试，当你真的需要实现一个红黑树的时候，可以对照着我讲的步骤，一点一点去实现。

现在，我就来总结一下，如何比较轻松地看懂我今天讲的操作过程。

第一点，把红黑树的平衡调整的过程比作魔方复原，不要过于深究这个算法的正确性。你只需要明白，只要按照固定的操作步骤，保持插入、删除的过程，不破坏平衡树的定义就行了。

第二点，找准关注节点，不要搞丢、搞错关注节点。因为每种操作规则，都是基于关注节点来做的，只有弄对了关注节点，才能对应到正确的操作规则中。在迭代的调整过程中，关注节点在不停地改变，所以，这个过程一定要注意，不要弄丢了关注节点。

第三点，插入操作的平衡调整比较简单，但是删除操作就比较复杂。针对删除操作，我们有两次调整，第一次是针对要删除的节点做初步调整，让调整后的红黑树继续满足第四条定义，“每个节点到可达叶子节点的路径都包含相同个数的黑色节点”。但是这个时候，第三条定义就不满足了，有可能会存在两个红色节点相邻的情况。第二次调整就是解决这个问题，让红黑树不存在相邻的红色节点。

课后思考
如果你以前了解或者学习过红黑树，关于红黑树的实现，你也可以在留言区讲讲，你是怎样来学习的？在学习的过程中，有过什么样的心得体会？有没有什么好的学习方法？

欢迎留言和我分享，我会第一时间给你反馈。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(147)

沉睡的木木夕
感觉看不下去了，多层级的左旋右旋过程能不能再详细说一下？还有新增，删除那里的case几种情况，是不是就是说红黑树操作只有这几种情况？这里面的左右旋真的没搞懂
2018-11-19


107

失火的夏天
我看到老师说道要我举个例子，我不太清楚是我说的那个问题还是关于红黑树的理解，这里也分个区
一：我说的case3的情况是表示老师的画的那个图，case3图的例子根节点到左边叶子节点只经过2个黑色节点，到右边叶子节点却经过了3个黑色节点。

二：我这里就大概说下吧（一家之言，自己的一点经验，也希望别的同学来一起讨论）：
1.左旋右旋这个，个人还是认为要画图，不画图我自己也写不出那个代码……哈哈。

2.说到插入删除的算法，我说用到了递推，就比如插入的CASE1的情况，CASE1的处理之后，关注节点从本身变成了他的祖父节点（红色节点），这就是往根节点递推。不过我认为CASE1处理过一次之后，不一定会进入case2或者case3，是有可能还在case1的。

换句话说，就是可以在case1的情况下，一直往根节点走，因为当前节点永远是红色，所以在最后要把根节点涂黑。同时，只要进入到case2,case3的情况，就是变成平衡二叉树的单旋和双旋的情况，双旋的处理逻辑就是把双旋变成单旋（比如先右后左旋就是把树变成“左撇子”）。这个就变成了单左旋能一步到位处理的平衡了，这个就是归纳。把未知情况转化为已知，如果我没有记错的话，数学归纳法的核心思想就是递推和归纳。

3.其实我们只要记住，除了关注的节点所在的子树，其他的子树本身都是一颗红黑树，他们是满足红黑树的所有特征的。当关注节点往根节点递推时，这个时候关注节点的子树也已经满足了红黑树的定义，我们就不用再去特别关注子树的特征。只要注意关注节点往上的部分。这样就能把问题简化，思考的时候思路会清晰一些。

4.再说到删除算法，我看到很多同学没理解为什么要红-黑，黑-黑节点的出现。这里我的看法是，红黑树最不好控制的其实是最后一个的性质4（每个节点，从该节点到达其可达叶子节点的所有路径，都包含相同数目的黑色节点），因为你永远不知道别的子树到底有多少个黑色节点。这里加入红-黑，黑-黑节点就可以控制红黑树满足性质4，到时候要恢复颜色，只要去掉多余的黑色即可。

接下来的处理思路就是要满足：1.每个节点不是红的就是黑的，2.相邻节点不能是红的。这个思路计时变复杂为简单。

删除的case1情况，并没有真正处理，而且为了进入接下来的case2,case3,case4，这里又是之前说到的归纳思想。case2的情况又是一个递推思路，关注节点往根节点递推，让其左右子树都满足红黑树的定义。因为往上推，右子树多了一个黑色节点，就把关注节点的兄弟节点变红，使其满足性质4.

删除的case3是为了进入case4，提前变色的原因和case2是一样的，都是为了满足性质4。同样是归纳推理的思路。都要记住一点，各种case下的其他子树节点都满足红黑树的定义，需要分类讨论的，都在这几种case情况中了。

4.最后的建议，其实说了这么多，很多的表达都不太清楚，但是个人感觉，数学基础好的同学，理解红黑树会好一些，学习的时候多画画图，人对图形的敏感肯定比文字高，另外的就是大家可以去看看源码，本人是做java开发的，jdk1.8的treemap就是用红黑树实现的，跟着源码多看看，跟着老师的说明或者百度上的教程思考，动笔画画图，都能理解的。我自己看jdk源码的也是看了将近两个月才大概明白（因为也在上班，只有晚上有一些时间来看看代码）。学习的过程中要耐心，学习红黑树本身也不是为了“默写”，而是去学习思想，锻炼思维，复杂问题简单化，新问题转化为已解决过的问题等等。其实说到最后，都是用到了数学的思维，这些思维都会在潜移默化中影响到自己。

ps:本人并不是什么大牛，不会的东西也是很多很多，上面只是自己的一点感想。老师的建议很多，不要太去扣细节，我们要在一个整体的角度上去看红黑树是怎么处理的，知道他的应用场景，什么时候要用他，什么时候该用他，为什么要用他。这几个地方弄清楚，大部分就够了，我们要有的放矢，抓准学习的核心内容。
作者回复: 👍 倾佩

2018-11-20

1

86

凡
文章还没看完，前面的就忘了
2018-11-19

2

55

pplegend
我决定了 放弃研究红黑树了，如果面试遇到算我倒霉，人生要学会放弃一些东西
2019-03-20

3

45

。。。
红黑树是由2-3树演变过来的，父节点指向的节点是红节点，那么就认为这两个节点其实是2-3树里面的3节点。如果有一个黑节点链接了两个红节点，那么就认为这是一个4-节点，因为2-3树不允许4-节点所以要将其提取出来。所谓的旋转。对于2-3树来说节点并没有变化。因为 红节点和指向他的节点本来就被认为是一个节点。建议看《算法》。里面讲了红黑树的精髓。看完以后怎么旋转怎么写红黑树就都知道了
2018-11-21

1

43

凉粉
一脸懵
2018-11-19


29

沉睡的木木夕
回到家我又翻看了《算法导论》中红黑树章节，又似乎加了点理解。
虽然里面时间复杂度依旧是用数学推导出来的，我看不懂，不过里面讲的红黑树5个性质：
1.每个节点不是红色就是黑色
2.根节点是黑色
3.每个叶子结点（NIL）是黑色的
4.如果一个节点是红色的，则他的两个子节点都是黑色的
5.对每个子结点，从该结点到其所有后代叶子结点的简单路劲上，均包含相同数目的黑色结点
后面讲到的3种情况都是为了满足这5点特性而做出的相应的变化
老师在讲解左右旋的时候一张图就概括了，说实话我第一时间真没看懂，花了大量时间这方面的理解，后来在《算法导论》中居然找到了浅显易懂的中文描述左右旋的过程，我概述为3点
1.左右旋操作中，只有指针的改变，其他所有属性都保持不变
2.左旋的过程与右旋的过程是对称的（伪代码也是对称的）
3.左旋为例，以x结点左旋，那么y成为该子树的跟结点，x成为y的左子结点，y的左子结点成为x的右子结点（所以右旋就是反过来的）
那么当多层级的呢，也就是文中case3中的右旋过程，因为是a的曾祖父结点来进行右旋，所以文中的“c”就是x，“a和b”就是y，那么右旋用文字描述就是“y（a,b）成为跟结点，x（c）成为y的右结点，y的右结点成为x的左结点，其他指针不变”
得到的子树结构然后根据前面说的5个特性（同老师说的4点特征）再做出响应的颜色变化
～～～～
唉，真是智商捉急
作者回复: 👍

2018-11-20

1

25

zixuan
这个不是设计而是推导出来的，源自2-3树 https://blog.csdn.net/fei33423/article/details/79132930
2018-11-19


24

ban
1、没看懂哪个节点跟哪个节点左旋或者右旋
2、为什么要有红/黑节点，为什么要有红-黑 黑-黑，作用是什么
2018-11-19


20

iron_man
红黑树是2-3树的变形，以2-3树的角度去理解红黑树就简单了，作者可以结合2-3数来讲讲红黑树插入删除节点时的各种操作
2018-11-19


15

Andylee
看到删除的部分突然懵了，什么时候多了一个红黑，黑黑，一个节点两个颜色的概念了……
2018-11-19


11

任旭东
老师能讲一下调整策略是怎么推出来的么？就像数学公式一样，只知道公式，不知道推理过程很难理解😂
2018-11-19


11

xiao皮孩。。
说实话，前几章都看懂了，这个真没懂
2019-02-15


7

数据结构和算法
这个图文结合对红黑树公析的很详细https://blog.csdn.net/abcdef314159/article/details/77193888
2018-11-30


7

花仙子
您好，老师有一点不太明白，就是删除操作时，以初步调整为例，case3的情况下，原文（如果节点 d 是黑色，为了不违反红黑树的最后一条定义，我们给节点 d 的右子节点 c 多加一个黑色，这个时候节点 c 就成了“红 - 黑”或者“黑 - 黑”；），最后一条是（每个节点，从该节点到达其可达叶子节点的所有路径，都包含相同数数目的黑色节点。），能理解要给节点 d 的右子节点 c 多加一个黑色，但图中的表示方法没看明白，引文原来的d节点是在c和e之间，所以所加的黑色节点是不是也应该在c和e之间，这点不太确定影响后边大半部分的理解，还请老师不吝赐教，多谢，真的挺焦急的
2018-11-28


6

往事随风，顺其自然
为什么红黑和黑黑这样来标注，这两种看成是黑色还是红色，什么时候当成黑色，什么时候当成红色
2018-11-19


6

失火的夏天
先提一个问题：老师，插入的case3情况是不是不满足红黑树的第四个条件？根节点到左边的叶子节点只经过两个黑色节点，但是根节点到右边的却经过三个黑色节点。

学习红黑树在于理解他的思想，比如为什么要旋转，是因为高度不平衡。为什么有双旋，因为单旋没法一步到位，所以把一个新问题转化为已经解决过的问题。旋转的学习其实自己画一下图，一步步走，数形结合的思想用上就好。插入的核心思想就是，把红色节点往根节点递推，然后把根节点涂黑。删除同样是往根节点递推，转化成处理过的情况因为越靠近根节点，节点关系也就越清晰。其实红黑树的处理也有动态规划的思想，只有处理的这个节点子树是可能破坏的，而其他节点子树都是红黑树，都满足红黑树的定义。用数学归纳法的思路来想这些问题，感觉就不会被复杂的情况搞得头晕。
作者回复: 能否举个例子呢

2018-11-19


6

qinggeouye
试着理解了一下「实现红黑树的基本思想」图例 1 中左旋和右旋的概念，可以将图例 1 中的树看作一个定滑轮：

围绕节点 X 的左旋：
拉住节点 X 左边的 a 子树，向下拉，将节点 Y 拉到节点 X 的位置，a 子树仍是节点 X 的左子树，而节点 X 成为了节点 Y 的左子节点，那么就将原先节点 Y 的左子树 b 摘下来，变成节点 X 的右子树；

同理，围绕节点 X 的右旋：
拉住节点 X 右边的 r 子树，向下拉，将节点 Y 拉到节点 X 的位置，a 子树仍是节点 Y 的左子树，而节点 X 成为了节点 Y 的右子节点，那么就将原先节点 Y 的右子树 b 摘下来，变成节点 X 的左子树；
2018-12-05

1

5

卡罗
魔方还原公式总共200多种，要全部背下来并熟练运用，花的时间因人而异。我觉得这和你完全要掌握红黑树一样，你需要把每种情况都熟记，方能熟练运用。
2018-11-19


5

daemon
这么讲不好懂哈，从源头来吧，一开始凭空扔一堆红性质让人不解，为什么维持平衡要有这几个性质呢，建议调整下讲法，比如从2-3树开始，一步步从原理来理解红黑树
2019-06-25

1

3
收起评论

99+99+






# 27 | 递归树：如何借助树来求解递归算法的时间复杂度？



数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



27 | 递归树：如何借助树来求解递归算法的时间复杂度？
王争 2018-11-21



12:28
讲述：修阳 大小：5.72M
今天，我们来讲树这种数据结构的一种特殊应用，递归树。

我们都知道，递归代码的时间复杂度分析起来很麻烦。我们在第 12 节《排序（下）》那里讲过，如何利用递推公式，求解归并排序、快速排序的时间复杂度，但是，有些情况，比如快排的平均时间复杂度的分析，用递推公式的话，会涉及非常复杂的数学推导。

除了用递推公式这种比较复杂的分析方法，有没有更简单的方法呢？今天，我们就来学习另外一种方法，借助递归树来分析递归算法的时间复杂度。

递归树与时间复杂度分析
我们前面讲过，递归的思想就是，将大问题分解为小问题来求解，然后再将小问题分解为小小问题。这样一层一层地分解，直到问题的数据规模被分解得足够小，不用继续递归分解为止。

如果我们把这个一层一层的分解过程画成图，它其实就是一棵树。我们给这棵树起一个名字，叫作递归树。我这里画了一棵斐波那契数列的递归树，你可以看看。节点里的数字表示数据的规模，一个节点的求解可以分解为左右子节点两个问题的求解。



通过这个例子，你对递归树的样子应该有个感性的认识了，看起来并不复杂。现在，我们就来看，如何用递归树来求解时间复杂度。

归并排序算法你还记得吧？它的递归实现代码非常简洁。现在我们就借助归并排序来看看，如何用递归树，来分析递归代码的时间复杂度。

归并排序的原理我就不详细介绍了，如果你忘记了，可以回看一下第 12 节的内容。归并排序每次会将数据规模一分为二。我们把归并排序画成递归树，就是下面这个样子：



因为每次分解都是一分为二，所以代价很低，我们把时间上的消耗记作常量 1。归并算法中比较耗时的是归并操作，也就是把两个子数组合并为大数组。从图中我们可以看出，每一层归并操作消耗的时间总和是一样的，跟要排序的数据规模有关。我们把每一层归并操作消耗的时间记作 n。

现在，我们只需要知道这棵树的高度 h，用高度 h 乘以每一层的时间消耗 n，就可以得到总的时间复杂度 O(n∗h)。

从归并排序的原理和递归树，可以看出来，归并排序递归树是一棵满二叉树。我们前两节中讲到，满二叉树的高度大约是 log2n，所以，归并排序递归实现的时间复杂度就是 O(nlogn)。我这里的时间复杂度都是估算的，对树的高度的计算也没有那么精确，但是这并不影响复杂度的计算结果。

利用递归树的时间复杂度分析方法并不难理解，关键还是在实战，所以，接下来我会通过三个实际的递归算法，带你实战一下递归的复杂度分析。学完这节课之后，你应该能真正掌握递归代码的复杂度分析。

实战一：分析快速排序的时间复杂度
在用递归树推导之前，我们先来回忆一下用递推公式的分析方法。你可以回想一下，当时，我们为什么说用递推公式来求解平均时间复杂度非常复杂？

快速排序在最好情况下，每次分区都能一分为二，这个时候用递推公式 T(n)=2T(n2)+n，很容易就能推导出时间复杂度是 O(nlogn)。但是，我们并不可能每次分区都这么幸运，正好一分为二。

我们假设平均情况下，每次分区之后，两个分区的大小比例为 1:k。当 k=9 时，如果用递推公式的方法来求解时间复杂度的话，递推公式就写成 T(n)=T(n10)+T(9n10)+n。

这个公式可以推导出时间复杂度，但是推导过程非常复杂。那我们来看看，用递归树来分析快速排序的平均情况时间复杂度，是不是比较简单呢？

我们还是取 k 等于 9，也就是说，每次分区都很不平均，一个分区是另一个分区的 9 倍。如果我们把递归分解的过程画成递归树，就是下面这个样子：



快速排序的过程中，每次分区都要遍历待分区区间的所有数据，所以，每一层分区操作所遍历的数据的个数之和就是 n。我们现在只要求出递归树的高度 h，这个快排过程遍历的数据个数就是 h∗n ，也就是说，时间复杂度就是 O(h∗n)。

因为每次分区并不是均匀地一分为二，所以递归树并不是满二叉树。这样一个递归树的高度是多少呢？

我们知道，快速排序结束的条件就是待排序的小区间，大小为 1，也就是说叶子节点里的数据规模是 1。从根节点 n 到叶子节点 1，递归树中最短的一个路径每次都乘以 110，最长的一个路径每次都乘以 910。通过计算，我们可以得到，从根节点到叶子节点的最短路径是 log10n，最长的路径是 log109n。



所以，遍历数据的个数总和就介于 nlog10n 和 nlog109n 之间。根据复杂度的大 O 表示法，对数复杂度的底数不管是多少，我们统一写成 logn，所以，当分区大小比例是 1:9 时，快速排序的时间复杂度仍然是 O(nlogn)。

刚刚我们假设 k=9，那如果 k=99，也就是说，每次分区极其不平均，两个区间大小是 1:99，这个时候的时间复杂度是多少呢？

我们可以类比上面 k=9 的分析过程。当 k=99 的时候，树的最短路径就是 log100n，最长路径是 log10099n，所以总遍历数据个数介于 nlog100n 和 nlog10099n 之间。尽管底数变了，但是时间复杂度也仍然是 O(nlogn)。

也就是说，对于 k 等于 9，99，甚至是 999，9999……，只要 k 的值不随 n 变化，是一个事先确定的常量，那快排的时间复杂度就是 O(nlogn)。所以，从概率论的角度来说，快排的平均时间复杂度就是 O(nlogn)。

实战二：分析斐波那契数列的时间复杂度
在递归那一节中，我们举了一个跨台阶的例子，你还记得吗？那个例子实际上就是一个斐波那契数列。为了方便你回忆，我把它的代码实现贴在这里。

int f(int n) {
  if (n == 1) return 1;
  if (n == 2) return 2;
  return f(n-1) + f(n-2);
}
这样一段代码的时间复杂度是多少呢？你可以先试着分析一下，然后再来看，我是怎么利用递归树来分析的。

我们先把上面的递归代码画成递归树，就是下面这个样子：



这棵递归树的高度是多少呢？

f(n) 分解为 f(n−1) 和 f(n−2)，每次数据规模都是 −1 或者 −2，叶子节点的数据规模是 1 或者 2。所以，从根节点走到叶子节点，每条路径是长短不一的。如果每次都是 −1，那最长路径大约就是 n；如果每次都是 −2，那最短路径大约就是 n2。

每次分解之后的合并操作只需要一次加法运算，我们把这次加法运算的时间消耗记作 1。所以，从上往下，第一层的总时间消耗是 1，第二层的总时间消耗是 2，第三层的总时间消耗就是 22。依次类推，第 k 层的时间消耗就是 2k−1，那整个算法的总的时间消耗就是每一层时间消耗之和。

如果路径长度都为 n，那这个总和就是 2n−1。



如果路径长度都是 n2 ，那整个算法的总的时间消耗就是 2n2−1。



所以，这个算法的时间复杂度就介于 O(2n) 和 O(2n2) 之间。虽然这样得到的结果还不够精确，只是一个范围，但是我们也基本上知道了上面算法的时间复杂度是指数级的，非常高。

实战三：分析全排列的时间复杂度
前面两个复杂度分析都比较简单，我们再来看个稍微复杂的。

我们在高中的时候都学过排列组合。“如何把 n 个数据的所有排列都找出来”，这就是全排列的问题。

我来举个例子。比如，1，2，3 这样 3 个数据，有下面这几种不同的排列：

1, 2, 3
1, 3, 2
2, 1, 3
2, 3, 1
3, 1, 2
3, 2, 1
如何编程打印一组数据的所有排列呢？这里就可以用递归来实现。

如果我们确定了最后一位数据，那就变成了求解剩下 n−1 个数据的排列问题。而最后一位数据可以是 n 个数据中的任意一个，因此它的取值就有 n 种情况。所以，“n 个数据的排列”问题，就可以分解成 n 个“n−1 个数据的排列”的子问题。

如果我们把它写成递推公式，就是下面这个样子：

假设数组中存储的是 1，2， 3...n。
        
f(1,2,...n) = {最后一位是 1, f(n-1)} + {最后一位是 2, f(n-1)} +...+{最后一位是 n, f(n-1)}。
如果我们把递推公式改写成代码，就是下面这个样子：

// 调用方式：
// int[]a = a={1, 2, 3, 4}; printPermutations(a, 4, 4);
// k 表示要处理的子数组的数据个数
public void printPermutations(int[] data, int n, int k) {
  if (k == 1) {
    for (int i = 0; i < n; ++i) {
      System.out.print(data[i] + " ");
    }
    System.out.println();
  }
 
  for (int i = 0; i < k; ++i) {
    int tmp = data[i];
    data[i] = data[k-1];
    data[k-1] = tmp;
 
    printPermutations(data, n, k - 1);
 
    tmp = data[i];
    data[i] = data[k-1];
    data[k-1] = tmp;
  }
}
如果不用我前面讲的递归树分析方法，这个递归代码的时间复杂度会比较难分析。现在，我们来看下，如何借助递归树，轻松分析出这个代码的时间复杂度。

首先，我们还是画出递归树。不过，现在的递归树已经不是标准的二叉树了。



第一层分解有 n 次交换操作，第二层有 n 个节点，每个节点分解需要 n−1 次交换，所以第二层总的交换次数是 n∗(n−1)。第三层有 n∗(n−1) 个节点，每个节点分解需要 n−2 次交换，所以第三层总的交换次数是 n∗(n−1)∗(n−2)。

以此类推，第 k 层总的交换次数就是 n∗(n−1)∗(n−2)∗…∗(n−k+1)。最后一层的交换次数就是 n∗(n−1)∗(n−2)∗…∗2∗1。每一层的交换次数之和就是总的交换次数。

n + n*(n-1) + n*(n-1)*(n-2) +... + n*(n-1)*(n-2)*...*2*1
这个公式的求和比较复杂，我们看最后一个数，n∗(n−1)∗(n−2)∗…∗2∗1 等于 n!，而前面的 n−1 个数都小于最后一个数，所以，总和肯定小于 n∗n!，也就是说，全排列的递归算法的时间复杂度大于 O(n!)，小于 O(n∗n!)，虽然我们没法知道非常精确的时间复杂度，但是这样一个范围已经让我们知道，全排列的时间复杂度是非常高的。

这里我稍微说下，掌握分析的方法很重要，思路是重点，不要纠结于精确的时间复杂度到底是多少。

内容小结
今天，我们用递归树分析了递归代码的时间复杂度。加上我们在排序那一节讲到的递推公式的时间复杂度分析方法，我们现在已经学习了两种递归代码的时间复杂度分析方法了。

有些代码比较适合用递推公式来分析，比如归并排序的时间复杂度、快速排序的最好情况时间复杂度；有些比较适合采用递归树来分析，比如快速排序的平均时间复杂度。而有些可能两个都不怎么适合使用，比如二叉树的递归前中后序遍历。

时间复杂度分析的理论知识并不多，也不复杂，掌握起来也不难，但是，在我们平时的工作、学习中，面对的代码千差万别，能够灵活应用学到的复杂度分析方法，来分析现有的代码，并不是件简单的事情，所以，你平时要多实战、多分析，只有这样，面对任何代码的时间复杂度分析，你才能做到游刃有余、毫不畏惧。

课后思考
1 个细胞的生命周期是 3 小时，1 小时分裂一次。求 n 小时后，容器内有多少细胞？请你用已经学过的递归时间复杂度的分析方法，分析一下这个递归问题的时间复杂度。

欢迎留言和我分享，我会第一时间给你反馈。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(105)

farFlight
假设细胞到了第三个小时是先分裂完再死亡，那么递推公式就应该是：
f(n) = f(n-1)*2 - f(n-3)
一次乘法和一次减法一起看作一次基本操作消耗，那么情况和斐波那契数列很像。
最高的树应该有n层， 最短的是n/3层，每层操作数都是指数增长。
那么时间复杂度应该是在O(2^n)量级的。
2018-11-21

2

228

qinggeouye
有些同学不明白点赞第一的意思，在此试着解释一下。

假设细胞先分裂再死亡，即，每个细胞分裂三次后死亡（存活三个小时）。

n 从第 0 个小时开始，

n = 0，f(0) = 1

n = 1，f(1) = 2*f(1)

n = 2，f(2) = 2*f(1)

n = 3，f(3) = 2*f(2) - f(0) ，减去存活了三个小时的细胞个数。

n = 4，f(4) = 2*f(3) - f(1)，减去存活了三个小时的细胞个数。

以此类推：

f(n) = 2*f(n-1) - f(n-3)，减去存活了三个小时的细胞个数。
2018-12-20

3

131

Jerry银银
说个有意思的现象，我平时除了看专栏本身的内容，我也会看留言。我发现从专栏开始时，精品留言点赞数达到500多，随着专栏的前行，点赞的人越来越少了😄

从中，也能发现端倪。

这挺有意思的
2018-11-27

1

74

Bryce
点赞第一的递推可能有些问题，这里假设经过三个小时的细胞分裂后再死亡。
通过留言可以看出有些同学可能没搞明白细胞分裂的方式，根据题意，细胞的生命周期是三个小时，一个小时后，第一个细胞分裂，此时细胞总数变成 2，但是这两个细胞的生存时间是不一样的，如果都当成新生细胞即存活时间为 0，那么给定的 3小时生命周期也就没意义了，所以这个时候其中一个细胞的生存时间变成了 1，另外一个刚分裂出来的是 0，下面简单表示一下分裂进程（-1 表示死亡）
时间 细胞状态 (生存时间) 细胞总数
  0 0 1
  1 1 0 2
  2 2 1 0 0 4
  3 -1 2 1 1 0 0 0 0 7
  4 -1 2 2 1 1 1 1 0 0 0 0 0 0 0 13
  5 -1 -1 2 2 2 2 1 1 1 1 1 1 1
                   0 0 0 0 0 0 0 0 0 0 0 0 0 24
  .... ............................................. ....
f0 = 1
f1 = 2
f2 = 4
f3 = 7
可以发现到第四个小时的时候，规律出来了，在第四个小时死亡的细胞是三小时前也就是第一个小时的时候同时出生的细胞，而在第一个小时同时出生的细胞数等于第一个小时前一个小时的细胞总数
所以有递推式：f(n) = 2 * f(n - 1) - f(n - 4)
2019-02-13

4

26

咬尖月牙儿
细胞分裂问题有个地方不解，1个细胞分裂之后不就变成2个新的细胞了，那么原来的细胞不就不存在了吗？那3小时后死亡怎么计算？
2019-01-15

2

21

菜鸡程序员
如果先分裂，经过画图发现 是1，2，4，7，13，24，44 发现应该是f(n)=2*f(n-1)-f(n-4) 置顶是错的
2018-12-27


19

纯洁的憎恶
思考题：
f0=1
f1=1+1=2
f2=1+1+2=4
f3=1+1+2+3-1=6 = f1 + f2
f4=1+1+2+3-1+5-1=10 = f2+f3
f5=1+1+2+4-1+5-1+8-2=16 = f3+f4
f（n）= f（n-1） + f（n-2）

与斐波那契数列的递归复杂度相同。
2018-11-21


19

Laughing_Lz
假设细胞到了第三个小时是先分裂完再死亡，递推公式为f(n) = 2f(n-1)-f(n-3)
假设细胞到了第三个小时是先死亡再其余的分裂，递推公式为f(n) = [f(n-1)-f(n-3)]*2
2018-12-06

1

16

于欣磊
打卡，立flag的同学少了一个数量级都不止啊
2018-11-23


15

朱凯
思路：f(n) = 2 * f(n-1) - 【n时刻点死掉的细胞数量】
而在【n时刻点死掉的细胞数量】就是【n-3时刻点新分裂的细胞数量】;【n-3时刻点新分裂的细胞数量】就是【n-4时刻点的细胞数总数】，即f(n-4)

故递推公式：f(n) = 2 * f(n-1) - f(n-4)
2019-02-20

1

11

komo0104
如果到了第三小时先分裂再死亡应该是f(n) = 2*f(n-1) - f(n-4)

—————————-
 
 public static int func(int hour){
   if(hour == 0) return 1;
   if(hour == 1) return 2;
   if(hour == 2) return 4;
   if(hour == 3) return 7;
   return 2*func(hour -1) - func(hour - 4);
 }

————-
带入hour=4
结果： 2 * func(3)-func(0)= 13
2018-11-22


11

张正龙
我是来重温算法的，所以看起来还是通俗易懂的，回想当年大学学算法一个算法最少要在poj上做几十道题才能比较好理解，算法和数据结构真不是看俩便书或者文章就能理解的，一定要是要多练习的！而且还要明白一个事实，就算练习了，过段时间你也会忘记！所以我又来重温了！
2019-03-14


5

Brandon
递归树分析递归算法的时间复杂度

把递归树画出来，计算每一层和每一层的一个耗时情况，求和
思考题：拒绝思考
2018-12-13


5

小罗是坏蛋
如果第三个小时不分裂，死亡：
f(n)=f(n-1)+f(n-2)
第三个小时分裂之后再死亡：
有两个公式表达
f(n)=f(n-1)+f(n-2)+f(n-3)

之后再用斐波那契数列中老师的树的分析方式分析，得到结果
第三个小时不分裂，就死亡，与斐波那契数列结果相同
第三个小时先分裂再死亡，时间复杂度在
O(3^n/3）至O(3^n)之间
2018-12-09


5

不成熟的萌
假设细胞3小时候先分裂再死亡。
life3 表示还能活3个小时， life2表示还能活2个小时，life1表示还能活1个小时
假设在第x时刻，存活细胞数为life1 = x, life2= y, life3 = z个，总细胞sum(x)
在第x + 1时刻，此时刻的life1细胞均来自上一时刻的life2细胞。此时刻life2细胞均来自上一时刻的life3细胞。上一时刻life1细胞死亡后，会分列均等数量life3细胞，因此上一时刻所有细胞均会分裂，所以此时刻life3细胞等于上一时刻所有细胞数。
所以x + 1时刻，life1 = y, life2 = z, life3 = sum(x), sum(x+1) = y + z + sum(x)
x + 2, life1 = z, life2 = sum(x), life3 = sum(x + 1), sum(x+2) = z + sum(x) + sum(x + 1)
x + 3, life1 = sum(x), life2 = sum(x + 1), life3 = sum(x + 2) , sum(x + 3) = sum(x) + sum(x + 1) + sum(x + 2)
因此递推式为
sum(x) = sum(x - 1) + sum(x - 2) + sum(x - 3)
1 sum函数
3 sum函数
9 sum函数
所以是3的0次方+3的1次方+3的二次方，为几何级数，算法复杂度为O(3的n次方)
2018-12-05


5

ppingfann
老师，有几个问题不明白：
1. 求归并排序的时间复杂度中
满二叉树的高度计算公式中的n指的是树中的节点的总个数，而归并排序中的n指的却是叶子节点的个数。所以归并排序中树的高度，我计算出来的是h=log2^2n-1。
2. 实战二中
“f(n) 分解为 f(n-1) 和 f(n-2)，每次数据规模都是 -1 或者 -2，叶子节点的数据规模是 1 或者 2。“
叶子节点为1或者2都不能再往下分叉了，所以，我计算出来的最长路径是n-2。举个具体的例子：n=5时，最长路径为3。
我计算出来的最短路径依据n的不同还会不同，
具体的例子：n=5时，最短路径为2，n=6时，最短路径依然为2。

是我理解的有偏差吗？请老师指点。
2018-11-21


5

沉睡的木木夕
有几点问题不懂
1.实战二：分析斐波那契数列的时间复杂度 一节提到
“f(n) 分解为 f(n-1) 和 f(n-2)，每次数据规模都是 -1 或者 -2，叶子节点的数据规模是 1 或者 2。所以，从根节点走到叶子节点，每条路径是长短不一的。如果每次都是 -1，那最长路径大约就是 n；如果每次都是 -2，那最短路径大约就是 n/2。”数据规模都是-1，-2 这怎么理解？每次都是-1，最长路径大约就是n 这又是怎么理解的？
2.实战3中提到
“第一层分解有 n 次交换操作，第二层有 n 个节点，每个节点分解需要 n-1 次交换，所以第二层总的交换次数是 n*(n-1)。第三层有 n*(n-1) 个节点，每个节点分解需要 n-2 次交换，所以第三层总的交换次数是 n*(n-1)*(n-2)。”
交换操作的次数是怎么的出来的？
这对于我来讲就好比，数学老师讲了一堆看似简单的东西（有同学基础不好），最后老师最后落笔：所以1+1=2，但我还是一脸懵逼
2018-11-21

1

4

Geek_zy
课后题目得时间复杂度为 2^(N+1)
树得最后三层减去树得前边的层数。即为时间复杂度。。
2018-12-19


3

诚实村的村长
如果先分裂后死亡细胞数量为1，2，4，7，13（置顶算出的是12因为多减了一个死亡的细胞，在最初f（3）已经减去了已经死亡的细胞f（0）此时f（1）中存活的细胞事实上只有一个，所以在f（4）时只需要减1即减去f（0））递推公式为f(n)=2*f(n-1)-f(n-4) 希望老师说一下标准答案
2019-04-09


2

嗯嗯
看完这章以后我感觉我要重头再来一遍😅，忘了挺多的
2019-03-17


2
收起评论

99+99+





# 不定期福利第二期 | 王争：羁绊前行的，不是肆虐的狂风，而是内心的迷茫



数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



不定期福利第二期 | 王争：羁绊前行的，不是肆虐的狂风，而是内心的迷茫
王争 2018-11-23



09:33
讲述：修阳 大小：4.38M
你好，我是王争。

专栏更新过半，我发现有些小伙伴已经掉队，虽然有人掉队也挺正常，但是我还是想尽量拉一把。于是，周末的时间，我就在想，究竟是什么原因让有些小伙伴掉队了？是内容本身太难了吗？是我讲的不够清楚吗？还是小伙伴本身基础太差、不够努力、没有掌握学习方法？

我觉得都不是，让你掉队的原因，从根儿上讲，是你内心的迷茫。如果我们不那么确信能不能看懂、能不能学会的时候，当面对困难的时候，很容易就会否定自己，也就很容易半途而废。

这就好比你迷失在沙漠中，对你来说，肆虐的狂风并不可怕，可怕的是，你不知道该努力多久才能走出沙漠，不知道到底能不能走出沙漠。这种对结果的未知、不确定，导致了你内心的恐惧，最后就差那么一点点就可以走出沙漠的时候，你放弃了。

学习也是同样的道理。所以，我今天不打算讲学习方法，也不打算给你灌输心灵鸡汤，我就讲讲，对这个专栏的学习，或者对于任何学习来说，我觉得你应该建立的一些正确认知。有了这些认知，希望你能在后面的专栏学习中，少一点迷茫，多一份坚持。

没有捷径，没有杀手锏，更没有一招致胜的“葵花宝典”


有小伙伴给我留言说：“看书五分钟，笔记两小时，急求学霸的学习方法”，还有人问，“数据结构和算法好难，到底该怎么学？是我的学习方法不对？还是我太笨？”

我想说，并没有什么杀手锏的学习方法，更没有一招致胜的“葵花宝典”。不知道这么说有没有让你失望。如果你真要“求”一个学习方法，那就再看看我在专栏开始写的“如何抓住重点，系统高效地学习数据结构与算法”那篇文章吧。

说实话，我也挺想知道学霸的学习方法的，所以，在求学路上，每当有学霸来分享学习方法，我都要去听一听。但是，听多了之后，我发现其实并没有太多用。因为那些所谓学霸的学习方法，其实都很简单，比如“认认真真听讲”“认认真真做每一道题”等等。

也不是他们说的不对，但是这种大实话，我总有一种领会不了的感觉，更别说真正指导我的学习了。而且，我觉得，很多时候，这些方法论的难点并不在于能不能听懂，而是在于能不能执行到位。比如很多人都听过“一万小时定律”，坚持一万个小时，你就能成为大牛，但有多少人能坚持一万个小时呢？

所以，这里我要纠正一个认知，那就是，学习没有“杀手锏”似的方法论。不要怀疑是不是自己的学习方法不对，不要在开始就否定自己。因为否定得越多，你就越迷茫，越不能坚持。

不要浮躁，不要丧失思考能力，不要丧失学习能力


有小伙伴给我留言说：“老师，这个地方看不懂，你能不能再解释一下”，还有小伙伴留言说：“《红黑树（上）》里的图为什么跟你的定义不相符？”

对于留言的问题，我都挺重视的，但是当仔细看这些问题的时候，我发现，实际上文章里已经有答案了，他根本没有认真看、认真思考，更别说去自己搜搜资料，再研究下，就来提问了。

一般情况下，我都会回复“你自己再认真看一遍”或者“你自己先去网上搜一下，研究研究，如果还不懂再给我留言”。告诉你答案，并不会花费我太长时间，但是，这样会让你丢失最宝贵的东西，那就是，你自己的思考能力、学习能力，能自己沉下心来研究的能力。这个是很可怕的。

现在，互联网如此发达，我们每天都会面对各种各样的信息轰炸，人也变得越来越浮躁。很多人习惯看些不动脑子就能看懂的东西，看到稍微复杂的东西，就感觉脑子转不动了。

上学的时候还好，要考试，有老师督促，还能坚持学习。但是工作之后，没有人监督，很多人陷入各种手机 App 中不能自拔，学一会儿就想玩会儿手机，想静下心来学上半个小时都无比困难。无法自律，沉不下心来，那你就基本可以跟学习说拜拜了。

只有做好打硬仗的心理准备，遇到困难才能心态平和


还有小伙伴给我留言说：“看不懂，一个 4000 多字的文章、10 分钟的音频，反复看了、听了 2 个小时都没怎么看懂”。我给他的回复是：“如果之前没有基础或者基础不好的话，看 2 个小时还不懂，很正常，看一个礼拜试试。”

“一个礼拜”的说法，我一点都不是夸张。虽然专栏的每篇文章都只有三四千字，10 分钟左右的音频，但是知识点的密度还是很高的。如果你潜意识里觉得应该一下子就能看懂，就会出现这样的情况：看了一遍不懂，又看了一遍还是不怎么懂，然后就放弃了。

数据结和算法就是一个非常难啃的硬骨头，可以说是计算机学科中最难学的学科之一了。我当时学习也费了老大的劲，能做到讲给你听，我靠的也是十年如一的积累和坚持。如果没有基础、或者基础不好，你怎能期望看 2 个小时就能完全掌握呢？

面对这种硬骨头，我觉得我们要有打硬仗、打持久战的心理准备。只有这样，在学习的过程中遇到困难的时候，心态才能更加平和，才能沉下心来有条不紊地去解决一个个的疑难问题。这样，碰到问题，你可能还会“窃喜”，我又遇到了一个之前不怎么懂的知识点了，看懂它我又进步了一点。甚至你还会“坏坏地”想，又多了一个拉开我跟其他人距离的地方了。跨过这些点，我就能比别人更厉害。

一口吃不成胖子，如果你基础不好，那就从长计议吧，给自己定一个长一点的“死磕”计划，比如一年。面对不懂的知识点，沉下心来逐个突破，这样你的信心慢慢也就建立了。

“放弃”的念头像是一个心魔，它会一直围绕着你


还有小伙伴给我留言说：“开始没怎么看懂，看了一下午，终于看懂了”。看到这样的留言，我其实挺为他感到庆幸的，庆幸他没有中途放弃。因为，放弃的念头就像一个心魔，在我们的学习过程中，它会一直围绕着我们，一旦被它打败一次，你就会被它打败很多次，掉队就不可避免了。

我分享一个我最近思考比较多的事情。前一段时间，我在研究多线程方面的东西，它涉及一块比较复杂的内容，“Java 内存模型”。虽然看懂并不难，但是要透彻、无盲点地理解并不容易。本来以为半天就能看懂的东西，结果我从周一一直看到周五下午，断断续续花了 5 天的时间才把它彻底搞懂。回忆起这 5 天，我有不下 10 次都想放弃，每次心里都在想：“算了，先放一放，以后再说吧”“太难了，啃不下来，算了。”“就这样吧，反正也用不到，没必要浪费时间”等等。这种放弃的念头就像一个邪恶的魔鬼一样，一直围绕着我这 5 天的研究中。

现在回想起来，我很庆幸我当时没有放弃，多坚持了几天。如果当时我放弃了，那之后再遇到技术难题时，“放弃”的心魔还会再来拜访我，潜意识里我还是会认输。

之所以没有放弃，我自己总结了两点原因。

第一，我对学习这件事情认识得比较清楚，我一直觉得，没有学不会的东西，没有攻克不了的技术难题，如果有，那就说明时间花得还不够多。

第二，我之前遇到卡壳的时候，几乎从来没有放弃过，即便短暂地停歇，我也会继续拎起来再死磕，而且每次都能搞定，正是这种正向的激励，给了我信心，让我再遇到困难的时候，都能坚信自己能搞定它。

入门是一个非常漫长和煎熬的过程，谁都逃不过


还有小伙伴留言说：“看到有小伙伴有很多疑问，我来帮作者说句话，文章写的很好，通俗易懂，如果有一定基础，看懂还是不成问题的。”

我觉得，有些小伙伴的觉悟还是挺高的：）。我文章写得再通俗易懂，对于之前没有任何基础的人来说，看起来还是挺费劲的。

第一，数据结构和算法这门课程本身的难度摆在那里，想要轻松看懂，本身就不太现实。第二，对于任何新知识的学习，入门都是一个非常漫长和煎熬的的过程。但是这个过程都是要经历的，谁都逃不过。只要你挺过去，入了门，再学习更深的知识就简单多了。

我大学里的第一堂课是 C 语言，现在回想起来，当时对我来说，简直就是听天书。因为之前没有接触过计算机，更别说编程语言，对我来说，C 语言就像另一个世界的东西。从完全看不懂，到慢慢有点看懂，再到完全看懂，不夸张地讲，我花了好几年的时间，但是当掌握了之后，我发现这个东西其实也不难。但是如果没有度过漫长和煎熬的入门的过程，如果没有一点韧性，没有一点点信念，那可能也没有现在的我了。

其实我一直觉得情商比智商更重要。对于很多学科的学习，智商并不是瓶颈，最终能够决定你能达到的高度的，还是情商，而情商中最重要的，我觉得就是逆商（逆境商数，Adversity Quotient），也就是，当你遇到困难时，你会如何去面对，这将会决定你的人生最终能够走多远。



好了，今天我想分享的关于学习的几个认知就讲完了。现在，你有没有对学习这件事有更加清晰的认识呢？能不能让你少一点迷茫，多一份坚持呢？

最后，我有一句送给你：吃得苦中苦，方为人上人。耐得住寂寞，才能守得住繁华。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(229)

王争 置顶
小伙伴们的这篇文章的留言我就不一一回复了 看的我很感动 很多留言都写的太好了 我自己都受益匪浅 感谢🙏
2018-11-23


81

P@tricK
老师出这篇学习方法真的用心良苦，感觉现在的人真的很难再去付出100%的专注去学习了，特别是在职搬砖的人。

个人觉得，学习的关键在于决心和自律。

加油吧各位。
2018-11-23


166

王楚然
每天上班路上会看老师的文章。作为女生，逻辑能力比男生差，理科又一直不好。遇到红黑树已经让我彻底懵逼，有了多看数学书多培养数学思维的想法。每天坐地铁都想说我想歇一歇，可是每次都跟自己说，我就看一篇就好。每次因为自己的笨都想放弃。每次都坚持告诉自己，就算看不懂当做开阔眼界也很好。看到老师今天的文章我终于放心了，因为连老师都说，不花大力气是学不好的，那么我所做的努力还远远不够，更不用急着否定自己了，感谢老师在我觉得艰难的时候能写下这样的文章拉了我一把😁
2018-11-23

2

128

Jerry银银
老师真心用心良苦，感谢！

在学习的算法的过程中，个人也有一些感触，分享给大家。极客时间留言字数有限制，我只好将留言完整版放到了其它地方，然后只截取了一小段放在这里。有兴趣的，可以看看完整的心路历程：https://zhuanlan.zhihu.com/p/50733874

【做好心理准备：学习过程，时而兴奋，时而备受打击】

我学习算法的主线，是通过机械工业出版社出版的、Ellis Horowitz等人著作的《数据结构(C语言版)》。说实话，刚开始只看这一本书，问题也不太大，但是当我学习红黑树的时候，问题就来了。如果不知道这种数据结构如何由来的话，直接去学，就很容易懵。中间我因为工作繁忙，晚上经常加班到深夜，而红黑树很多次又看不懂，再加上身心很疲惫，很容易放弃；中间，我确实放弃了很多次，又重新捡起来很多次。所幸的是，我没有真正的放弃（因为有梦想的支持）。某一天，我真正决定了：必须搞懂红黑树。于是，在国庆节期间，再加上我请了三天假，总共花了十天左右的时间，仔细研究二叉树查找树的特性，再去leetcode上找二叉树基础性的题目做；等二叉树学习得差不多了，再继续深入2-3树，真正理解二叉树为什么需要『平衡』，仔细研究2-3树如何构造，反复在草稿纸画图；当搞明白了2-3树的时，深入研究红黑树，理解rotate left、rotate right，这中间依然是在草稿纸进行反复画图，理解红黑树的构造。

这中间还有一个小插曲，在《算法》一书中，红黑树的定义是这样的：红黑树是含有红黑链接并满足下列条件的二叉查找树：
1. 红链接均为左链接；
2. 没有任何一个结点同时和两条红链接相连；
3. 该树是完美黑色平衡的，即任意空链接到根结点的路经上的黑链接数量相同。
当看到第一条的时候，我直接就懵了。因为，我看到《算法导论》和一些网络博客对红黑树的定义允许有红色右链接呀。为了解答这个问题，我查阅了各种资料，最后在wikipedia红黑树条目中找到了真相：原来Robert Sedgewick 这样定义，是为了简单化红黑树，精简红黑树实现的代码。

学习红黑树的过程，我犯了一些错误：
1. 贪快，缺乏耐心。有时候会看得过快，忽略之前章节的学习，直接进入后续章节学习。但是『专业性很强的教课书』一般都会有条理的进行编排，也就是说，前面的章节可能是后面章节的『原因』，如果基础不是很好，直接进入『结果』的学习，导致的情况就是：懵！
2. 一本书看不懂，就死磕。书籍是人写的，每个人对每个领域的理解不一样，阐述也可能不一样，某一个人说出来的『东西』不是很容易理解，也有可能是对方讲的不够好嘛。试试找找其它的材料看看呢！我在学习红黑树的时候，死磕了一本书之后，发现不行，终于意识到得找找其它同类型的资料了，最终发现了《算法》一书（这么经典的书，我都不知道），同时还在网上发现了一个比较好的网站：https://visualgo.net/en 《算法》一书用的描述语言是Java，合胃口; 理解红黑树，我就通过《算法》一书理解的。我觉得作者就非常抓重点和让人容易理解，后来一查，才发现，作者 Robert Sedgewick 曾经对红黑进行改造，让红黑树的代码实现精简了很多。可想而知，作者对红黑树的理解够透彻和权威了吧。
通过这次的经历，我稍微把自己学习算法的方式进行了调整：
1. 我购入了《算法图解》一书，在稍微轻松的心情中，对算法有了一个整体的脉络，连带急切想知道的图和动态规划都稍微了解了一下
2. 我开始用线上的一些比较好的网站，进行一些『练习』。比如在熟悉基础概念阶段，使用https://visualgo.net/en进行练习，基础概念掌握差不多了之后，开始在leetcode上找一些easy的题目开始做（leetcode上easy题目，虽说找到最优解也要花一点功夫，可以至少起初能找到一些方案）
既然为了精通算法，多买几本算法参考书还是要的，多花点钱也没什么大不了的。😄 为了搞懂问题，我参考的资料一般有：权威的专业书籍、Wikipedia、一些人的博客

写完这一段时，我突然想到《士兵突击》中那句经典的台词：“不抛弃，不放弃”。 对算法也得多喊喊：“不抛弃，不放弃”！
2018-11-24


47

只会安卓De小鹿
王争老师分享的这波很不错，我也一直坚信甚至经常和身边的小伙伴们提起「学习没有捷径，只有付出与不付出」。有一点想和王争老师分享的是，我觉得学习像数据结构与算法这种难度比较大，零碎的知识点比较多，导致了很多同学处于一种迷茫的阶段的状况，原因有一下几种:

1、执行力不足，每当开始学习的时候，一些小的基础概念都没有弄明白，一味地学习后边的知识，导致学习的挫败感越来越强。

2、学习技巧。王争老师也说了，学霸有没有学习方法我们不知道，毕竟我们是玩技术的，不像是学霸每天和各种学科打交道，我之前也是一个学渣，更别说是数据结构与算法了，最基础的程序语言都很难弄明白，但是当我入门一门语言的时候，感觉再学习其他的语言和编程就感觉很快就会入门。我认真反思了一下，原因就是一个好的学习方法实在是太重要的，就说数据结构吧，很多人可能没有想过怎么才能让自己王争老师分享的每一篇文章都找到一根线掌握起来，然后将所有的课和知识点掌握起来，这就涉及到学习方法问题了，因为自己对学习方法研究比较深，也经常在朋友圈和公众号给我的小伙伴们更多的分享学习方法，因为我觉得这比分享更多的技术更为重要，有句话说的好「治病先治根」，哪里有病，首先找到病根的原因，然后对症下药。

3、习惯。我觉得坚持学习，还不如说成一种习惯。自从王争老师出了这门数据结构与算法课程之后，我逐渐爱上了这门科目，之前课老师上讲很基础，涉及不到那么深，再加上买的那些书籍资料太乏味，导致让我很难学习下去。王争老师这门课出了之后，感觉学习数据结构也没有这么难，自己也研究了一套学习数据结构的方法，正在努力给自己完善中。在学校做小项目时，很多问题导致我无法去解决，身边几乎没人去学习这么重要的科目，学习有的重要的技巧就是活学活用，这门课很多的技术解决了我实际的问题，有时候就是恍然大悟，由于自己跟着王争老师学习的比较深入，遇到问题就像是条件反射一样，遇到了一个很难解决的问题，脑子里就不由自主的跳出一个数据结构的解决方法，然后仔细一想，确实可以解决这个方法。也逐渐的，每天看王争老师分享的数据结构与算法成为了一种习惯，每天都去学习思考，都要简单做做笔记，一天不去看，就感觉今天有什么事情没有完成一样，我觉得自己已经深爱上了这个课程，成为了一种习惯。

最后感谢极客时间，感谢王争老师能够出这么一门好的数据结构与算法的文章，让我受益很多。
2018-11-23


36

伟忠
赞啊，我是从药学转计算机的，中间吃了多少苦恐怕只有自己懂，只有真爱，不断坚持，才能深入理解。
Never give up
2018-11-23


20

fumeck.com🍋🌴summer sk...
买了快二十个专栏.就数老师和《趣谈网络协议》这两个专栏最用心了。
授人以鱼更授人以渔，很庆幸我能坚持，一周也就三更硬啃下来不要掉队太久就能跟上大队
我的学习方法是先把理论和概念先弄懂，至于代码的实现与细节以后有时间再来专栏看一遍仔细雕琢。这样以后遇到问题起码有解决思路了再说，再对症下药把解决方案对应的专栏里代码与实现细节弄懂它
然后就是多看留言，真正的精华其实在这里。大家一起坚持，加油
2018-11-23

1

19

醉比
既然老师都总结了这么多东西，那我们当然也不能不反思吧。说一说我的看法，对于从事这份工作的人来说，想要看懂作者的文章，并不难，这也就能反应出作者的文章并不是写得不明白，如果真的理解不了可能就是基础还需要加强。其次，弄懂并不难，可是是否掌握，这一点只有我们自己内心才最清楚。我们不妨扪心自问，很多地方到底掌握了没有，代码自己实现了没有，说实话考复制代码自己运行，这真的不算掌握。说实话我自己也有很多没掌握的地方，每周一三五早上学完习，其实也就学完了，我保证了每天文章都看懂了，但是今天我回顾前面的课程，真正能让我清晰的记住的东西，还是太朦胧太少了。自身也确实缺少了一些韧劲吧，有些代码，看着很简单，你让我关了网页自己写，我还真是在写bug。工作后的人需要沉下心来，需要专注的学习一块内容，才是正确有效的学习方式。否则学一会jvm，学一会算法，学一会springboot，可能就导致什么也没记住。如果你的状态和我一样，共勉吧，沉下心来，愿我们在我们的工作领域，都能更上一层楼。
2018-11-23


15

Leslie心蓝
很多内容当时感觉学会了，理解了，但是很快又忘了。。。老是记不住。。。
2018-11-23


11

$Jason
老师，我一直有个学习的困惑，排序哪块的知识看了多次，有一次看了好久终于看懂了。但是事后再去看的时候依然想不起来思路是什么了，越学越忘，然后后面就堆积了很多课。到现在依然卡在这里。然后前面的数据结构的章节也有点忘记了，每次都从头学，觉得效率不高。
2018-11-26


7

勿闻轩外香
我并不是掉队，而是在研究的过程中，老师更新课程了，所有现在才研究到一半
2018-11-23


5

Vincent
之前一段时间很忙，掉了五六节课程。最近终于又赶上来了，在有时间的情况下，都自己实现一遍。我发现听懂看懂不一定真的懂了，只有动手了才知道是否深刻理解了。立一个flag把课程的所有数据结构都实现一次。
2018-11-23


5

失火的夏天
老师说的很对，其实数据结构和算法的学习嘛，三分学，七分练。打个最简单的例子，单链表反转这个算法，思路都非常简单。就是指针反向，但是要真正自己闭卷写出来的，其实没有那么容易。只有自己真正动手了，才算把东西给学习和练习了。我个人对数据结构和算法挺喜欢的，所以一般有这方面的课程都会来学习。这边也打一个广告～覃超老师那边是关于算法面试的视频课，说了一些面试的情况和解题的技巧，有兴趣的同学也可以去那边学习，本人是两边都有购买。两位老师各有特点，学习嘛，博采众长。

说一点自己的想法，看了老师这篇文章，其实心里还是有点窃喜的，为什么呢？因为我发现老师这样的大牛，以前也被这些问题卡死了这么久。哈哈……所以没什么害怕的。比如红黑树的学习，我自己当时是手动把treemap的的代码相当于自己改了一遍，把＜key，value＞改成了＜E＞的那种红黑树，虽然写完后自己大部分也忘记了，尤其是删除那块。但是写的过程中自己是在思考的，会在边上写下注释和自己的想法，我认为这些东西比代码本身重要，因为这些才是自己学习留下来的东西。学习知识，然后把知识忘记，剩下来的东西就是你学到的，我认为就是这个了。
2018-11-23


5

梁成志（鹏金所）
从这篇专栏可以看出王峥老师是非常用心，很负责任，希望大家真正学会和学好算法的。
     我在学跳表的时候，花了几天的时候才想清楚，领略到妙点的时候，后来有种拍大腿的感觉，觉得这种数据结构的设计怎么好神奇。学快排和归纳排序，也感受到了算法的奇妙，都是前人很多研究的结果。专栏也有提到，跳表这种数据结构在很多年都没有真正的去写好的，都是存在缺陷，也证明了数据结构和算法，其实是一种在成长和演化。我们有幸跟随王峥老师学习，用最通俗的学习很难得。我大学的时候学数据结构我记得是很糊涂，知其然，不知所以然。而且大学泛于理论，学起来没什么兴趣和枯燥。
     王峥老师举了很多实用的例子，还有结合实现，在工作中很常用的，比如redis、map用到跳表、散列表这种数据结构，拍大腿，原来是这样的。也感受到了，如果你不懂数据结构，很难真正理解，为什么它会存在和发展。在前段时间，我用阻塞队列实现了跟踪第三方交易状态，能在不损害性能的情况下，秒同步第三方的结果，这让我感受到数据结构的强大。也许我们还能用于很多地方。
     这里很多大神，希望跟着王峥老师一点点学习和进步。希望大家不要放弃。也不要去背。真正理解了，把数据结构算法奇妙领略到，将来变种成自己设计成自己的数据结构，去实现和设计这些问题才真正有趣。
2018-11-23


4

好名字可以让你的朋友更容易妒忌...
大家好,我是老年人学编程. 确实啊, 难度在那摆着. 抽象思维的能力需要时间, 只能一点点死磕了. 今天没搞懂, 写不出代码. 我是不会放弃的, 明天还继续. 要是连着3天都没搞懂.. 我就会先放放. 让这个东西在脑袋里发酵下. 有时候突然在地铁上,感觉就有了. 代码验证就 OK. 有点小成就感的啦.
2018-11-25


3

对方正在输入
说到底还是很多人太浮躁了,静不下心来
2018-11-23


3

末了 。
这个鸡汤来的真及时，我是老师眼中那些没有基础的学生，所以看起来很费劲，一直似懂非懂，越到后面就越不懂了。不光是算法吧，其他所有学习都是这样，逆境总会有的，加油吧自己
2018-11-23


3

新人佳佳家
这里给学习的小伙伴一个建议。我是今年2019年1月份才购入这个专栏的。我是科班毕业，上学的时候接触过，那时候就觉得数据结构真难学，然后就随便混了。出来工作以后才觉得每天的CRUD是无法提升的，你写更多的业务，那也不过是业务代码。无法真正提升一个人的思考和编程功力，因此想真的提升自己，建议一起学习的伙伴们能坚持下来。分享一下我的学习方法：
1.每天就看一讲，不多不少2小时。（这里可以用一些计时软件计时）；因为我知道数据结构这一块很烧脑，看多了人会烦躁，因此就2小时。如果时间有余，我会去leetCode找些题目来练。
2.这两小时做笔记是一定要的，不管是你精简老师的话，写成自己的东西，还是按你的理解写下来的。
3.切勿贪快。以前我看数据结构的时候，一看觉得自己已经会了，下面就没细看；其实想想，没人逼你学，也不需要考试，别人有可能聪明学的快半年掌握了。我们要花一年，但是，最终我们还是掌握了不是么
4.不断地回顾和复习。怎么复习?看自己的笔记，如果看到自己的笔记回忆不起来，再去看一遍老师说的文章
5.不要死磕实现代码，就像老师说的要知道每个数据结构与算法后面的思想和适用场景，死记代码是没用的
2019-01-25


2

Jerry银银
曾经遇到一道算法题：
给定一个32位二进制数，统计里面有多少1？

就为了彻底搞懂这一题，花了至少一个星期的时间。

这道题的解法：位运算 和 查表法都好理解，最后败在来自Hacker's Delight书中提到的解法中。至今，那种解法，还没有彻底搞懂。

而且，背后涉及到知识点：汉明权重 汉明编码 汉明距离，也还没有完全弄明白。


所以，特别认同老师说的：花一两天没有理解的算法，花一个星期看看，花一个星期不够，再花半个月看看。我觉得对于，树这种数据结构，花一个月的时间，甚至两个月的时间，都不为过
2018-11-24


2

ban
最近一边看专栏，一边看大话数据结构这本书，确实有时候有点难不好懂，其实只是时间和火候不到。看书的时候我今天看了两个小时没看懂，好吧明天继续坑，明天坑不了，后天继续看那几个内容，从各个角度想，结果想通了也就明白，所以能不能学到就看下的功夫有多少
2018-11-23


2
收起评论

99+99+





# 28 | 堆和堆排序：为什么说堆排序没有快速排序快？



数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



28 | 堆和堆排序：为什么说堆排序没有快速排序快？
王争 2018-11-26



15:34
讲述：修阳 大小：7.14M
我们今天讲另外一种特殊的树，“堆”（Heap）。堆这种数据结构的应用场景非常多，最经典的莫过于堆排序了。堆排序是一种原地的、时间复杂度为 O(nlogn) 的排序算法。

前面我们学过快速排序，平均情况下，它的时间复杂度为 O(nlogn)。尽管这两种排序算法的时间复杂度都是 O(nlogn)，甚至堆排序比快速排序的时间复杂度还要稳定，但是，在实际的软件开发中，快速排序的性能要比堆排序好，这是为什么呢？

现在，你可能还无法回答，甚至对问题本身还有点疑惑。没关系，带着这个问题，我们来学习今天的内容。等你学完之后，或许就能回答出来了。

如何理解“堆”？
前面我们提到，堆是一种特殊的树。我们现在就来看看，什么样的树才是堆。我罗列了两点要求，只要满足这两点，它就是一个堆。

堆是一个完全二叉树；

堆中每一个节点的值都必须大于等于（或小于等于）其子树中每个节点的值。

我分别解释一下这两点。

第一点，堆必须是一个完全二叉树。还记得我们之前讲的完全二叉树的定义吗？完全二叉树要求，除了最后一层，其他层的节点个数都是满的，最后一层的节点都靠左排列。

第二点，堆中的每个节点的值必须大于等于（或者小于等于）其子树中每个节点的值。实际上，我们还可以换一种说法，堆中每个节点的值都大于等于（或者小于等于）其左右子节点的值。这两种表述是等价的。

对于每个节点的值都大于等于子树中每个节点值的堆，我们叫作“大顶堆”。对于每个节点的值都小于等于子树中每个节点值的堆，我们叫作“小顶堆”。

定义解释清楚了，你来看看，下面这几个二叉树是不是堆？



其中第 1 个和第 2 个是大顶堆，第 3 个是小顶堆，第 4 个不是堆。除此之外，从图中还可以看出来，对于同一组数据，我们可以构建多种不同形态的堆。

如何实现一个堆？
要实现一个堆，我们先要知道，堆都支持哪些操作以及如何存储一个堆。

我之前讲过，完全二叉树比较适合用数组来存储。用数组来存储完全二叉树是非常节省存储空间的。因为我们不需要存储左右子节点的指针，单纯地通过数组的下标，就可以找到一个节点的左右子节点和父节点。

我画了一个用数组存储堆的例子，你可以先看下。



从图中我们可以看到，数组中下标为 i 的节点的左子节点，就是下标为 i∗2 的节点，右子节点就是下标为 i∗2+1 的节点，父节点就是下标为 i2 的节点。

知道了如何存储一个堆，那我们再来看看，堆上的操作有哪些呢？我罗列了几个非常核心的操作，分别是往堆中插入一个元素和删除堆顶元素。（如果没有特殊说明，我下面都是拿大顶堆来讲解）。

1. 往堆中插入一个元素
往堆中插入一个元素后，我们需要继续满足堆的两个特性。

如果我们把新插入的元素放到堆的最后，你可以看我画的这个图，是不是不符合堆的特性了？于是，我们就需要进行调整，让其重新满足堆的特性，这个过程我们起了一个名字，就叫作堆化（heapify）。

堆化实际上有两种，从下往上和从上往下。这里我先讲从下往上的堆化方法。



堆化非常简单，就是顺着节点所在的路径，向上或者向下，对比，然后交换。

我这里画了一张堆化的过程分解图。我们可以让新插入的节点与父节点对比大小。如果不满足子节点小于等于父节点的大小关系，我们就互换两个节点。一直重复这个过程，直到父子节点之间满足刚说的那种大小关系。



我将上面讲的往堆中插入数据的过程，翻译成了代码，你可以结合着一块看。

public class Heap {
  private int[] a; // 数组，从下标 1 开始存储数据
  private int n;  // 堆可以存储的最大数据个数
  private int count; // 堆中已经存储的数据个数
 
  public Heap(int capacity) {
    a = new int[capacity + 1];
    n = capacity;
    count = 0;
  }
 
  public void insert(int data) {
    if (count >= n) return; // 堆满了
    ++count;
    a[count] = data;
    int i = count;
    while (i/2 > 0 && a[i] > a[i/2]) { // 自下往上堆化
      swap(a, i, i/2); // swap() 函数作用：交换下标为 i 和 i/2 的两个元素
      i = i/2;
    }
  }
 }
2. 删除堆顶元素
从堆的定义的第二条中，任何节点的值都大于等于（或小于等于）子树节点的值，我们可以发现，堆顶元素存储的就是堆中数据的最大值或者最小值。

假设我们构造的是大顶堆，堆顶元素就是最大的元素。当我们删除堆顶元素之后，就需要把第二大的元素放到堆顶，那第二大元素肯定会出现在左右子节点中。然后我们再迭代地删除第二大节点，以此类推，直到叶子节点被删除。

这里我也画了一个分解图。不过这种方法有点问题，就是最后堆化出来的堆并不满足完全二叉树的特性。



实际上，我们稍微改变一下思路，就可以解决这个问题。你看我画的下面这幅图。我们把最后一个节点放到堆顶，然后利用同样的父子节点对比方法。对于不满足父子节点大小关系的，互换两个节点，并且重复进行这个过程，直到父子节点之间满足大小关系为止。这就是从上往下的堆化方法。

因为我们移除的是数组中的最后一个元素，而在堆化的过程中，都是交换操作，不会出现数组中的“空洞”，所以这种方法堆化之后的结果，肯定满足完全二叉树的特性。



我把上面的删除过程同样也翻译成了代码，贴在这里，你可以结合着看。

public void removeMax() {
  if (count == 0) return -1; // 堆中没有数据
  a[1] = a[count];
  --count;
  heapify(a, count, 1);
}
 
private void heapify(int[] a, int n, int i) { // 自上往下堆化
  while (true) {
    int maxPos = i;
    if (i*2 <= n && a[i] < a[i*2]) maxPos = i*2;
    if (i*2+1 <= n && a[maxPos] < a[i*2+1]) maxPos = i*2+1;
    if (maxPos == i) break;
    swap(a, i, maxPos);
    i = maxPos;
  }
}
我们知道，一个包含 n 个节点的完全二叉树，树的高度不会超过 log2n。堆化的过程是顺着节点所在路径比较交换的，所以堆化的时间复杂度跟树的高度成正比，也就是 O(logn)。插入数据和删除堆顶元素的主要逻辑就是堆化，所以，往堆中插入一个元素和删除堆顶元素的时间复杂度都是 O(logn)。

如何基于堆实现排序？
前面我们讲过好几种排序算法，我们再来回忆一下，有时间复杂度是 O(n2) 的冒泡排序、插入排序、选择排序，有时间复杂度是 O(nlogn) 的归并排序、快速排序，还有线性排序。

这里我们借助于堆这种数据结构实现的排序算法，就叫作堆排序。这种排序方法的时间复杂度非常稳定，是 O(nlogn)，并且它还是原地排序算法。如此优秀，它是怎么做到的呢？

我们可以把堆排序的过程大致分解成两个大的步骤，建堆和排序。

1. 建堆
我们首先将数组原地建成一个堆。所谓“原地”就是，不借助另一个数组，就在原数组上操作。建堆的过程，有两种思路。

第一种是借助我们前面讲的，在堆中插入一个元素的思路。尽管数组中包含 n 个数据，但是我们可以假设，起初堆中只包含一个数据，就是下标为 1 的数据。然后，我们调用前面讲的插入操作，将下标从 2 到 n 的数据依次插入到堆中。这样我们就将包含 n 个数据的数组，组织成了堆。

第二种实现思路，跟第一种截然相反，也是我这里要详细讲的。第一种建堆思路的处理过程是从前往后处理数组数据，并且每个数据插入堆中时，都是从下往上堆化。而第二种实现思路，是从后往前处理数组，并且每个数据都是从上往下堆化。

我举了一个例子，并且画了一个第二种实现思路的建堆分解步骤图，你可以看下。因为叶子节点往下堆化只能自己跟自己比较，所以我们直接从第一个非叶子节点开始，依次堆化就行了。



对于程序员来说，看代码可能更好理解一些，所以，我将第二种实现思路翻译成了代码，你可以看下。

private static void buildHeap(int[] a, int n) {
  for (int i = n/2; i >= 1; --i) {
    heapify(a, n, i);
  }
}
 
private static void heapify(int[] a, int n, int i) {
  while (true) {
    int maxPos = i;
    if (i*2 <= n && a[i] < a[i*2]) maxPos = i*2;
    if (i*2+1 <= n && a[maxPos] < a[i*2+1]) maxPos = i*2+1;
    if (maxPos == i) break;
    swap(a, i, maxPos);
    i = maxPos;
  }
}
你可能已经发现了，在这段代码中，我们对下标从 n2 开始到 1 的数据进行堆化，下标是 n2+1 到 n 的节点是叶子节点，我们不需要堆化。实际上，对于完全二叉树来说，下标从 n2+1 到 n 的节点都是叶子节点。

现在，我们来看，建堆操作的时间复杂度是多少呢？

每个节点堆化的时间复杂度是 O(logn)，那 n2+1 个节点堆化的总时间复杂度是不是就是 O(nlogn) 呢？这个答案虽然也没错，但是这个值还是不够精确。实际上，堆排序的建堆过程的时间复杂度是 O(n)。我带你推导一下。

因为叶子节点不需要堆化，所以需要堆化的节点从倒数第二层开始。每个节点堆化的过程中，需要比较和交换的节点个数，跟这个节点的高度 k 成正比。

我把每一层的节点个数和对应的高度画了出来，你可以看看。我们只需要将每个节点的高度求和，得出的就是建堆的时间复杂度。



我们将每个非叶子节点的高度求和，就是下面这个公式：



这个公式的求解稍微有点技巧，不过我们高中应该都学过：把公式左右都乘以 2，就得到另一个公式 S2。我们将 S2 错位对齐，并且用 S2 减去 S1，可以得到 S。



S 的中间部分是一个等比数列，所以最后可以用等比数列的求和公式来计算，最终的结果就是下面图中画的这个样子。



因为 h=log2n，代入公式 S，就能得到 S=O(n)，所以，建堆的时间复杂度就是 O(n)。

2. 排序
建堆结束之后，数组中的数据已经是按照大顶堆的特性来组织的。数组中的第一个元素就是堆顶，也就是最大的元素。我们把它跟最后一个元素交换，那最大元素就放到了下标为 n 的位置。

这个过程有点类似上面讲的“删除堆顶元素”的操作，当堆顶元素移除之后，我们把下标为 n 的元素放到堆顶，然后再通过堆化的方法，将剩下的 n−1 个元素重新构建成堆。堆化完成之后，我们再取堆顶的元素，放到下标是 n−1 的位置，一直重复这个过程，直到最后堆中只剩下标为 1 的一个元素，排序工作就完成了。



堆排序的过程，我也翻译成了代码。结合着代码看，你理解起来应该会更加容易。

// n 表示数据的个数，数组 a 中的数据从下标 1 到 n 的位置。
public static void sort(int[] a, int n) {
  buildHeap(a, n);
  int k = n;
  while (k > 1) {
    swap(a, 1, k);
    --k;
    heapify(a, k, 1);
  }
}
现在，我们再来分析一下堆排序的时间复杂度、空间复杂度以及稳定性。

整个堆排序的过程，都只需要极个别临时存储空间，所以堆排序是原地排序算法。堆排序包括建堆和排序两个操作，建堆过程的时间复杂度是 O(n)，排序过程的时间复杂度是 O(nlogn)，所以，堆排序整体的时间复杂度是 O(nlogn)。

堆排序不是稳定的排序算法，因为在排序的过程，存在将堆的最后一个节点跟堆顶节点互换的操作，所以就有可能改变值相同数据的原始相对顺序。

今天的内容到此就讲完了。我这里要稍微解释一下，在前面的讲解以及代码中，我都假设，堆中的数据是从数组下标为 1 的位置开始存储。那如果从 0 开始存储，实际上处理思路是没有任何变化的，唯一变化的，可能就是，代码实现的时候，计算子节点和父节点的下标的公式改变了。

如果节点的下标是 i，那左子节点的下标就是 2∗i+1，右子节点的下标就是 2∗i+2，父节点的下标就是 i−12。

解答开篇
现在我们来看开篇的问题，在实际开发中，为什么快速排序要比堆排序性能好？

我觉得主要有两方面的原因。

第一点，堆排序数据访问的方式没有快速排序友好。

对于快速排序来说，数据是顺序访问的。而对于堆排序来说，数据是跳着访问的。 比如，堆排序中，最重要的一个操作就是数据的堆化。比如下面这个例子，对堆顶节点进行堆化，会依次访问数组下标是 1，2，4，8 的元素，而不是像快速排序那样，局部顺序访问，所以，这样对 CPU 缓存是不友好的。



第二点，对于同样的数据，在排序过程中，堆排序算法的数据交换次数要多于快速排序。

我们在讲排序的时候，提过两个概念，有序度和逆序度。对于基于比较的排序算法来说，整个排序过程就是由两个基本的操作组成的，比较和交换（或移动）。快速排序数据交换的次数不会比逆序度多。

但是堆排序的第一步是建堆，建堆的过程会打乱数据原有的相对先后顺序，导致原数据的有序度降低。比如，对于一组已经有序的数据来说，经过建堆之后，数据反而变得更无序了。



对于第二点，你可以自己做个试验看下。我们用一个记录交换次数的变量，在代码中，每次交换的时候，我们就对这个变量加一，排序完成之后，这个变量的值就是总的数据交换次数。这样你就能很直观地理解我刚刚说的，堆排序比快速排序交换次数多。

内容小结
今天我们讲了堆这种数据结构。堆是一种完全二叉树。它最大的特性是：每个节点的值都大于等于（或小于等于）其子树节点的值。因此，堆被分成了两类，大顶堆和小顶堆。

堆中比较重要的两个操作是插入一个数据和删除堆顶元素。这两个操作都要用到堆化。插入一个数据的时候，我们把新插入的数据放到数组的最后，然后从下往上堆化；删除堆顶数据的时候，我们把数组中的最后一个元素放到堆顶，然后从上往下堆化。这两个操作时间复杂度都是 O(logn)。

除此之外，我们还讲了堆的一个经典应用，堆排序。堆排序包含两个过程，建堆和排序。我们将下标从 n2 到 1 的节点，依次进行从上到下的堆化操作，然后就可以将数组中的数据组织成堆这种数据结构。接下来，我们迭代地将堆顶的元素放到堆的末尾，并将堆的大小减一，然后再堆化，重复这个过程，直到堆中只剩下一个元素，整个数组中的数据就都有序排列了。

课后思考
在讲堆排序建堆的时候，我说到，对于完全二叉树来说，下标从 n2+1 到 n 的都是叶子节点，这个结论是怎么推导出来的呢？

我们今天讲了堆的一种经典应用，堆排序。关于堆，你还能想到它的其他应用吗？

欢迎留言和我分享，我会第一时间给你反馈。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(113)

Jerry银银
## 第一题：

使用数组存储表示完全二叉树时，从数组下标为1开始存储数据，数组下标为i的节点，左子节点为2i, 右子节点为2i + 1. 这个结论很重要（可以用数学归纳法证明)，将此结论记为『原理1』，以下证明会用到这个原理。

为什么，对于完全二叉树来说，下标从n/2 + 1 到 n的节点都是叶子节点？ 使用反证法证明即可：

如果下标为n/2 + 1的节点不是叶子节点，即它存在子节点，按照『原理1』，它的左子节点为：2(n/2 + 1) = n + 2，大家明显可以看出，这个数字已经大于n + 1，超出了实现完全二叉树所用数组的大小（数组下标从1开始记录数据，对于n个节点来说，数组大小是n + 1），左子节点都已经超出了数组容量，更何况右子节点。以此类推，很容易得出：下标大于n/2 + 1的节点肯定都是也叶子节点了，故而得出结论：对于完全二叉树来说，下标从n/2 + 1 到 n的节点都是叶子节点

备注下：用数组存储表示完全二叉树时，也可以从下标为0开始，只是这样做的话，计算左子节点时，会多一次加法运算

--------------------------------------------------------
## 第二题：

堆的应用除了堆排以外，还有如下一些应用：
1. 从大数量级数据中筛选出top n 条数据； 比如：从几十亿条订单日志中筛选出金额靠前的1000条数据
2. 在一些场景中，会根据不同优先级来处理网络请求，此时也可以用到优先队列(用堆实现的数据结构)；比如：网络框架Volley就用了Java中PriorityBlockingQueue，当然它是线程安全的
3. 可以用堆来实现多路归并，从而实现有序，leetcode上也有相关的一题：Merge K Sorted Lists

暂时只能想到以上三种常见的应用场景，其它的，希望老师补充！
2018-11-26

3

181

Jessie
强烈建议，在进入课程的左侧，做一个目录，这样就不用每次都从最新的滑到最下面了。例如：目前是学到了第35课，已进入课堂，就是35课，假如我想看第一课，就得使劲滑。如果学到100课，那得滑老半天……所以强烈建议给左侧添加一个目录。可以连接到每一节课。！！！
2018-12-13

2

115

WhoAmWe
应用:
1.topK
2.流里面的中值
3.流里面的中位数
作者回复: 👍

2018-11-26


41

冯选刚
不知道有没有人很容易看懂原理思路，就是不愿意看代码
2018-11-27


38

无心拾贝
这TM估计是我唯一看的懂的数据结构与算法吧。 谢谢老师！
2018-11-26


24

猫头鹰爱拿铁
思考题1:堆是完全二叉树，求最后的非叶子节点即是求最大的叶子节点的父节点。最大的叶子节点下标为n，他的父节点为n/2，这是最后一个非叶子节点，所以n/2+1到n都是叶子节点。
思考题2:堆排序的应用-topk问题，例如求数据频率最高的k个数，建立k个数的最小顶堆，然后剩余数据和堆顶比较，如果比堆顶大则替换堆顶并重新调整最小顶堆。
2018-11-26

1

20

insist
这种数据结构堆和java内存模型中的堆内存有什么关系呢？
作者回复: 完全没关系的。

2018-11-26


16

Smallfly
堆应该可以用于实现优先级队列。
2018-11-26


10

朝夕心
思考题1证明
结论：对于完全二叉树来说，下标从(n/2)+1到n都是叶子节点
证明：
假设堆有n个节点
假设满二叉树有h层 则满二叉树的总节点数 2^0+2^1...+2^(h-2)+2^(h-1)=(2^h)-1> n n为h层完全二叉树节点数
堆为完全二叉树，相同高度，完全二叉树总结点数小于满二叉树节点数，即n<(2^h)-1， 即(2^h)>n+1 -----①
完全二叉树1到h-1层节点的数量总和： 2^0+2^1...+2^(h-2)=(2^(h-1))-1=(2^h)/2 -1 -----②
如果数组的第0位也存储数据，由②可知，完全二叉树的第h层开始的节点的下标为i=(2^h)/2 -1，由①，i>((n+1)/2)-1=(n/2)+1
结论1：如果数组的第0位也存储数据，完全二叉树的节点下标至少开始于(n/2)+1
如果数组的第0位不存储数据，则由②可知，完全二叉树的第h层开始的节点的下标为j=(2^h)/2，由①，j>(n+1)/2=(n/2)+2
结论2：如果数组的第0位不存储数据，完全二叉树的节点下标至少开始于(n/2)+2
综上，堆（完全二叉树）的叶子节点的下标范围从(n/2)+1到n-1或从(n/2)+2到n，也即堆的叶子节点下标从(n/2)+1到n
欢迎指正
--不为别的，就为成为更合格的自己
作者回复: 👍

2019-02-26

1

9

鲍勃
linux内核内存中的堆和这个有关系吗？
作者回复: 没关系 完全是两个东西

2018-11-30


7

Brandon
排序队------时间复杂度
堆满足两条：1、完全二叉树（可以很方便的使用数组存储），2、父节点大于或小于子节点-----
插入元素-先放入队尾，再进行堆化（heapify）
删除元素-从最后取一个元素放到删除元素位置，从上往下调整

快排比堆排性能好的原因有二：1、堆排序数据访问的方式有没有快速排序友好；
2、对于同样的数据，在排序的过程中堆排序算法的交换次数多于快速排序
2018-12-14


4

.
"对堆顶节点进行堆化，会依次访问数组下标是 1，2，4，8"。这里图画错了吧，数组下标2 (20)和数组下标3(21)的位置应该是弄反了。如果按原图对堆顶元素堆化的话顺序应该是1,3,6不应该是1,2,4,8
作者回复: 嗯嗯 多谢指正

2018-12-14


4

若星
删除堆顶元素的代码第二行return -1。。
2018-12-12


4

李建轰
老师你好～
heapify方法好像有点问题？
假如第一个非叶子节点是5，左叶子节点是7，右叶子节点是6
然后入heapify方法的这段代码
```
while (true) {
    int maxPos = i;
    if (i*2 <= n && a[i] < a[i*2]) maxPos = i*2;
    if (i*2+1 <= n && a[i] < a[i*2+1]) maxPos = i*2+1
    if (maxPos == i) break;
    swap(a, i, maxPos);
    i = maxPos;
}
```
就会变成第一个非叶子节点是6，左叶子节点是7，右叶子节点是5，因为swap只会执行一次。
我觉得swap方法在前面两个if里面都得有，并且第二个if必须用if，不能用else if。
斗胆提问，请老师答疑～
2018-11-30

1

4

yaya
最后一个结点的父节点是n/2.这是最后一个非叶子结点所以，叶子结点是n/2+1到n。
优先队列的实现用的就是堆
2018-11-26


4

博予liutxer
堆排序和快速排序相比实际开发中不如后者性能好，那堆排序在哪些场景比较有优势呢？
作者回复: 时间复杂度比较稳定 有些排序函数会使用这种排序算法

2018-12-09


3

小二黑
老师，请问堆化自上而下，那段代码，节点和子节点比较大小，是用if判断的吗
作者回复: if判断是什么意思呢

2019-03-27


2

Rephontil
这一节课看了两遍，看得清清楚楚，明明白白😊
2019-01-07


2

Rephontil
老师，“我们将每个非叶子节点的高度求和，就是下面这个公式”，这个公式的末尾部分2^(h-1) * 1应该是不需要的吧，因为这个2^(h-1) * 1是最底层叶子节点的高度。
2019-01-05


2

惟新
好久没看了，又开始重新看了。另外还在线画了思维导图。
2019-01-04


2
收起评论

99+99+






# 29 | 堆的应用：如何快速获取到Top 10最热门的搜索关键词？



数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



29 | 堆的应用：如何快速获取到Top 10最热门的搜索关键词？
王争 2018-11-28



18:44
讲述：修阳 大小：17.16M
搜索引擎的热门搜索排行榜功能你用过吗？你知道这个功能是如何实现的吗？实际上，它的实现并不复杂。搜索引擎每天会接收大量的用户搜索请求，它会把这些用户输入的搜索关键词记录下来，然后再离线地统计分析，得到最热门的 Top 10 搜索关键词。

那请你思考下，假设现在我们有一个包含 10 亿个搜索关键词的日志文件，如何能快速获取到热门榜 Top 10 的搜索关键词呢？

这个问题就可以用堆来解决，这也是堆这种数据结构一个非常典型的应用。上一节我们讲了堆和堆排序的一些理论知识，今天我们就来讲一讲，堆这种数据结构几个非常重要的应用：优先级队列、求 Top K 和求中位数。

堆的应用一：优先级队列
首先，我们来看第一个应用场景：优先级队列。

优先级队列，顾名思义，它首先应该是一个队列。我们前面讲过，队列最大的特性就是先进先出。不过，在优先级队列中，数据的出队顺序不是先进先出，而是按照优先级来，优先级最高的，最先出队。

如何实现一个优先级队列呢？方法有很多，但是用堆来实现是最直接、最高效的。这是因为，堆和优先级队列非常相似。一个堆就可以看作一个优先级队列。很多时候，它们只是概念上的区分而已。往优先级队列中插入一个元素，就相当于往堆中插入一个元素；从优先级队列中取出优先级最高的元素，就相当于取出堆顶元素。

你可别小看这个优先级队列，它的应用场景非常多。我们后面要讲的很多数据结构和算法都要依赖它。比如，赫夫曼编码、图的最短路径、最小生成树算法等等。不仅如此，很多语言中，都提供了优先级队列的实现，比如，Java 的 PriorityQueue，C++ 的 priority_queue 等。

只讲这些应用场景比较空泛，现在，我举两个具体的例子，让你感受一下优先级队列具体是怎么用的。

1. 合并有序小文件
假设我们有 100 个小文件，每个文件的大小是 100MB，每个文件中存储的都是有序的字符串。我们希望将这些 100 个小文件合并成一个有序的大文件。这里就会用到优先级队列。

整体思路有点像归并排序中的合并函数。我们从这 100 个文件中，各取第一个字符串，放入数组中，然后比较大小，把最小的那个字符串放入合并后的大文件中，并从数组中删除。

假设，这个最小的字符串来自于 13.txt 这个小文件，我们就再从这个小文件取下一个字符串，放到数组中，重新比较大小，并且选择最小的放入合并后的大文件，将它从数组中删除。依次类推，直到所有的文件中的数据都放入到大文件为止。

这里我们用数组这种数据结构，来存储从小文件中取出来的字符串。每次从数组中取最小字符串，都需要循环遍历整个数组，显然，这不是很高效。有没有更加高效方法呢？

这里就可以用到优先级队列，也可以说是堆。我们将从小文件中取出来的字符串放入到小顶堆中，那堆顶的元素，也就是优先级队列队首的元素，就是最小的字符串。我们将这个字符串放入到大文件中，并将其从堆中删除。然后再从小文件中取出下一个字符串，放入到堆中。循环这个过程，就可以将 100 个小文件中的数据依次放入到大文件中。

我们知道，删除堆顶数据和往堆中插入数据的时间复杂度都是 O(logn)，n 表示堆中的数据个数，这里就是 100。是不是比原来数组存储的方式高效了很多呢？

2. 高性能定时器
假设我们有一个定时器，定时器中维护了很多定时任务，每个任务都设定了一个要触发执行的时间点。定时器每过一个很小的单位时间（比如 1 秒），就扫描一遍任务，看是否有任务到达设定的执行时间。如果到达了，就拿出来执行。



但是，这样每过 1 秒就扫描一遍任务列表的做法比较低效，主要原因有两点：第一，任务的约定执行时间离当前时间可能还有很久，这样前面很多次扫描其实都是徒劳的；第二，每次都要扫描整个任务列表，如果任务列表很大的话，势必会比较耗时。

针对这些问题，我们就可以用优先级队列来解决。我们按照任务设定的执行时间，将这些任务存储在优先级队列中，队列首部（也就是小顶堆的堆顶）存储的是最先执行的任务。

这样，定时器就不需要每隔 1 秒就扫描一遍任务列表了。它拿队首任务的执行时间点，与当前时间点相减，得到一个时间间隔 T。

这个时间间隔 T 就是，从当前时间开始，需要等待多久，才会有第一个任务需要被执行。这样，定时器就可以设定在 T 秒之后，再来执行任务。从当前时间点到（T-1）秒这段时间里，定时器都不需要做任何事情。

当 T 秒时间过去之后，定时器取优先级队列中队首的任务执行。然后再计算新的队首任务的执行时间点与当前时间点的差值，把这个值作为定时器执行下一个任务需要等待的时间。

这样，定时器既不用间隔 1 秒就轮询一次，也不用遍历整个任务列表，性能也就提高了。

堆的应用二：利用堆求 Top K
刚刚我们学习了优先级队列，我们现在来看，堆的另外一个非常重要的应用场景，那就是“求 Top K 问题”。

我把这种求 Top K 的问题抽象成两类。一类是针对静态数据集合，也就是说数据集合事先确定，不会再变。另一类是针对动态数据集合，也就是说数据集合事先并不确定，有数据动态地加入到集合中。

针对静态数据，如何在一个包含 n 个数据的数组中，查找前 K 大数据呢？我们可以维护一个大小为 K 的小顶堆，顺序遍历数组，从数组中取出数据与堆顶元素比较。如果比堆顶元素大，我们就把堆顶元素删除，并且将这个元素插入到堆中；如果比堆顶元素小，则不做处理，继续遍历数组。这样等数组中的数据都遍历完之后，堆中的数据就是前 K 大数据了。

遍历数组需要 O(n) 的时间复杂度，一次堆化操作需要 O(logK) 的时间复杂度，所以最坏情况下，n 个元素都入堆一次，时间复杂度就是 O(nlogK)。

针对动态数据求得 Top K 就是实时 Top K。怎么理解呢？我举一个例子。一个数据集合中有两个操作，一个是添加数据，另一个询问当前的前 K 大数据。

如果每次询问前 K 大数据，我们都基于当前的数据重新计算的话，那时间复杂度就是 O(nlogK)，n 表示当前的数据的大小。实际上，我们可以一直都维护一个 K 大小的小顶堆，当有数据被添加到集合中时，我们就拿它与堆顶的元素对比。如果比堆顶元素大，我们就把堆顶元素删除，并且将这个元素插入到堆中；如果比堆顶元素小，则不做处理。这样，无论任何时候需要查询当前的前 K 大数据，我们都可以立刻返回给他。

堆的应用三：利用堆求中位数
前面我们讲了如何求 Top K 的问题，现在我们来讲下，如何求动态数据集合中的中位数。

中位数，顾名思义，就是处在中间位置的那个数。如果数据的个数是奇数，把数据从小到大排列，那第 n2+1 个数据就是中位数；如果数据的个数是偶数的话，那处于中间位置的数据有两个，第 n2 个和第 n2+1 个数据，这个时候，我们可以随意取一个作为中位数，比如取两个数中靠前的那个，就是第 n2 个数据。



对于一组静态数据，中位数是固定的，我们可以先排序，第 n2 个数据就是中位数。每次询问中位数的时候，我们直接返回这个固定的值就好了。所以，尽管排序的代价比较大，但是边际成本会很小。但是，如果我们面对的是动态数据集合，中位数在不停地变动，如果再用先排序的方法，每次询问中位数的时候，都要先进行排序，那效率就不高了。

借助堆这种数据结构，我们不用排序，就可以非常高效地实现求中位数操作。我们来看看，它是如何做到的？

我们需要维护两个堆，一个大顶堆，一个小顶堆。大顶堆中存储前半部分数据，小顶堆中存储后半部分数据，且小顶堆中的数据都大于大顶堆中的数据。

也就是说，如果有 n 个数据，n 是偶数，我们从小到大排序，那前 n2 个数据存储在大顶堆中，后 n2 个数据存储在小顶堆中。这样，大顶堆中的堆顶元素就是我们要找的中位数。如果 n 是奇数，情况是类似的，大顶堆就存储 n2+1 个数据，小顶堆中就存储 n2 个数据。



我们前面也提到，数据是动态变化的，当新添加一个数据的时候，我们如何调整两个堆，让大顶堆中的堆顶元素继续是中位数呢？

如果新加入的数据小于等于大顶堆的堆顶元素，我们就将这个新数据插入到大顶堆；否则，我们就将这个新数据插入到小顶堆。

这个时候就有可能出现，两个堆中的数据个数不符合前面约定的情况：如果 n 是偶数，两个堆中的数据个数都是 n2；如果 n 是奇数，大顶堆有 n2+1 个数据，小顶堆有 n2 个数据。这个时候，我们可以从一个堆中不停地将堆顶元素移动到另一个堆，通过这样的调整，来让两个堆中的数据满足上面的约定。



于是，我们就可以利用两个堆，一个大顶堆、一个小顶堆，实现在动态数据集合中求中位数的操作。插入数据因为需要涉及堆化，所以时间复杂度变成了 O(logn)，但是求中位数我们只需要返回大顶堆的堆顶元素就可以了，所以时间复杂度就是 O(1)。

实际上，利用两个堆不仅可以快速求出中位数，还可以快速求其他百分位的数据，原理是类似的。还记得我们在“为什么要学习数据结构与算法”里的这个问题吗？“如何快速求接口的 99% 响应时间？”我们现在就来看下，利用两个堆如何来实现。

在开始这个问题的讲解之前，我先解释一下，什么是“99% 响应时间”。

中位数的概念就是将数据从小到大排列，处于中间位置，就叫中位数，这个数据会大于等于前面 50% 的数据。99 百分位数的概念可以类比中位数，如果将一组数据从小到大排列，这个 99 百分位数就是大于前面 99% 数据的那个数据。

如果你还是不太理解，我再举个例子。假设有 100 个数据，分别是 1，2，3，……，100，那 99 百分位数就是 99，因为小于等于 99 的数占总个数的 99%。



弄懂了这个概念，我们再来看 99% 响应时间。如果有 100 个接口访问请求，每个接口请求的响应时间都不同，比如 55 毫秒、100 毫秒、23 毫秒等，我们把这 100 个接口的响应时间按照从小到大排列，排在第 99 的那个数据就是 99% 响应时间，也叫 99 百分位响应时间。

我们总结一下，如果有 n 个数据，将数据从小到大排列之后，99 百分位数大约就是第 n*99% 个数据，同类，80 百分位数大约就是第 n*80% 个数据。

弄懂了这些，我们再来看如何求 99% 响应时间。

我们维护两个堆，一个大顶堆，一个小顶堆。假设当前总数据的个数是 n，大顶堆中保存 n*99% 个数据，小顶堆中保存 n*1% 个数据。大顶堆堆顶的数据就是我们要找的 99% 响应时间。

每次插入一个数据的时候，我们要判断这个数据跟大顶堆和小顶堆堆顶数据的大小关系，然后决定插入到哪个堆中。如果这个新插入的数据比大顶堆的堆顶数据小，那就插入大顶堆；如果这个新插入的数据比小顶堆的堆顶数据大，那就插入小顶堆。

但是，为了保持大顶堆中的数据占 99%，小顶堆中的数据占 1%，在每次新插入数据之后，我们都要重新计算，这个时候大顶堆和小顶堆中的数据个数，是否还符合 99:1 这个比例。如果不符合，我们就将一个堆中的数据移动到另一个堆，直到满足这个比例。移动的方法类似前面求中位数的方法，这里我就不啰嗦了。

通过这样的方法，每次插入数据，可能会涉及几个数据的堆化操作，所以时间复杂度是 O(logn)。每次求 99% 响应时间的时候，直接返回大顶堆中的堆顶数据即可，时间复杂度是 O(1)。

解答开篇
学懂了上面的一些应用场景的处理思路，我想你应该能解决开篇的那个问题了吧。假设现在我们有一个包含 10 亿个搜索关键词的日志文件，如何快速获取到 Top 10 最热门的搜索关键词呢？

处理这个问题，有很多高级的解决方法，比如使用 MapReduce 等。但是，如果我们将处理的场景限定为单机，可以使用的内存为 1GB。那这个问题该如何解决呢？

因为用户搜索的关键词，有很多可能都是重复的，所以我们首先要统计每个搜索关键词出现的频率。我们可以通过散列表、平衡二叉查找树或者其他一些支持快速查找、插入的数据结构，来记录关键词及其出现的次数。

假设我们选用散列表。我们就顺序扫描这 10 亿个搜索关键词。当扫描到某个关键词时，我们去散列表中查询。如果存在，我们就将对应的次数加一；如果不存在，我们就将它插入到散列表，并记录次数为 1。以此类推，等遍历完这 10 亿个搜索关键词之后，散列表中就存储了不重复的搜索关键词以及出现的次数。

然后，我们再根据前面讲的用堆求 Top K 的方法，建立一个大小为 10 的小顶堆，遍历散列表，依次取出每个搜索关键词及对应出现的次数，然后与堆顶的搜索关键词对比。如果出现次数比堆顶搜索关键词的次数多，那就删除堆顶的关键词，将这个出现次数更多的关键词加入到堆中。

以此类推，当遍历完整个散列表中的搜索关键词之后，堆中的搜索关键词就是出现次数最多的 Top 10 搜索关键词了。

不知道你发现了没有，上面的解决思路其实存在漏洞。10 亿的关键词还是很多的。我们假设 10 亿条搜索关键词中不重复的有 1 亿条，如果每个搜索关键词的平均长度是 50 个字节，那存储 1 亿个关键词起码需要 5GB 的内存空间，而散列表因为要避免频繁冲突，不会选择太大的装载因子，所以消耗的内存空间就更多了。而我们的机器只有 1GB 的可用内存空间，所以我们无法一次性将所有的搜索关键词加入到内存中。这个时候该怎么办呢？

我们在哈希算法那一节讲过，相同数据经过哈希算法得到的哈希值是一样的。我们可以根据哈希算法的这个特点，将 10 亿条搜索关键词先通过哈希算法分片到 10 个文件中。

具体可以这样做：我们创建 10 个空文件 00，01，02，……，09。我们遍历这 10 亿个关键词，并且通过某个哈希算法对其求哈希值，然后哈希值同 10 取模，得到的结果就是这个搜索关键词应该被分到的文件编号。

对这 10 亿个关键词分片之后，每个文件都只有 1 亿的关键词，去除掉重复的，可能就只有 1000 万个，每个关键词平均 50 个字节，所以总的大小就是 500MB。1GB 的内存完全可以放得下。

我们针对每个包含 1 亿条搜索关键词的文件，利用散列表和堆，分别求出 Top 10，然后把这个 10 个 Top 10 放在一块，然后取这 100 个关键词中，出现次数最多的 10 个关键词，这就是这 10 亿数据中的 Top 10 最频繁的搜索关键词了。

内容小结
我们今天主要讲了堆的几个重要的应用，它们分别是：优先级队列、求 Top K 问题和求中位数问题。

优先级队列是一种特殊的队列，优先级高的数据先出队，而不再像普通的队列那样，先进先出。实际上，堆就可以看作优先级队列，只是称谓不一样罢了。求 Top K 问题又可以分为针对静态数据和针对动态数据，只需要利用一个堆，就可以做到非常高效率的查询 Top K 的数据。求中位数实际上还有很多变形，比如求 99 百分位数据、90 百分位数据等，处理的思路都是一样的，即利用两个堆，一个大顶堆，一个小顶堆，随着数据的动态添加，动态调整两个堆中的数据，最后大顶堆的堆顶元素就是要求的数据。

课后思考
有一个访问量非常大的新闻网站，我们希望将点击量排名 Top 10 的新闻摘要，滚动显示在网站首页 banner 上，并且每隔 1 小时更新一次。如果你是负责开发这个功能的工程师，你会如何来实现呢？

欢迎留言和我分享，我会第一时间给你反馈。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(121)

feifei
有一个访问量非常大的新闻网站，我们希望将点击量排名 Top 10 的新闻摘要，滚动显示在网站首页 banner 上，并且每隔 1 小时更新一次。如果你是负责开发这个功能的工程师，你会如何来实现呢？

我的思路是这样子，
1，对每篇新闻摘要计算一个hashcode，并建立摘要与hashcode的关联关系，使用map存储，以hashCode为key，新闻摘要为值
2，按每小时一个文件的方式记录下被点击的摘要的hashCode
3，当一个小时结果后，上一个小时的文件被关闭，开始计算上一个小时的点击top10
4，将hashcode分片到多个文件中，通过对hashCode取模运算，即可将相同的hashCode分片到相同的文件中
5，针对每个文件取top10的hashCode，使用Map<hashCode,int>的方式，统计出所有的摘要点击次数，然后再使用小顶堆（大小为10）计算top10,
6，再针对所有分片计算一个总的top10,最后合并的逻辑也是使用小顶堆，计算top10
7，如果仅展示前一个小时的top10,计算结束
8，如果需要展示全天，需要与上一次的计算按hashCode进行合并，然后在这合并的数据中取top10
9，在展示时，将计算得到的top10的hashcode，转化为新闻摘要显示即可

老师，你讲的这些例子，我觉得对我的工作和学习很有帮助，于是我花了一个周末将这一章节，将你所讲的堆的应用示例，全部翻译成了代码，并做了相关的验证，感觉自己收获很多，我也将这块代码上传了github，欢迎老师你的指正，需要的同学，也可以一起交流，

1，合并有序小文件
https://github.com/kkzfl22/datastruct/tree/master/src/main/java/com/liujun/datastruct/heap/solution/margeSmailFile
2，高性能定时器的应用
https://github.com/kkzfl22/datastruct/tree/master/src/main/java/com/liujun/datastruct/heap/solution/highTimeSchedule
3，求topk
https://github.com/kkzfl22/datastruct/tree/master/src/main/java/com/liujun/datastruct/heap/solution/topK
4，求中位数
https://github.com/kkzfl22/datastruct/tree/master/src/main/java/com/liujun/datastruct/heap/solution/midnum
5 ,大文件的关键字的统计
https://github.com/kkzfl22/datastruct/tree/master/src/main/java/com/liujun/datastruct/heap/solution/bigFileTopN

2018-12-02

2

280

Miletos
“如果新加入的数据小于等于大顶堆的堆顶元素，我们就将这个新数据插入到大顶堆；如果新加入的数据大于等于小顶堆的堆顶元素，我们就将这个新数据插入到小顶堆。”

1. 这里不太对劲，前文中说到，小顶堆的堆顶大于大顶堆的堆顶。

如果新进元素在小顶堆堆顶和大顶堆堆顶元素值之间，没有规定插入哪个堆。

我觉得，是不是只要判断一次就可以了。新进元素值大于等于小顶堆堆顶元素的，插入小顶堆，否则插入大顶堆。
当某一个堆数据过多时再重新移动堆顶元素。

2. 求中位数的源数据中，是否允许重复数据？
作者回复: 1 你说的对 我改下 多谢指正
2 可以重复

2018-11-28

1

55

蔷薇骑士
定时任务这个例子感觉有问题吧，定时任务是动态加入的，假设当前堆顶的任务是一个小时后的，难道这一个小时都不做扫描吗，随时可能会加入需要更早执行的任务
2018-12-14

5

43

守着云开
10亿关键词分片之后 每个文件并不一定有1亿的关键词吧 老师
2018-11-28


28

想当上帝的司机
堆求topK的静态数据 应该是先把堆填满 再拿数组中的元素跟堆顶比较吧
2018-12-23


18

oatlmy
老师，请问为什么评价算法性能是根据时间和空间复杂度，而不是别的参数？是因为计算机结构是冯诺依曼体系，除了输入输出设备和控制器，就剩下运算器和存储器了吗？
作者回复: 你理解的没错

2018-11-28


16

豪华
老师，分片求取前十是不是有bug，如果有一个关键词在每一组分片中都是前第十一位，在整个十亿中个数总和是第一位，是不是用分片求出了错误的结果呢？
作者回复: 不会的 相同的关键词经过哈希之后只会到一台机器

2018-11-28


15

辉哥
思考题：1，维护两个散列表，一个是一小时新增的点击量的散列表，以新闻id为键，点击次数为值。一个是全部点击量的散列表。每隔一小时把新增的散列表的数据同步到全部点击量的散列表。然后把这小时内有变化的全部点击量的散列表的数据（即此小时有新增点击量的新闻数据）和我们维护的10个元素小顶堆堆顶进行比较，比堆顶的点击量大的，则使用该元素替换堆顶，再进行堆化。比堆顶点击量小的则不做处理。然后比较完，根据堆顶的10个元素的id，从数据库读取相应的新闻摘要显示在banner上。除此之外，还要把变化后的全部点击量散列表同步到数据库。因为保存的是新闻id，所以散列表长度不会很大，所占用的内存也不会很大。而每个小时新增的访问量的新闻id数也不会很多，毕竟很多人只会阅读热门消息。所以新增的点击量的新闻数据假设为k,则每小时同步小顶堆的时间负责度为o(klg 10);
2018-12-02


12

Aaaaaaaaaaayou
topK 是不是应该先要填满堆，后面插入的时候再做删除操作
作者回复: 是的。

2019-02-20

1

9

ALAN
1:建一个散射列表，key为点击网址，value为点击次数。散射列表通过从log中计算得来。
2:建一个10个数据的小顶堆，数据值为点击次数，扫描散射列表，新元素次数比堆顶元素大则删除堆顶元素，插入新元素，小则继续扫描散射列表。
3:扫描完整个散射列表后，即得到top 10点击量，将点击网址存储在数组A中。数组A一个小时更新一次。
4:散射列表实时更新，小顶堆也实时更新，以一小时为间隔，将小顶堆结果更新到数组A中。
2018-11-28


8

ZX
看了这一章，发现堆删除任意元素这个方法毫无意义啊。只有删除堆顶元素才有意义
作者回复: 是的啊 没有说过删除任意元素呢

2018-12-02


6

happiness_xcy
方案前提，所有数据都保存在一台服务器的内存中，不考虑HA、数据更新冲突等情况。我们假设每条新闻都有一个全局唯一的新闻ID，使用hashmap(map_a)来保存每篇新闻的访问量，key为新闻ID，value为当前访问总次数。使用另一个hashmap(map_b)来保存一个周期内map_a中value值发生变化的key。

整个方案分为三个阶段，堆的初始化、hashmap实时变更、堆更新。
初始化阶段：建立一个大小为10的小顶堆，遍历此时的hashmap，完成堆的初始化。
hashmap实时变更阶段：保存在当前周期内，将map_a中value产生变化的key到map_b中。
堆更新阶段：在一个周期结束后，遍历map_b，并将map_a中保存的value与当前堆顶进行比较，如果大于堆顶，则删除堆顶，并插入该value，如果小于堆顶则不做处理。遍历完map_b之后，该堆保有了上个周期访问量top10的新闻id和value。最后清空map_b，为下一个周期作准备。最坏时间复杂度为O(nlog10)，其中n为map_b中key的数量。
2018-12-22


5

小新是也
如果我要1%到99%响应时间，这样建的堆就有点多了
作者回复: 这需求...具体问题具体分析吧

2018-12-09


5

Jerry银银
早起的鸟儿读算法。


原理上跟统计热门搜索关键词类似。后台起一个定时任务，从最新被新点击的新闻日志文件中统计出每条新闻的点击量(也得类似于老师那样使用散列表)，然后建立和维护内存中大小为10的最大堆，这样网站点击次数Top10的新闻就被统计出来了。

这题也可以使用MapReduce算法
2018-11-28

1

4

小美
王老师 第一点合并有序小文件 为什么要用到优先级队列 和 堆还是不理解。两个比最小取出合并，只要两个数组是有序就可以了，快排成有序，从小到大比较合并，不可以吗，为什么要用到优先级队列，方便老师解答下吗
作者回复: 没太看懂你说的 用优先级是为了效率

2018-11-28


3

A_F
Hadoop、Spark入门demo——wordcount了解下
2018-11-28


3

Jerry银银
早起的鸟儿读算法。

文章中『解答开篇』部分，说是扫描1亿个热门关键词，这应该是错别字吧，应该是10亿个吧。看了好几遍，我应该没理解错吧😄

老师说使用散列表统计10亿个搜索关键词的频率，但是这里的约束条件是10亿个关键词中确实有很多重复，而且去重之后的数据，内存中是能够放得下的。如果单机内存放不下，应该就不能这么做了

---------------------------------------------------------

以上是我早上本来要留言的，但是并没有一字不漏的看完文章。我回头一想不对，文章中肯定会考虑到这个情况。当我看完，我就把以上留言删了。

唉，阅读时，犯了一个低级错误，记录在此，提醒自己
作者回复: 是我写错了 不好意思 马上修改

2018-11-28


3

小花小黑的铲屎官
我们遍历这 10 亿个关键词，并且通过某个哈希算法对其求哈希值，然后哈希值同 10 取模，得到的结果就是这个搜索关键词应该被分到的文件编号。
这样并不能保证每个文件都是一亿条数据吧？可能多也可能少吧？
作者回复: 是的 你说的没错

2018-12-14


2

竹林清风
思考题：
1、实时建立散列表，key是新闻的摘要，value是点击量；
2、建立一个10的小顶堆，每隔一个小时扫描一次散列表，根据点击量大小放入到小顶堆中，扫描完散列表后即出现Top10 的新闻点击量。
2018-12-05


2

吴宇晨
可以先用散列表存帖子和点击数的关系，然后每一小时定时遍历散列表用文中的方法，往大小为10的小顶堆插数据？
2018-11-28


2
收起评论

99+99+





# 30 | 图的表示：如何存储微博、微信等社交网络中的好友关系？



数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



30 | 图的表示：如何存储微博、微信等社交网络中的好友关系？
王争 2018-11-30



13:52
讲述：修阳 大小：12.71M
微博、微信、LinkedIn 这些社交软件我想你肯定都玩过吧。在微博中，两个人可以互相关注；在微信中，两个人可以互加好友。那你知道，如何存储微博、微信等这些社交网络的好友关系吗？

这就要用到我们今天要讲的这种数据结构：图。实际上，涉及图的算法有很多，也非常复杂，比如图的搜索、最短路径、最小生成树、二分图等等。我们今天聚焦在图存储这一方面，后面会分好几节来依次讲解图相关的算法。

如何理解“图”？
我们前面讲过了树这种非线性表数据结构，今天我们要讲另一种非线性表数据结构，图（Graph）。和树比起来，这是一种更加复杂的非线性表结构。

我们知道，树中的元素我们称为节点，图中的元素我们就叫作顶点（vertex）。从我画的图中可以看出来，图中的一个顶点可以与任意其他顶点建立连接关系。我们把这种建立的关系叫作边（edge）。



我们生活中就有很多符合图这种结构的例子。比如，开篇问题中讲到的社交网络，就是一个非常典型的图结构。

我们就拿微信举例子吧。我们可以把每个用户看作一个顶点。如果两个用户之间互加好友，那就在两者之间建立一条边。所以，整个微信的好友关系就可以用一张图来表示。其中，每个用户有多少个好友，对应到图中，就叫作顶点的度（degree），就是跟顶点相连接的边的条数。

实际上，微博的社交关系跟微信还有点不一样，或者说更加复杂一点。微博允许单向关注，也就是说，用户 A 关注了用户 B，但用户 B 可以不关注用户 A。那我们如何用图来表示这种单向的社交关系呢？

我们可以把刚刚讲的图结构稍微改造一下，引入边的“方向”的概念。

如果用户 A 关注了用户 B，我们就在图中画一条从 A 到 B 的带箭头的边，来表示边的方向。如果用户 A 和用户 B 互相关注了，那我们就画一条从 A 指向 B 的边，再画一条从 B 指向 A 的边。我们把这种边有方向的图叫作“有向图”。以此类推，我们把边没有方向的图就叫作“无向图”。



我们刚刚讲过，无向图中有“度”这个概念，表示一个顶点有多少条边。在有向图中，我们把度分为入度（In-degree）和出度（Out-degree）。

顶点的入度，表示有多少条边指向这个顶点；顶点的出度，表示有多少条边是以这个顶点为起点指向其他顶点。对应到微博的例子，入度就表示有多少粉丝，出度就表示关注了多少人。

前面讲到了微信、微博、无向图、有向图，现在我们再来看另一种社交软件：QQ。

QQ 中的社交关系要更复杂的一点。不知道你有没有留意过 QQ 亲密度这样一个功能。QQ 不仅记录了用户之间的好友关系，还记录了两个用户之间的亲密度，如果两个用户经常往来，那亲密度就比较高；如果不经常往来，亲密度就比较低。如何在图中记录这种好友关系的亲密度呢？

这里就要用到另一种图，带权图（weighted graph）。在带权图中，每条边都有一个权重（weight），我们可以通过这个权重来表示 QQ 好友间的亲密度。



关于图的概念比较多，我今天也只是介绍了几个常用的，理解起来都不复杂，不知道你都掌握了没有？掌握了图的概念之后，我们再来看下，如何在内存中存储图这种数据结构呢？

邻接矩阵存储方法
图最直观的一种存储方法就是，邻接矩阵（Adjacency Matrix）。

邻接矩阵的底层依赖一个二维数组。对于无向图来说，如果顶点 i 与顶点 j 之间有边，我们就将 A[i][j] 和 A[j][i] 标记为 1；对于有向图来说，如果顶点 i 到顶点 j 之间，有一条箭头从顶点 i 指向顶点 j 的边，那我们就将 A[i][j] 标记为 1。同理，如果有一条箭头从顶点 j 指向顶点 i 的边，我们就将 A[j][i] 标记为 1。对于带权图，数组中就存储相应的权重。



用邻接矩阵来表示一个图，虽然简单、直观，但是比较浪费存储空间。为什么这么说呢？

对于无向图来说，如果 A[i][j] 等于 1，那 A[j][i] 也肯定等于 1。实际上，我们只需要存储一个就可以了。也就是说，无向图的二维数组中，如果我们将其用对角线划分为上下两部分，那我们只需要利用上面或者下面这样一半的空间就足够了，另外一半白白浪费掉了。

还有，如果我们存储的是稀疏图（Sparse Matrix），也就是说，顶点很多，但每个顶点的边并不多，那邻接矩阵的存储方法就更加浪费空间了。比如微信有好几亿的用户，对应到图上就是好几亿的顶点。但是每个用户的好友并不会很多，一般也就三五百个而已。如果我们用邻接矩阵来存储，那绝大部分的存储空间都被浪费了。

但这也并不是说，邻接矩阵的存储方法就完全没有优点。首先，邻接矩阵的存储方式简单、直接，因为基于数组，所以在获取两个顶点的关系时，就非常高效。其次，用邻接矩阵存储图的另外一个好处是方便计算。这是因为，用邻接矩阵的方式存储图，可以将很多图的运算转换成矩阵之间的运算。比如求解最短路径问题时会提到一个Floyd-Warshall 算法，就是利用矩阵循环相乘若干次得到结果。

邻接表存储方法
针对上面邻接矩阵比较浪费内存空间的问题，我们来看另外一种图的存储方法，邻接表（Adjacency List）。

我画了一张邻接表的图，你可以先看下。乍一看，邻接表是不是有点像散列表？每个顶点对应一条链表，链表中存储的是与这个顶点相连接的其他顶点。另外我需要说明一下，图中画的是一个有向图的邻接表存储方式，每个顶点对应的链表里面，存储的是指向的顶点。对于无向图来说，也是类似的，不过，每个顶点的链表中存储的，是跟这个顶点有边相连的顶点，你可以自己画下。



还记得我们之前讲过的时间、空间复杂度互换的设计思想吗？邻接矩阵存储起来比较浪费空间，但是使用起来比较节省时间。相反，邻接表存储起来比较节省空间，但是使用起来就比较耗时间。

就像图中的例子，如果我们要确定，是否存在一条从顶点 2 到顶点 4 的边，那我们就要遍历顶点 2 对应的那条链表，看链表中是否存在顶点 4。而且，我们前面也讲过，链表的存储方式对缓存不友好。所以，比起邻接矩阵的存储方式，在邻接表中查询两个顶点之间的关系就没那么高效了。

在散列表那几节里，我讲到，在基于链表法解决冲突的散列表中，如果链过长，为了提高查找效率，我们可以将链表换成其他更加高效的数据结构，比如平衡二叉查找树等。我们刚刚也讲到，邻接表长得很像散列。所以，我们也可以将邻接表同散列表一样进行“改进升级”。

我们可以将邻接表中的链表改成平衡二叉查找树。实际开发中，我们可以选择用红黑树。这样，我们就可以更加快速地查找两个顶点之间是否存在边了。当然，这里的二叉查找树可以换成其他动态数据结构，比如跳表、散列表等。除此之外，我们还可以将链表改成有序动态数组，可以通过二分查找的方法来快速定位两个顶点之间否是存在边。

解答开篇
有了前面讲的理论知识，现在我们回过头来看开篇的问题，如何存储微博、微信等社交网络中的好友关系？

前面我们分析了，微博、微信是两种“图”，前者是有向图，后者是无向图。在这个问题上，两者的解决思路差不多，所以我只拿微博来讲解。

数据结构是为算法服务的，所以具体选择哪种存储方法，与期望支持的操作有关系。针对微博用户关系，假设我们需要支持下面这样几个操作：

判断用户 A 是否关注了用户 B；

判断用户 A 是否是用户 B 的粉丝；

用户 A 关注用户 B；

用户 A 取消关注用户 B；

根据用户名称的首字母排序，分页获取用户的粉丝列表；

根据用户名称的首字母排序，分页获取用户的关注列表。

关于如何存储一个图，前面我们讲到两种主要的存储方法，邻接矩阵和邻接表。因为社交网络是一张稀疏图，使用邻接矩阵存储比较浪费存储空间。所以，这里我们采用邻接表来存储。

不过，用一个邻接表来存储这种有向图是不够的。我们去查找某个用户关注了哪些用户非常容易，但是如果要想知道某个用户都被哪些用户关注了，也就是用户的粉丝列表，是非常困难的。

基于此，我们需要一个逆邻接表。邻接表中存储了用户的关注关系，逆邻接表中存储的是用户的被关注关系。对应到图上，邻接表中，每个顶点的链表中，存储的就是这个顶点指向的顶点，逆邻接表中，每个顶点的链表中，存储的是指向这个顶点的顶点。如果要查找某个用户关注了哪些用户，我们可以在邻接表中查找；如果要查找某个用户被哪些用户关注了，我们从逆邻接表中查找。



基础的邻接表不适合快速判断两个用户之间是否是关注与被关注的关系，所以我们选择改进版本，将邻接表中的链表改为支持快速查找的动态数据结构。选择哪种动态数据结构呢？红黑树、跳表、有序动态数组还是散列表呢？

因为我们需要按照用户名称的首字母排序，分页来获取用户的粉丝列表或者关注列表，用跳表这种结构再合适不过了。这是因为，跳表插入、删除、查找都非常高效，时间复杂度是 O(logn)，空间复杂度上稍高，是 O(n)。最重要的一点，跳表中存储的数据本来就是有序的了，分页获取粉丝列表或关注列表，就非常高效。

如果对于小规模的数据，比如社交网络中只有几万、几十万个用户，我们可以将整个社交关系存储在内存中，上面的解决思路是没有问题的。但是如果像微博那样有上亿的用户，数据规模太大，我们就无法全部存储在内存中了。这个时候该怎么办呢？

我们可以通过哈希算法等数据分片方式，将邻接表存储在不同的机器上。你可以看下面这幅图，我们在机器 1 上存储顶点 1，2，3 的邻接表，在机器 2 上，存储顶点 4，5 的邻接表。逆邻接表的处理方式也一样。当要查询顶点与顶点关系的时候，我们就利用同样的哈希算法，先定位顶点所在的机器，然后再在相应的机器上查找。



除此之外，我们还有另外一种解决思路，就是利用外部存储（比如硬盘），因为外部存储的存储空间要比内存会宽裕很多。数据库是我们经常用来持久化存储关系数据的，所以我这里介绍一种数据库的存储方式。

我用下面这张表来存储这样一个图。为了高效地支持前面定义的操作，我们可以在表上建立多个索引，比如第一列、第二列，给这两列都建立索引。



内容小结
今天我们学习了图这种非线性表数据结构，关于图，你需要理解这样几个概念：无向图、有向图、带权图、顶点、边、度、入度、出度。除此之外，我们还学习了图的两个主要的存储方式：邻接矩阵和邻接表。

邻接矩阵存储方法的缺点是比较浪费空间，但是优点是查询效率高，而且方便矩阵运算。邻接表存储方法中每个顶点都对应一个链表，存储与其相连接的其他顶点。尽管邻接表的存储方式比较节省存储空间，但链表不方便查找，所以查询效率没有邻接矩阵存储方式高。针对这个问题，邻接表还有改进升级版，即将链表换成更加高效的动态数据结构，比如平衡二叉查找树、跳表、散列表等。

课后思考
关于开篇思考题，我们只讲了微博这种有向图的解决思路，那像微信这种无向图，应该怎么存储呢？你可以照着我的思路，自己做一下练习。

除了我今天举的社交网络可以用图来表示之外，符合图这种结构特点的例子还有很多，比如知识图谱（Knowledge Graph）。关于图这种数据结构，你还能想到其他生活或者工作中的例子吗？

欢迎留言和我分享，我会第一时间给你反馈。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(89)

传说中的成大大
学了这么久的数据结构和算法，今天突然顿悟，基础的数据结构就是数组和链表， 而后面更加复杂的 树 队列 图 等等 都可以通过数组和链表等方式存储， 出现树 队列 图 等数据结构的原因 就是为了解决 部分问题处理过程中时间复杂度过高的问题， 所以数据结构就是为了算法而生的！ 尤其是学习了时间复杂度过后 在工作和学习过程中 就应该分析自己的代码复杂度 以进行优化或者选择更好的数据结构和算法！这样才能写出更好的代码更好的解决问题
2018-11-30


257

Jerry银银
地图

网络

Gradle这个编译工具，内部组织task的方式用的是有向图

Android framework层提供了一个CoordinatorLayout，其内部协调子view的联动，也是用的图
作者回复: 👍

2018-11-30


58

黄金的太阳
请教老师
解决现实问题的时候当存储图有多种选择，例如:
1.用邻接表自己存
2.关系型库
3.图数据库
那么这三种方式每一种的适用场景，优缺点分别是什么呢？该如何取舍
作者回复: 1 内存中用临界表
2 要持久化存储就用数据库
2 超大图 并且涉及大量图计算。用专业的图数据库

2018-12-04


32

五岳寻仙
课后思考题：
1. 微信好友关系存储方式。无向图，也可以使用邻接表的方式存储每个人所对应的好友列表。为了支持快速查找，好友列表可以使用红黑树存储。
2. 生活工作中应用图的例子。很多，互联网上网页之间通过超链接连接成一张有向图；城市乃至全国交通网络是一张加权图；人与人之间的人际关系够成一张图，著名的六度分割理论据说就是基于这个得到的。
作者回复: 👍

2018-11-30

1

28

花见笑
学到现在有一种特别明显的感受就是描述一种需求模型可以有很多种组合数据结构，而这些复杂数据结构都是基础数据结构组合起来的，而这些数据结构去的选择又是基于需求模型对时间和空间这两个维度来的，所以解决问题的关键是我们都需求的理解以及我们对数据结构的熟练运用。
2018-12-01


22

汝林外史
真心感谢王老师，以前看见数据结构和算法都直接略过，感觉很难啃直接就放弃了，不求甚解，经过这段时间得学习发现自己还是可以学的会的，而且也慢慢喜欢看这些数据结构了，老师的功力真的很深厚！
2018-12-06


15

鹏程万里
判断用户 A 是否关注了用户 B； 判断用户 A 是否是用户B的粉丝。这两个操作我怎么觉得是一个意思呢？
作者回复: 好像是的 第二个应该是 判断a是否被b关注

2018-12-03


14

姜戈
有序动态数组能否讲解一下
作者回复: 数据有序排列的动态数组

2018-11-30


12

🐱您的好友William🐱
刚刚还在写Topology Sort，就是leetcode那个给课程先后顺序排列的题。我还知道社交Graph在推荐系统中应用非常广泛（腾讯的人亲口说这是他们很多产品的最大亮点，因为可以做社交）。使用了social trust的推荐系统非常的robust且能够经受大规模水军的攻击，因为水军无法取得用户的trust（graph中无法建立联系），所以水军的行为在推荐系统中会被认为对给用户的影响会非常的小，使得系统的预测基本不变。
2018-11-30


11

ppingfann
微信社交关系的存储方式

因为顶点的数量大且关系相对少，所以不适合用邻接矩阵来存储，应该用邻接表来存储。
微信社交关系的相关操作：1. 判断A、B是否为好友关系 2. A删除B，断开与B的好友关系 3. 展示出A的所有好友，并按名称首字母进行排序

因为是无向图，所以我们仅需要一个邻接表就行了，然后将链表改造为跳表增加查找速度且在列出好友是会比较方便。最后，若有n台机器可供使用，那么我们可以对n取余来划分这些数据到不同的机器上，毕竟微信的用户量太大，一个机器的内存应该是不够用的。
2018-11-30


10

微418信Im团a队teapot
微信也是有向图吧……微信单方面删除好友之后另一方仍然会显示在好友列表中的啊(俗称僵尸)
作者回复: 哈哈，在这个问题上，从你的昵称来看，你最有发言权了。

2019-02-08


8

qinggeouye
复杂网络可以说也是基于图，抽象出来的随机网络、小世界网络、无标度网络等都可以用图表示；根据图的组成基本要素：节点和边，现实世界中只要可以将具体的事物抽象出节点，并且节点之间是有联系的，那么应该都可以成为图；比如以城市机场作为节点，城市之间的航班飞行网络；...
2018-12-23


4

任雪龙
终于到图了，感觉有点小激动呢
2018-11-30

1

4

Monday
第1题：使用邻接表存储，并且使用改进升级版（使用跳表或散列表等）
第2题：1）我司所开发的工作流项目描述的就是有向图。2）小到公交车/地铁网络图，大到国家的铁路分布图。3）韩国偶像局，人物之间的暗恋关系。4）ETL跑批时，各JOB之间的依赖关系。。。等等等等太多了
作者回复: 👍

2018-12-04


3

qpm
微信的用户无向图中，首先为了节约空间，采用的要是邻接表的方式，由于数据量巨大，进一步关于存储的优化和老师文中记述的类似。
图的数据结构相对其他数据结构而言是更加贴合生活场景的，事物和联系的信息可以映射为节点和边，例如百度在地图中的寻路功能应该是要利用到节点和边权重等方面的信息，期待老师对图的用法做更深入的讲解。
最后我希望提一个关于邻接表的问题，文中邻接表中，‘节点’指向的是下一个‘节点’的信息，那么‘边’的信息应该如何保存？要是‘节点’指向的是‘边’的信息，‘边’自己又包含另一头‘节点’的下标，这样的存储方式虽然不是很直观，但是也是一种有效的存储方式。老师是否可以就‘邻接表’上‘边’的存储讲解一下？
作者回复: 实际上 我们并不需要显示的存储边 具体存储方式你可以看下一节课开头的代码

2018-12-02


3

yongxiang
问题一：
微信好友：
1、微信的好友关系是稀疏矩阵，为了减少空间浪费，使用邻接表；
2、为了提高查找效率，将邻接表中的链表改为支持快速查找的动态数据结构，这里使用红黑树、跳表都可以，考虑到好友列表是按照字母排序的，可以使用跳表
问题二：
图的例子还有：操作系统的资源分配图是有向图，用来分析死锁问题。
2018-12-01


3

不靠谱的琴谱
有向图的矩阵下标2 0和3 2的1和0感觉画反了，还有带权图线上面表示的是5矩阵里面表示的5 3不是很理解
作者回复: adj行列都是从1开始的。我检查了一下 好像没画错

2018-11-30


3

想当上帝的司机
感觉最后数据库中那张表用起来就能满足需求了，上面说的图的优势是什么呢
2018-12-24


2

葵花老师傅
对于课后习题的第一题：
对于无向图的存储使用邻接表存储的时候，如果出现要去除两个顶点间的边的话，是不是得操作两次呢？
然后看到评论的大神们邻接表的链表使用能支持快速查询的数据结构如红黑树、散列表等结构，这样的话可能在进行修改，删除操作的时候的消耗会不会随之增加。 如果按这个来说无向图使用邻接表会不会是一个最优的解呢。 本人愚昧 暂时没想到更好的办法- -
作者回复: 即便是两次操作，操作成本稍微高了点，但时间复杂度并没有变大。最优解？这个本身就不存在什么最优解呢？要根据具体业务场景来看。

2019-07-25


1

Knight²º¹⁸
图只是逻辑上的一个概念，把实体的关系反映在一张图上，实际储存等操作本质上还是数组+链表，因此优化手段也就是前面所讲到的散列、二叉平衡查找树、跳表等
2019-05-30


1
收起评论

8999+






# 31 | 深度和广度优先搜索：如何找出社交网络中的三度好友关系？




数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



31 | 深度和广度优先搜索：如何找出社交网络中的三度好友关系？
王争 2018-12-03



10:42
讲述：修阳 大小：9.81M
上一节我们讲了图的表示方法，讲到如何用有向图、无向图来表示一个社交网络。在社交网络中，有一个六度分割理论，具体是说，你与世界上的另一个人间隔的关系不会超过六度，也就是说平均只需要六步就可以联系到任何两个互不相识的人。

一个用户的一度连接用户很好理解，就是他的好友，二度连接用户就是他好友的好友，三度连接用户就是他好友的好友的好友。在社交网络中，我们往往通过用户之间的连接关系，来实现推荐“可能认识的人”这么一个功能。今天的开篇问题就是，给你一个用户，如何找出这个用户的所有三度（其中包含一度、二度和三度）好友关系？

这就要用到今天要讲的深度优先和广度优先搜索算法。

什么是“搜索”算法？
我们知道，算法是作用于具体数据结构之上的，深度优先搜索算法和广度优先搜索算法都是基于“图”这种数据结构的。这是因为，图这种数据结构的表达能力很强，大部分涉及搜索的场景都可以抽象成“图”。

图上的搜索算法，最直接的理解就是，在图中找出从一个顶点出发，到另一个顶点的路径。具体方法有很多，比如今天要讲的两种最简单、最“暴力”的深度优先、广度优先搜索，还有 A*、IDA* 等启发式搜索算法。

我们上一节讲过，图有两种主要存储方法，邻接表和邻接矩阵。今天我会用邻接表来存储图。

我这里先给出图的代码实现。需要说明一下，深度优先搜索算法和广度优先搜索算法，既可以用在无向图，也可以用在有向图上。在今天的讲解中，我都针对无向图来讲解。

public class Graph { // 无向图
  private int v; // 顶点的个数
  private LinkedList<Integer> adj[]; // 邻接表
 
  public Graph(int v) {
    this.v = v;
    adj = new LinkedList[v];
    for (int i=0; i<v; ++i) {
      adj[i] = new LinkedList<>();
    }
  }
 
  public void addEdge(int s, int t) { // 无向图一条边存两次
    adj[s].add(t);
    adj[t].add(s);
  }
}
广度优先搜索（BFS）
广度优先搜索（Breadth-First-Search），我们平常都把简称为 BFS。直观地讲，它其实就是一种“地毯式”层层推进的搜索策略，即先查找离起始顶点最近的，然后是次近的，依次往外搜索。理解起来并不难，所以我画了一张示意图，你可以看下。



尽管广度优先搜索的原理挺简单，但代码实现还是稍微有点复杂度。所以，我们重点讲一下它的代码实现。

这里面，bfs() 函数就是基于之前定义的，图的广度优先搜索的代码实现。其中 s 表示起始顶点，t 表示终止顶点。我们搜索一条从 s 到 t 的路径。实际上，这样求得的路径就是从 s 到 t 的最短路径。

public void bfs(int s, int t) {
  if (s == t) return;
  boolean[] visited = new boolean[v];
  visited[s]=true;
  Queue<Integer> queue = new LinkedList<>();
  queue.add(s);
  int[] prev = new int[v];
  for (int i = 0; i < v; ++i) {
    prev[i] = -1;
  }
  while (queue.size() != 0) {
    int w = queue.poll();
   for (int i = 0; i < adj[w].size(); ++i) {
      int q = adj[w].get(i);
      if (!visited[q]) {
        prev[q] = w;
        if (q == t) {
          print(prev, s, t);
          return;
        }
        visited[q] = true;
        queue.add(q);
      }
    }
  }
}
 
private void print(int[] prev, int s, int t) { // 递归打印 s->t 的路径
  if (prev[t] != -1 && t != s) {
    print(prev, s, prev[t]);
  }
  System.out.print(t + " ");
}
这段代码不是很好理解，里面有三个重要的辅助变量 visited、queue、prev。只要理解这三个变量，读懂这段代码估计就没什么问题了。

visited是用来记录已经被访问的顶点，用来避免顶点被重复访问。如果顶点 q 被访问，那相应的 visited[q] 会被设置为 true。

queue是一个队列，用来存储已经被访问、但相连的顶点还没有被访问的顶点。因为广度优先搜索是逐层访问的，也就是说，我们只有把第 k 层的顶点都访问完成之后，才能访问第 k+1 层的顶点。当我们访问到第 k 层的顶点的时候，我们需要把第 k 层的顶点记录下来，稍后才能通过第 k 层的顶点来找第 k+1 层的顶点。所以，我们用这个队列来实现记录的功能。

prev用来记录搜索路径。当我们从顶点 s 开始，广度优先搜索到顶点 t 后，prev 数组中存储的就是搜索的路径。不过，这个路径是反向存储的。prev[w] 存储的是，顶点 w 是从哪个前驱顶点遍历过来的。比如，我们通过顶点 2 的邻接表访问到顶点 3，那 prev[3] 就等于 2。为了正向打印出路径，我们需要递归地来打印，你可以看下 print() 函数的实现方式。

为了方便你理解，我画了一个广度优先搜索的分解图，你可以结合着代码以及我的讲解一块儿看。



掌握了广优先搜索算法的原理，我们来看下，广度优先搜索的时间、空间复杂度是多少呢？

最坏情况下，终止顶点 t 离起始顶点 s 很远，需要遍历完整个图才能找到。这个时候，每个顶点都要进出一遍队列，每个边也都会被访问一次，所以，广度优先搜索的时间复杂度是 O(V+E)，其中，V 表示顶点的个数，E 表示边的个数。当然，对于一个连通图来说，也就是说一个图中的所有顶点都是连通的，E 肯定要大于等于 V-1，所以，广度优先搜索的时间复杂度也可以简写为 O(E)。

广度优先搜索的空间消耗主要在几个辅助变量 visited 数组、queue 队列、prev 数组上。这三个存储空间的大小都不会超过顶点的个数，所以空间复杂度是 O(V)。

深度优先搜索（DFS）
深度优先搜索（Depth-First-Search），简称 DFS。最直观的例子就是“走迷宫”。

假设你站在迷宫的某个岔路口，然后想找到出口。你随意选择一个岔路口来走，走着走着发现走不通的时候，你就回退到上一个岔路口，重新选择一条路继续走，直到最终找到出口。这种走法就是一种深度优先搜索策略。

走迷宫的例子很容易能看懂，我们现在再来看下，如何在图中应用深度优先搜索，来找某个顶点到另一个顶点的路径。

你可以看我画的这幅图。搜索的起始顶点是 s，终止顶点是 t，我们希望在图中寻找一条从顶点 s 到顶点 t 的路径。如果映射到迷宫那个例子，s 就是你起始所在的位置，t 就是出口。

我用深度递归算法，把整个搜索的路径标记出来了。这里面实线箭头表示遍历，虚线箭头表示回退。从图中我们可以看出，深度优先搜索找出来的路径，并不是顶点 s 到顶点 t 的最短路径。



实际上，深度优先搜索用的是一种比较著名的算法思想，回溯思想。这种思想解决问题的过程，非常适合用递归来实现。回溯思想我们后面会有专门的一节来讲，我们现在还回到深度优先搜索算法上。

我把上面的过程用递归来翻译出来，就是下面这个样子。我们发现，深度优先搜索代码实现也用到了 prev、visited 变量以及 print() 函数，它们跟广度优先搜索代码实现里的作用是一样的。不过，深度优先搜索代码实现里，有个比较特殊的变量 found，它的作用是，当我们已经找到终止顶点 t 之后，我们就不再递归地继续查找了。

boolean found = false; // 全局变量或者类成员变量
 
public void dfs(int s, int t) {
  found = false;
  boolean[] visited = new boolean[v];
  int[] prev = new int[v];
  for (int i = 0; i < v; ++i) {
    prev[i] = -1;
  }
  recurDfs(s, t, visited, prev);
  print(prev, s, t);
}
 
private void recurDfs(int w, int t, boolean[] visited, int[] prev) {
  if (found == true) return;
  visited[w] = true;
  if (w == t) {
    found = true;
    return;
  }
  for (int i = 0; i < adj[w].size(); ++i) {
    int q = adj[w].get(i);
    if (!visited[q]) {
      prev[q] = w;
      recurDfs(q, t, visited, prev);
    }
  }
}
理解了深度优先搜索算法之后，我们来看，深度度优先搜索的时、空间间复杂度是多少呢？

从我前面画的图可以看出，每条边最多会被访问两次，一次是遍历，一次是回退。所以，图上的深度优先搜索算法的时间复杂度是 O(E)，E 表示边的个数。

深度优先搜索算法的消耗内存主要是 visited、prev 数组和递归调用栈。visited、prev 数组的大小跟顶点的个数 V 成正比，递归调用栈的最大深度不会超过顶点的个数，所以总的空间复杂度就是 O(V)。

解答开篇
了解了深度优先搜索和广度优先搜索的原理之后，开篇的问题是不是变得很简单了呢？我们现在来一起看下，如何找出社交网络中某个用户的三度好友关系？

上一节我们讲过，社交网络可以用图来表示。这个问题就非常适合用图的广度优先搜索算法来解决，因为广度优先搜索是层层往外推进的。首先，遍历与起始顶点最近的一层顶点，也就是用户的一度好友，然后再遍历与用户距离的边数为 2 的顶点，也就是二度好友关系，以及与用户距离的边数为 3 的顶点，也就是三度好友关系。

我们只需要稍加改造一下广度优先搜索代码，用一个数组来记录每个顶点与起始顶点的距离，非常容易就可以找出三度好友关系。

内容小结
广度优先搜索和深度优先搜索是图上的两种最常用、最基本的搜索算法，比起其他高级的搜索算法，比如 A*、IDA* 等，要简单粗暴，没有什么优化，所以，也被叫作暴力搜索算法。所以，这两种搜索算法仅适用于状态空间不大，也就是说图不大的搜索。

广度优先搜索，通俗的理解就是，地毯式层层推进，从起始顶点开始，依次往外遍历。广度优先搜索需要借助队列来实现，遍历得到的路径就是，起始顶点到终止顶点的最短路径。深度优先搜索用的是回溯思想，非常适合用递归实现。换种说法，深度优先搜索是借助栈来实现的。在执行效率方面，深度优先和广度优先搜索的时间复杂度都是 O(E)，空间复杂度是 O(V)。

课后思考
我们通过广度优先搜索算法解决了开篇的问题，你可以思考一下，能否用深度优先搜索来解决呢？

学习数据结构最难的不是理解和掌握原理，而是能灵活地将各种场景和问题抽象成对应的数据结构和算法。今天的内容中提到，迷宫可以抽象成图，走迷宫可以抽象成搜索算法，你能具体讲讲，如何将迷宫抽象成一个图吗？或者换个说法，如何在计算机中存储一个迷宫？

欢迎留言和我分享，也欢迎点击“请朋友读”，把今天的内容分享给你的好友，和他一起讨论、学习。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(78)

Jerry银银
朗读者原谅我的有强迫症：queue这个单词读错了，付上正确的音标如下［kju］

我觉得避免这种问题，有个方法就是，朗读之前，逐个查询一下单词的正确发音，一篇文章中的单词屈指可数，这个工作量按理说应该不大。

但是这个简单的举措，能大大提高听文章的体验，不然听起来总觉得很怪

往大了说影响，毕竟咱们极客时间做的是知识，做的是学问
作者回复: 😂

2018-12-03


89

The Sword of Damocles
看的费劲的同学可以先去网上找找二叉树的深度、广度优先遍历看看。图的搜索和这个类似。
深度：借助一个栈
广度：借助一个队列

老师的代码没有注释，变量名称也比较简洁，虽然下文有解释，但是来回上下翻实在是看的费劲。建议能稍微优化一下。
2018-12-16


47

P@tricK
思考题：
1. 可以。DFS递归时传多一个离初始节点的距离值，访问节点时，距离超过3的不再继续递归

2. 初始化两个顶点为迷宫起点和终点，从起点开始，遇到分叉点，为每个分支都新建一个节点，并和前一节点连接，递归每个分支直到终点
2018-12-03


39

李东勇
老师， 我觉得深度优先搜索的代码中有一个可以改进的地方， 可以在21行之后加一句： if (found == true) return; 这样， 在一个顶点的for循环之中， 如果已经找到了t, 就可以跳出这个for循环了。目前的逻辑是， 这个for循环中剩下的还会继续执行， 每次都调用一次recurDfs函数， 但recurDfs函数在第一行就return了。
作者回复: 嗯嗯 👍

2018-12-18


20

五岳寻仙
课后思考题：
1. 深度优先用于寻找3度好友，可以设定搜索的深度，到3就向上回溯。正如文中提到的，可能不是最短路径，所以会涉及到更新结点度的问题。

2. 关于迷宫存储问题。类似于欧拉七桥问题，需要将迷宫抽象成图，每个分叉路口作为顶点，顶点之间连成边，构成一张无向图，可以存储在邻接矩阵或邻接表中。
2018-12-03


13

韩
我的想法:迷宫可以用带权无向图存储，每个多岔路口是一个顶点，相邻的多岔路口是一条边。带权是为了记录两个顶点间的距离。

但用上面这种方式，会丢失一些拐点信息。可以结合业务场景，如果需要这些信息，就把拐点也作为一个顶点存储。
2018-12-03


6

Jerry银银
留言笔记不小心被自己删了（问了客服，也不能找回了），补上：

1. 可以用深度遍历，每次遍历到三度人脉，再回溯到上层节点，直到所有的三度人脉都找完。

2. 将迷宫的每个岔口记为"顶点"，岔口之间的路径记为"边"，可以用邻接表存储，也可以用邻接矩阵存储。但是个人感觉，像那种标准的方格迷宫，适合用邻接矩阵存储，因为稠密度比较高。
2018-12-03


5

luo
老师针对图这个数据结构的应用 我有点疑惑，从结构来看无论是临近矩阵还是临近表 其实都需要有一个唯一下标作为这个顶点，那么问题来了 在实际数据量庞大的时候，这种数据结构是不是就没法用了（临近矩阵就不说了，临近表的话也是需要一个大的数组存储每个顶点 ），或者只能拆成以hash先分id，之后映射到对应的机器上存储各自的临近表部分，但这样进行深度广度搜索就有网络io了。
作者回复: 你说的没错，但是做工程就是trade-off，只能权衡来选择方案。如果实在存不下，可以降低些执行效率。不过，现在有很多图数据库，也可以解决你说的问题，把图直接存在硬盘中。

2019-01-04


4

德尼
说几个自己觉得是问题的小问题噢。在无向图代码中 adj声明的每个顶点的类型不是Integer吗？怎么在下面赋值时变成了LinkList？
还有就是语音上在讲述dfs空间复杂度的时候，听到的是dfs的时间（实质上是空间）复杂度为Ov。
2019-01-02


3

唯她命
老师，你好，我怎么觉得，递归完成之后，回溯到上一步，需要执行visited[w] = false呢，，因为路径不通，所以要回溯，但是应该重置为false，以便下次搜索
2018-12-21


3

Laughing_Lz
我基础非常差，写了老半天的非递归深度优先遍历，还请各位看看写的对不对

/**
* 深度优先遍历
*
* @param start 路径查找起始点
* @param end 路径查找终点
*/
public void depthFirstSearch(int start, int end) {
if (start == end) {
return;
}
// 定义一个visited数组，保存是否访问过
boolean[] visited = new boolean[v];
// 定义一个栈，作为一个后进先出栈，保存已访问，但相连节点未访问的节点
Stack<Integer> stack = new Stack<Integer>();
// 先将start压入栈中
visited[start] = true;
stack.push(start);
while (!stack.isEmpty()) {
// 取出，但不出栈
int step = stack.peek();
// 标识位，标识step节点下的邻接节点中是否有未走过的节点
boolean hasNoVisited = false;
for (int i = 0; i < adj[step].size(); i++) {
int nextStep = adj[step].get(i);
// 存在未走过节点，则flag = true,将nextStep压入栈中，继续前行
if (visited[nextStep] == false) {
hasNoVisited = true;
visited[nextStep] = true;
stack.push(nextStep);
if (nextStep == end) {
return;
}
break;
}
}
// 邻接的节点都是已走过的，则出栈
if (hasNoVisited == false) {
stack.pop();
}
}
// 遍历输出栈中存储的节点，即路径
if (!stack.isEmpty()) {
Iterator<Integer> it = stack.iterator();
while (it.hasNext()) {
System.out.print(it.next() + " ");
}
}
}
2018-12-13


3

Liam
对于今天的问题，无权图，如果采用深度优先。拿到的路径不一定是最短路径吧
作者回复: 不是最短路径的。广度优先可以取到最短路径。

2019-02-13


2

JzyCc
弱弱的问一下，宽搜代码那块，如果给的图中 1 和 3的位置互换，那么得出来的就不是最短路径了吧
作者回复: 不，宽搜对于无权图来说，肯定能找到最短路径的。因为整体的逻辑是离起点越近的，越早被访问到。

2019-02-09


2

qinggeouye

思考题 2、图的特点：顶点和边（顶点之间的连接关系）。

迷宫，选一个入口作为起始顶点，遇到岔路口，将岔路口作为顶点，并建立连接关系（边），终止条件应该是：到出口 或者 到下一个路口之后不能再前进为止。这里仍然用深度优先搜索的方法实现。
2018-12-30


2

+ +
广度优先 有点像树中的层序遍历啊 也是借助一个队列来实现的
2018-12-05


2

他在她城断了弦
可不可以这样理解，深度优先用递归思想，广度优先用迭代思想？
作者回复: 不大行 因为深度优先也可以用非递归的方式实现

2018-12-04


2

猫头鹰爱拿铁
我感觉用深度优先查找人脉的算法可能会把小于这个度数的数据查找出来吧，例如查找度数为3的顶点，用文中广度优先搜索的那个数据，使用深度优先的算法会把0，1，4，3也给查出来。。。
2018-12-03


2

Smallfly
老师把广度和深度优先搜索讲的真的是通俗易懂。我有个问题是，如果图中存在相同的节点，两种算法是不是就不能工作了？
作者回复: 可以的。看你用什么信息去查找 以及怎么定义找到。所谓相同节点 这个说法有点笼统了 怎样才算两个节点相同呢

2018-12-03

1

2

🎸 风筝
老师讲的很清楚，打卡跟进！
2019-07-23


1

CathyLin
1. 开篇问题可以用 dfs 来解决，可以通过限制递归深度的方式来做到。
2. 如何存迷宫？我想到了以下几种方法：
1) 开一个二维数组 G[i][j]，0 表示为可走的路，1 表示为墙走不过去。
2) 用邻接矩阵的方式, Adj[i][j] = 1 表示 i 到 j 存在可以走的路；注意迷宫可能为一个无向图，所以 Adj[i][j] = Adj[j][i] = 1;
3) 用邻接表的方式，把每个点可以走到的下一个点存到这个点的链表中去。
2019-07-15


1
收起评论

7899+






# 32 | 字符串匹配基础（上）：如何借助哈希算法实现高效字符串匹配？




数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



32 | 字符串匹配基础（上）：如何借助哈希算法实现高效字符串匹配？
王争 2018-12-05



12:55
讲述：修阳 大小：11.84M
从今天开始，我们来学习字符串匹配算法。字符串匹配这样一个功能，我想对于任何一个开发工程师来说，应该都不会陌生。我们用的最多的就是编程语言提供的字符串查找函数，比如 Java 中的 indexOf()，Python 中的 find() 函数等，它们底层就是依赖接下来要讲的字符串匹配算法。

字符串匹配算法很多，我会分四节来讲解。今天我会讲两种比较简单的、好理解的，它们分别是：BF 算法和 RK 算法。下一节，我会讲两种比较难理解、但更加高效的，它们是：BM 算法和 KMP 算法。

这两节讲的都是单模式串匹配的算法，也就是一个串跟一个串进行匹配。第三节、第四节，我会讲两种多模式串匹配算法，也就是在一个串中同时查找多个串，它们分别是 Trie 树和 AC 自动机。

今天讲的两个算法中，RK 算法是 BF 算法的改进，它巧妙借助了我们前面讲过的哈希算法，让匹配的效率有了很大的提升。那RK 算法是如何借助哈希算法来实现高效字符串匹配的呢？你可以带着这个问题，来学习今天的内容。

BF 算法
BF 算法中的 BF 是 Brute Force 的缩写，中文叫作暴力匹配算法，也叫朴素匹配算法。从名字可以看出，这种算法的字符串匹配方式很“暴力”，当然也就会比较简单、好懂，但相应的性能也不高。

在开始讲解这个算法之前，我先定义两个概念，方便我后面讲解。它们分别是主串和模式串。这俩概念很好理解，我举个例子你就懂了。

比方说，我们在字符串 A 中查找字符串 B，那字符串 A 就是主串，字符串 B 就是模式串。我们把主串的长度记作 n，模式串的长度记作 m。因为我们是在主串中查找模式串，所以 n>m。

作为最简单、最暴力的字符串匹配算法，BF 算法的思想可以用一句话来概括，那就是，我们在主串中，检查起始位置分别是 0、1、2…n-m 且长度为 m 的 n-m+1 个子串，看有没有跟模式串匹配的。我举一个例子给你看看，你应该可以理解得更清楚。



从上面的算法思想和例子，我们可以看出，在极端情况下，比如主串是“aaaaa…aaaaaa”（省略号表示有很多重复的字符 a），模式串是“aaaaab”。我们每次都比对 m 个字符，要比对 n-m+1 次，所以，这种算法的最坏情况时间复杂度是 O(n*m)。

尽管理论上，BF 算法的时间复杂度很高，是 O(n*m)，但在实际的开发中，它却是一个比较常用的字符串匹配算法。为什么这么说呢？原因有两点。

第一，实际的软件开发中，大部分情况下，模式串和主串的长度都不会太长。而且每次模式串与主串中的子串匹配的时候，当中途遇到不能匹配的字符的时候，就可以就停止了，不需要把 m 个字符都比对一下。所以，尽管理论上的最坏情况时间复杂度是 O(n*m)，但是，统计意义上，大部分情况下，算法执行效率要比这个高很多。

第二，朴素字符串匹配算法思想简单，代码实现也非常简单。简单意味着不容易出错，如果有 bug 也容易暴露和修复。在工程中，在满足性能要求的前提下，简单是首选。这也是我们常说的KISS（Keep it Simple and Stupid）设计原则。

所以，在实际的软件开发中，绝大部分情况下，朴素的字符串匹配算法就够用了。

RK 算法
RK 算法的全称叫 Rabin-Karp 算法，是由它的两位发明者 Rabin 和 Karp 的名字来命名的。这个算法理解起来也不是很难。我个人觉得，它其实就是刚刚讲的 BF 算法的升级版。

我在讲 BF 算法的时候讲过，如果模式串长度为 m，主串长度为 n，那在主串中，就会有 n-m+1 个长度为 m 的子串，我们只需要暴力地对比这 n-m+1 个子串与模式串，就可以找出主串与模式串匹配的子串。

但是，每次检查主串与子串是否匹配，需要依次比对每个字符，所以 BF 算法的时间复杂度就比较高，是 O(n*m)。我们对朴素的字符串匹配算法稍加改造，引入哈希算法，时间复杂度立刻就会降低。

RK 算法的思路是这样的：我们通过哈希算法对主串中的 n-m+1 个子串分别求哈希值，然后逐个与模式串的哈希值比较大小。如果某个子串的哈希值与模式串相等，那就说明对应的子串和模式串匹配了（这里先不考虑哈希冲突的问题，后面我们会讲到）。因为哈希值是一个数字，数字之间比较是否相等是非常快速的，所以模式串和子串比较的效率就提高了。



不过，通过哈希算法计算子串的哈希值的时候，我们需要遍历子串中的每个字符。尽管模式串与子串比较的效率提高了，但是，算法整体的效率并没有提高。有没有方法可以提高哈希算法计算子串哈希值的效率呢？

这就需要哈希算法设计的非常有技巧了。我们假设要匹配的字符串的字符集中只包含 K 个字符，我们可以用一个 K 进制数来表示一个子串，这个 K 进制数转化成十进制数，作为子串的哈希值。表述起来有点抽象，我举了一个例子，看完你应该就能懂了。

比如要处理的字符串只包含 a～z 这 26 个小写字母，那我们就用二十六进制来表示一个字符串。我们把 a～z 这 26 个字符映射到 0～25 这 26 个数字，a 就表示 0，b 就表示 1，以此类推，z 表示 25。

在十进制的表示法中，一个数字的值是通过下面的方式计算出来的。对应到二十六进制，一个包含 a 到 z 这 26 个字符的字符串，计算哈希的时候，我们只需要把进位从 10 改成 26 就可以。



这个哈希算法你应该看懂了吧？现在，为了方便解释，在下面的讲解中，我假设字符串中只包含 a～z 这 26 个小写字符，我们用二十六进制来表示一个字符串，对应的哈希值就是二十六进制数转化成十进制的结果。

这种哈希算法有一个特点，在主串中，相邻两个子串的哈希值的计算公式有一定关系。我这有个个例子，你先找一下规律，再来看我后面的讲解。



从这里例子中，我们很容易就能得出这样的规律：相邻两个子串 s[i-1] 和 s[i]（i 表示子串在主串中的起始位置，子串的长度都为 m），对应的哈希值计算公式有交集，也就是说，我们可以使用 s[i-1] 的哈希值很快的计算出 s[i] 的哈希值。如果用公式表示的话，就是下面这个样子：



不过，这里有一个小细节需要注意，那就是 26^(m-1) 这部分的计算，我们可以通过查表的方法来提高效率。我们事先计算好 26^0、26^1、26^2……26^(m-1)，并且存储在一个长度为 m 的数组中，公式中的“次方”就对应数组的下标。当我们需要计算 26 的 x 次方的时候，就可以从数组的下标为 x 的位置取值，直接使用，省去了计算的时间。



我们开头的时候提过，RK 算法的效率要比 BF 算法高，现在，我们就来分析一下，RK 算法的时间复杂度到底是多少呢？

整个 RK 算法包含两部分，计算子串哈希值和模式串哈希值与子串哈希值之间的比较。第一部分，我们前面也分析了，可以通过设计特殊的哈希算法，只需要扫描一遍主串就能计算出所有子串的哈希值了，所以这部分的时间复杂度是 O(n)。

模式串哈希值与每个子串哈希值之间的比较的时间复杂度是 O(1)，总共需要比较 n-m+1 个子串的哈希值，所以，这部分的时间复杂度也是 O(n)。所以，RK 算法整体的时间复杂度就是 O(n)。

这里还有一个问题就是，模式串很长，相应的主串中的子串也会很长，通过上面的哈希算法计算得到的哈希值就可能很大，如果超过了计算机中整型数据可以表示的范围，那该如何解决呢？

刚刚我们设计的哈希算法是没有散列冲突的，也就是说，一个字符串与一个二十六进制数一一对应，不同的字符串的哈希值肯定不一样。因为我们是基于进制来表示一个字符串的，你可以类比成十进制、十六进制来思考一下。实际上，我们为了能将哈希值落在整型数据范围内，可以牺牲一下，允许哈希冲突。这个时候哈希算法该如何设计呢？

哈希算法的设计方法有很多，我举一个例子说明一下。假设字符串中只包含 a～z 这 26 个英文字母，那我们每个字母对应一个数字，比如 a 对应 1，b 对应 2，以此类推，z 对应 26。我们可以把字符串中每个字母对应的数字相加，最后得到的和作为哈希值。这种哈希算法产生的哈希值的数据范围就相对要小很多了。

不过，你也应该发现，这种哈希算法的哈希冲突概率也是挺高的。当然，我只是举了一个最简单的设计方法，还有很多更加优化的方法，比如将每一个字母从小到大对应一个素数，而不是 1，2，3……这样的自然数，这样冲突的概率就会降低一些。

那现在新的问题来了。之前我们只需要比较一下模式串和子串的哈希值，如果两个值相等，那这个子串就一定可以匹配模式串。但是，当存在哈希冲突的时候，有可能存在这样的情况，子串和模式串的哈希值虽然是相同的，但是两者本身并不匹配。

实际上，解决方法很简单。当我们发现一个子串的哈希值跟模式串的哈希值相等的时候，我们只需要再对比一下子串和模式串本身就好了。当然，如果子串的哈希值与模式串的哈希值不相等，那对应的子串和模式串肯定也是不匹配的，就不需要比对子串和模式串本身了。

所以，哈希算法的冲突概率要相对控制得低一些，如果存在大量冲突，就会导致 RK 算法的时间复杂度退化，效率下降。极端情况下，如果存在大量的冲突，每次都要再对比子串和模式串本身，那时间复杂度就会退化成 O(n*m)。但也不要太悲观，一般情况下，冲突不会很多，RK 算法的效率还是比 BF 算法高的。

解答开篇 & 内容小结
今天我们讲了两种字符串匹配算法，BF 算法和 RK 算法。

BF 算法是最简单、粗暴的字符串匹配算法，它的实现思路是，拿模式串与主串中是所有子串匹配，看是否有能匹配的子串。所以，时间复杂度也比较高，是 O(n*m)，n、m 表示主串和模式串的长度。不过，在实际的软件开发中，因为这种算法实现简单，对于处理小规模的字符串匹配很好用。

RK 算法是借助哈希算法对 BF 算法进行改造，即对每个子串分别求哈希值，然后拿子串的哈希值与模式串的哈希值比较，减少了比较的时间。所以，理想情况下，RK 算法的时间复杂度是 O(n)，跟 BF 算法相比，效率提高了很多。不过这样的效率取决于哈希算法的设计方法，如果存在冲突的情况下，时间复杂度可能会退化。极端情况下，哈希算法大量冲突，时间复杂度就退化为 O(n*m)。

课后思考
我们今天讲的都是一维字符串的匹配方法，实际上，这两种算法都可以类比到二维空间。假设有下面这样一个二维字符串矩阵（图中的主串），借助今天讲的处理思路，如何在其中查找另一个二维字符串矩阵（图中的模式串）呢？



欢迎留言和我分享，也欢迎点击“请朋友读”，把今天的内容分享给你的好友，和他一起讨论、学习。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(84)

Jerry银银
觉得今天的hash算法真是巧妙
2018-12-05


78

ZX
RK算法，在对主串构建的时候，就对比是不是一样的，一样就不继续计算后面的hash，这样会不会更快一点
作者回复: 你说的很对 代码实现就是这样处理的

2018-12-06


27

P@tricK
思考题：
假设二维主串和模式串的维度分别是 m*n 和 i*j，横向在[0, m-i]，纵向在[0, n-j]取起始点，然后取同样的子串窗口对比，共有(m-i+1)*(n-j+1)个子串。

ps：
文中计算子串哈希值h[i]的公式中，第二个h[i-1]和后面的h[i+m-1]，应该是主串中的第i-1个和第i+m-1个字符的哈希值…
2018-12-05


20

Smallfly
思考题：

以模式串矩阵的大小，去匹配主串矩阵，每个小矩阵可以构建成字符串，就能用 RK 算法做字符串匹配了。

如果主串的大小是 M * N，模式串大小为 m * n，则时间复杂度为 (M - m + 1) * (N - n + 1)。
2018-12-05


13

Alan
h[i] = 26*(h[i-1]-26^(m-1)*h[i-1]) + h[i+m-1];

其中, h[i]、h[i-1] 分别对应 s[i] 和 s[i-1] 两个子串的哈希值
------------------
文中这个公式，26*(h[i-1]-26^(m-1)*h[i-1])可以化简为26*h[i-1]*(1-26^(m-1))，所以这里是不是应该改为26*(h[i-1]-26^(m-1)*s[i-1])，用s[i-1]代表当前位置的字符串的值，例如图中d的值是3，同样的公式后面加 h[i+m-1]是不是也是s[i+m-1]呢
作者回复: 写错了 感谢指正 已经改了

2018-12-05


10

Flash
看了很多评论后，发现思考题其实就是举一反三，我们可以在比较时，将二维串矩阵看作是字符串来处理，至于怎么转换成一维字符串，应该有很多方法，比如子串矩阵和模式串矩阵都用同样的规则来组成一个字符串，从左到右，再从上到下遍历取矩阵的元素a[i][j]。转换为一维字符后，就可以用BF或者RK算法了 。
复杂度分析，假设二维主串矩阵和模式串矩阵的维度分别是 m*n 和 i*j，按一个个矩阵来看子串的话，共有(m-i+1) * (n-j+1)个子串矩阵。
用RK算法的话，复杂度就是O((m-i+1) * (n-j+1))。
2019-01-27

1

8

yaya
二维矩阵只要如果以i'j为左上角，即可定义一个i.j i+1.j i. j+1 i+1.j+1的子串，其本质是和字符串相同的，即可以由rf又可以由bf解
2018-12-05


6

coulson
老师，前天面试被问到一个问题，关于地图算法的，比如线路推荐。请问地图算法会讲到么
作者回复: 在高级篇那部分会涉及一点

2018-12-05


5

朱月俊
以前刷题的时候，遇到过rk算法，当时是没太考虑hash冲突，一个字母对应一个数字，子串的hash值就是子串中的字母对应的数字想加。
今天大佬将之抽象提炼出来，还专门提到冲突解决方法，不可谓不妙！
2018-12-05


5

Rephontil
老师您应该把公式的推理过程简单地说一下，这公式对您来说非常简单，但是对于我这种基础差的人，完全是懵逼的状态。看着大家讨论，却无法深入下去。/(ㄒoㄒ)/~~
作者回复: 我补一下

2019-01-09


3

星君
好几期没看了，感觉跟不上了
作者回复: 不着急 慢慢来 没必要一直紧跟着

2018-12-12


3

煦暖
“h[i] = 26*(h[i-1]-26^(m-1)*h[i-1]) + h[i+m-1];其中, h[i]、h[i-1] 分别对应 s[i] 和 s[i-1] 两个子串的哈希值。”老师你好，26^(m-1)*h[i-1]中的h[i-1]和h[i+m-1]应该是一个字符的哈希值而不应该是子串的哈希值吧？？PS：用您的例子套用公式：h0 = 3*26*26+1*26+2 = 2056；h1=26*(h0-26*26*h0)+(4*26*26+3*26+4) = -36080014 和期望的哈希值1*26*26+2*26+4=732不符。

2018-12-05

1

3

王婵
思考题二维数组用RK算法计算哈希值要复杂一些，i-1 j-1不越界的情况下，如果模式串的行数大于列数可以通过h[i-1,j]计算h[i,j]，如果列数大于行数可以通过h[i,j-1]计算h[i,j] 还有更好的方法计算哈希值吗？
另外正文里的计算哈希值的公式貌似写错了，应该是
h[i] = 26*(h[i-1]-26^(m-1)*(s[i-1]-‘a’)) + (s[i+m-1]-‘a’);
2018-12-05


3

晓龙
RK算法有两个可以改进的点，一个可以避免hash冲突，另一个可以减少hash计算次数。

改进一：先计算模式串的hash值，记录下来，然后计算每一个子串的hash，计算一次，就对比一次，如果hash值匹配，在全量对比字符串。这样做可以不用关心hash冲突问题。

改进二：计算子串hash值的时候只要计算到n-（n-m）处即可，剩下的子串长度小于模式串，不用计算。
2019-03-01


2

Rephontil
h[i] = 26*(h[i-1]-26^(m-1)*(s[i-1]-'a')) + (s[i+m-1]-'a');
其中, h[i]、h[i-1] 分别对应 s[i] 和 s[i-1] 两个子串的哈希值
  好吧，这一段代码我对照上下文看了10遍，看懂了。我承认我很蠢
作者回复: 抱歉 没写清楚

2019-01-09


2

qinggeouye
RK 算法，计算相邻两个子串哈希值的规律，比如，相邻两个子串分别为 "dbc" 和 "bce"，那么 s[i-1] = 'd'，s[i]='b' ，与 'a' 相减意思是，它们的 ASCII 码值的差值正好表示字母的数值；
评论中有同学不明白老师给的哈希值 h[i] 和 h[i-1] 之间的关系，我想应该是 s[i] 和 s[i-1] 代表什么这点没明白。
2018-12-31


2

大刚
老师，下面的不懂，能不能在详细讲解下
h[i] = 26*(h[i-1]-26^(m-1)*(s[i-1]-'a')) + (s[i+m-1]-'a');
2018-12-20


2

漫漫越
停看了好多天，最后还是决定继续跟随老师的脚步，为自己加油~
作者回复: 停一停 歇歇挺好的 也没必要跟的很紧 搞的自己很窘迫

2018-12-18


2

Smallfly
用 K 进制表示字符串应该不会出现哈希冲突吧，比如 “0” 到 “F” 的字符，用 16 进制表示， 有且仅有 "FFFF" 的结果是 0xFFFF 的值呀。
2018-12-07


2

hunterlodge
RK算法和布隆过滤器的思想是一致的
2018-12-07


2
收起评论

8499+






# 33 | 字符串匹配基础（中）：如何实现文本编辑器中的查找功能？



数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



33 | 字符串匹配基础（中）：如何实现文本编辑器中的查找功能？
王争 2018-12-07



18:20
讲述：修阳 大小：16.80M
文本编辑器中的查找替换功能，我想你应该不陌生吧？比如，我们在 Word 中把一个单词统一替换成另一个，用的就是这个功能。你有没有想过，它是怎么实现的呢？

当然，你用上一节讲的 BF 算法和 RK 算法，也可以实现这个功能，但是在某些极端情况下，BF 算法性能会退化的比较严重，而 RK 算法需要用到哈希算法，而设计一个可以应对各种类型字符的哈希算法并不简单。

对于工业级的软件开发来说，我们希望算法尽可能的高效，并且在极端情况下，性能也不要退化的太严重。那么，对于查找功能是重要功能的软件来说，比如一些文本编辑器，它们的查找功能都是用哪种算法来实现的呢？有没有比 BF 算法和 RK 算法更加高效的字符串匹配算法呢？

今天，我们就来学习 BM（Boyer-Moore）算法。它是一种非常高效的字符串匹配算法，有实验统计，它的性能是著名的KMP 算法的 3 到 4 倍。BM 算法的原理很复杂，比较难懂，学起来会比较烧脑，我会尽量给你讲清楚，同时也希望你做好打硬仗的准备。好，现在我们正式开始！

BM 算法的核心思想
我们把模式串和主串的匹配过程，看作模式串在主串中不停地往后滑动。当遇到不匹配的字符时，BF 算法和 RK 算法的做法是，模式串往后滑动一位，然后从模式串的第一个字符开始重新匹配。我举个例子解释一下，你可以看我画的这幅图。



在这个例子里，主串中的 c，在模式串中是不存在的，所以，模式串向后滑动的时候，只要 c 与模式串有重合，肯定无法匹配。所以，我们可以一次性把模式串往后多滑动几位，把模式串移动到 c 的后面。



由现象找规律，你可以思考一下，当遇到不匹配的字符时，有什么固定的规律，可以将模式串往后多滑动几位呢？这样一次性往后滑动好几位，那匹配的效率岂不是就提高了？

我们今天要讲的 BM 算法，本质上其实就是在寻找这种规律。借助这种规律，在模式串与主串匹配的过程中，当模式串和主串某个字符不匹配的时候，能够跳过一些肯定不会匹配的情况，将模式串往后多滑动几位。

BM 算法原理分析
BM 算法包含两部分，分别是坏字符规则（bad character rule）和好后缀规则（good suffix shift）。我们下面依次来看，这两个规则分别都是怎么工作的。

1. 坏字符规则
前面两节讲的算法，在匹配的过程中，我们都是按模式串的下标从小到大的顺序，依次与主串中的字符进行匹配的。这种匹配顺序比较符合我们的思维习惯，而 BM 算法的匹配顺序比较特别，它是按照模式串下标从大到小的顺序，倒着匹配的。我画了一张图，你可以看下。



我们从模式串的末尾往前倒着匹配，当我们发现某个字符没法匹配的时候。我们把这个没有匹配的字符叫作坏字符（主串中的字符）。



我们拿坏字符 c 在模式串中查找，发现模式串中并不存在这个字符，也就是说，字符 c 与模式串中的任何字符都不可能匹配。这个时候，我们可以将模式串直接往后滑动三位，将模式串滑动到 c 后面的位置，再从模式串的末尾字符开始比较。



这个时候，我们发现，模式串中最后一个字符 d，还是无法跟主串中的 a 匹配，这个时候，还能将模式串往后滑动三位吗？答案是不行的。因为这个时候，坏字符 a 在模式串中是存在的，模式串中下标是 0 的位置也是字符 a。这种情况下，我们可以将模式串往后滑动两位，让两个 a 上下对齐，然后再从模式串的末尾字符开始，重新匹配。



第一次不匹配的时候，我们滑动了三位，第二次不匹配的时候，我们将模式串后移两位，那具体滑动多少位，到底有没有规律呢？

当发生不匹配的时候，我们把坏字符对应的模式串中的字符下标记作 si。如果坏字符在模式串中存在，我们把这个坏字符在模式串中的下标记作 xi。如果不存在，我们把 xi 记作 -1。那模式串往后移动的位数就等于 si-xi。（注意，我这里说的下标，都是字符在模式串的下标）。



这里我要特别说明一点，如果坏字符在模式串里多处出现，那我们在计算 xi 的时候，选择最靠后的那个，因为这样不会让模式串滑动过多，导致本来可能匹配的情况被滑动略过。

利用坏字符规则，BM 算法在最好情况下的时间复杂度非常低，是 O(n/m)。比如，主串是 aaabaaabaaabaaab，模式串是 aaaa。每次比对，模式串都可以直接后移四位，所以，匹配具有类似特点的模式串和主串的时候，BM 算法非常高效。

不过，单纯使用坏字符规则还是不够的。因为根据 si-xi 计算出来的移动位数，有可能是负数，比如主串是 aaaaaaaaaaaaaaaa，模式串是 baaa。不但不会向后滑动模式串，还有可能倒退。所以，BM 算法还需要用到“好后缀规则”。

2. 好后缀规则
好后缀规则实际上跟坏字符规则的思路很类似。你看我下面这幅图。当模式串滑动到图中的位置的时候，模式串和主串有 2 个字符是匹配的，倒数第 3 个字符发生了不匹配的情况。



这个时候该如何滑动模式串呢？当然，我们还可以利用坏字符规则来计算模式串的滑动位数，不过，我们也可以使用好后缀处理规则。两种规则到底如何选择，我稍后会讲。抛开这个问题，现在我们来看，好后缀规则是怎么工作的？

我们把已经匹配的 bc 叫作好后缀，记作{u}。我们拿它在模式串中查找，如果找到了另一个跟{u}相匹配的子串{u*}，那我们就将模式串滑动到子串{u*}与主串中{u}对齐的位置。



如果在模式串中找不到另一个等于{u}的子串，我们就直接将模式串，滑动到主串中{u}的后面，因为之前的任何一次往后滑动，都没有匹配主串中{u}的情况。



不过，当模式串中不存在等于{u}的子串时，我们直接将模式串滑动到主串{u}的后面。这样做是否有点太过头呢？我们来看下面这个例子。这里面 bc 是好后缀，尽管在模式串中没有另外一个相匹配的子串{u*}，但是如果我们将模式串移动到好后缀的后面，如图所示，那就会错过模式串和主串可以匹配的情况。



如果好后缀在模式串中不存在可匹配的子串，那在我们一步一步往后滑动模式串的过程中，只要主串中的{u}与模式串有重合，那肯定就无法完全匹配。但是当模式串滑动到前缀与主串中{u}的后缀有部分重合的时候，并且重合的部分相等的时候，就有可能会存在完全匹配的情况。



所以，针对这种情况，我们不仅要看好后缀在模式串中，是否有另一个匹配的子串，我们还要考察好后缀的后缀子串，是否存在跟模式串的前缀子串匹配的。

所谓某个字符串 s 的后缀子串，就是最后一个字符跟 s 对齐的子串，比如 abc 的后缀子串就包括 c, bc。所谓前缀子串，就是起始字符跟 s 对齐的子串，比如 abc 的前缀子串有 a，ab。我们从好后缀的后缀子串中，找一个最长的并且能跟模式串的前缀子串匹配的，假设是{v}，然后将模式串滑动到如图所示的位置。



坏字符和好后缀的基本原理都讲完了，我现在回答一下前面那个问题。当模式串和主串中的某个字符不匹配的时候，如何选择用好后缀规则还是坏字符规则，来计算模式串往后滑动的位数？

我们可以分别计算好后缀和坏字符往后滑动的位数，然后取两个数中最大的，作为模式串往后滑动的位数。这种处理方法还可以避免我们前面提到的，根据坏字符规则，计算得到的往后滑动的位数，有可能是负数的情况。

BM 算法代码实现
学习完了基本原理，我们再来看，如何实现 BM 算法？

“坏字符规则”本身不难理解。当遇到坏字符时，要计算往后移动的位数 si-xi，其中 xi 的计算是重点，我们如何求得 xi 呢？或者说，如何查找坏字符在模式串中出现的位置呢？

如果我们拿坏字符，在模式串中顺序遍历查找，这样就会比较低效，势必影响这个算法的性能。有没有更加高效的方式呢？我们之前学的散列表，这里可以派上用场了。我们可以将模式串中的每个字符及其下标都存到散列表中。这样就可以快速找到坏字符在模式串的位置下标了。

关于这个散列表，我们只实现一种最简单的情况，假设字符串的字符集不是很大，每个字符长度是 1 字节，我们用大小为 256 的数组，来记录每个字符在模式串中出现的位置。数组的下标对应字符的 ASCII 码值，数组中存储这个字符在模式串中出现的位置。



如果将上面的过程翻译成代码，就是下面这个样子。其中，变量 b 是模式串，m 是模式串的长度，bc 表示刚刚讲的散列表。

private static final int SIZE = 256; // 全局变量或成员变量
private void generateBC(char[] b, int m, int[] bc) {
  for (int i = 0; i < SIZE; ++i) {
    bc[i] = -1; // 初始化 bc
  }
  for (int i = 0; i < m; ++i) {
    int ascii = (int)b[i]; // 计算 b[i] 的 ASCII 值
    bc[ascii] = i;
  }
}
掌握了坏字符规则之后，我们先把 BM 算法代码的大框架写好，先不考虑好后缀规则，仅用坏字符规则，并且不考虑 si-xi 计算得到的移动位数可能会出现负数的情况。

public int bm(char[] a, int n, char[] b, int m) {
  int[] bc = new int[SIZE]; // 记录模式串中每个字符最后出现的位置
  generateBC(b, m, bc); // 构建坏字符哈希表
  int i = 0; // i 表示主串与模式串对齐的第一个字符
  while (i <= n - m) {
    int j;
    for (j = m - 1; j >= 0; --j) { // 模式串从后往前匹配
      if (a[i+j] != b[j]) break; // 坏字符对应模式串中的下标是 j
    }
    if (j < 0) {
      return i; // 匹配成功，返回主串与模式串第一个匹配的字符的位置
    }
    // 这里等同于将模式串往后滑动 j-bc[(int)a[i+j]] 位
    i = i + (j - bc[(int)a[i+j]]); 
  }
  return -1;
}
代码里的注释已经很详细了，我就不再赘述了。不过，为了你方便理解，我画了一张图，将其中的一些关键变量标注在上面了，结合着图，代码应该更好理解。



至此，我们已经实现了包含坏字符规则的框架代码，只剩下往框架代码中填充好后缀规则了。现在，我们就来看看，如何实现好后缀规则。它的实现要比坏字符规则复杂一些。

在讲实现之前，我们先简单回顾一下，前面讲过好后缀的处理规则中最核心的内容：

在模式串中，查找跟好后缀匹配的另一个子串；

在好后缀的后缀子串中，查找最长的、能跟模式串前缀子串匹配的后缀子串；

在不考虑效率的情况下，这两个操作都可以用很“暴力”的匹配查找方式解决。但是，如果想要 BM 算法的效率很高，这部分就不能太低效。如何来做呢？

因为好后缀也是模式串本身的后缀子串，所以，我们可以在模式串和主串正式匹配之前，通过预处理模式串，预先计算好模式串的每个后缀子串，对应的另一个可匹配子串的位置。这个预处理过程比较有技巧，很不好懂，应该是这节最难懂的内容了，你要认真多读几遍。

我们先来看，如何表示模式串中不同的后缀子串呢？因为后缀子串的最后一个字符的位置是固定的，下标为 m-1，我们只需要记录长度就可以了。通过长度，我们可以确定一个唯一的后缀子串。



现在，我们要引入最关键的变量 suffix 数组。suffix 数组的下标 k，表示后缀子串的长度，下标对应的数组值存储的是，在模式串中跟好后缀{u}相匹配的子串{u*}的起始下标值。这句话不好理解，我举一个例子。



但是，如果模式串中有多个（大于 1 个）子串跟后缀子串{u}匹配，那 suffix 数组中该存储哪一个子串的起始位置呢？为了避免模式串往后滑动得过头了，我们肯定要存储模式串中最靠后的那个子串的起始位置，也就是下标最大的那个子串的起始位置。不过，这样处理就足够了吗？

实际上，仅仅是选最靠后的子串片段来存储是不够的。我们再回忆一下好后缀规则。

我们不仅要在模式串中，查找跟好后缀匹配的另一个子串，还要在好后缀的后缀子串中，查找最长的能跟模式串前缀子串匹配的后缀子串。

如果我们只记录刚刚定义的 suffix，实际上，只能处理规则的前半部分，也就是，在模式串中，查找跟好后缀匹配的另一个子串。所以，除了 suffix 数组之外，我们还需要另外一个 boolean 类型的 prefix 数组，来记录模式串的后缀子串是否能匹配模式串的前缀子串。



现在，我们来看下，如何来计算并填充这两个数组的值？这个计算过程非常巧妙。

我们拿下标从 0 到 i 的子串（i 可以是 0 到 m-2）与整个模式串，求公共后缀子串。如果公共后缀子串的长度是 k，那我们就记录 suffix[k]=j（j 表示公共后缀子串的起始下标）。如果 j 等于 0，也就是说，公共后缀子串也是模式串的前缀子串，我们就记录 prefix[k]=true。



我们把 suffix 数组和 prefix 数组的计算过程，用代码实现出来，就是下面这个样子：

// b 表示模式串，m 表示长度，suffix，prefix 数组事先申请好了
private void generateGS(char[] b, int m, int[] suffix, boolean[] prefix) {
  for (int i = 0; i < m; ++i) { // 初始化
    suffix[i] = -1;
    prefix[i] = false;
  }
  for (int i = 0; i < m - 1; ++i) { // b[0, i]
    int j = i;
    int k = 0; // 公共后缀子串长度
    while (j >= 0 && b[j] == b[m-1-k]) { // 与 b[0, m-1] 求公共后缀子串
      --j;
      ++k;
      suffix[k] = j+1; //j+1 表示公共后缀子串在 b[0, i] 中的起始下标
    }
    i
    if (j == -1) prefix[k] = true; // 如果公共后缀子串也是模式串的前缀子串
  }
}
有了这两个数组之后，我们现在来看，在模式串跟主串匹配的过程中，遇到不能匹配的字符时，如何根据好后缀规则，计算模式串往后滑动的位数？

假设好后缀的长度是 k。我们先拿好后缀，在 suffix 数组中查找其匹配的子串。如果 suffix[k] 不等于 -1（-1 表示不存在匹配的子串），那我们就将模式串往后移动 j-suffix[k]+1 位（j 表示坏字符对应的模式串中的字符下标）。如果 suffix[k] 等于 -1，表示模式串中不存在另一个跟好后缀匹配的子串片段。我们可以用下面这条规则来处理。



好后缀的后缀子串 b[r, m-1]（其中，r 取值从 j+2 到 m-1）的长度 k=m-r，如果 prefix[k] 等于 true，表示长度为 k 的后缀子串，有可匹配的前缀子串，这样我们可以把模式串后移 r 位。



如果两条规则都没有找到可以匹配好后缀及其后缀子串的子串，我们就将整个模式串后移 m 位。



至此，好后缀规则的代码实现我们也讲完了。我们把好后缀规则加到前面的代码框架里，就可以得到 BM 算法的完整版代码实现。

// a,b 表示主串和模式串；n，m 表示主串和模式串的长度。
public int bm(char[] a, int n, char[] b, int m) {
  int[] bc = new int[SIZE]; // 记录模式串中每个字符最后出现的位置
  generateBC(b, m, bc); // 构建坏字符哈希表
  int[] suffix = new int[m];
  boolean[] prefix = new boolean[m];
  generateGS(b, m, suffix, prefix);
  int i = 0; // j 表示主串与模式串匹配的第一个字符
  while (i <= n - m) {
    int j;
    for (j = m - 1; j >= 0; --j) { // 模式串从后往前匹配
      if (a[i+j] != b[j]) break; // 坏字符对应模式串中的下标是 j
    }
    if (j < 0) {
      return i; // 匹配成功，返回主串与模式串第一个匹配的字符的位置
    }
    int x = j - bc[(int)a[i+j]];
    int y = 0;
    if (j < m-1) { // 如果有好后缀的话
      y = moveByGS(j, m, suffix, prefix);
    }
    i = i + Math.max(x, y);
  }
  return -1;
}
 
// j 表示坏字符对应的模式串中的字符下标 ; m 表示模式串长度
private int moveByGS(int j, int m, int[] suffix, boolean[] prefix) {
  int k = m - 1 - j; // 好后缀长度
  if (suffix[k] != -1) return j - suffix[k] +1;
  for (int r = j+2; r <= m-1; ++r) {
    if (prefix[m-r] == true) {
      return r;
    }
  }
  return m;
}
BM 算法的性能分析及优化
我们先来分析 BM 算法的内存消耗。整个算法用到了额外的 3 个数组，其中 bc 数组的大小跟字符集大小有关，suffix 数组和 prefix 数组的大小跟模式串长度 m 有关。

如果我们处理字符集很大的字符串匹配问题，bc 数组对内存的消耗就会比较多。因为好后缀和坏字符规则是独立的，如果我们运行的环境对内存要求苛刻，可以只使用好后缀规则，不使用坏字符规则，这样就可以避免 bc 数组过多的内存消耗。不过，单纯使用好后缀规则的 BM 算法效率就会下降一些了。

对于执行效率来说，我们可以先从时间复杂度的角度来分析。

实际上，我前面讲的 BM 算法是个初级版本。为了让你能更容易理解，有些复杂的优化我没有讲。基于我目前讲的这个版本，在极端情况下，预处理计算 suffix 数组、prefix 数组的性能会比较差。

比如模式串是 aaaaaaa 这种包含很多重复的字符的模式串，预处理的时间复杂度就是 O(m^2)。当然，大部分情况下，时间复杂度不会这么差。关于如何优化这种极端情况下的时间复杂度退化，如果感兴趣，你可以自己研究一下。

实际上，BM 算法的时间复杂度分析起来是非常复杂，这篇论文“A new proof of the linearity of the Boyer-Moore string searching algorithm”证明了在最坏情况下，BM 算法的比较次数上限是 5n。这篇论文“Tight bounds on the complexity of the Boyer-Moore string matching algorithm”证明了在最坏情况下，BM 算法的比较次数上限是 3n。你可以自己阅读看看。

解答开篇 & 内容小结
今天，我们讲了一种比较复杂的字符串匹配算法，BM 算法。尽管复杂、难懂，但匹配的效率却很高，在实际的软件开发中，特别是一些文本编辑器中，应用比较多。如果一遍看不懂的话，你就多看几遍。

BM 算法核心思想是，利用模式串本身的特点，在模式串中某个字符与主串不能匹配的时候，将模式串往后多滑动几位，以此来减少不必要的字符比较，提高匹配的效率。BM 算法构建的规则有两类，坏字符规则和好后缀规则。好后缀规则可以独立于坏字符规则使用。因为坏字符规则的实现比较耗内存，为了节省内存，我们可以只用好后缀规则来实现 BM 算法。

课后思考
你熟悉的编程语言中的查找函数，或者工具、软件中的查找功能，都是用了哪种字符串匹配算法呢？

欢迎留言和我分享，也欢迎点击“请朋友读”，把今天的内容分享给你的好友，和他一起讨论、学习。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(150)

Smallfly
BM 算法分析着实比较复杂，不过按照老师的思路，一步一步走，看懂应该没问题的。但其实有些代码实现细节看不懂关系也不大。我们学算法主要目的是学习算法的思想，能在需要的时候加以应用就好。

但对于平时工作，几乎不可能遇到，需要自己手写一个字符串匹配算法的场景。那我们还要学，图的是什么？

我认为文章中值得学习借鉴的思想有：

1、要有优化意识，前面的 BF，RK 算法已经能够满足我们需求了，为什么发明 BM 算法？是为了减少时间复杂度，但是带来的弊端是，优化代码变得复杂，维护成本变高。

2、需要查找，需要减少时间复杂度，应该想到什么？散列表。

3、如果某个表达式计算开销比较大，又需要频繁的使用怎么办？预处理，并缓存。

（一点拙见，可能文中还有其它优秀的思想，没能 Get 到）
作者回复: 👍

2018-12-08


123

meng
我对这次课的内容一知半解，于是在网上搜到一个文档，里面的图挺好的，跟大家分享一下：http://www.cs.jhu.edu/~langmea/resources/lecture_notes/boyer_moore.pdf
2018-12-09

1

44

suke
老师以后的代码中的变量能不能起的有意义一些，这样更加方便大家理解代码啊，不要总拿a b c bc这种完全没有意义的名字来命名变量
2018-12-19


38

纯洁的憎恶
大体思路应该是看懂了，不过具体实现和代码细节还需要时间消化。BM算法的核心思想是通过将模式串沿着主串大踏步的向后滑动，从而大大减少比较次数，降低时间复杂度。而算法的关键在于如何兼顾步子迈得足够大与无遗漏，同时要尽量提高执行效率。这就需要模式串在向后滑动时，遵守坏字符规则与好后缀规则，同时采用一些技巧。

坏字符规则：从后往前逐位比较模式串与主串的字符，当找到不匹配的坏字符时，记录模式串的下标值si，并找到坏字符在模式串中，位于下标si前的最近位置xi（若无则记为-1），si-xi即为向后滑动距离。（PS：我觉得加上xi必须在si前面，也就是比si小的条件，就不用担心计算出的距离为负了）。但是坏字符规则向后滑动的步幅还不够大，于是需要好后缀规则。

好后缀规则：从后往前逐位比较模式串与主串的字符，当出现坏字符时停止。若存在已匹配成功的子串｛u｝，那么在模式串的｛u｝前面找到最近的｛u｝，记作｛u'｝。再将模式串后移，使得模式串的｛u'｝与主串的｛u｝重叠。若不存在｛u'｝，则直接把模式串移到主串的｛u｝后面。为了没有遗漏，需要找到最长的、能够跟模式串的前缀子串匹配的，好后缀的后缀子串（同时也是模式串的后缀子串）。然后把模式串向右移到其左边界，与这个好后缀的后缀子串在主串中的左边界对齐。

何时使用坏字符规则和好后缀规则呢？首先在每次匹配过程中，一旦发现坏字符，先执行坏字符规则，如果发现存在好后缀，还要执行好后缀规则，并从两者中选择后移距离最大的方案执行。

技巧：
1.通过散列表实现，坏字符在模式串中下标位置的快速查询。
2.每次执行好后缀原则时，都会计算多次能够与模式串前缀子串相匹配的好后缀的最长后缀子串。为了提高效率，可以预先计算模式串的所有后缀子串，在模式串中与之匹配的另一个子串的位置。同时预计算模式串中（同长度的）后缀子串与前缀子串是否匹配并记录。在具体操作中直接使用，大大提高效率。
3.如何快速记录模式串后缀子串匹配的另一个子串位置，以及模式串（相同长度）前缀与后缀子串石否匹配呢？先用一个suffix数组，下标值k为后缀子串的长度，从模式串下标为i（0~m-2）的字符为最后一个字符，查找这个子串是否与后缀子串匹配，若匹配则将子串起始位置的下标值j赋给suffix[k]。若j为0，说明这个匹配子串的起始位置为模式串的起始位置，则用一个数组prefix，将prefix[k]设为true，否则设为false。k从0到m（模式串的长度）于是就得到了模式串所有前缀与后缀子串的匹配情况。
2018-12-10


22

meng
这篇文章啃了很长时间了，有个问题请教：是否可以不要prefix数组，直接通过suffix[k]==0来判断前缀子串的匹配与否？
2018-12-23

2

16

Jerry银银
曾经一度觉得字符串匹配的几大算法，都是高山仰止的，难以理解。

但是前阵子受两句话启发，从此以后对字符串匹配问题，至少在战略层面藐视了它：
1. 善用之前信息(从信息论的角度：消除信息的不确定性，就是引入信息)

2. 增加效率，在资源有限的情况下，只有想办法少做事情
2018-12-07

1

12

Liam
好后缀原则下，最后一种情况为什么移到坏字符后面呢，不能移到好后缀的后面吗？即m+1,而不是j + 1
作者回复: 你说的对 👍 我改下

2018-12-07


11

五岳寻仙
老师好！今天讲的BM算法确实有点复杂，不过听的时候有熟悉的感觉，似乎跟之前接触过的Boyer Moore算法很像，查了一下才发现原来是同一种算法😂

在工作中遇到过这样的情况，需要在一个长度为n (比如十亿级)的巨大的主串中查找长度为m(比如几百)的模式串。主串是固定的，从直观上讲，要加快搜索速度，就需要对主串建索引。BWT-FM算法是解决这类问题最经典的算法，刚接触时也是不好理解，但感觉非常神奇，可以将搜索的时间复杂度降到O(m)，是我认为最伟大的算法之一。
2018-12-07


9

nopsky
讲shuffix的第一个图中shuffix[4] = -1，这个-1怎么来的，不能理解，能不能再讲一下
2018-12-07

1

7

cygnus
generateGS函数里suffix和prefix的赋值应该放到while循环内，即每次k变动时都要赋值。
另外请问下：好后缀的后缀子串 b[r, m-1]，这里的r的初值j+2是怎么得来的啊？
作者回复: j表示坏字符的下标 好狗追其实下标j+1

2018-12-08


5

P@tricK
老师，suffix和prefix的赋值那里有BUG，应该在每一次k的变动都要有suffix赋值。
作者回复: 是的 多谢

2018-12-07


5

Fstar
。。。我知道为什么老师说 si-xi 可能是负数了。

虽然理论上应该是从 si 的位置往前找 xi。但代码实现为了提高效率，使用了哈希表，记录的是不同字符在模式串中“最后出现的位置”，并不是 si 的位置往前查找的第一个位置，所以确实会出现 xi 大于 si 的情况，原来如此原来如此。。。
awsl。。
2019-02-25


4

Ryoma
跟课程以来觉得最难的一次，也有可能之前使用手机看的原因。总体上，拿手机看了3次，今天在电脑上看了第一次，终于将好后缀那部分理解清晰。学生时代接触的性能较高字符串匹配算法就是KMP，个人感觉BM比KMP更难理解，大家如果有没理解的，还是要多多看，或者拿着笔画一画
2018-12-13


4

Alan
在计算suffix 数组和 prefix 数组的代码中，第15行的i是不是多余的诶~？
2018-12-12


4

传说中的成大大
在用一个256的数组 用字符的ascii码做下标 记录该字符出现的位置 如果存在相同字符怎么办呢？之前的会被新的覆盖掉的把！
作者回复: 是的 就是要覆盖掉 留最大的

2018-12-10


4

seniusen
好后缀原则中，最后一种情况，应该是移动 m 位吧，移动整个模式串的长度。
作者回复: 是的

2018-12-07


4

Liam
好后缀原则中，最后一种情况，为什么是移动j + 1 位，而不是m+1位
作者回复: 移动到坏字符后面 移动m+1位是怎么理解的呢

2018-12-07


4

不凉青年
这块断断续续看了好几天- -
2018-12-21


3

Jamin
generateGS code第15行 没有写完吗？
2018-12-11


3

距离
对于还没毕业的我有点坚持不下去了
编辑回复: 再坚持一下

2018-12-10


3
收起评论

99+99+







# 34 | 字符串匹配基础（下）：如何借助BM算法轻松理解KMP算法？



数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



34 | 字符串匹配基础（下）：如何借助BM算法轻松理解KMP算法？
王争 2018-12-10



12:03
讲述：修阳 大小：11.04M
上一节我们讲了 BM 算法，尽管它很复杂，也不好理解，但却是工程中非常常用的一种高效字符串匹配算法。有统计说，它是最高效、最常用的字符串匹配算法。不过，在所有的字符串匹配算法里，要说最知名的一种的话，那就非 KMP 算法莫属。很多时候，提到字符串匹配，我们首先想到的就是 KMP 算法。

尽管在实际的开发中，我们几乎不大可能自己亲手实现一个 KMP 算法。但是，学习这个算法的思想，作为让你开拓眼界、锻炼下逻辑思维，也是极好的，所以我觉得有必要拿出来给你讲一讲。不过，KMP 算法是出了名的不好懂。我会尽力把它讲清楚，但是你自己也要多动动脑子。

实际上，KMP 算法跟 BM 算法的本质是一样的。上一节，我们讲了好后缀和坏字符规则，今天，我们就看下，如何借助上一节 BM 算法的讲解思路，让你能更好地理解 KMP 算法？

KMP 算法基本原理
KMP 算法是根据三位作者（D.E.Knuth，J.H.Morris 和 V.R.Pratt）的名字来命名的，算法的全称是 Knuth Morris Pratt 算法，简称为 KMP 算法。

KMP 算法的核心思想，跟上一节讲的 BM 算法非常相近。我们假设主串是 a，模式串是 b。在模式串与主串匹配的过程中，当遇到不可匹配的字符的时候，我们希望找到一些规律，可以将模式串往后多滑动几位，跳过那些肯定不会匹配的情况。

还记得我们上一节讲到的好后缀和坏字符吗？这里我们可以类比一下，在模式串和主串匹配的过程中，把不能匹配的那个字符仍然叫作坏字符，把已经匹配的那段字符串叫作好前缀。



当遇到坏字符的时候，我们就要把模式串往后滑动，在滑动的过程中，只要模式串和好前缀有上下重合，前面几个字符的比较，就相当于拿好前缀的后缀子串，跟模式串的前缀子串在比较。这个比较的过程能否更高效了呢？可以不用一个字符一个字符地比较了吗？



KMP 算法就是在试图寻找一种规律：在模式串和主串匹配的过程中，当遇到坏字符后，对于已经比对过的好前缀，能否找到一种规律，将模式串一次性滑动很多位？

我们只需要拿好前缀本身，在它的后缀子串中，查找最长的那个可以跟好前缀的前缀子串匹配的。假设最长的可匹配的那部分前缀子串是{v}，长度是 k。我们把模式串一次性往后滑动 j-k 位，相当于，每次遇到坏字符的时候，我们就把 j 更新为 k，i 不变，然后继续比较。



为了表述起来方便，我把好前缀的所有后缀子串中，最长的可匹配前缀子串的那个后缀子串，叫作最长可匹配后缀子串；对应的前缀子串，叫作最长可匹配前缀子串。



如何来求好前缀的最长可匹配前缀和后缀子串呢？我发现，这个问题其实不涉及主串，只需要通过模式串本身就能求解。所以，我就在想，能不能事先预处理计算好，在模式串和主串匹配的过程中，直接拿过来就用呢？

类似 BM 算法中的 bc、suffix、prefix 数组，KMP 算法也可以提前构建一个数组，用来存储模式串中每个前缀（这些前缀都有可能是好前缀）的最长可匹配前缀子串的结尾字符下标。我们把这个数组定义为next 数组，很多书中还给这个数组起了一个名字，叫失效函数（failure function）。

数组的下标是每个前缀结尾字符下标，数组的值是这个前缀的最长可以匹配前缀子串的结尾字符下标。这句话有点拗口，我举了一个例子，你一看应该就懂了。



有了 next 数组，我们很容易就可以实现 KMP 算法了。我先假设 next 数组已经计算好了，先给出 KMP 算法的框架代码。

// a, b 分别是主串和模式串；n, m 分别是主串和模式串的长度。
public static int kmp(char[] a, int n, char[] b, int m) {
  int[] next = getNexts(b, m);
  int j = 0;
  for (int i = 0; i < n; ++i) {
    while (j > 0 && a[i] != b[j]) { // 一直找到 a[i] 和 b[j]
      j = next[j - 1] + 1;
    }
    if (a[i] == b[j]) {
      ++j;
    }
    if (j == m) { // 找到匹配模式串的了
      return i - m + 1;
    }
  }
  return -1;
}
失效函数计算方法
KMP 算法的基本原理讲完了，我们现在来看最复杂的部分，也就是 next 数组是如何计算出来的？

当然，我们可以用非常笨的方法，比如要计算下面这个模式串 b 的 next[4]，我们就把 b[0, 4] 的所有后缀子串，从长到短找出来，依次看看，是否能跟模式串的前缀子串匹配。很显然，这个方法也可以计算得到 next 数组，但是效率非常低。有没有更加高效的方法呢？



这里的处理非常有技巧，类似于动态规划。不过，动态规划我们在后面才会讲到，所以，我这里换种方法解释，也能让你听懂。

我们按照下标从小到大，依次计算 next 数组的值。当我们要计算 next[i] 的时候，前面的 next[0]，next[1]，……，next[i-1] 应该已经计算出来了。利用已经计算出来的 next 值，我们是否可以快速推导出 next[i] 的值呢？

如果 next[i-1]=k-1，也就是说，子串 b[0, k-1] 是 b[0, i-1] 的最长可匹配前缀子串。如果子串 b[0, k-1] 的下一个字符 b[k]，与 b[0, i-1] 的下一个字符 b[i] 匹配，那子串 b[0, k] 就是 b[0, i] 的最长可匹配前缀子串。所以，next[i] 等于 k。但是，如果 b[0, k-1] 的下一字符 b[k] 跟 b[0, i-1] 的下一个字符 b[i] 不相等呢？这个时候就不能简单地通过 next[i-1] 得到 next[i] 了。这个时候该怎么办呢？



我们假设 b[0, i] 的最长可匹配后缀子串是 b[r, i]。如果我们把最后一个字符去掉，那 b[r, i-1] 肯定是 b[0, i-1] 的可匹配后缀子串，但不一定是最长可匹配后缀子串。所以，既然 b[0, i-1] 最长可匹配后缀子串对应的模式串的前缀子串的下一个字符并不等于 b[i]，那么我们就可以考察 b[0, i-1] 的次长可匹配后缀子串 b[x, i-1] 对应的可匹配前缀子串 b[0, i-1-x] 的下一个字符 b[i-x] 是否等于 b[i]。如果等于，那 b[x, i] 就是 b[0, i] 的最长可匹配后缀子串。



可是，如何求得 b[0, i-1] 的次长可匹配后缀子串呢？次长可匹配后缀子串肯定被包含在最长可匹配后缀子串中，而最长可匹配后缀子串又对应最长可匹配前缀子串 b[0, y]。于是，查找 b[0, i-1] 的次长可匹配后缀子串，这个问题就变成，查找 b[0, y] 的最长匹配后缀子串的问题了。



按照这个思路，我们可以考察完所有的 b[0, i-1] 的可匹配后缀子串 b[y, i-1]，直到找到一个可匹配的后缀子串，它对应的前缀子串的下一个字符等于 b[i]，那这个 b[y, i] 就是 b[0, i] 的最长可匹配后缀子串。

前面我已经给出 KMP 算法的框架代码了，现在我把这部分的代码也写出来了。这两部分代码合在一起，就是整个 KMP 算法的代码实现。

// b 表示模式串，m 表示模式串的长度
private static int[] getNexts(char[] b, int m) {
  int[] next = new int[m];
  next[0] = -1;
  int k = -1;
  for (int i = 1; i < m; ++i) {
    while (k != -1 && b[k + 1] != b[i]) {
      k = next[k];
    }
    if (b[k + 1] == b[i]) {
      ++k;
    }
    next[i] = k;
  }
  return next;
}
KMP 算法复杂度分析
KMP 算法的原理和实现我们就讲完了，我们现在来分析一下 KMP 算法的时间、空间复杂度是多少？

空间复杂度很容易分析，KMP 算法只需要一个额外的 next 数组，数组的大小跟模式串相同。所以空间复杂度是 O(m)，m 表示模式串的长度。

KMP 算法包含两部分，第一部分是构建 next 数组，第二部分才是借助 next 数组匹配。所以，关于时间复杂度，我们要分别从这两部分来分析。

我们先来分析第一部分的时间复杂度。

计算 next 数组的代码中，第一层 for 循环中 i 从 1 到 m-1，也就是说，内部的代码被执行了 m-1 次。for 循环内部代码有一个 while 循环，如果我们能知道每次 for 循环、while 循环平均执行的次数，假设是 k，那时间复杂度就是 O(k*m)。但是，while 循环执行的次数不怎么好统计，所以我们放弃这种分析方法。

我们可以找一些参照变量，i 和 k。i 从 1 开始一直增加到 m，而 k 并不是每次 for 循环都会增加，所以，k 累积增加的值肯定小于 m。而 while 循环里 k=next[k]，实际上是在减小 k 的值，k 累积都没有增加超过 m，所以 while 循环里面 k=next[k] 总的执行次数也不可能超过 m。因此，next 数组计算的时间复杂度是 O(m)。

我们再来分析第二部分的时间复杂度。分析的方法是类似的。

i 从 0 循环增长到 n-1，j 的增长量不可能超过 i，所以肯定小于 n。而 while 循环中的那条语句 j=next[j-1]+1，不会让 j 增长的，那有没有可能让 j 不变呢？也没有可能。因为 next[j-1] 的值肯定小于 j-1，所以 while 循环中的这条语句实际上也是在让 j 的值减少。而 j 总共增长的量都不会超过 n，那减少的量也不可能超过 n，所以 while 循环中的这条语句总的执行次数也不会超过 n，所以这部分的时间复杂度是 O(n)。

所以，综合两部分的时间复杂度，KMP 算法的时间复杂度就是 O(m+n)。

解答开篇 & 内容小结
KMP 算法讲完了，不知道你理解了没有？如果没有，建议多看几遍，自己多思考思考。KMP 算法和上一节讲的 BM 算法的本质非常类似，都是根据规律在遇到坏字符的时候，把模式串往后多滑动几位。

BM 算法有两个规则，坏字符和好后缀。KMP 算法借鉴 BM 算法的思想，可以总结成好前缀规则。这里面最难懂的就是 next 数组的计算。如果用最笨的方法来计算，确实不难，但是效率会比较低。所以，我讲了一种类似动态规划的方法，按照下标 i 从小到大，依次计算 next[i]，并且 next[i] 的计算通过前面已经计算出来的 next[0]，next[1]，……，next[i-1] 来推导。

KMP 算法的时间复杂度是 O(n+m)，不过它的分析过程稍微需要一点技巧，不那么直观，你只要看懂就好了，并不需要掌握，在我们平常的开发中，很少会有这么难分析的代码。

课后思考
至此，我们把经典的单模式串匹配算法全部讲完了，它们分别是 BF 算法、RK 算法、BM 算法和 KMP 算法，关于这些算法，你觉得什么地方最难理解呢？

欢迎留言和我分享，也欢迎点击“请朋友读”，把今天的内容分享给你的好友，和他一起讨论、学习。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(118)

ZX
最难理解的地方是
k = next[k]
因为前一个的最长串的下一个字符不与最后一个相等，需要找前一个的次长串，问题就变成了求0到next(k)的最长串，如果下个字符与最后一个不等，继续求次长串，也就是下一个next(k)，直到找到，或者完全没有
作者回复: 你掌握了精髓

2018-12-16

2

83

他在她城断了弦
关于求next数组这部分写的太不好懂了，建议作者别用太多长句，切换成短句，方便大家理解。。
2018-12-15


29

slvher
「我们假设 b[0, i] 的最长可匹配后缀子串是 b[r, i]。如果我们把最后一个字符去掉，那 b[r, i-1] 肯定是 b[0, i-1] 的可匹配后缀子串，但不一定是最长可匹配后缀子串。」

========= 手动分割线 ========

对文中这句话，我的理解如下：

因为 b[i] 的约束可能导致 r 靠近 i，故去掉 b[i] 字符后，b[r, i-1] 虽然肯定是 b[0, i-1] 的可匹配后缀子串，但不一定是其中最长的。

例如：设模式串好前缀为 "abxabcabxabx"，其最长可匹配后缀子串为 "abx"，去掉最后的字符 'x' 后，虽然 "ab" 还是好前缀的可匹配后缀子串，但 "abxab" 才是最长可匹配后缀子串。

这句话虽然本身逻辑上是正确的，与上下文逻辑衔接性不强，感觉去掉这句更有利于对 next 数组第二种情况的理解。
2018-12-19


22

Smallfly
「那 b[r, i-1] 肯定是 b[0, i-1] 的可匹配后缀子串，但并不一定是最长可匹配后缀子串。」后半句不是很理解，如果模式串是 b[0, i-1]，i-1 已经是最后一个字符了，那么为什么 b[r, i-1] 不一定是 b[0, i-1] 的最长可匹配后缀子串呢？
2018-12-11


18

Alpha.
推荐读者先去看下这篇文章，然后再来看看，理解next会比较有帮助。
https://www.zhihu.com/question/21923021，逍遥行 的回答
2019-01-19


13

Niulx
我觉得bm算法倒是好理解但是kmp的算法的next数组我感觉不太好理解啊
2018-12-16


12

feifei
一个双休，加上好几个早上的时间，这两篇关于字符串匹配，弄明白了，代码我自己也实现了一遍，就论代码实现来说，KMP算法比BM算法要简单一点，这个BM算法，一个双休送给了他，慢慢的一点点理解规则，然后再一点点的，按照自己所理解的思想来实现，虽然觉得这样子慢，但能学到的会更多，要论最难理解的地方，这个ＢＭ的算法的计算next数组，这脑子绕了好久！
作者回复: 我写的时候也绕了好久

2018-12-14


10

李
终于看明白了，感觉设置了很多干扰项。其实用迭代思想解释就能理解了。
这个算法本质是找相等的最长匹配前缀和最长匹配后缀。
有两种情况，
（1）如果b[i-1]的最长前缀下一个字符与b[i]相等，则next[i]=next[i-1]+1.
（2）如果不相等，则我们假设找到b[i-1]的最长前缀里有b[0,y]与后缀的子串b[z,i-1]相等，然后只要b[y+1]与b[i]相等，那么b[0,y+1]就是最长匹配前缀。这个y可以不断的通过迭代缩小就可以找到
2018-12-14


7

李
百度了下，终于搞明白了，回答自己前面一个问题。
关键是要搞明白k值是啥东西。
比如求aba 每个前缀最长可匹配前缀子串的结尾字符下标
这句话很容易引起歧义。
aba的前缀有a,ab, 后缀有ba,a 只有a与a匹配。 所以匹配的结尾下标是0.
abab 显然ab和ab可以匹配，所以匹配的结尾下标是1
abaaba 下标是2
ababa 下标是2
aaaa 下标是2




作者回复: 👍

2018-12-14

1

6

不上进的码农
厉害厉害，这个算法的精髓是不是就是求next数组啊，还有BM算法中的应该也是求那两个数组。我觉着应该理一理这两种求数组的过程，这求数组的过程是不是也是一个特别好的算法呀！
2018-12-10


6

P@tricK
如果 next[i-1]=k-1，也就是说，子串 b[0, k-1] 是 b[0, i-1] 的最长可匹配前缀子串。如果子串 b[0, k-1] 的下一个字符 b[k]，与 b[0, i-1] 的下一个字符 b[i] 匹配，那子串 b[0, k] 就是 b[0, i] 的最长可匹配前缀子串。所以，next[i-1] 等于 k。

---------------

末尾应该是 next[i] 等于 k
作者回复: 嗯嗯 多谢指正

2018-12-10


5

Flash

最难理解的是KMP算法了。
总体上，KMP算法是借鉴了BM算法本质思想的，都是遇到坏字符的时候，把模式串往后多滑动几位。
1.但是这里要注意一个细节，不然容易被前面学的BM算法给误导，导致难以理解。
BM算法是对模式串从后往前比较，每次是将主串的下标 ”i“ 往后移动多位。(这符合我们正常的思维，所以好理解)
KMP虽然也是往后移动多位，但是比较时，是对模式串从前往后比较；
对于主串已经比较过的部分，保持主串的 ”i“ 指针(即下标)不回溯。
而是通过修改模式串的”j“指针，变相地让模式串移动到有效的位置。(这里修改"j"，是让"j"变小了，我们说的还是将模式串往后移动，所以不太好理解)

2.KMP算法中不好难理解的，构建next数组，其实很简单，要多下自己的脑筋，不要被带偏了，就好理解了。就是求next[i](动态规划的思想，根据前面已经计算好的结果next[0]...next[i-1]来得到next[i])，前一个的最长串的下一个字符与最后一个相等，那next[i]就=next[i-1]+1；否则就需要找前一个的次长串，递归这个过程，直到找到或没有。
2019-02-16


4

煦暖
老师你好，第二幅图的上半部分的模式串前缀子串画错了，应该从a开始，abab，而不是baba。
作者回复: 嗯嗯 多谢指正

2018-12-10


4

luo
3遍才理解了差不多，还有一句话之前留言的还是木有理解，BM是去滑动主串，KMP是利用模式串的好前缀规则去跳过模式串（相当于滑动模式串）主串递增的形式。最难理解的就是next数组中的求解，如果b[0,i-1]的最长前缀是k-1 那b[0,k-1]就是最长的前缀 这里开始分两种情况，
第一种情况：b[0,k-1]的下一个字符b[k]=b[i],则最长前缀子串就变成b[0,k]，最长后缀就变成b[i-k,i]。next[i]=next[i-1]+1
第二种情况：b[0,k-1]的下一个字符b[k]≠b[i]，这时候我们要去寻找的就是b[0,i-1]中的最长前缀子串（最长匹配前后缀子串b[0,y] 和b[i-y-1,i-1]这两本身就是一一匹配的，而next数组记录的只有前缀我们仍然利用现有条件做推断）的最长可匹配前缀子串（必然跟后缀子串一致），就是b[0,i-1]的次长可匹配子串（划重点）（因为b[0,i-1]的最长可匹配子串c因为c这个串接下来一个字符跟b[i]不等，求取c它的最长可匹配子串一直到下个字符b[x+1]与b[i]相等递归求取）。
可能我说的跟理解的有点问题，举个例子： abeabfabeabe(主串) abeabfabeabc（模型串） 到e处不能匹配，最长可匹配子串就是 abeab接下来发现f与e不一致然后再求取abeab的最长可匹配子串 ， 为ab接下去的e刚好跟e匹配。
2019-01-10


3

Kevin
时间复杂度那个while增长量是怎么推敲出整体小于m或者n的，有点不大理解
2018-12-27


3

Stephen
看了好几天，终于搞懂了
2018-12-13


3

P@tricK
最难理解的就是kmp的next数组的这个求法了，思路本身就难，几个边界情况靠自己理清写出来没BUG更是难。
自己想到的一个简单点的解法，就是先将所有模式串的前缀子串全列出来，然后用哈希表存储，key是串，value是串长度，求解next数组值的时候将后缀子串从长到短去哈希表里找。
作者回复: 👍 人才啊 不过时间复杂度就高了 后缀字串是模式串前缀的后缀子串 并不是模式串的后缀子串

2018-12-10


3

饺子
😂😂😂讲移动那幅图是不是写错了 j=j-k
不应该是j=k嘛
2019-02-25


2

李
那 b[r, i-1] 肯定是 b[0, i-1] 的可匹配后缀子串，但并不一定是最长可匹配后缀子串。
我研究了一会，这句话有误，建议更正。这里应该说一定就是最长可匹配字符串。
假设不是最长的，那b[r-1]就应该有匹配相等的，这显然矛盾
2018-12-14


2

walor
可是，如何求得 b[0, i-1] 的次长可匹配后缀子串呢？次长可匹配后缀子串肯定被包含在最长可匹配后缀子串中，而最长可匹配后缀子串又对应最长可匹配前缀子串 b[0, y]。于是，查找 b[0, i-1] 的次长可匹配后缀子串，这个问题就变成，查找 b[0, y] 的最长匹配后缀子串的问题了。

@争哥 怎么就转换为 b[0, y] 的最长匹配后缀子串了？
2018-12-10


2
收起评论

99+99+






# 35 | Trie树：如何实现搜索引擎的搜索关键词提示功能？




数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



35 | Trie树：如何实现搜索引擎的搜索关键词提示功能？
王争 2018-12-12



14:32
讲述：修阳 大小：9.99M
搜索引擎的搜索关键词提示功能，我想你应该不陌生吧？为了方便快速输入，当你在搜索引擎的搜索框中，输入要搜索的文字的某一部分的时候，搜索引擎就会自动弹出下拉框，里面是各种关键词提示。你可以直接从下拉框中选择你要搜索的东西，而不用把所有内容都输入进去，一定程度上节省了我们的搜索时间。



尽管这个功能我们几乎天天在用，作为一名工程师，你是否思考过，它是怎么实现的呢？它底层使用的是哪种数据结构和算法呢？

像 Google、百度这样的搜索引擎，它们的关键词提示功能非常全面和精准，肯定做了很多优化，但万变不离其宗，底层最基本的原理就是今天要讲的这种数据结构：Trie 树。

什么是“Trie 树”？
Trie 树，也叫“字典树”。顾名思义，它是一个树形结构。它是一种专门处理字符串匹配的数据结构，用来解决在一组字符串集合中快速查找某个字符串的问题。

当然，这样一个问题可以有多种解决方法，比如散列表、红黑树，或者我们前面几节讲到的一些字符串匹配算法，但是，Trie 树在这个问题的解决上，有它特有的优点。不仅如此，Trie 树能解决的问题也不限于此，我们一会儿慢慢分析。

现在，我们先来看下，Trie 树到底长什么样子。

我举个简单的例子来说明一下。我们有 6 个字符串，它们分别是：how，hi，her，hello，so，see。我们希望在里面多次查找某个字符串是否存在。如果每次查找，都是拿要查找的字符串跟这 6 个字符串依次进行字符串匹配，那效率就比较低，有没有更高效的方法呢？

这个时候，我们就可以先对这 6 个字符串做一下预处理，组织成 Trie 树的结构，之后每次查找，都是在 Trie 树中进行匹配查找。Trie 树的本质，就是利用字符串之间的公共前缀，将重复的前缀合并在一起。最后构造出来的就是下面这个图中的样子。



其中，根节点不包含任何信息。每个节点表示一个字符串中的字符，从根节点到红色节点的一条路径表示一个字符串（注意：红色节点并不都是叶子节点）。

为了让你更容易理解 Trie 树是怎么构造出来的，我画了一个 Trie 树构造的分解过程。构造过程的每一步，都相当于往 Trie 树中插入一个字符串。当所有字符串都插入完成之后，Trie 树就构造好了。



当我们在 Trie 树中查找一个字符串的时候，比如查找字符串“her”，那我们将要查找的字符串分割成单个的字符 h，e，r，然后从 Trie 树的根节点开始匹配。如图所示，绿色的路径就是在 Trie 树中匹配的路径。



如果我们要查找的是字符串“he”呢？我们还用上面同样的方法，从根节点开始，沿着某条路径来匹配，如图所示，绿色的路径，是字符串“he”匹配的路径。但是，路径的最后一个节点“e”并不是红色的。也就是说，“he”是某个字符串的前缀子串，但并不能完全匹配任何字符串。



如何实现一棵 Trie 树？
知道了 Trie 树长什么样子，我们现在来看下，如何用代码来实现一个 Trie 树。

从刚刚 Trie 树的介绍来看，Trie 树主要有两个操作，一个是将字符串集合构造成 Trie 树。这个过程分解开来的话，就是一个将字符串插入到 Trie 树的过程。另一个是在 Trie 树中查询一个字符串。

了解了 Trie 树的两个主要操作之后，我们再来看下，如何存储一个 Trie 树？

从前面的图中，我们可以看出，Trie 树是一个多叉树。我们知道，二叉树中，一个节点的左右子节点是通过两个指针来存储的，如下所示 Java 代码。那对于多叉树来说，我们怎么存储一个节点的所有子节点的指针呢？

class BinaryTreeNode {
  char data;
  BinaryTreeNode left;
  BinaryTreeNode right;  
}
我先介绍其中一种存储方式，也是经典的存储方式，大部分数据结构和算法书籍中都是这么讲的。还记得我们前面讲到的散列表吗？借助散列表的思想，我们通过一个下标与字符一一映射的数组，来存储子节点的指针。这句话稍微有点抽象，不怎么好懂，我画了一张图你可以看看。



假设我们的字符串中只有从 a 到 z 这 26 个小写字母，我们在数组中下标为 0 的位置，存储指向子节点 a 的指针，下标为 1 的位置存储指向子节点 b 的指针，以此类推，下标为 25 的位置，存储的是指向的子节点 z 的指针。如果某个字符的子节点不存在，我们就在对应的下标的位置存储 null。

class TrieNode {
  char data;
  TrieNode children[26];
}
当我们在 Trie 树中查找字符串的时候，我们就可以通过字符的 ASCII 码减去“a”的 ASCII 码，迅速找到匹配的子节点的指针。比如，d 的 ASCII 码减去 a 的 ASCII 码就是 3，那子节点 d 的指针就存储在数组中下标为 3 的位置中。

描述了这么多，有可能你还是有点懵，我把上面的描述翻译成了代码，你可以结合着一块看下，应该有助于你理解。

public class Trie {
  private TrieNode root = new TrieNode('/'); // 存储无意义字符
 
  // 往 Trie 树中插入一个字符串
  public void insert(char[] text) {
    TrieNode p = root;
    for (int i = 0; i < text.length; ++i) {
      int index = text[i] - 'a';
      if (p.children[index] == null) {
        TrieNode newNode = new TrieNode(text[i]);
        p.children[index] = newNode;
      }
      p = p.children[index];
    }
    p.isEndingChar = true;
  }
 
  // 在 Trie 树中查找一个字符串
  public boolean find(char[] pattern) {
    TrieNode p = root;
    for (int i = 0; i < pattern.length; ++i) {
      int index = pattern[i] - 'a';
      if (p.children[index] == null) {
        return false; // 不存在 pattern
      }
      p = p.children[index];
    }
    if (p.isEndingChar == false) return false; // 不能完全匹配，只是前缀
    else return true; // 找到 pattern
  }
 
  public class TrieNode {
    public char data;
    public TrieNode[] children = new TrieNode[26];
    public boolean isEndingChar = false;
    public TrieNode(char data) {
      this.data = data;
    }
  }
}
Trie 树的实现，你现在应该搞懂了。现在，我们来看下，在 Trie 树中，查找某个字符串的时间复杂度是多少？

如果要在一组字符串中，频繁地查询某些字符串，用 Trie 树会非常高效。构建 Trie 树的过程，需要扫描所有的字符串，时间复杂度是 O(n)（n 表示所有字符串的长度和）。但是一旦构建成功之后，后续的查询操作会非常高效。

每次查询时，如果要查询的字符串长度是 k，那我们只需要比对大约 k 个节点，就能完成查询操作。跟原本那组字符串的长度和个数没有任何关系。所以说，构建好 Trie 树后，在其中查找字符串的时间复杂度是 O(k)，k 表示要查找的字符串的长度。

Trie 树真的很耗内存吗？
前面我们讲了 Trie 树的实现，也分析了时间复杂度。现在你应该知道，Trie 树是一种非常独特的、高效的字符串匹配方法。但是，关于 Trie 树，你有没有听过这样一种说法：“Trie 树是非常耗内存的，用的是一种空间换时间的思路”。这是什么原因呢？

刚刚我们在讲 Trie 树的实现的时候，讲到用数组来存储一个节点的子节点的指针。如果字符串中包含从 a 到 z 这 26 个字符，那每个节点都要存储一个长度为 26 的数组，并且每个数组存储一个 8 字节指针（或者是 4 字节，这个大小跟 CPU、操作系统、编译器等有关）。而且，即便一个节点只有很少的子节点，远小于 26 个，比如 3、4 个，我们也要维护一个长度为 26 的数组。

我们前面讲过，Trie 树的本质是避免重复存储一组字符串的相同前缀子串，但是现在每个字符（对应一个节点）的存储远远大于 1 个字节。按照我们上面举的例子，数组长度为 26，每个元素是 8 字节，那每个节点就会额外需要 26*8=208 个字节。而且这还是只包含 26 个字符的情况。

如果字符串中不仅包含小写字母，还包含大写字母、数字、甚至是中文，那需要的存储空间就更多了。所以，也就是说，在某些情况下，Trie 树不一定会节省存储空间。在重复的前缀并不多的情况下，Trie 树不但不能节省内存，还有可能会浪费更多的内存。

当然，我们不可否认，Trie 树尽管有可能很浪费内存，但是确实非常高效。那为了解决这个内存问题，我们是否有其他办法呢？

我们可以稍微牺牲一点查询的效率，将每个节点中的数组换成其他数据结构，来存储一个节点的子节点指针。用哪种数据结构呢？我们的选择其实有很多，比如有序数组、跳表、散列表、红黑树等。

假设我们用有序数组，数组中的指针按照所指向的子节点中的字符的大小顺序排列。查询的时候，我们可以通过二分查找的方法，快速查找到某个字符应该匹配的子节点的指针。但是，在往 Trie 树中插入一个字符串的时候，我们为了维护数组中数据的有序性，就会稍微慢了点。

替换成其他数据结构的思路是类似的，这里我就不一一分析了，你可以结合前面学过的内容，自己分析一下。

实际上，Trie 树的变体有很多，都可以在一定程度上解决内存消耗的问题。比如，缩点优化，就是对只有一个子节点的节点，而且此节点不是一个串的结束节点，可以将此节点与子节点合并。这样可以节省空间，但却增加了编码难度。这里我就不展开详细讲解了，你如果感兴趣，可以自行研究下。



Trie 树与散列表、红黑树的比较
实际上，字符串的匹配问题，笼统上讲，其实就是数据的查找问题。对于支持动态数据高效操作的数据结构，我们前面已经讲过好多了，比如散列表、红黑树、跳表等等。实际上，这些数据结构也可以实现在一组字符串中查找字符串的功能。我们选了两种数据结构，散列表和红黑树，跟 Trie 树比较一下，看看它们各自的优缺点和应用场景。

在刚刚讲的这个场景，在一组字符串中查找字符串，Trie 树实际上表现得并不好。它对要处理的字符串有及其严苛的要求。

第一，字符串中包含的字符集不能太大。我们前面讲到，如果字符集太大，那存储空间可能就会浪费很多。即便可以优化，但也要付出牺牲查询、插入效率的代价。

第二，要求字符串的前缀重合比较多，不然空间消耗会变大很多。

第三，如果要用 Trie 树解决问题，那我们就要自己从零开始实现一个 Trie 树，还要保证没有 bug，这个在工程上是将简单问题复杂化，除非必须，一般不建议这样做。

第四，我们知道，通过指针串起来的数据块是不连续的，而 Trie 树中用到了指针，所以，对缓存并不友好，性能上会打个折扣。

综合这几点，针对在一组字符串中查找字符串的问题，我们在工程中，更倾向于用散列表或者红黑树。因为这两种数据结构，我们都不需要自己去实现，直接利用编程语言中提供的现成类库就行了。

讲到这里，你可能要疑惑了，讲了半天，我对 Trie 树一通否定，还让你用红黑树或者散列表，那 Trie 树是不是就没用了呢？是不是今天的内容就白学了呢？

实际上，Trie 树只是不适合精确匹配查找，这种问题更适合用散列表或者红黑树来解决。Trie 树比较适合的是查找前缀匹配的字符串，也就是类似开篇问题的那种场景。

解答开篇
Trie 树就讲完了，我们来看下开篇提到的问题：如何利用 Trie 树，实现搜索关键词的提示功能？

我们假设关键词库由用户的热门搜索关键词组成。我们将这个词库构建成一个 Trie 树。当用户输入其中某个单词的时候，把这个词作为一个前缀子串在 Trie 树中匹配。为了讲解方便，我们假设词库里只有 hello、her、hi、how、so、see 这 6 个关键词。当用户输入了字母 h 的时候，我们就把以 h 为前缀的 hello、her、hi、how 展示在搜索提示框内。当用户继续键入字母 e 的时候，我们就把以 he 为前缀的 hello、her 展示在搜索提示框内。这就是搜索关键词提示的最基本的算法原理。



不过，我讲的只是最基本的实现原理，实际上，搜索引擎的搜索关键词提示功能远非我讲的这么简单。如果再稍微深入一点，你就会想到，上面的解决办法遇到下面几个问题：

我刚讲的思路是针对英文的搜索关键词提示，对于更加复杂的中文来说，词库中的数据又该如何构建成 Trie 树呢？

如果词库中有很多关键词，在搜索提示的时候，用户输入关键词，作为前缀在 Trie 树中可以匹配的关键词也有很多，如何选择展示哪些内容呢？

像 Google 这样的搜索引擎，用户单词拼写错误的情况下，Google 还是可以使用正确的拼写来做关键词提示，这个又是怎么做到的呢？

你可以先思考一下如何来解决，如果不会也没关系，这些问题，我们会在实战篇里具体来讲解。

实际上，Trie 树的这个应用可以扩展到更加广泛的一个应用上，就是自动输入补全，比如输入法自动补全功能、IDE 代码编辑器自动补全功能、浏览器网址输入的自动补全功能等等。

内容小结
今天我们讲了一种特殊的树，Trie 树。Trie 树是一种解决字符串快速匹配问题的数据结构。如果用来构建 Trie 树的这一组字符串中，前缀重复的情况不是很多，那 Trie 树这种数据结构总体上来讲是比较费内存的，是一种空间换时间的解决问题思路。

尽管比较耗费内存，但是对内存不敏感或者内存消耗在接受范围内的情况下，在 Trie 树中做字符串匹配还是非常高效的，时间复杂度是 O(k)，k 表示要匹配的字符串的长度。

但是，Trie 树的优势并不在于，用它来做动态集合数据的查找，因为，这个工作完全可以用更加合适的散列表或者红黑树来替代。Trie 树最有优势的是查找前缀匹配的字符串，比如搜索引擎中的关键词提示功能这个场景，就比较适合用它来解决，也是 Trie 树比较经典的应用场景。

课后思考
我们今天有讲到，Trie 树应用场合对数据要求比较苛刻，比如字符串的字符集不能太大，前缀重合比较多等。如果现在给你一个很大的字符串集合，比如包含 1 万条记录，如何通过编程量化分析这组字符串集合是否比较适合用 Trie 树解决呢？也就是如何统计字符串的字符集大小，以及前缀重合的程度呢？

欢迎留言和我分享，也欢迎点击“请朋友读”，把今天的内容分享给你的好友，和他一起讨论、学习。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(64)

Jerry银银
找到了一个Trie树的开源库：Apache Commons，里面有关于Trie的实现
作者回复: 👍

2018-12-28

4

39

ban
上面代码里： p.isEndingChar = true; 应该是放在for循环的外面吧？
不然如果hello，那不就变成 h e l l o 都是叶子节点？
2018-12-13


22

Smallfly
思考题：

依次读取每个字符串的字符构建 Trie 树，用散列表来存储每一个节点。每一层树的所有散列表的元素用一个链表串联起来，
求某一长度的前缀重合，在对应树层级上遍历该层链表，求链表长度，除以字符集大小，值越小前缀重合率越高。

遍历所有树层级的链表，存入散列表，最后散列表包含元素的个数，就代表字符集的大小。
2018-12-12


17

传说中的成大大
今天的课程比上两节的课程理解起来容易多了 总体觉得就像是构造出来的多叉树，相同的前缀字符串就是同一棵树下来的不同分之
2018-12-13


11

kepmov
trie树实际项目中由于内存问题用的不是很多，老师可以讲解下DAT（双数组trie树）的具体实现吗
作者回复: 这个还是自己研究吧 内容太多了 文章有限。或者后面我收集下 统一写几篇加餐文章吧

2018-12-12


10

等风来
if (p.isEndingChar == false) return false; // 不能完全匹配，只是前缀
else return true; // 找到 pattern
这小段代码有点不大牛.^_^
return p.isEndingChar;就好了
作者回复: 嗯嗯 怕看不懂嘛

2018-12-12


8

ZX
老师，字符串匹配这里，还差后缀树没讲，很多场合需要用到这种结构，希望老师可以讲一讲
作者回复: 那个更高级 不讲了 自学吧亲

2018-12-17


7

feifei
如何统计字符串的字符集大小，以及前缀重合的程度呢？

统计字符集的大小，这个问题，其实就是在求字符的最小值以及最大值的问题。
我的解决办法
1，遍历字符串集合
2，将每个字符转化为int数字
3，设置最小以及最大的变量，当字符中比最大字符的变量大的时候，将最大字符变量改为当前字符，或者比最小字符小，就修改最小字符
4，遍历完成后，所求得的最大值与最小值的差，就是字符集的大小

前缀重合的程度，这个问题的求解，其实就是做字符的统计问题
我的解决办法：
使用哈希表来记录下统计数，key为字符，value为统计计数
遍历每条记录，假如每条记录中仅包含一个单词（如果多单词，多一步分隔操作，分隔成一个一个的单词）
统计计数算法，就是从前到后遍历，遇到存在的，加1，不存在，则存入hash表
比如hello这个单词，在哈希表中存储就为
h 1
he 1
hel 1
hell 1
hello 1
当再将出现，比如he
就会变成
h 2
he 2
hel 1
hell 1
hello 1

统计数据完成后，对这个结果计算重合的字符数与整个字符的占比，
具体计算公式为: count(value > 1) / count(all)
但我的算法复杂度有点高，是m*n,m表示整个字符的长度，n表示单个单表的长度。

2018-12-16


7

王鸿运
isEndingChar可以修改成uint型字段，这样不仅够可以判断是否包含该字符串，还可以进行字符串出现次数
2018-12-29


6

Jerry银银
老师帮忙推荐一些包含Trie树实现的优秀的开源库呗，好让我们深入研究
2018-12-28


3

忽忽
请问下老师，这些图是什么工具画的呀？
作者回复: paper

2018-12-25


3

小美
老师 红黑树 如何实现字符串查找 方便王老师稍微点拨下吗
作者回复: 把字符串整体当做一个数据 存储在节点里

2018-12-12


3

夏洛克的救赎
问题思考：
1 中文转换成ASCII码？
2 根据以往用户搜索记录，选择占比最高的
3 从词库检索匹配？
2018-12-12


3

追风者
王老师，关于Trie树有两点疑问。
1.文中用‘he’和‘her’构建Trie树，当我要查询‘he’的时候怎么办？
2.像jieba分词这种切词工具，为什么要用Trie树呢？
作者回复: 1. he的e节点也会被标记为结尾字符节点
2. jieba分词不怎么了解呢。。。

2019-01-04


2

起点·终站
看完后发现我们项目的屏蔽字检测就是用trie树写的。。666
2018-12-17


2

Li Yao
p = p.children[index];
p.isEndingChar = true;
是不是应该放到for循环外面？ 否则每个节点都会被标记为endingChar?
作者回复: 已经改正 多谢🙏

2018-12-17


2

TryTs
老师，麻烦请问一下您请问一下对于一些新的领域，没有现成的书，教程你会通过什么方法跟途径或者说平台去体系的学习？还有我就是想请教一下老师您对AR的看法？
作者回复: 没有现成的教程 书。只能自己摸索了。多看看别人分享的文章 自己理个知识大纲 然后再查缺补漏吧

2018-12-12


2

freeland
以太坊上header里的transaction .root ,state root,receipt root用的是Merkle-PatriciaTrie(MPT)，和今天的这个是一个么
作者回复: 思路差不多 更高级点

2018-12-12


2

掸尘
C 版本代码：

#define OK 1
#define ERROR 0
#define TRUE 1
#define FALSE 0

typedef int Status;

typedef struct Node {
    char data;
    struct Node *children[26];
    Status end;
} Trie, *TriePtr;

void Init(TriePtr *T)
{
    (*T) = (TriePtr)malloc(sizeof(Trie));
    (*T)->data = '/';
    (*T)->end = FALSE;
}

void Insert(TriePtr T, char *str) {

    int index;
    char c;

    while(c = *str++)
    {
        index = c - 'a';
        if (T->children[index] == NULL)
        {
            TriePtr Node;
            Node = (TriePtr)malloc(sizeof(Trie));
            Node->data = c;
            Node->end = FALSE;
            T->children[index] = Node;
        }

        T = T->children[index];
    }

    T->end = TRUE;
}


Status Search(TriePtr T, char *str) {

    int index;
    char c;

    while(c = *str++)
    {
        index = c - 'a';
        if (T->children[index] == NULL)
        {
            return FALSE;
        }

        T = T->children[index];
    }

    if (T->end) {
        return TRUE;
    } else {
        return FALSE;
    }
}
2019-05-09


1

Robert
思考题我想的比较简单：将字符串去重后统计数量，看看与原始字符串数量的比例。
2019-05-06


1
收起评论

6499+






# 36 | AC自动机：如何用多模式串匹配实现敏感词过滤功能？



数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



36 | AC自动机：如何用多模式串匹配实现敏感词过滤功能？
王争 2018-12-14



12:55
讲述：修阳 大小：8.88M
很多支持用户发表文本内容的网站，比如 BBS，大都会有敏感词过滤功能，用来过滤掉用户输入的一些淫秽、反动、谩骂等内容。你有没有想过，这个功能是怎么实现的呢？

实际上，这些功能最基本的原理就是字符串匹配算法，也就是通过维护一个敏感词的字典，当用户输入一段文字内容之后，通过字符串匹配算法，来查找用户输入的这段文字，是否包含敏感词。如果有，就用“***”把它替代掉。

我们前面讲过好几种字符串匹配算法了，它们都可以处理这个问题。但是，对于访问量巨大的网站来说，比如淘宝，用户每天的评论数有几亿、甚至几十亿。这时候，我们对敏感词过滤系统的性能要求就要很高。毕竟，我们也不想，用户输入内容之后，要等几秒才能发送出去吧？我们也不想，为了这个功能耗费过多的机器吧？那如何才能实现一个高性能的敏感词过滤系统呢？这就要用到今天的多模式串匹配算法。

基于单模式串和 Trie 树实现的敏感词过滤
我们前面几节讲了好几种字符串匹配算法，有 BF 算法、RK 算法、BM 算法、KMP 算法，还有 Trie 树。前面四种算法都是单模式串匹配算法，只有 Trie 树是多模式串匹配算法。

我说过，单模式串匹配算法，是在一个模式串和一个主串之间进行匹配，也就是说，在一个主串中查找一个模式串。多模式串匹配算法，就是在多个模式串和一个主串之间做匹配，也就是说，在一个主串中查找多个模式串。

尽管，单模式串匹配算法也能完成多模式串的匹配工作。例如开篇的思考题，我们可以针对每个敏感词，通过单模式串匹配算法（比如 KMP 算法）与用户输入的文字内容进行匹配。但是，这样做的话，每个匹配过程都需要扫描一遍用户输入的内容。整个过程下来就要扫描很多遍用户输入的内容。如果敏感词很多，比如几千个，并且用户输入的内容很长，假如有上千个字符，那我们就需要扫描几千遍这样的输入内容。很显然，这种处理思路比较低效。

与单模式匹配算法相比，多模式匹配算法在这个问题的处理上就很高效了。它只需要扫描一遍主串，就能在主串中一次性查找多个模式串是否存在，从而大大提高匹配效率。我们知道，Trie 树就是一种多模式串匹配算法。那如何用 Trie 树实现敏感词过滤功能呢？

我们可以对敏感词字典进行预处理，构建成 Trie 树结构。这个预处理的操作只需要做一次，如果敏感词字典动态更新了，比如删除、添加了一个敏感词，那我们只需要动态更新一下 Trie 树就可以了。

当用户输入一个文本内容后，我们把用户输入的内容作为主串，从第一个字符（假设是字符 C）开始，在 Trie 树中匹配。当匹配到 Trie 树的叶子节点，或者中途遇到不匹配字符的时候，我们将主串的开始匹配位置后移一位，也就是从字符 C 的下一个字符开始，重新在 Trie 树中匹配。

基于 Trie 树的这种处理方法，有点类似单模式串匹配的 BF 算法。我们知道，单模式串匹配算法中，KMP 算法对 BF 算法进行改进，引入了 next 数组，让匹配失败时，尽可能将模式串往后多滑动几位。借鉴单模式串的优化改进方法，能否对多模式串 Trie 树进行改进，进一步提高 Trie 树的效率呢？这就要用到 AC 自动机算法了。

经典的多模式串匹配算法：AC 自动机
AC 自动机算法，全称是 Aho-Corasick 算法。其实，Trie 树跟 AC 自动机之间的关系，就像单串匹配中朴素的串匹配算法，跟 KMP 算法之间的关系一样，只不过前者针对的是多模式串而已。所以，AC 自动机实际上就是在 Trie 树之上，加了类似 KMP 的 next 数组，只不过此处的 next 数组是构建在树上罢了。如果代码表示，就是下面这个样子：

public class AcNode {
  public char data; 
  public AcNode[] children = new AcNode[26]; // 字符集只包含 a~z 这 26 个字符
  public boolean isEndingChar = false; // 结尾字符为 true
  public int length = -1; // 当 isEndingChar=true 时，记录模式串长度
  public AcNode fail; // 失败指针
  public AcNode(char data) {
    this.data = data;
  }
}
所以，AC 自动机的构建，包含两个操作：

将多个模式串构建成 Trie 树；

在 Trie 树上构建失败指针（相当于 KMP 中的失效函数 next 数组）。

关于如何构建 Trie 树，我们上一节已经讲过了。所以，这里我们就重点看下，构建好 Trie 树之后，如何在它之上构建失败指针？

我用一个例子给你讲解。这里有 4 个模式串，分别是 c，bc，bcd，abcd；主串是 abcd。



Trie 树中的每一个节点都有一个失败指针，它的作用和构建过程，跟 KMP 算法中的 next 数组极其相似。所以要想看懂这节内容，你要先理解 KMP 算法中 next 数组的构建过程。如果你还有点不清楚，建议你先回头去弄懂 KMP 算法。

假设我们沿 Trie 树走到 p 节点，也就是下图中的紫色节点，那 p 的失败指针就是从 root 走到紫色节点形成的字符串 abc，跟所有模式串前缀匹配的最长可匹配后缀子串，就是箭头指的 bc 模式串。

这里的最长可匹配后缀子串，我稍微解释一下。字符串 abc 的后缀子串有两个 bc，c，我们拿它们与其他模式串匹配，如果某个后缀子串可以匹配某个模式串的前缀，那我们就把这个后缀子串叫作可匹配后缀子串。

我们从可匹配后缀子串中，找出最长的一个，就是刚刚讲到的最长可匹配后缀子串。我们将 p 节点的失败指针指向那个最长匹配后缀子串对应的模式串的前缀的最后一个节点，就是下图中箭头指向的节点。



计算每个节点的失败指针这个过程看起来有些复杂。其实，如果我们把树中相同深度的节点放到同一层，那么某个节点的失败指针只有可能出现在它所在层的上一层。

我们可以像 KMP 算法那样，当我们要求某个节点的失败指针的时候，我们通过已经求得的、深度更小的那些节点的失败指针来推导。也就是说，我们可以逐层依次来求解每个节点的失败指针。所以，失败指针的构建过程，是一个按层遍历树的过程。

首先 root 的失败指针为 NULL，也就是指向自己。当我们已经求得某个节点 p 的失败指针之后，如何寻找它的子节点的失败指针呢？

我们假设节点 p 的失败指针指向节点 q，我们看节点 p 的子节点 pc 对应的字符，是否也可以在节点 q 的子节点中找到。如果找到了节点 q 的一个子节点 qc，对应的字符跟节点 pc 对应的字符相同，则将节点 pc 的失败指针指向节点 qc。



如果节点 q 中没有子节点的字符等于节点 pc 包含的字符，则令 q=q->fail（fail 表示失败指针，这里有没有很像 KMP 算法里求 next 的过程？），继续上面的查找，直到 q 是 root 为止，如果还没有找到相同字符的子节点，就让节点 pc 的失败指针指向 root。



我将构建失败指针的代码贴在这里，你可以对照着讲解一块看下，应该更容易理解。这里面，构建 Trie 树的代码我并没有贴出来，你可以参看上一节的代码，自己实现。

public void buildFailurePointer() {
  Queue<AcNode> queue = new LinkedList<>();
  root.fail = null;
  queue.add(root);
  while (!queue.isEmpty()) {
    AcNode p = queue.remove();
    for (int i = 0; i < 26; ++i) {
      AcNode pc = p.children[i];
      if (pc == null) continue;
      if (p == root) {
        pc.fail = root;
      } else {
        AcNode q = p.fail;
        while (q != null) {
          AcNode qc = q.children[pc.data - 'a'];
          if (qc != null) {
            pc.fail = qc;
            break;
          }
          q = q.fail;
        }
        if (q == null) {
          pc.fail = root;
        }
      }
      queue.add(pc);
    }
  }
}
通过按层来计算每个节点的子节点的失效指针，刚刚举的那个例子，最后构建完成之后的 AC 自动机就是下面这个样子：



AC 自动机到此就构建完成了。我们现在来看下，如何在 AC 自动机上匹配主串？

我们还是拿之前的例子来讲解。在匹配过程中，主串从 i=0 开始，AC 自动机从指针 p=root 开始，假设模式串是 b，主串是 a。

如果 p 指向的节点有一个等于 b[i] 的子节点 x，我们就更新 p 指向 x，这个时候我们需要通过失败指针，检测一系列失败指针为结尾的路径是否是模式串。这一句不好理解，你可以结合代码看。处理完之后，我们将 i 加一，继续这两个过程；

如果 p 指向的节点没有等于 b[i] 的子节点，那失败指针就派上用场了，我们让 p=p->fail，然后继续这 2 个过程。

关于匹配的这部分，文字描述不如代码看得清楚，所以我把代码贴了出来，非常简短，并且添加了详细的注释，你可以对照着看下。这段代码输出的就是，在主串中每个可以匹配的模式串出现的位置。

public void match(char[] text) { // text 是主串
  int n = text.length;
  AcNode p = root;
  for (int i = 0; i < n; ++i) {
    int idx = text[i] - 'a';
    while (p.children[idx] == null && p != root) {
      p = p.fail; // 失败指针发挥作用的地方
    }
    p = p.children[idx];
    if (p == null) p = root; // 如果没有匹配的，从 root 开始重新匹配
    AcNode tmp = p;
    while (tmp != root) { // 打印出可以匹配的模式串
      if (tmp.isEndingChar == true) {
        int pos = i-tmp.length+1;
        System.out.println(" 匹配起始下标 " + pos + "; 长度 " + tmp.length);
      }
      tmp = tmp.fail;
    }
  }
}
解答开篇
AC 自动机的内容讲完了，关于开篇的问题，你应该能解答了吧？实际上，我上面贴出来的代码，已经是一个敏感词过滤的原型代码了。它可以找到所有敏感词出现的位置（在用户输入的文本中的起始下标）。你只需要稍加改造，再遍历一遍文本内容（主串），就可以将文本中的所有敏感词替换成“***”。

所以我这里着重讲一下，AC 自动机实现的敏感词过滤系统，是否比单模式串匹配方法更高效呢？

首先，我们需要将敏感词构建成 AC 自动机，包括构建 Trie 树以及构建失败指针。

我们上一节讲过，Trie 树构建的时间复杂度是 O(m*len)，其中 len 表示敏感词的平均长度，m 表示敏感词的个数。那构建失败指针的时间复杂度是多少呢？我这里给出一个不是很紧确的上界。

假设 Trie 树中总的节点个数是 k，每个节点构建失败指针的时候，（你可以看下代码）最耗时的环节是 while 循环中的 q=q->fail，每运行一次这个语句，q 指向节点的深度都会减少 1，而树的高度最高也不会超过 len，所以每个节点构建失败指针的时间复杂度是 O(len)。整个失败指针的构建过程就是 O(k*len)。

不过，AC 自动机的构建过程都是预先处理好的，构建好之后，并不会频繁地更新，所以不会影响到敏感词过滤的运行效率。

我们再来看下，用 AC 自动机做匹配的时间复杂度是多少？

跟刚刚构建失败指针的分析类似，for 循环依次遍历主串中的每个字符，for 循环内部最耗时的部分也是 while 循环，而这一部分的时间复杂度也是 O(len)，所以总的匹配的时间复杂度就是 O(n*len)。因为敏感词并不会很长，而且这个时间复杂度只是一个非常宽泛的上限，实际情况下，可能近似于 O(n)，所以 AC 自动机做敏感词过滤，性能非常高。

你可以会说，从时间复杂度上看，AC 自动机匹配的效率跟 Trie 树一样啊。实际上，因为失效指针可能大部分情况下都指向 root 节点，所以绝大部分情况下，在 AC 自动机上做匹配的效率要远高于刚刚计算出的比较宽泛的时间复杂度。只有在极端情况下，如图所示，AC 自动机的性能才会退化的跟 Trie 树一样。



内容小结
今天我们讲了多模式串匹配算法，AC 自动机。单模式串匹配算法是为了快速在主串中查找一个模式串，而多模式串匹配算法是为了快速在主串中查找多个模式串。

AC 自动机是基于 Trie 树的一种改进算法，它跟 Trie 树的关系，就像单模式串中，KMP 算法与 BF 算法的关系一样。KMP 算法中有一个非常关键的 next 数组，类比到 AC 自动机中就是失败指针。而且，AC 自动机失败指针的构建过程，跟 KMP 算法中计算 next 数组极其相似。所以，要理解 AC 自动机，最好先掌握 KMP 算法，因为 AC 自动机其实就是 KMP 算法在多模式串上的改造。

整个 AC 自动机算法包含两个部分，第一部分是将多个模式串构建成 AC 自动机，第二部分是在 AC 自动机中匹配主串。第一部分又分为两个小的步骤，一个是将模式串构建成 Trie 树，另一个是在 Trie 树上构建失败指针。

课后思考
到此为止，字符串匹配算法我们全都讲完了，你能试着分析总结一下，各个字符串匹配算法的特点和比较适合的应用场景吗？

欢迎留言和我分享，也欢迎点击“请朋友读”，把今天的内容分享给你的好友，和他一起讨论、学习。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(53)

zixuan
思考题:
一、单模式串匹配：
1. BF： 简单场景，主串和模式串都不太长, O(m*n)
2. KP：字符集范围不要太大且模式串不要太长， 否则hash值可能冲突，O(n)
3. naive-BM：模式串最好不要太长（因为预处理较重），比如IDE编辑器里的查找场景； 预处理O(m*m), 匹配O(n)， 实现较复杂，需要较多额外空间.
4. KMP：适合所有场景，整体实现起来也比BM简单，O(n+m)，仅需一个next数组的O(n)额外空间；但统计意义下似乎BM更快，原因不明.
5. 另外查资料的时候还看到一种比BM/KMP更快，且实现+理解起来都更容易的的Sunday算法，有兴趣的可以看这里:
http://www.inf.fh-flensburg.de/lang/algorithmen/pattern/sundayen.htm
https://www.jianshu.com/p/2e6eb7386cd3

二、多模式串匹配：
1. naive-Trie: 适合多模式串公共前缀较多的匹配(O(n*k)) 或者 根据公共前缀进行查找(O(k))的场景，比如搜索框的自动补全提示.
2. AC自动机: 适合大量文本中多模式串的精确匹配查找, 可以到O(n).
  
2018-12-14


62

A_F
我只想说，老师你真牛X
2018-12-14


25

bboy孙晨杰
在看kmp和本节的ac自动机，很多文字描述我也理解不了，于是我就在纸上画一些具体的例子，然后按代码一步步的debug下去，虽然方法笨，但是很有助于理解。
2018-12-19


12

zixuan
前面激动说错了哈 ，跟DATrie没有半毛钱关系，后者只是一种Trie的具体实现.
"其实，如果我们把树中相同深度的节点放到同一层，那么某个节点的失败指针只有可能出现在它所在层的上一层"， 这里改成 "那么某个节点的失败指针只有可能指向比他所在层更小的层数的节点" 似乎更精确，虽然例子里刚好都是差一层，但实际应该可以往前跨多层的.
和KMP算法一样，这个通过层次遍历来编织failNode数组的过程非常精妙，真的就像是织网一样。
2018-12-14


10

O_o
做安卓开发的，前边全部都理解+可动手手写。跟到最近几章感到面试可能确实用不到这些了，平时工作也确实用不到了。感谢老师最近的授课，通俗易懂！
作者回复: 👍 厉害。最近这几讲不讲的话 知识就有缺陷 你可以不用太费劲看懂 知道有这个东西就行

2018-12-17


9

润鑫
红黑树、KPM跟AC自动机这几节有点跟不上。。
2018-12-14


7

roc
王争老师，想问一下，我前面的内容掌握了有80%，如果不是面试算法岗，应该还算过关吧？
2018-12-14


6

TryTs
老师，我觉得学你这个课之后除了学习新的知识之外，还能够让我能够了解平时间那些常见应用背后的操作，最关键的时候在激发我的好奇心，让我能够去思考那些技术。嗯……我觉得很多时候好奇心就是学好知识的基础
2018-12-19


5

blacknhole
终于完全看懂了。
有几个疑问：
1，“首先 root 的失败指针为 NULL，也就是指向自己。”后半句是不准确或错误的，root的失败指针并非指向自身，因为root不等于null。
2，“如果 p 指向的节点有一个等于 b[i] 的子节点 x……”以及下文中提到的b[i]，是笔误吗？应该为a[i]吧，因为a才是主串。
2018-12-23


3

EidLeung
老师，如果要添加模式串，怎么改fail指针啊？
2018-12-14


3

QQ怪
正好要做这个敏感词过滤系统😂
2019-03-05


2

QQ怪
ac自动机跟DFA算法有啥不同?
2019-03-05


2

深蓝...
完犊子了 从字符串匹配开始就掉队了 之前红黑树也是一脸懵逼。
2018-12-14

2

2

wahaha
“我这里给出一个不是很紧确的上界。”
不是“紧确”应该是“精确”
编辑回复: 没问题的 就是紧确 意思和精确类似 你可以查一查

2019-05-24


1

懒猫
老师，这里求最长可匹配后缀子串没理解，您举的例子：abc的最长可匹配后缀子串为bc，但是按照kmp的思想，abc的前缀子串为a、ab，后缀子串为c、bc，这里bc就不是最长可匹配后缀子串了呀，而且abc的最长可匹配后缀子串长度应该为0，不是吗
作者回复: 你理解错了。这里说的最长可匹配后缀子串是：其他模式串可以匹配到abc的最长后缀子串。并不是abc自己的后缀子串匹配自己。

2019-04-11


1

文祥
之前没看代码，一直在想到底怎么一层一层的给失败指针赋值，想破头也想不到。这一手linkedlist用也太巧妙了吧，保证了一层一层，从左到右给失败指针赋值，感动的我都哭了。
2019-03-20


1

闫飞
可以讲讲自动机的概念吧，否则总有些感觉突兀
作者回复: 么机会了。专栏已经更新完了。不过，你的问题我记下来了，我会更新到我的公众号里，你可以关注我的公众号：“小争哥”

2019-01-17


1

zixuan
这是不是就是Double Array Trie (DATrie)？之前一直看不太理解，感谢老师解惑。
For More: https://linux.thai.net/~thep/datrie/
2018-12-14


1

吴宇晨
请教下老师，第三幅图，如果把d换成e，那pc的失败指针是不是要指向root了，但是和之前说的只会指向上一层节点不一样啊，希望老师解答下
作者回复: 不是指向上一层 而是上层 上几层都有哦可能

2018-12-14


1

野猪佩奇
AC自动机在某个字符的匹配的过程就好像俄罗斯方块一样，都是在前人的基础上去寻找自己的匹配模式串。底下随着主串参与匹配的字符越来越多，而越来越水涨船高（匹配到的模式串越来越长），突然来一根棍子，往缝隙中一插（代表主串某个字符在前人的基础上不匹配模式串后面的子节点了），就砍掉模式串底下一截，也就是使用模式串的一部分后缀再去尝试匹配，再没找到就再砍（这个砍的过程就是根据fail指针重新找模式串的过程）。然后随着后头又来字符，又慢慢水涨船高。如果棍子太给力，一下子消掉了所有的砖块，就要从头开始了，头就是root
2019-09-06


收起评论

5399+






# 37 | 贪心算法：如何用贪心算法实现Huffman压缩编码？




数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



37 | 贪心算法：如何用贪心算法实现Huffman压缩编码？
王争 2018-12-17



15:40
讲述：修阳 大小：14.36M
基础的数据结构和算法我们基本上学完了，接下来几节，我会讲几种更加基本的算法。它们分别是贪心算法、分治算法、回溯算法、动态规划。更加确切地说，它们应该是算法思想，并不是具体的算法，常用来指导我们设计具体的算法和编码等。

贪心、分治、回溯、动态规划这 4 个算法思想，原理解释起来都很简单，但是要真正掌握且灵活应用，并不是件容易的事情。所以，接下来的这 4 个算法思想的讲解，我依旧不会长篇大论地去讲理论，而是结合具体的问题，让你自己感受这些算法是怎么工作的，是如何解决问题的，带你在问题中体会这些算法的本质。我觉得，这比单纯记忆原理和定义要更有价值。

今天，我们先来学习一下贪心算法（greedy algorithm）。贪心算法有很多经典的应用，比如霍夫曼编码（Huffman Coding）、Prim 和 Kruskal 最小生成树算法、还有 Dijkstra 单源最短路径算法。最小生成树算法和最短路径算法我们后面会讲到，所以我们今天讲下霍夫曼编码，看看它是如何利用贪心算法来实现对数据压缩编码，有效节省数据存储空间的。

如何理解“贪心算法”？
关于贪心算法，我们先看一个例子。

假设我们有一个可以容纳 100kg 物品的背包，可以装各种物品。我们有以下 5 种豆子，每种豆子的总量和总价值都各不相同。为了让背包中所装物品的总价值最大，我们如何选择在背包中装哪些豆子？每种豆子又该装多少呢？



实际上，这个问题很简单，我估计你一下子就能想出来，没错，我们只要先算一算每个物品的单价，按照单价由高到低依次来装就好了。单价从高到低排列，依次是：黑豆、绿豆、红豆、青豆、黄豆，所以，我们可以往背包里装 20kg 黑豆、30kg 绿豆、50kg 红豆。

这个问题的解决思路显而易见，它本质上借助的就是贪心算法。结合这个例子，我总结一下贪心算法解决问题的步骤，我们一起来看看。

第一步，当我们看到这类问题的时候，首先要联想到贪心算法：针对一组数据，我们定义了限制值和期望值，希望从中选出几个数据，在满足限制值的情况下，期望值最大。

类比到刚刚的例子，限制值就是重量不能超过 100kg，期望值就是物品的总价值。这组数据就是 5 种豆子。我们从中选出一部分，满足重量不超过 100kg，并且总价值最大。

第二步，我们尝试看下这个问题是否可以用贪心算法解决：每次选择当前情况下，在对限制值同等贡献量的情况下，对期望值贡献最大的数据。

类比到刚刚的例子，我们每次都从剩下的豆子里面，选择单价最高的，也就是重量相同的情况下，对价值贡献最大的豆子。

第三步，我们举几个例子看下贪心算法产生的结果是否是最优的。大部分情况下，举几个例子验证一下就可以了。严格地证明贪心算法的正确性，是非常复杂的，需要涉及比较多的数学推理。而且，从实践的角度来说，大部分能用贪心算法解决的问题，贪心算法的正确性都是显而易见的，也不需要严格的数学推导证明。

实际上，用贪心算法解决问题的思路，并不总能给出最优解。

我来举一个例子。在一个有权图中，我们从顶点 S 开始，找一条到顶点 T 的最短路径（路径中边的权值和最小）。贪心算法的解决思路是，每次都选择一条跟当前顶点相连的权最小的边，直到找到顶点 T。按照这种思路，我们求出的最短路径是 S->A->E->T，路径长度是 1+4+4=9。



但是，这种贪心的选择方式，最终求的路径并不是最短路径，因为路径 S->B->D->T 才是最短路径，因为这条路径的长度是 2+2+2=6。为什么贪心算法在这个问题上不工作了呢？

在这个问题上，贪心算法不工作的主要原因是，前面的选择，会影响后面的选择。如果我们第一步从顶点 S 走到顶点 A，那接下来面对的顶点和边，跟第一步从顶点 S 走到顶点 B，是完全不同的。所以，即便我们第一步选择最优的走法（边最短），但有可能因为这一步选择，导致后面每一步的选择都很糟糕，最终也就无缘全局最优解了。

贪心算法实战分析
对于贪心算法，你是不是还有点懵？如果死抠理论的话，确实很难理解透彻。掌握贪心算法的关键是多练习。只要多练习几道题，自然就有感觉了。所以，我带着你分析几个具体的例子，帮助你深入理解贪心算法。

1. 分糖果
我们有 m 个糖果和 n 个孩子。我们现在要把糖果分给这些孩子吃，但是糖果少，孩子多（m<n），所以糖果只能分配给一部分孩子。

每个糖果的大小不等，这 m 个糖果的大小分别是 s1，s2，s3，……，sm。除此之外，每个孩子对糖果大小的需求也是不一样的，只有糖果的大小大于等于孩子的对糖果大小的需求的时候，孩子才得到满足。假设这 n 个孩子对糖果大小的需求分别是 g1，g2，g3，……，gn。

我的问题是，如何分配糖果，能尽可能满足最多数量的孩子？

我们可以把这个问题抽象成，从 n 个孩子中，抽取一部分孩子分配糖果，让满足的孩子的个数（期望值）是最大的。这个问题的限制值就是糖果个数 m。

我们现在来看看如何用贪心算法来解决。对于一个孩子来说，如果小的糖果可以满足，我们就没必要用更大的糖果，这样更大的就可以留给其他对糖果大小需求更大的孩子。另一方面，对糖果大小需求小的孩子更容易被满足，所以，我们可以从需求小的孩子开始分配糖果。因为满足一个需求大的孩子跟满足一个需求小的孩子，对我们期望值的贡献是一样的。

我们每次从剩下的孩子中，找出对糖果大小需求最小的，然后发给他剩下的糖果中能满足他的最小的糖果，这样得到的分配方案，也就是满足的孩子个数最多的方案。

2. 钱币找零
这个问题在我们的日常生活中更加普遍。假设我们有 1 元、2 元、5 元、10 元、20 元、50 元、100 元这些面额的纸币，它们的张数分别是 c1、c2、c5、c10、c20、c50、c100。我们现在要用这些钱来支付 K 元，最少要用多少张纸币呢？

在生活中，我们肯定是先用面值最大的来支付，如果不够，就继续用更小一点面值的，以此类推，最后剩下的用 1 元来补齐。

在贡献相同期望值（纸币数目）的情况下，我们希望多贡献点金额，这样就可以让纸币数更少，这就是一种贪心算法的解决思路。直觉告诉我们，这种处理方法就是最好的。实际上，要严谨地证明这种贪心算法的正确性，需要比较复杂的、有技巧的数学推导，我不建议你花太多时间在上面，不过如果感兴趣的话，可以自己去研究下。

3. 区间覆盖
假设我们有 n 个区间，区间的起始端点和结束端点分别是 [l1, r1]，[l2, r2]，[l3, r3]，……，[ln, rn]。我们从这 n 个区间中选出一部分区间，这部分区间满足两两不相交（端点相交的情况不算相交），最多能选出多少个区间呢？



这个问题的处理思路稍微不是那么好懂，不过，我建议你最好能弄懂，因为这个处理思想在很多贪心算法问题中都有用到，比如任务调度、教师排课等等问题。

这个问题的解决思路是这样的：我们假设这 n 个区间中最左端点是 lmin，最右端点是 rmax。这个问题就相当于，我们选择几个不相交的区间，从左到右将 [lmin, rmax] 覆盖上。我们按照起始端点从小到大的顺序对这 n 个区间排序。

我们每次选择的时候，左端点跟前面的已经覆盖的区间不重合的，右端点又尽量小的，这样可以让剩下的未覆盖区间尽可能的大，就可以放置更多的区间。这实际上就是一种贪心的选择方法。



解答开篇
今天的内容就讲完了，我们现在来看开篇的问题，如何用贪心算法实现霍夫曼编码？

假设我有一个包含 1000 个字符的文件，每个字符占 1 个 byte（1byte=8bits），存储这 1000 个字符就一共需要 8000bits，那有没有更加节省空间的存储方式呢？

假设我们通过统计分析发现，这 1000 个字符中只包含 6 种不同字符，假设它们分别是 a、b、c、d、e、f。而 3 个二进制位（bit）就可以表示 8 个不同的字符，所以，为了尽量减少存储空间，每个字符我们用 3 个二进制位来表示。那存储这 1000 个字符只需要 3000bits 就可以了，比原来的存储方式节省了很多空间。不过，还有没有更加节省空间的存储方式呢？

a(000)、b(001)、c(010)、d(011)、e(100)、f(101)
霍夫曼编码就要登场了。霍夫曼编码是一种十分有效的编码方法，广泛用于数据压缩中，其压缩率通常在 20%～90% 之间。

霍夫曼编码不仅会考察文本中有多少个不同字符，还会考察每个字符出现的频率，根据频率的不同，选择不同长度的编码。霍夫曼编码试图用这种不等长的编码方法，来进一步增加压缩的效率。如何给不同频率的字符选择不同长度的编码呢？根据贪心的思想，我们可以把出现频率比较多的字符，用稍微短一些的编码；出现频率比较少的字符，用稍微长一些的编码。

对于等长的编码来说，我们解压缩起来很简单。比如刚才那个例子中，我们用 3 个 bit 表示一个字符。在解压缩的时候，我们每次从文本中读取 3 位二进制码，然后翻译成对应的字符。但是，霍夫曼编码是不等长的，每次应该读取 1 位还是 2 位、3 位等等来解压缩呢？这个问题就导致霍夫曼编码解压缩起来比较复杂。为了避免解压缩过程中的歧义，霍夫曼编码要求各个字符的编码之间，不会出现某个编码是另一个编码前缀的情况。



假设这 6 个字符出现的频率从高到低依次是 a、b、c、d、e、f。我们把它们编码下面这个样子，任何一个字符的编码都不是另一个的前缀，在解压缩的时候，我们每次会读取尽可能长的可解压的二进制串，所以在解压缩的时候也不会歧义。经过这种编码压缩之后，这 1000 个字符只需要 2100bits 就可以了。



尽管霍夫曼编码的思想并不难理解，但是如何根据字符出现频率的不同，给不同的字符进行不同长度的编码呢？这里的处理稍微有些技巧。

我们把每个字符看作一个节点，并且辅带着把频率放到优先级队列中。我们从队列中取出频率最小的两个节点 A、B，然后新建一个节点 C，把频率设置为两个节点的频率之和，并把这个新节点 C 作为节点 A、B 的父节点。最后再把 C 节点放入到优先级队列中。重复这个过程，直到队列中没有数据。



现在，我们给每一条边加上画一个权值，指向左子节点的边我们统统标记为 0，指向右子节点的边，我们统统标记为 1，那从根节点到叶节点的路径就是叶节点对应字符的霍夫曼编码。



内容小结
今天我们学习了贪心算法。

实际上，贪心算法适用的场景比较有限。这种算法思想更多的是指导设计基础算法。比如最小生成树算法、单源最短路径算法，这些算法都用到了贪心算法。从我个人的学习经验来讲，不要刻意去记忆贪心算法的原理，多练习才是最有效的学习方法。

贪心算法的最难的一块是如何将要解决的问题抽象成贪心算法模型，只要这一步搞定之后，贪心算法的编码一般都很简单。贪心算法解决问题的正确性虽然很多时候都看起来是显而易见的，但是要严谨地证明算法能够得到最优解，并不是件容易的事。所以，很多时候，我们只需要多举几个例子，看一下贪心算法的解决方案是否真的能得到最优解就可以了。

课后思考
在一个非负整数 a 中，我们希望从中移除 k 个数字，让剩下的数字值最小，如何选择移除哪 k 个数字呢？

假设有 n 个人等待被服务，但是服务窗口只有一个，每个人需要被服务的时间长度是不同的，如何安排被服务的先后顺序，才能让这 n 个人总的等待时间最短？

欢迎留言和我分享，也欢迎点击“请朋友读”，把今天的内容分享给你的好友，和他一起讨论、学习。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(100)

cirno
1、由最高位开始，比较低一位数字，如高位大，移除，若高位小，则向右移一位继续比较两个数字，直到高位大于低位则移除，循环k次，如：
4556847594546移除5位-》455647594546-》45547594546-》4547594546-》4447594546-》444594546

2、由等待时间最短的开始服务
2018-12-17

2

117

开心小毛
找零问题不能用贪婪算法，即使有面值为一元的币值也不行：考虑币值为100，99和1的币种，每种各一百张，找396元。
 动态规划可求出四张99元，但贪心算法解出需三张一百和96张一元。
作者回复: 是的 👍

2018-12-31

2

56

Alexis何春光
留言里feifei说的两种解决思路都是错的，给的链接也失效了.... 老师可以回复一下防止误导后来的同学呀！
以及没有看出来霍夫曼算法和贪心算法有什么联系，求详细讲解
2019-01-12

2

25

Jalyn
想知道目前没掉队的有多少 哈哈
作者回复: 慢慢学 不着急😄

2018-12-17

1

23

feifei
1，在一个非负整数 a 中，我们希望从中移除 k 个数字，让剩下的数字值最小，如何选择移除哪 k 个数字呢？
对于此题，我的求解思路是每次选择数据的最高位的数据值进行移除，这样我们每次选择的移除的数值都是最大的，剩下的数值也是最小的。
比如，数据5892，将数据拆成5000,800,90,2，然后使用大顶堆来进行存储，然后每次移除大顶堆中堆顶最大的元素。

2，假设有 n 个人等待被服务，但是服务窗口只有一个，每个人需要被服务的时间长度是不同的，如何安排被服务的先后顺序，才能让这 n 个人总的等待时间最短？
对于此问题，我的求解思路是让待时间最长的来安排先后顺序
比如，现在有3个人，a、b、c,a等待了10分钟，b待待了20分钟，c待待了30分钟
同样使用大顶堆来进行存储等待时间，堆顶的元素就是当前等待时间最长的人
然后每次从堆拿出堆顶元素的人来进行服务，这样就可以让这n个人的总的等待时间最短。




对于学习的贪心算法，老师虽然只进行了理论讲解，但我看完了老师所讲的，我对贪心算法的理解有了一定的认识，我就试着把贪心算法的内容中涉及的东西，都翻译成了代码，
感觉收获良多，也把这个分享给童鞋，希望对他们有帮助。
1，这是第一个示例，背包中豆子的最大价值的问题
https://github.com/kkzfl22/datastruct/tree/master/src/main/java/com/liujun/algorithm/greedyAlgorithm/case1
2，这是孩子分糖果的问题
https://github.com/kkzfl22/datastruct/tree/master/src/main/java/com/liujun/algorithm/greedyAlgorithm/case2
3，这是钱币支付的问题
https://github.com/kkzfl22/datastruct/tree/master/src/main/java/com/liujun/algorithm/greedyAlgorithm/case3
4，这是区间覆盖的问题
https://github.com/kkzfl22/datastruct/tree/master/src/main/java/com/liujun/algorithm/greedyAlgorithm/case4
5，这是霍夫漫编码的实现
https://github.com/kkzfl22/datastruct/tree/master/src/main/java/com/liujun/algorithm/greedyAlgorithm/huffman

欢迎大家与我交流，也欢迎老师给我指正，谢谢
2018-12-20

6

18

qinggeouye
1、在一个非负整数 a 中，希望从中移除 k 个数字，让剩下的数字值最小，如何选择移除哪 k 个数字呢？

整数 a，由若干位数字组成，移除 k 个数字后的值最小。从高位开始移除：移除高位数字比它低位数字大的那个；K 次循环。

也可以用 Top K 排序，求出 K 个最大的数字，移除。

2、假设有 n 个人等待被服务，但是窗口只有一个，每个需要被服务的时间长度是不同的，如何安排被服务的先后顺序，才能让这 n 个人总的等待时间最短？

每个人需要被服务的时间不一样，但所有人加起来总的被服务时间是固定的。

题意是求 n 个人总的等待时间，每个人在被服务之前，所经过的等待时间是不同的。

而当前被服务的人所需的服务时间，会累加到剩下的那些等待被服务人的等待时间上。

要使 n 个人总的等待时间最短，那么每次安排服务时间最短的那个人被服务：堆排序（小顶堆）。


另外，@Alexis何春光 的留言，第一句话表示赞同。
2019-01-19


12

luxinfeng
老师能详细讲讲区间覆盖这个问题的选择过程么？
2018-12-17


11

🐱您的好友William🐱
给大家提个醒，货币找零问题如果没有C1货币的话得用动态规划去解，如果出现{C2，C7，C10}货币找零11块的时候使用greedy就会出现找不开的情况。。。。有C1就不会出现找不开的情况且多个C1可以构成任何面值，所以这种情况下使用greedy是对的！（leetcode322题调了一下午的路过。。。）
2018-12-17


8

www.xnsms.com小鸟接码
霍夫曼编码，用一个树来避免某个字符的编码是另一个字符编码的前缀，真的是好巧妙
2019-01-06


6

睡痴儿😑
第一个题，可以反着来想。给定另一个数组，怎么从中原本的中挑出n-k个，使其值最小。
首先第一位必须要是最小的一个，但是因为有顺序，所以只能是从0到n-1-k个中挑一个最小的，下标为m。以后依次类推，从m到n-k中挑一个最小的。如果有相等的情况，以下标小的为准。
第二个，就是从小到大排序即可。
2019-01-22


5

Jerry银银
打个卡，我还在
2018-12-19


5

小美
老师 区间覆盖的问题， (1-5) 和 (2-4) 中为什么选(2-4) 方便老师解释下吗， 贪心不能全局最优 用贪心 如何在这个问题上全局最优呢
作者回复: 24让剩下的没有被覆盖的区间最大 如果你选15 那我完全可以用24替代15 这样子 只有更好 不会更差

2018-12-17


5

bingo
@吴：wiki上的哈夫曼树是标准的生成步骤，老师这里举的例子是一种特殊情况，哈夫曼树构建的一般性方法在本科的教程上就写的很通俗了。
我用wiki里的值举个例子吧：原始集合的值是[2,3,4,4,5,7]
第一步：从原始集合中取出最小的两个值并将这两个值从原始集合中剔除，这两个最小的值相加得到一个新的值并加入原始集合，这两个小值作为这个新值的树叶，新值当然就是树根了。这一步执行之后原始集合就变成了这样：
       [ ⑤, 4,4,5,7]
/ \
      2 3

第二步：从更新后的集合中再取最小的两个值并剔除，同样相加得到新值加入到集合。这一步执行之后集合就变成了
       [⑤, ⑧ ,5,7]
/ \ /\
      2 3 4 4

第三步，重复以上步骤，你懂得。结果是：
       [ ⑩, ⑧, 7]
/ \ / \
        5 ⑤ 4 4
/ \
2 3
第四步，结果是：
       [ ⑩, 15,]
/ \ / \
      5 ⑤ 7 ⑧
/\ / \
2 3 4 4
最后一步，结果是：
               (25) (打不出圆圈了，用这个代替，应该不难理解，嗯)
              / \
         ⑩ 15
/ \ / \
      5 ⑤ 7 ⑧
/\ / \
2 3 4 4

wiki哈夫曼树链接：https://zh.wikipedia.org/wiki/%E9%9C%8D%E5%A4%AB%E6%9B%BC%E7%BC%96%E7%A0%81
ps:大半夜手打，排版扎心
作者回复: 👍啊 就喜欢你这么极致的人！

2019-02-22


3

白若
思考题(自己的想法，不知道对不对，希望老师能给我评论。)

1.从前往后两两比较，若前数大于等于后数，选择移除。如果一轮下来没达到k个数，就移除最后的m个数，m为k-已选出个数。
2.时间越短位置越靠前。
2018-12-17


3

蒋礼锐
第一个问题不知道0可不可以被保留在最高位，如果可以的话那么应该每次移除该整数的非零最高位，比如909090，k为2的话，最小的值应该是0090，如果0不能在最高位，就贪心算法就不能得到最优解了，跟之前的加权图一样，因为决策会相互影响。

第二个问题假设5个人，时间分别是1-5-3-4-2分钟，等待的时间是每个人等待时间的总和即单个服务时间*剩余等待人数。不管现在服务的是谁，剩余等待的人数是不会变的，所以只需要找单个服务时间最小的，即按服务时间数升序服务即1-2-3-4-5，总的时间为1*4+2*3+3*2+4*1=20

就像春运取票，你如果是去取售票机上买票的话，后面排队着急的人会说，让我先取吧，我直接取很快。这样集体时间效率最高，但是对单个个体来说就不一定了，比如之前那个要买票的。
2018-12-17


3

coder
区间覆盖问题，把区间按照结束时刻排序，每次选择最早结束且没有冲突的区间即可
2019-04-15


2

乐凡
老师，我觉得那个霍夫曼编码可能有点缺陷，就是不同字符在字符串中出现的频率很接近，那如果还是按照给每个字符用不同长度的二进制码表示，很有可能会比前面用相同二进制码表示耗费的空间多（亲自测过）。我觉得每一个字符在字符串中出现的频率需要满足一定的大小差距，这样使用空间才会比使用相同数量的二进制码更少。这个大小差距点的公式不太好算，笨一点的办法就是用两种方式比较下占用空间大小。
作者回复: 给个你的测试用例我看看

2019-03-21


2

发飙的蜗牛
个人觉得分糖果不能使用贪心算法，如果使用可以加个条件一个孩子只能分一个糖果，因为可能存在孩子的满意度大于最小的糖果，但是最小的两个的和刚好满足。这个情况贪心就无法满足了。
作者回复: 哈哈，你很细心，是的，一个孩子最多一个糖果

2019-02-28


2

CathyLin
课后思考：
1. 第一道题一开始没有想到...以为直接删除最大的那 k 个数字就好了，后来举了几个样例发现是错的。然后看了评论区小伙伴们的留言，太奇妙了！！！我是真的没有想到这种思路😫
1) 从高位往低位走，删掉高位比低位大的数；为什么这样子是好的呢？试想:
4596743 如果我们只能删一位，我们会删第三位的 9，因为这样就相当于是把高位给减少了，变成了456743，但是如果删 6，变成了 459743 则没有之前那个优。删后面的数更起不到高位的那种作用。
2) 如果所有数字都是递增的，那么我们删除倒数
k 个数字就好了。

2. 想让所有人的等待时间最短，那么我们得先处理服务时间短的，尽快把他们处理完了才能够处理后面的人！

贪心反思：有些时候思路还是难以打开，可能还是跟老师说的那样，多练习、多积累才是最好的学习方法！
2019-07-31


1

天，很蓝 ～
如果文档中只有4个字符，分别是a，b，c，d出现的频率相等，都是100次。如果用00，01，10，11分别表示a，b，c，d的话，总共需要800bit就可以了。但是如果用霍夫曼编码的话，用1，01，001，000分别表示a，b，c，d的话反而需要900bit。这个是不是说明霍夫曼编码有时候是起不到压缩作用的？望老师解答
作者回复: 用霍夫曼编码也是00、01、10、11的，你再看下霍夫曼编码的原理吧

2019-06-20

1

1
收起评论

99+99+






# 38 | 分治算法：谈一谈大规模计算框架MapReduce中的分治思想




数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



38 | 分治算法：谈一谈大规模计算框架MapReduce中的分治思想
王争 2018-12-19



11:47
讲述：修阳 大小：10.80M
MapReduce 是 Google 大数据处理的三驾马车之一，另外两个是 GFS 和 Bigtable。它在倒排索引、PageRank 计算、网页分析等搜索引擎相关的技术中都有大量的应用。

尽管开发一个 MapReduce 看起来很高深，感觉跟我们遥不可及。实际上，万变不离其宗，它的本质就是我们今天要学的这种算法思想，分治算法。

如何理解分治算法？
为什么说 MapRedue 的本质就是分治算法呢？我们先来看，什么是分治算法？

分治算法（divide and conquer）的核心思想其实就是四个字，分而治之 ，也就是将原问题划分成 n 个规模较小，并且结构与原问题相似的子问题，递归地解决这些子问题，然后再合并其结果，就得到原问题的解。

这个定义看起来有点类似递归的定义。关于分治和递归的区别，我们在排序（下）的时候讲过，分治算法是一种处理问题的思想，递归是一种编程技巧。实际上，分治算法一般都比较适合用递归来实现。分治算法的递归实现中，每一层递归都会涉及这样三个操作：

分解：将原问题分解成一系列子问题；

解决：递归地求解各个子问题，若子问题足够小，则直接求解；

合并：将子问题的结果合并成原问题。

分治算法能解决的问题，一般需要满足下面这几个条件：

原问题与分解成的小问题具有相同的模式；

原问题分解成的子问题可以独立求解，子问题之间没有相关性，这一点是分治算法跟动态规划的明显区别，等我们讲到动态规划的时候，会详细对比这两种算法；

具有分解终止条件，也就是说，当问题足够小时，可以直接求解；

可以将子问题合并成原问题，而这个合并操作的复杂度不能太高，否则就起不到减小算法总体复杂度的效果了。

分治算法应用举例分析
理解分治算法的原理并不难，但是要想灵活应用并不容易。所以，接下来，我会带你用分治算法解决我们在讲排序的时候涉及的一个问题，加深你对分治算法的理解。

还记得我们在排序算法里讲的数据的有序度、逆序度的概念吗？我当时讲到，我们用有序度来表示一组数据的有序程度，用逆序度表示一组数据的无序程度。

假设我们有 n 个数据，我们期望数据从小到大排列，那完全有序的数据的有序度就是 n(n-1)/2，逆序度等于 0；相反，倒序排列的数据的有序度就是 0，逆序度是 n(n-1)/2。除了这两种极端情况外，我们通过计算有序对或者逆序对的个数，来表示数据的有序度或逆序度。



我现在的问题是，如何编程求出一组数据的有序对个数或者逆序对个数呢？因为有序对个数和逆序对个数的求解方式是类似的，所以你可以只思考逆序对个数的求解方法。

最笨的方法是，拿每个数字跟它后面的数字比较，看有几个比它小的。我们把比它小的数字个数记作 k，通过这样的方式，把每个数字都考察一遍之后，然后对每个数字对应的 k 值求和，最后得到的总和就是逆序对个数。不过，这样操作的时间复杂度是 O(n^2)。那有没有更加高效的处理方法呢？

我们用分治算法来试试。我们套用分治的思想来求数组 A 的逆序对个数。我们可以将数组分成前后两半 A1 和 A2，分别计算 A1 和 A2 的逆序对个数 K1 和 K2，然后再计算 A1 与 A2 之间的逆序对个数 K3。那数组 A 的逆序对个数就等于 K1+K2+K3。

我们前面讲过，使用分治算法其中一个要求是，子问题合并的代价不能太大，否则就起不了降低时间复杂度的效果了。那回到这个问题，如何快速计算出两个子问题 A1 与 A2 之间的逆序对个数呢？

这里就要借助归并排序算法了。你可以先试着想想，如何借助归并排序算法来解决呢？

归并排序中有一个非常关键的操作，就是将两个有序的小数组，合并成一个有序的数组。实际上，在这个合并的过程中，我们就可以计算这两个小数组的逆序对个数了。每次合并操作，我们都计算逆序对个数，把这些计算出来的逆序对个数求和，就是这个数组的逆序对个数了。



尽管我画了张图来解释，但是我个人觉得，对于工程师来说，看代码肯定更好理解一些，所以我们把这个过程翻译成了代码，你可以结合着图和文字描述一起看下。

private int num = 0; // 全局变量或者成员变量
 
public int count(int[] a, int n) {
  num = 0;
  mergeSortCounting(a, 0, n-1);
  return num;
}
 
private void mergeSortCounting(int[] a, int p, int r) {
  if (p >= r) return;
  int q = (p+r)/2;
  mergeSortCounting(a, p, q);
  mergeSortCounting(a, q+1, r);
  merge(a, p, q, r);
}
 
private void merge(int[] a, int p, int q, int r) {
  int i = p, j = q+1, k = 0;
  int[] tmp = new int[r-p+1];
  while (i<=q && j<=r) {
    if (a[i] <= a[j]) {
      tmp[k++] = a[i++];
    } else {
      num += (q-i+1); // 统计 p-q 之间，比 a[j] 大的元素个数
      tmp[k++] = a[j++];
    }
  }
  while (i <= q) { // 处理剩下的
    tmp[k++] = a[i++];
  }
  while (j <= r) { // 处理剩下的
    tmp[k++] = a[j++];
  }
  for (i = 0; i <= r-p; ++i) { // 从 tmp 拷贝回 a
    a[p+i] = tmp[i];
  }
}
有很多同学经常说，某某算法思想如此巧妙，我是怎么也想不到的。实际上，确实是的。有些算法确实非常巧妙，并不是每个人短时间都能想到的。比如这个问题，并不是每个人都能想到可以借助归并排序算法来解决，不夸张地说，如果之前没接触过，绝大部分人都想不到。但是，如果我告诉你可以借助归并排序算法来解决，那你就应该要想到如何改造归并排序，来求解这个问题了，只要你能做到这一点，我觉得就很棒了。

关于分治算法，我这还有两道比较经典的问题，你可以自己练习一下。

二维平面上有 n 个点，如何快速计算出两个距离最近的点对？

有两个 n*n 的矩阵 A，B，如何快速求解两个矩阵的乘积 C=A*B？

分治思想在海量数据处理中的应用
分治算法思想的应用是非常广泛的，并不仅限于指导编程和算法设计。它还经常用在海量数据处理的场景中。我们前面讲的数据结构和算法，大部分都是基于内存存储和单机处理。但是，如果要处理的数据量非常大，没法一次性放到内存中，这个时候，这些数据结构和算法就无法工作了。

比如，给 10GB 的订单文件按照金额排序这样一个需求，看似是一个简单的排序问题，但是因为数据量大，有 10GB，而我们的机器的内存可能只有 2、3GB 这样子，无法一次性加载到内存，也就无法通过单纯地使用快排、归并等基础算法来解决了。

要解决这种数据量大到内存装不下的问题，我们就可以利用分治的思想。我们可以将海量的数据集合根据某种方法，划分为几个小的数据集合，每个小的数据集合单独加载到内存来解决，然后再将小数据集合合并成大数据集合。实际上，利用这种分治的处理思路，不仅仅能克服内存的限制，还能利用多线程或者多机处理，加快处理的速度。

比如刚刚举的那个例子，给 10GB 的订单排序，我们就可以先扫描一遍订单，根据订单的金额，将 10GB 的文件划分为几个金额区间。比如订单金额为 1 到 100 元的放到一个小文件，101 到 200 之间的放到另一个文件，以此类推。这样每个小文件都可以单独加载到内存排序，最后将这些有序的小文件合并，就是最终有序的 10GB 订单数据了。

如果订单数据存储在类似 GFS 这样的分布式系统上，当 10GB 的订单被划分成多个小文件的时候，每个文件可以并行加载到多台机器上处理，最后再将结果合并在一起，这样并行处理的速度也加快了很多。不过，这里有一个点要注意，就是数据的存储与计算所在的机器是同一个或者在网络中靠的很近（比如一个局域网内，数据存取速度很快），否则就会因为数据访问的速度，导致整个处理过程不但不会变快，反而有可能变慢。

你可能还有印象，这个就是我在讲线性排序的时候举的例子。实际上，在前面已经学习的课程中，我还讲了很多利用分治思想来解决的问题。

解答开篇
分治算法到此就讲完了，我们现在来看下开篇的问题，为什么说 MapReduce 的本质就是分治思想？

我们刚刚举的订单的例子，数据有 10GB 大小，可能给你的感受还不强烈。那如果我们要处理的数据是 1T、10T、100T 这样子的，那一台机器处理的效率肯定是非常低的。而对于谷歌搜索引擎来说，网页爬取、清洗、分析、分词、计算权重、倒排索引等等各个环节中，都会面对如此海量的数据（比如网页）。所以，利用集群并行处理显然是大势所趋。

一台机器过于低效，那我们就把任务拆分到多台机器上来处理。如果拆分之后的小任务之间互不干扰，独立计算，最后再将结果合并。这不就是分治思想吗？

实际上，MapReduce 框架只是一个任务调度器，底层依赖 GFS 来存储数据，依赖 Borg 管理机器。它从 GFS 中拿数据，交给 Borg 中的机器执行，并且时刻监控机器执行的进度，一旦出现机器宕机、进度卡壳等，就重新从 Borg 中调度一台机器执行。

尽管 MapReduce 的模型非常简单，但是在 Google 内部应用非常广泛。它除了可以用来处理这种数据与数据之间存在关系的任务，比如 MapReduce 的经典例子，统计文件中单词出现的频率。除此之外，它还可以用来处理数据与数据之间没有关系的任务，比如对网页分析、分词等，每个网页可以独立的分析、分词，而这两个网页之间并没有关系。网页几十亿、上百亿，如果单机处理，效率低下，我们就可以利用 MapReduce 提供的高可靠、高性能、高容错的并行计算框架，并行地处理这几十亿、上百亿的网页。

内容小结
今天我们讲了一种应用非常广泛的算法思想，分治算法。

分治算法用四个字概括就是“分而治之”，将原问题划分成 n 个规模较小而结构与原问题相似的子问题，递归地解决这些子问题，然后再合并其结果，就得到原问题的解。这个思想非常简单、好理解。

今天我们讲了两种分治算法的典型的应用场景，一个是用来指导编码，降低问题求解的时间复杂度，另一个是解决海量数据处理问题。比如 MapReduce 本质上就是利用了分治思想。

我们也时常感叹 Google 的创新能力如此之强，总是在引领技术的发展。实际上，创新并非离我们很远，创新的源泉来自对事物本质的认识。无数优秀架构设计的思想来源都是基础的数据结构和算法，这本身就是算法的一个魅力所在。

课后思考
我们前面讲过的数据结构、算法、解决思路，以及举的例子中，有哪些采用了分治算法的思想呢？除此之外，生活、工作中，还有没有其他用到分治算法的地方呢？你可以自己回忆、总结一下，这对你将零散的知识提炼成体系非常有帮助。

欢迎留言和我分享，也欢迎点击“请朋友读”，把今天的内容分享给你的好友，和他一起讨论、学习。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(54)

Williamzhang 置顶
第一个留言有问题可以再理解一下，不要误导后边人，作者的num+=语句位置正确
作者回复: 哈哈 终于有人看懂了 我的跟留言那位同学的思路不一样而已 他的更简洁些

2018-12-20


11

三木子
在统计方面比较多，比如统计我国人口，要知道我国人口就要先知道每个省人口，要知道省人口就要知道每个市人口，要知道市人口就要知道每个区县人口，直到村社区，然后汇总求的总人数。
作者回复: 👍

2018-12-19


21

Jiemr
老师，我有两个疑问：
给 10GB 的订单排序，我们就可以先扫描一遍订单
-------------------------------------
1.场景中描述的机器内存只有2、3GB，我理解的是直接加载文件内存应该不够用来扫描一次10GB订单文件，对吗？如果不能，那应该怎么扫描呢？
2.如果用buffer来缓存扫描结果的话，即使能扫描完成，又该怎么对文件根据金额区间进行分割呢？
2019-01-11

2

18

MIAN-勉
把归并排序merge方法的参数列表 由merge(int[] a, int p, int q, int r) 改为 merge(int[] a, int low, int middle, int high) 更容易理解😂，小细节，哈哈
2018-12-27


16

刘远通
第一个求最近的点对
分成两块 单独求其中一块点对最小距离
然后求这两块之间点对的最小距离 通过一些排序和删除 可以减少到6个点之间比较 很神奇

第二个矩阵计算
v.斯特拉森提出了2*2分块矩阵的计算公式 从原来的8次乘法 缩减到了7次
当n规模很大的时候 缩减效果就很明显 （7/8）^(logn)
2018-12-20


11

Yves
代码略有问题：1，num += (q - i + 1)，应该是在 a[i] <= a[j] 这个条件分支里面；2，while (i <= q) 里面不应该有 num += (q - i + 1)，3，最后的修改原数组迭代条件应该是 i < r - p + 1 而不是 i < r - p 。

private void merge(int[] a, int p, int q, int r) {
        int i = p, j = q + 1, k = 0;
        int[] tmp = new int[r - p + 1];
        while (i <= q && j <= r) {
            if (a[i] <= a[j]) {
                tmp[k++] = a[i++];
            } else {
                num += (q - i + 1);
                tmp[k++] = a[j++];
            }
        }
        while (i <= q) {
            tmp[k++] = a[i++];
        }
        while (j <= r) {
            tmp[k++] = a[j++];
        }
        for (i = 0; i < r - p + 1; ++i) {
            a[p + i] = tmp[i];
        }
    }
作者回复: 是的 大家代码直接看这位同学的 我晚点改正下。写的时候匆忙 不好意思

2018-12-19


10

Smallfly
「创新并非离我们很远，创新的源泉来自对事物本质的认识。无数优秀架构设计的思想来源都是基础的数据结构和算法，这本身就是算法的一个魅力所在。」

这句话讲的太好啦。各种前端框架层出不穷，本质的东西，也是基本都没有变。

与其最新，不如求本。
2018-12-19


7

刘文坛
分治算法本质上就是利用多核cpu并行计算能力，如果只是单核cpu，分治算法是不是就不可行了？
作者回复: 不。单核也可以利用多线程并行。毕竟一般的算法代码都包括：内存访问、CPU计算两部分，并不只是CPU计算。

2019-02-02

1

3

ALAN
老师，你好，有一个建议，就是对于代码每一行里不是很显然易懂的地方，能否注释下此行代码的作用，不然有时看了代码也不知为啥这样写。
2018-12-19


3

不上进的码农
if (a[i] <= a[j]) {
      num += (j - q - 1);
      tmp[k++] = a[i++];
    } else {
      tmp[k++] = a[j++];
    }
我想了想，这段代码应该求的是有序对而不是逆序对吧
作者回复: 逆序对

2018-12-19


3

康斯坦丁
前面的数据结构与算法中： 归并排序、桶排序、快速排序使用了分治算法.
工作/生活中: 美国大选统计选票.
2019-07-02


2

h…
王争老师，我是后台开发，想换算法类工作，能不能给我点建议
作者回复: 算法现在很火啊 供不应求 如果年轻的话 并且愿意学习的话 转起来也不难 建议找几本书看看 多代码练习一下 入了门之后 先找个一般的公司干干 积累些项目经验 以此再去好点公司

2018-12-20


2

Sharry
使用归并排序求逆序度, 实在是太妙了! 老师的代码一点儿问题都没有, (j-q-1) 记录的是比子序列 A 中当前即将添加到 tmp 数组中的元素的逆序对的个数, 看到留言里小伙伴说应该放在下面的 else 里, 可能需要再斟酌斟酌
2018-12-20


2

🎸 风筝
老师，请问我做java但是不从事算法岗位，这门课需要学习到什么程度呢？总觉得心里有目标会更好点。
作者回复: 把比较基础的算法看懂就可以了，我后面有一篇文章分享关于新手如何循序渐进学习的，你可以看下。

2019-08-13


1

CathyLin
本来已经刷完了，但感觉没想明白怎样合并平面中两个距离最近的点对于是又网上查资料嗑了 2 个晚上。
发现通过数学公式的计算，对于左区间中的一个点，我们最多只需要比较右区间中 7 个点就可以了，所以也是相当于是 linear time。
然后通过 T(n) = 2*T(n/2) + O(n) 得到最后的时间复杂度是 O(NlogN)。
Ref: https://en.wikipedia.org/wiki/Closest_pair_of_points_problem

课后思考：深刻的理解到了递归就是实现分治的最好方法，例如我们在构建树的问题时，首先构建左子树，然后再构建右子树，最后把两个子树合并起来形成当前节点。
生活中：就像评论区所留言的那样，美国大选，先从镇开始，然后到州，最后在合并起来。

2019-08-06


1

未来的胡先森
公司的管理也是分治吧，先把大的任务分到各大部门，部门再划分任务到团队，团队划分到个人（达到能够独立求解），个人完成任务，到团体完成任务，到大任务完成即合并。
2019-08-02


1

Geek_54edc1
用快排也可以算逆序度，只要记录数据交换的次数就可以了
2019-05-23


1

wahaha
老师，求有(逆)序对只需一遍扫描即可，O(n)就能解决，所以用归并排序求解的这个例子并不太合适。
作者回复: 怎么搞定的呢？貌似不行吧

2019-04-26


1

涂
leetcode 315
2019-03-27


1

www.xnsms.com小鸟接码
归并排序忘记了，又跑头前面看一下，不然看不懂了……忘的好快……
2019-01-06


1
收起评论

5499+






# 不定期福利第三期 | 测一测你的算法阶段学习成果



数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



不定期福利第三期 | 测一测你的算法阶段学习成果
王争 2018-12-21



01:25
讲述：修阳 大小：1.32M
专栏最重要的基础篇马上就要讲完了，不知道你掌握了多少？我从前面的文章中挑选了一些案例，稍加修改，组成了一套测试题。

你先不要着急看答案，自己先想一想怎么解决，测一测自己对之前的知识掌握的程度。如果有哪里卡壳或者不怎么清楚的，可以回过头再复习一下。

正所谓温故知新，这种通过实际问题查缺补漏的学习方法，非常利于你巩固前面讲的知识点，你可要好好珍惜这次机会哦！

实战测试题（一）
假设猎聘网有 10 万名猎头顾问，每个猎头顾问都可以通过做任务（比如发布职位），来积累积分，然后通过积分来下载简历。假设你是猎聘网的一名工程师，如何在内存中存储这 10 万个猎头 ID 和积分信息，让它能够支持这样几个操作：

根据猎头的 ID 快速查找、删除、更新这个猎头的积分信息；

查找积分在某个区间的猎头 ID 列表；

查询积分从小到大排在第 x 位的猎头 ID 信息；

查找按照积分从小到大排名在第 x 位到第 y 位之间的猎头 ID 列表。

相关章节
17 | 跳表：为什么 Redis 一定要用跳表来实现有序集合？

20 | 散列表（下）：为什么散列表和链表经常会一起使用？

25 | 红黑树：为什么工程中都用红黑树这种二叉树？

题目解析
这个问题既要通过 ID 来查询，又要通过积分来查询，所以，对于猎头这样一个对象，我们需要将其组织成两种数据结构，才能支持这两类操作。

我们按照 ID，将猎头信息组织成散列表。这样，就可以根据 ID 信息快速的查找、删除、更新猎头的信息。我们按照积分，将猎头信息组织成跳表这种数据结构，按照积分来查找猎头信息，就非常高效，时间复杂度是 O(logn)。

我刚刚讲的是针对第一个、第二个操作的解决方案。第三个、第四个操作是类似的，按照排名来查询，这两个操作该如何实现呢？

我们可以对刚刚的跳表进行改造，每个索引结点中加入一个 span 字段，记录这个索引结点到下一个索引结点的包含的链表结点的个数。这样就可以利用跳表索引，快速计算出排名在某一位的猎头或者排名在某个区间的猎头列表。

实际上，这些就是 Redis 中有序集合这种数据类型的实现原理。在开发中，我们并不需要从零开始代码实现一个散列表和跳表，我们可以直接利用 Redis 的有序集合来完成。

实战测试题（二）
电商交易系统中，订单数据一般都会很大，我们一般都分库分表来存储。假设我们分了 10 个库并存储在不同的机器上，在不引入复杂的分库分表中间件的情况下，我们希望开发一个小的功能，能够快速地查询金额最大的前 K 个订单（K 是输入参数，可能是 1、10、1000、10000，假设最大不会超过 10 万）。如果你是这个功能的设计开发负责人，你会如何设计一个比较详细的、可以落地执行的设计方案呢？

为了方便你设计，我先交代一些必要的背景，在设计过程中，如果有其他需要明确的背景，你可以自行假设。

数据库中，订单表的金额字段上建有索引，我们可以通过 select order by limit 语句来获取数据库中的数据；

我们的机器的可用内存有限，比如只有几百 M 剩余可用内存。希望你的设计尽量节省内存，不要发生 Out of Memory Error。

相关章节
12 | 排序（下）：如何用快排思想在 O(n) 内查找第 K 大元素？

28 | 堆和堆排序：为什么说堆排序没有快速排序快？

29 | 堆的应用：如何快速获取到 Top 10 最热门的搜索关键词？

题目解析
解决这个题目的基本思路我想你应该能想到，就是借助归并排序中的合并函数，这个我们在排序（下）以及堆的应用那一节中讲过。

我们从每个数据库中，通过 select order by limit 语句，各取局部金额最大的订单，把取出来的 10 个订单放到优先级队列中，取出最大值（也就是大顶堆堆顶数据），就是全局金额最大的订单。然后再从这个全局金额最大订单对应的数据库中，取出下一条订单（按照订单金额从大到小排列的），然后放到优先级队列中。一直重复上面的过程，直到找到金额前 K（K 是用户输入的）大订单。

从算法的角度看起来，这个方案非常完美，但是，从实战的角度来说，这个方案并不高效，甚至很低效。因为我们忽略了，数据库读取数据的性能才是这个问题的性能瓶颈。所以，我们要尽量减少 SQL 请求，每次多取一些数据出来，那一次性取出多少才合适呢？这就比较灵活、比较有技巧了。一次性取太多，会导致数据量太大，SQL 执行很慢，还有可能触发超时，而且，我们题目中也说了，内存有限，太多的数据加载到内存中，还有可能导致 Out of Memory Error。

所以，一次性不能取太多数据，也不能取太少数据，到底是多少，还要根据实际的硬件环境做 benchmark 测试去找最合适的。

实战测试题（三）
我们知道，CPU 资源是有限的，任务的处理速度与线程个数并不是线性正相关。相反，过多的线程反而会导致 CPU 频繁切换，处理性能下降。所以，线程池的大小一般都是综合考虑要处理任务的特点和硬件环境，来事先设置的。

当我们向固定大小的线程池中请求一个线程时，如果线程池中没有空闲资源了，这个时候线程池如何处理这个请求？是拒绝请求还是排队请求？各种处理策略又是怎么实现的呢？

相关章节
09 | 队列：队列在线程池等有限资源池中的应用

题目解析
这个问题的答案涉及队列这种数据结构。队列可以应用在任何有限资源池中，用于排队请求，比如数据库连接池等。实际上，对于大部分资源有限的场景，当没有空闲资源时，基本上都可以通过“队列”这种数据结构来实现请求排队。

这个问题的具体答案，在队列那一节我已经讲得非常详细了，你可以回去看看，这里我就不赘述了。

实战测试题（四）
通过 IP 地址来查找 IP 归属地的功能，不知道你有没有用过？没用过也没关系，你现在可以打开百度，在搜索框里随便输一个 IP 地址，就会看到它的归属地。

这个功能并不复杂，它是通过维护一个很大的 IP 地址库来实现的。地址库中包括 IP 地址范围和归属地的对应关系。比如，当我们想要查询 202.102.133.13 这个 IP 地址的归属地时，我们就在地址库中搜索，发现这个 IP 地址落在 [202.102.133.0, 202.102.133.255] 这个地址范围内，那我们就可以将这个 IP 地址范围对应的归属地“山东东营市”显示给用户了。

[202.102.133.0, 202.102.133.255]  山东东营市 
[202.102.135.0, 202.102.136.255]  山东烟台 
[202.102.156.34, 202.102.157.255] 山东青岛 
[202.102.48.0, 202.102.48.255] 江苏宿迁 
[202.102.49.15, 202.102.51.251] 江苏泰州 
[202.102.56.0, 202.102.56.255] 江苏连云港
在庞大的地址库中逐一比对 IP 地址所在的区间，是非常耗时的。假设在内存中有 12 万条这样的 IP 区间与归属地的对应关系，如何快速定位出一个 IP 地址的归属地呢？

相关章节
15 | 二分查找（上）：如何用最省内存的方式实现快速查找功能？

16 | 二分查找（下）：如何快速定位 IP 对应的省份地址？

题目解析
这个问题可以用二分查找来解决，不过，普通的二分查找是不行的，我们需要用到二分查找的变形算法，查找最后一个小于等于某个给定值的数据。不过，二分查找最难的不是原理，而是实现。要实现一个二分查找的变形算法，并且实现的代码没有 bug，可不是一件容易的事情，不信你自己写写试试。

关于这个问题的解答以及写出 bug free 的二分查找代码的技巧，我们在二分查找（下）那一节有非常详细的讲解，你可以回去看看，我这里就不赘述了。

实战测试题（五）
假设我们现在希望设计一个简单的海量图片存储系统，最大预期能够存储 1 亿张图片，并且希望这个海量图片存储系统具有下面这样几个功能：

存储一张图片及其它的元信息，主要的元信息有：图片名称以及一组 tag 信息。比如图片名称叫玫瑰花，tag 信息是{红色，花，情人节}；

根据关键词搜索一张图片，比如关键词是“情人节 花”“玫瑰花”；

避免重复插入相同的图片。这里，我们不能单纯地用图片的元信息，来比对是否是同一张图片，因为有可能存在名称相同但图片内容不同，或者名称不同图片内容相同的情况。

我们希望自助开发一个简单的系统，不希望借助和维护过于复杂的三方系统，比如数据库（MySQL、Redis 等）、分布式存储系统（GFS、Bigtable 等），并且我们单台机器的性能有限，比如硬盘只有 1TB，内存只有 2GB，如何设计一个符合我们上面要求，操作高效，且使用机器资源最少的存储系统呢？

相关章节
21 | 哈希算法（上）：如何防止数据库中的用户信息被脱库？

22 | 哈希算法（下）：哈希算法在分布式系统中有哪些应用？

题目解析
这个问题可以分成两部分，第一部分是根据元信息的搜索功能，第二部分是图片判重。

第一部分，我们可以借助搜索引擎中的倒排索引结构。关于倒排索引我会在实战篇详细讲解，我这里先简要说下。

如题目中所说，一个图片会对应一组元信息，比如玫瑰花对应{红色，花，情人节}，牡丹花对应{白色，花}，我们可以将这种图片与元信息之间的关系，倒置过来建立索引。“花”这个关键词对应{玫瑰花，牡丹花}，“红色”对应{玫瑰花}，“白色”对应{牡丹花}，“情人节”对应{玫瑰花}。

当我们搜索“情人节 花”的时候，我们拿两个搜索关键词分别在倒排索引中查找，“花”查找到了{玫瑰花，牡丹花}，“情人节”查找到了{玫瑰花}，两个关键词对应的结果取交集，就是最终的结果了。

第二部分关于图片判重，我们要基于图片本身来判重，所以可以用哈希算法，对图片内容取哈希值。我们对哈希值建立散列表，这样就可以通过哈希值以及散列表，快速判断图片是否存在。

我这里只说说我的思路，这个问题中还有详细的内存和硬盘的限制。要想给出更加详细的设计思路，还需要根据这些限制，给出一个估算。详细的解答，我都放在在哈希算法（下）那一节里到了，你可以自己回去看。

实战测试题（六）
我们知道，散列表的查询效率并不能笼统地说成是 O(1)。它跟散列函数、装载因子、散列冲突等都有关系。如果散列函数设计得不好，或者装载因子过高，都可能导致散列冲突发生的概率升高，查询效率下降。

在极端情况下，有些恶意的攻击者，还有可能通过精心构造的数据，使得所有的数据经过散列函数之后，都散列到同一个槽里。如果我们使用的是基于链表的冲突解决方法，那这个时候，散列表就会退化为链表，查询的时间复杂度就从 O(1) 急剧退化为 O(n)。

如果散列表中有 10 万个数据，退化后的散列表查询的效率就下降了 10 万倍。更直观点说，如果之前运行 100 次查询只需要 0.1 秒，那现在就需要 1 万秒。这样就有可能因为查询操作消耗大量 CPU 或者线程资源，导致系统无法响应其他请求，从而达到拒绝服务攻击（DoS）的目的。这也就是散列表碰撞攻击的基本原理。

如何设计一个可以应对各种异常情况的工业级散列表，来避免在散列冲突的情况下，散列表性能的急剧下降，并且能抵抗散列碰撞攻击？

相关章节
18 | 散列表（上）：Word 文档中的单词拼写检查功能是如何实现的？

19 | 散列表（中）：如何打造一个工业级水平的散列表？

题目解析
我经常把这道题拿来作为面试题考察候选人。散列表可以说是我们最常用的一种数据结构了，编程语言中很多数据类型，都是用散列表来实现的。尽管很多人能对散列表都知道一二，知道有几种散列表冲突解决方案，知道散列表操作的时间复杂度，但是理论跟实践还是有一定距离的。光知道这些基础的理论并不足以开发一个工业级的散列表。

所以，我在散列表（中）那一节中详细给你展示了一个工业级的散列表要处理哪些问题，以及如何处理的，也就是这个问题的详细答案。

这六道题你回答得怎么样呢？或许你还无法 100% 回答正确，没关系。其实只要你看了解析之后，有比较深的印象，能立马想到哪节课里讲过，这已经说明你掌握得不错了。毕竟想要完全掌握我讲的全部内容还是需要时间沉淀的。对于这门课的学习，你一定不要心急，慢慢来。只要方向对了就都对了，剩下就交给时间和努力吧！

通过这套题，你对自己的学习状况应该有了一个了解。从专栏开始到现在，三个月过去了，我们的内容也更新了大半。你在专栏开始的时候设定的目标是什么？现在实施得如何了？你可以在留言区给这三个月的学习做个阶段性学习复盘。重新整理，继续出发！



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(41)

　　　　　　　　
老师是高手，把这么多其他人甚至课本上讲的蹩脚难懂的知识，娓娓道来，深入浅出。
买了这门课一开始没怎么看，最近两天有空就看，觉得是一种享受！
2018-12-21


39

陈阿票
基本上一下子都知道用什么数据结构和算法去解决，但是实际代码我肯定写不出来，心里总有一种纸上谈兵的感觉。
2018-12-21


29

alic
这门课程以后也会反复看的，希望老师也不要因为掉队人多了就松懈了，加油。
2018-12-22


10

渔人
第二题，前K大的订单，您的描述有些简略，不容易理解，我重复描述一下，您看对不对哈。 10个库，取前K大的订单， 第一次从各个库中分别取出最大的订单，组成一个数量为10的大顶堆。另外维护一个数组，刚开始是空的。 这时从大顶堆中弹出堆顶元素(堆中最大值)，将堆顶元素写入数组，然后在该元素所在的库中按序拿出第二个元素写入大顶堆填上空缺，大顶堆会重新平衡，堆顶元素可能会变。 这时重复上面的步骤，继续弹出堆顶写入数组，并在弹出元素所在库中按序拿下一个值填入大顶堆，大顶堆又会重新平衡，接着继续弹出堆顶元素写入数组····直到数组的长度为K时，整个过程结束。

大顶堆的大小一直为10，堆每次平衡后，就将堆顶搞出来，重新写入一个值，周而复始，取K次堆顶就是前K大的集合了。
@ban
2019-01-28


4

jiemoon
老师，像那个猎头的题目，用多个数据结构的话，更新操作会出现数据不一致的情况？
作者回复: 加个锁？主要还是看操作是不是对数据一致性敏感吧

2018-12-21


3

Zoctopus
认真看了老师六个实战题目和详细解析，我觉得每道题可以当做一个小项目来练手了。同时也真实感受到基础的重要性！
作者回复: 是的，好好写写，收获会很大。

2019-02-08


2

怀特
实战测试题一：
其实算法问题，可以笼统的归纳为：数据以及数据之上的索引。
有的数据是自带索引的，比如数组其实自带了下标的索引
如果数据没有索引，就需要自建索引。如果我们自己建，那就是采取各种数据结构来构造一个索引；否则，比如据库的索引，也是建了与数据分离的索引的数据结构。
从这个角度讲：
1、根据id来查找猎头信息： 猎头信息存储到数组中就可以，这样很快
2、根据积分来查找猎头信息：可以旁边建立基于积分的数组来作为索引，节点数据就是猎头id
这样：
1、猎头信息存储在数组中
2、自建一个索引，分别是 积分+id的有序数组
注意积分变化时维护自建索引的有效性，就可以了。
这样没有用高深的数据结构，可能会费一些内存和费一些cpu，但实现简单，基本够用了，比较通用。
2019-01-09


2

以圭
学习的老师的这门课程，总有种相见恨晚的感觉，真正体悟到了算法之美。举重若轻，方为大师，老师真可谓大师。
作者回复: 哈哈哈 过奖了

2018-12-25


2

传说中的成大大
实战测试1：
     本来想的用树来维护通过ID的增删改查， 用积分做成一个hash表 每个hash下标对应多个猎头ID， 也可以用跳表实现增删改查

实战测试2：
维护一个大小为k的小顶堆 每次读一个库的数据 然后维护这个小顶堆

实战测试3：
      维护一个优先队列，根据优先级来判定 突然到来的线程请求是否该执行，也就是该线程是否在优先队列优先级高的区域

实战测试4：
       能想到二分法

实战测试5：
        不会

实战测试6：
        不会
以上题目是未看过任何答案和提示想出来的

看了解答 除了测试6没多大印象以外，其他的都能有很深刻的印象

学习目标: 最开始学习数据结构和算法的目标就是说要掌握好树和图，但是实际上却发现了更多需要我去掌握的数据结构和算法
实施情况， 坚持了三个月 每一篇文章都认真仔细的学习了 ，总得来说收获颇多，尤其是了解很多以前都不了解的数据结果和算法，扩充了自己的知识面

接下来的目标还是以本位为测试基准，优先针对性的复习，然后再把课程过一遍，坚持自己的学习初衷 我一定要把数据结果和算法学好！
 还是谢谢老师

2018-12-21


2

Phoenix
老师，第二题，我有另一条思路，想请老师教导和指点
正如老师所说，数据库最大性能瓶颈就是在IO，所以反复执行DB的IO操作是低效的
我想法是要高效实现第二题的要求，又尽量对数据库的IO操作，有以下思路
1 借助桶排序的思想，将订单按金额从小到大的规则分布在10个库中
2 要查找金额最大的前k订单，就先从第10个库中检索订单，满足K数量就直接返回
3 不满足k数量，在从第9个库中查找，以此类推，直到满足k数量，返回结果
2019-02-28


1

挨踢菜鸟
老师，我想问一下，您除了讲数据结构之外，本专栏之后还会讲一些其他的吗，比如设计模式之类的，看您的课程真是一种享受，非常期待您其他的专栏
2018-12-23


1

ban
把取出来的10个订单放到优先级队列中，取出最大值（也就是大顶堆堆顶数据），就是全局金额最大的订单。然后再从这个全局金额最大订单对应的数据库中，取出下一条订单（按照订单金额从大到小排列的），然后放到优先级队列中。一直重复上面的过程。

老师这段话我看到好多遍，想了好多次一直没搞懂，为什么取出最大金额的数据库查到下一条订单放到队列能理解，但是下次重复这个过程还是从队列中取出最大金额的下一个订单，这样每次最大的金额不是同一个吗，取出的订单还是同一个？

还有另外一个问题就是全部取出来后怎么判断这个队列是 top k的订单金额？

第二次回复，求老师讲解，自己研究好久没搞透
2018-12-22


1

才才
还得看好几遍，还得练习
2018-12-21


1

DFighting
看了这些题目，怎么说呢，有点知其然，不知其所以然的感觉。应该是没有实际应用过的缘故吧，这个彩蛋很好，适合动手实践实践，不然过段时间又忘了
作者回复: 知其所以然看里面的文章链接呢，毕竟是测试题，限于篇幅，不可能讲解太多。

2019-08-07



不去彼岸
实战测试题二：
如果k的值很大，用归并排序merge的方法时间复杂度会很高，是不是可以用二分查找的思想
取每个库中第k位的金额，然后根据这些金额中的最大金额max与最小金额min，得到中间值mid，再用这个中间值去各个库中查大于这个值的数量，加起来就是这个中间值的排名ki，ki>k则说明中间值比要找的金额大，递归查找(min,mid)中间值的排名，ki<k,递归查找(mid,max)中间值的排名，这样时间复杂度就是10*logn 也就是O(logn)
2019-04-25



路上的始终
涉及到一定的需求场景时虽然不能立刻写出代码，但是有很多思路，能写伪代码
2019-04-24



天空只能仰望？
哈哈，第二遍刷过来很多例子多写了一遍，还是有很多的印象，测试相关题目不一定想到的都是最优解但是也都能联想到相关数据结构和问题解决办法，感谢老师👨‍🏫！
2019-04-20



H.L.
题目2: 从10个库中分别取n条数据，放在内存中，再构建一个堆，不断的删堆顶，从内存中的数据放到堆，再堆化，如果其中一个库在内存中没数据了，就触发一次sql操作，取下一批数据回来放到内存
2019-04-12



小智e
最近在找实习，恶补基础知识，正在努力追赶老师的步伐，感觉超值的课程
2019-03-25



睡痴儿😑
查找ip地址是否可以使用tire树呢。毕竟有着大量相同的后缀
2019-01-23


收起评论

4199+





# 39 | 回溯算法：从电影《蝴蝶效应》中学习回溯算法的核心思想




数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



39 | 回溯算法：从电影《蝴蝶效应》中学习回溯算法的核心思想
王争 2018-12-24



09:18
讲述：修阳 大小：8.52M
我们在第 31 节提到，深度优先搜索算法利用的是回溯算法思想。这个算法思想非常简单，但是应用却非常广泛。它除了用来指导像深度优先搜索这种经典的算法设计之外，还可以用在很多实际的软件开发场景中，比如正则表达式匹配、编译原理中的语法分析等。

除此之外，很多经典的数学问题都可以用回溯算法解决，比如数独、八皇后、0-1 背包、图的着色、旅行商问题、全排列等等。既然应用如此广泛，我们今天就来学习一下这个算法思想，看看它是如何指导我们解决问题的。

如何理解“回溯算法”？
在我们的一生中，会遇到很多重要的岔路口。在岔路口上，每个选择都会影响我们今后的人生。有的人在每个岔路口都能做出最正确的选择，最后生活、事业都达到了一个很高的高度；而有的人一路选错，最后碌碌无为。如果人生可以量化，那如何才能在岔路口做出最正确的选择，让自己的人生“最优”呢？

我们可以借助前面学过的贪心算法，在每次面对岔路口的时候，都做出看起来最优的选择，期望这一组选择可以使得我们的人生达到“最优”。但是，我们前面也讲过，贪心算法并不一定能得到最优解。那有没有什么办法能得到最优解呢？

2004 年上映了一部非常著名的电影《蝴蝶效应》，讲的就是主人公为了达到自己的目标，一直通过回溯的方法，回到童年，在关键的岔路口，重新做选择。当然，这只是科幻电影，我们的人生是无法倒退的，但是这其中蕴含的思想其实就是回溯算法。

笼统地讲，回溯算法很多时候都应用在“搜索”这类问题上。不过这里说的搜索，并不是狭义的指我们前面讲过的图的搜索算法，而是在一组可能的解中，搜索满足期望的解。

回溯的处理思想，有点类似枚举搜索。我们枚举所有的解，找到满足期望的解。为了有规律地枚举所有可能的解，避免遗漏和重复，我们把问题求解的过程分为多个阶段。每个阶段，我们都会面对一个岔路口，我们先随意选一条路走，当发现这条路走不通的时候（不符合期望的解），就回退到上一个岔路口，另选一种走法继续走。

理论的东西还是过于抽象，老规矩，我还是举例说明一下。我举一个经典的回溯例子，我想你可能已经猜到了，那就是八皇后问题。

我们有一个 8x8 的棋盘，希望往里放 8 个棋子（皇后），每个棋子所在的行、列、对角线都不能有另一个棋子。你可以看我画的图，第一幅图是满足条件的一种方法，第二幅图是不满足条件的。八皇后问题就是期望找到所有满足这种要求的放棋子方式。



我们把这个问题划分成 8 个阶段，依次将 8 个棋子放到第一行、第二行、第三行……第八行。在放置的过程中，我们不停地检查当前的方法，是否满足要求。如果满足，则跳到下一行继续放置棋子；如果不满足，那就再换一种方法，继续尝试。

回溯算法非常适合用递归代码实现，所以，我把八皇后的算法翻译成代码。我在代码里添加了详细的注释，你可以对比着看下。如果你之前没有接触过八皇后问题，建议你自己用熟悉的编程语言实现一遍，这对你理解回溯思想非常有帮助。

int[] result = new int[8];// 全局或成员变量, 下标表示行, 值表示 queen 存储在哪一列
public void cal8queens(int row) { // 调用方式：cal8queens(0);
  if (row == 8) { // 8 个棋子都放置好了，打印结果
    printQueens(result);
    return; // 8 行棋子都放好了，已经没法再往下递归了，所以就 return
  }
  for (int column = 0; column < 8; ++column) { // 每一行都有 8 中放法
    if (isOk(row, column)) { // 有些放法不满足要求
      result[row] = column; // 第 row 行的棋子放到了 column 列
      cal8queens(row+1); // 考察下一行
    }
  }
}
 
private boolean isOk(int row, int column) {// 判断 row 行 column 列放置是否合适
  int leftup = column - 1, rightup = column + 1;
  for (int i = row-1; i >= 0; --i) { // 逐行往上考察每一行
    if (result[i] == column) return false; // 第 i 行的 column 列有棋子吗？
    if (leftup >= 0) { // 考察左上对角线：第 i 行 leftup 列有棋子吗？
      if (result[i] == leftup) return false;
    }
    if (rightup < 8) { // 考察右上对角线：第 i 行 rightup 列有棋子吗？
      if (result[i] == rightup) return false;
    }
    --leftup; ++rightup;
  }
  return true;
}
 
private void printQueens(int[] result) { // 打印出一个二维矩阵
  for (int row = 0; row < 8; ++row) {
    for (int column = 0; column < 8; ++column) {
      if (result[row] == column) System.out.print("Q ");
      else System.out.print("* ");
    }
    System.out.println();
  }
  System.out.println();
}
两个回溯算法的经典应用
回溯算法的理论知识很容易弄懂。不过，对于新手来说，比较难的是用递归来实现。所以，我们再通过两个例子，来练习一下回溯算法的应用和实现。

1.0-1 背包
0-1 背包是非常经典的算法问题，很多场景都可以抽象成这个问题模型。这个问题的经典解法是动态规划，不过还有一种简单但没有那么高效的解法，那就是今天讲的回溯算法。动态规划的解法我下一节再讲，我们先来看下，如何用回溯法解决这个问题。

0-1 背包问题有很多变体，我这里介绍一种比较基础的。我们有一个背包，背包总的承载重量是 Wkg。现在我们有 n 个物品，每个物品的重量不等，并且不可分割。我们现在期望选择几件物品，装载到背包中。在不超过背包所能装载重量的前提下，如何让背包中物品的总重量最大？

实际上，背包问题我们在贪心算法那一节，已经讲过一个了，不过那里讲的物品是可以分割的，我可以装某个物品的一部分到背包里面。今天讲的这个背包问题，物品是不可分割的，要么装要么不装，所以叫 0-1 背包问题。显然，这个问题已经无法通过贪心算法来解决了。我们现在来看看，用回溯算法如何来解决。

对于每个物品来说，都有两种选择，装进背包或者不装进背包。对于 n 个物品来说，总的装法就有 2^n 种，去掉总重量超过 Wkg 的，从剩下的装法中选择总重量最接近 Wkg 的。不过，我们如何才能不重复地穷举出这 2^n 种装法呢？

这里就可以用回溯的方法。我们可以把物品依次排列，整个问题就分解为了 n 个阶段，每个阶段对应一个物品怎么选择。先对第一个物品进行处理，选择装进去或者不装进去，然后再递归地处理剩下的物品。描述起来很费劲，我们直接看代码，反而会更加清晰一些。

这里还稍微用到了一点搜索剪枝的技巧，就是当发现已经选择的物品的重量超过 Wkg 之后，我们就停止继续探测剩下的物品。你可以看我写的具体的代码。

public int maxW = Integer.MIN_VALUE; // 存储背包中物品总重量的最大值
// cw 表示当前已经装进去的物品的重量和；i 表示考察到哪个物品了；
// w 背包重量；items 表示每个物品的重量；n 表示物品个数
// 假设背包可承受重量 100，物品个数 10，物品重量存储在数组 a 中，那可以这样调用函数：
// f(0, 0, a, 10, 100)
public void f(int i, int cw, int[] items, int n, int w) {
  if (cw == w || i == n) { // cw==w 表示装满了 ;i==n 表示已经考察完所有的物品
    if (cw > maxW) maxW = cw;
    return;
  }
  f(i+1, cw, items, n, w);
  if (cw + items[i] <= w) {// 已经超过可以背包承受的重量的时候，就不要再装了
    f(i+1,cw + items[i], items, n, w);
  }
}
2. 正则表达式
看懂了 0-1 背包问题，我们再来看另外一个例子，正则表达式匹配。

对于一个开发工程师来说，正则表达式你应该不陌生吧？在平时的开发中，或多或少都应该用过。实际上，正则表达式里最重要的一种算法思想就是回溯。

正则表达式中，最重要的就是通配符，通配符结合在一起，可以表达非常丰富的语义。为了方便讲解，我假设正表达式中只包含“*”和“?”这两种通配符，并且对这两个通配符的语义稍微做些改变，其中，“*”匹配任意多个（大于等于 0 个）任意字符，“?”匹配零个或者一个任意字符。基于以上背景假设，我们看下，如何用回溯算法，判断一个给定的文本，能否跟给定的正则表达式匹配？

我们依次考察正则表达式中的每个字符，当是非通配符时，我们就直接跟文本的字符进行匹配，如果相同，则继续往下处理；如果不同，则回溯。

如果遇到特殊字符的时候，我们就有多种处理方式了，也就是所谓的岔路口，比如“*”有多种匹配方案，可以匹配任意个文本串中的字符，我们就先随意的选择一种匹配方案，然后继续考察剩下的字符。如果中途发现无法继续匹配下去了，我们就回到这个岔路口，重新选择一种匹配方案，然后再继续匹配剩下的字符。

有了前面的基础，是不是这个问题就好懂多了呢？我把这个过程翻译成了代码，你可以结合着一块看下，应该有助于你理解。

public class Pattern {
  private boolean matched = false;
  private char[] pattern; // 正则表达式
  private int plen; // 正则表达式长度
 
  public Pattern(char[] pattern, int plen) {
    this.pattern = pattern;
    this.plen = plen;
  }
 
  public boolean match(char[] text, int tlen) { // 文本串及长度
    matched = false;
    rmatch(0, 0, text, tlen);
    return matched;
  }
 
  private void rmatch(int ti, int pj, char[] text, int tlen) {
    if (matched) return; // 如果已经匹配了，就不要继续递归了
    if (pj == plen) { // 正则表达式到结尾了
      if (ti == tlen) matched = true; // 文本串也到结尾了
      return;
    }
    if (pattern[pj] == '*') { // * 匹配任意个字符
      for (int k = 0; k <= tlen-ti; ++k) {
        rmatch(ti+k, pj+1, text, tlen);
      }
    } else if (pattern[pj] == '?') { // ? 匹配 0 个或者 1 个字符
      rmatch(ti, pj+1, text, tlen);
      rmatch(ti+1, pj+1, text, tlen);
    } else if (ti < tlen && pattern[pj] == text[ti]) { // 纯字符匹配才行
      rmatch(ti+1, pj+1, text, tlen);
    }
  }
}
内容小结
回溯算法的思想非常简单，大部分情况下，都是用来解决广义的搜索问题，也就是，从一组可能的解中，选择出一个满足要求的解。回溯算法非常适合用递归来实现，在实现的过程中，剪枝操作是提高回溯效率的一种技巧。利用剪枝，我们并不需要穷举搜索所有的情况，从而提高搜索效率。

尽管回溯算法的原理非常简单，但是却可以解决很多问题，比如我们开头提到的深度优先搜索、八皇后、0-1 背包问题、图的着色、旅行商问题、数独、全排列、正则表达式匹配等等。如果感兴趣的话，你可以自己搜索研究一下，最好还能用代码实现一下。如果这几个问题都能实现的话，你基本就掌握了回溯算法。

课后思考
现在我们对今天讲到的 0-1 背包问题稍加改造，如果每个物品不仅重量不同，价值也不同。如何在不超过背包重量的情况下，让背包中的总价值最大？

欢迎留言和我分享，也欢迎点击“请朋友读”，把今天的内容分享给你的好友，和他一起讨论、学习。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(82)

纯洁的憎恶
回溯算法本质上就是枚举，优点在于其类似于摸着石头过河的查找策略，且可以通过剪枝少走冤枉路。它可能适合应用于缺乏规律，或我们还不了解其规律的搜索场景中。
作者回复: 👍

2018-12-24


76

slvher
0-1 背包问题的回溯实现技巧：

第 11 行的递归调用表示不选择当前物品，直接考虑下一个（第 i+1 个），故 cw 不更新

第 13 行的递归调用表示选择了当前物品，故考虑下一个时，cw 通过入参更新为 cw + items[i]

函数入口处的 if 分支表明递归结束条件，并保证 maxW 跟踪所有选择中的最大值
2018-12-24

1

52

G.S.K
0-1背包问题根据老师下边这句话的讲解，代码再加两行注释就非常容易理解了

我们可以把物品依次排列，整个问题就分解为了 n 个阶段，每个阶段对应一个物品怎么选择。先对第一个物品进行处理，选择装进去或者不装进去，然后再递归地处理剩下的物品。

public int maxW = Integer.MIN_VALUE; // 存储背包中物品总重量的最大值
// cw 表示当前已经装进去的物品的重量和；i 表示考察到哪个物品了；
// w 背包重量；items 表示每个物品的重量；n 表示物品个数
// 假设背包可承受重量 100，物品个数 10，物品重量存储在数组 a 中，那可以这样调用函数：
// f(0, 0, a, 10, 100)
public void f(int i, int cw, int[] items, int n, int w) {
  if (cw == w || i == n) { // cw==w 表示装满了 ;i==n 表示已经考察完所有的物品
    if (cw > maxW) maxW = cw;
    return;
  }
  f(i+1, cw, items, n, w); //当前物品不装进背包
  if (cw + items[i] <= w) {// 已经超过可以背包承受的重量的时候，就不要再装了
    f(i+1,cw + items[i], items, n, w); //当前物品装进背包
  }
}
2019-03-03


24

www.xnsms.com小鸟接码
看不懂背包问题代码同学，请好好仔细看看下面这句话，再结合代码你就看懂了

我们可以把物品依次排列，整个问题就分解为了 n 个阶段，每个阶段对应一个物品怎么选择。先对第一个物品进行处理，选择装进去或者不装进去，然后再递归地处理剩下的物品。
作者回复: 👍

2019-01-06


19

纯洁的憎恶
0-1背包的递归代码里第11行非常巧妙，它借助回溯过程，实现了以每一个可能的物品，作为第一个装入背包的，以尝试所有物品组合。但如果仅按从前向后执行的顺序看，是不太容易发现这一点的。
2018-12-24


19

Shawn
0-1背包问题理解：
假设三个物品，每个物品在考虑时有两种选择，1-放进包，0-不放
11行代码表示不放进包里。13行代码表示放进包里。
三个物品遍历过程如下：
0 0 0 update maxW
0 0 1 update maxW
0 1 0 update maxW
0 1 1 update maxW
1 0 0 update maxW
1 0 1 update maxW
1 1 0 update maxW
1 1 1 update maxW
作者回复: 👍

2019-05-30


10

传说中的成大大
今天又读了一遍这个文章,又写一遍八皇后,写的更快，更流畅,背包和正则匹配的代码也理解得更透彻了
2018-12-27


9

siegfried
回溯就是暴力枚举的解法吧？遍历所有情况，当满足情况就停止遍历（剪枝）。
作者回复: 是的

2018-12-24


7

叶明
老师，你好，背包问题，貌似只记录了可以放进去的最大值，没有记录放进最大值对应的放法，我稍微
改了下，算出了最大值对应的所有放法，不知道可行不，希望老师回复下。
private int maxW = Integer.MIN_VALUE; // 存储背包中物品总重量的最大值
    // 下标表示物品序号，值表示是否放进背包:1放，0不放
    private int[] currentAnswer;
    //存储所有解(map key表示放进去的重量，value表示对应重量的物品放法)，
    //最终所有最优解为bestAnswerMap.get(maxW)
    private Map<Integer, List<int[]>> bestAnswerMap = new HashMap();

    // cw 表示当前已经装进去的物品的重量和；i 表示考察到哪个物品了；
    // w 背包重量；items 表示每个物品的重量；n 表示物品个数
    // 假设背包可承受重量 100，物品个数 10，物品重量存储在数组 a 中，那可以这样调用函数：
    // f(0, 0, a, 10, 100)
    public void f(int i, int cw, int[] items, int n, int w) {
        if(currentAnswer == null){
            currentAnswer = new int[n];
        }

        if (cw == w || i == n) { // cw==w 表示装满了 ;i==n 表示已经考察完所有的物品
            if (cw >= maxW) {
                maxW = cw;
                int[] bestAnswer = new int[currentAnswer.length];
                for(int j=0; j<currentAnswer.length; j++){
                    bestAnswer[j] = currentAnswer[j];
                }
                if(bestAnswerMap.containsKey(cw)){
                    bestAnswerMap.get(cw).add(bestAnswer);
                }else{
                    List<int[]> list = new ArrayList<int[]>();
                    list.add(bestAnswer);
                    bestAnswerMap.put(cw, list);
                }
            }
            return;
        }
        currentAnswer[i] = 0;
        f(i+1, cw, items, n, w);
        if (cw + items[i] <= w) {// 已经超过可以背包承受的重量的时候，就不要再装了
            currentAnswer[i] = 1;
            f(i+1,cw + items[i], items, n, w);
        }
    }

最终maxW 对应的所有最优解为bestAnswerMap.get(maxW)
2019-01-30


6

猫头鹰爱拿铁
总觉得背包问题11行代码应该写在14行后，那个if条件后面。
2018-12-28


6

Monday
8皇后以前提到就觉得难懂，今天硬着头皮去写，竟虽然难还是写出来了。多写多写多写
2018-12-25


6

Kudo
0-1背包python实现：
maxW = -1 # tracking the max weight

def backpack(i, cw, items, w):
    '''
    # i: the ith item, integer
    # cw: current weight, integer
    # items: python list of item weights
    # w: upper limit weight the backpack can load
    '''
    global maxW
    
    if cw==w or i==len(items): # base case
        if cw > maxW:
            maxW = cw
        return
    
    # There are 2 states, traverse both!!!
    backpack(i+1, cw, items, w) # do not choose
    if (cw + items[i] <= w):
        backpack(i+1, cw+items[i], items, w) # choose
    
 how to use
items = [2, 2, 4, 6, 3]
backpack(0, 0, items, 10)
print(maxW)
2018-12-27


3

传说中的成大大
我今天也把8皇后写出来了 虽然是第一次
作者回复: 写多了你就会发现 这玩意贼简单

2018-12-25


3

Paul Shan
回溯算法的核心就是试了再比，不行回退的思路。
2019-07-25


2

Geek_bd613f
看完这篇文章，写了个求n位逐位整除数的题，发现剪枝技巧其实在考虑题目限制条件时自然就用上了，比如背包问题会判断weigh＜背包最大载重，如果不判断，递归到最后就不能直接取maxW了，因为这个值可能超过背包最大载重。
2019-06-19


2

notfresh
有一个小小的请求: 代码注释可以分行写吗?
    // i 表示考察到哪个物品了；
    // cw 表示当前已经装进去的物品的重量和；
    // items 表示每个物品的重量；
    // n 表示物品个数
    // w 背包重量；

2019-03-10


2

唯她命
aab c*a*b 正则表达式，能匹配通过，文章的代码通过不了，代码有问题
作者回复: 你自己搞错了吧，没法通过匹配啊

2019-02-25

4

2

饺子
流程大概就是：
第一个不放，第二个不放，……，第n-1个不放，第n个不放。
第一个不放，第二个不放，……，第n-1个不放，
第n个放。
第一个不放，第二个不放， ……，第n-1个放，
第n个不放。
第一个不放，第二个不放， ……，第n-1个放，
第n个放。
……
以此类推
感觉这些问题就是将概率论知识转化成代码实现。
2019-02-23


2

Joker
老师，我经过查资料，找到，其实判断是否在一条斜线上还有更加简便的做法，就是如果行互减的绝对值等于列互减的绝对值，那么就是在一条斜线上的。
if (Math.abs(row - i) == Math.abs(column - result[i])) {
                return false;
            }
作者回复: 是的，我写的时候也查过资料。

2019-02-01

2

2

Kudo
八皇后python实现：
result = [0, 0, 0, 0, 0, 0, 0, 0]

def cal8queens(row): # 调用方式：cal8queens(0)
    if row == 8: # 递归终止条件
        printQueens(result) # 打印结果
        print('-' * 20) # 分隔符
        return
    
    for col in range(8): # 每行有8种放法，依次遍历
        if isOk(row, col): # 放法是否满足要求
            result[row] = col # 选择该列
            cal8queens(row+1) # 考察下一行
            
def isOk(row, col):
    leftup, rightup = col-1, col+1
    for r in range(row-1,-1,-1): # 遍历[row-1，-1)行
        if result[r] in [leftup,rightup,col]:
            return False
        leftup -= 1; rightup += 1
    return True

def printQueens(result): # 打印8*8结果
    for row in range(8):
        for col in range(8):
            if result[row] == col:
                print('Q', end=' ')
            else:
                print('*', end=' ')
        print() # 换行
2018-12-27


2
收起评论

8299+





# 40 | 初识动态规划：如何巧妙解决“双十一”购物时的凑单问题？



数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



40 | 初识动态规划：如何巧妙解决“双十一”购物时的凑单问题？
王争 2018-12-26



16:25
讲述：修阳 大小：15.04M
淘宝的“双十一”购物节有各种促销活动，比如“满 200 元减 50 元”。假设你女朋友的购物车中有 n 个（n>100）想买的商品，她希望从里面选几个，在凑够满减条件的前提下，让选出来的商品价格总和最大程度地接近满减条件（200 元），这样就可以极大限度地“薅羊毛”。作为程序员的你，能不能编个代码来帮她搞定呢？

要想高效地解决这个问题，就要用到我们今天讲的动态规划（Dynamic Programming）。

动态规划学习路线
动态规划比较适合用来求解最优问题，比如求最大值、最小值等等。它可以非常显著地降低时间复杂度，提高代码的执行效率。不过，它也是出了名的难学。它的主要学习难点跟递归类似，那就是，求解问题的过程不太符合人类常规的思维方式。对于新手来说，要想入门确实不容易。不过，等你掌握了之后，你会发现，实际上并没有想象中那么难。

为了让你更容易理解动态规划，我分了三节给你讲解。这三节分别是，初识动态规划、动态规划理论、动态规划实战。

第一节，我会通过两个非常经典的动态规划问题模型，向你展示我们为什么需要动态规划，以及动态规划解题方法是如何演化出来的。实际上，你只要掌握了这两个例子的解决思路，对于其他很多动态规划问题，你都可以套用类似的思路来解决。

第二节，我会总结动态规划适合解决的问题的特征，以及动态规划解题思路。除此之外，我还会将贪心、分治、回溯、动态规划这四种算法思想放在一起，对比分析它们各自的特点以及适用的场景。

第三节，我会教你应用第二节讲的动态规划理论知识，实战解决三个非常经典的动态规划问题，加深你对理论的理解。弄懂了这三节中的例子，对于动态规划这个知识点，你就算是入门了。

0-1 背包问题
我在讲贪心算法、回溯算法的时候，多次讲到背包问题。今天，我们依旧拿这个问题来举例。

对于一组不同重量、不可分割的物品，我们需要选择一些装入背包，在满足背包最大重量限制的前提下，背包中物品总重量的最大值是多少呢？

关于这个问题，我们上一节讲了回溯的解决方法，也就是穷举搜索所有可能的装法，然后找出满足条件的最大值。不过，回溯算法的复杂度比较高，是指数级别的。那有没有什么规律，可以有效降低时间复杂度呢？我们一起来看看。

// 回溯算法实现。注意：我把输入的变量都定义成了成员变量。
private int maxW = Integer.MIN_VALUE; // 结果放到 maxW 中
private int[] weight = {2，2，4，6，3};  // 物品重量
private int n = 5; // 物品个数
private int w = 9; // 背包承受的最大重量
public void f(int i, int cw) { // 调用 f(0, 0)
  if (cw == w || i == n) { // cw==w 表示装满了，i==n 表示物品都考察完了
    if (cw > maxW) maxW = cw;
    return;
  }
  f(i+1, cw); // 选择不装第 i 个物品
  if (cw + weight[i] <= w) {
    f(i+1,cw + weight[i]); // 选择装第 i 个物品
  }
}
规律是不是不好找？那我们就举个例子、画个图看看。我们假设背包的最大承载重量是 9。我们有 5 个不同的物品，每个物品的重量分别是 2，2，4，6，3。如果我们把这个例子的回溯求解过程，用递归树画出来，就是下面这个样子：



递归树中的每个节点表示一种状态，我们用（i, cw）来表示。其中，i 表示将要决策第几个物品是否装入背包，cw 表示当前背包中物品的总重量。比如，（2，2）表示我们将要决策第 2 个物品是否装入背包，在决策前，背包中物品的总重量是 2。

从递归树中，你应该能会发现，有些子问题的求解是重复的，比如图中 f(2, 2) 和 f(3,4) 都被重复计算了两次。我们可以借助递归那一节讲的“备忘录”的解决方式，记录已经计算好的 f(i, cw)，当再次计算到重复的 f(i, cw) 的时候，可以直接从备忘录中取出来用，就不用再递归计算了，这样就可以避免冗余计算。

private int maxW = Integer.MIN_VALUE; // 结果放到 maxW 中
private int[] weight = {2，2，4，6，3};  // 物品重量
private int n = 5; // 物品个数
private int w = 9; // 背包承受的最大重量
private boolean[][] mem = new boolean[5][10]; // 备忘录，默认值 false
public void f(int i, int cw) { // 调用 f(0, 0)
  if (cw == w || i == n) { // cw==w 表示装满了，i==n 表示物品都考察完了
    if (cw > maxW) maxW = cw;
    return;
  }
  if (mem[i][cw]) return; // 重复状态
  mem[i][cw] = true; // 记录 (i, cw) 这个状态
  f(i+1, cw); // 选择不装第 i 个物品
  if (cw + weight[i] <= w) {
    f(i+1,cw + weight[i]); // 选择装第 i 个物品
  }
}
这种解决方法非常好。实际上，它已经跟动态规划的执行效率基本上没有差别。但是，多一种方法就多一种解决思路，我们现在来看看动态规划是怎么做的。

我们把整个求解过程分为 n 个阶段，每个阶段会决策一个物品是否放到背包中。每个物品决策（放入或者不放入背包）完之后，背包中的物品的重量会有多种情况，也就是说，会达到多种不同的状态，对应到递归树中，就是有很多不同的节点。

我们把每一层重复的状态（节点）合并，只记录不同的状态，然后基于上一层的状态集合，来推导下一层的状态集合。我们可以通过合并每一层重复的状态，这样就保证每一层不同状态的个数都不会超过 w 个（w 表示背包的承载重量），也就是例子中的 9。于是，我们就成功避免了每层状态个数的指数级增长。

我们用一个二维数组 states[n][w+1]，来记录每层可以达到的不同状态。

第 0 个（下标从 0 开始编号）物品的重量是 2，要么装入背包，要么不装入背包，决策完之后，会对应背包的两种状态，背包中物品的总重量是 0 或者 2。我们用 states[0][0]=true 和 states[0][2]=true 来表示这两种状态。

第 1 个物品的重量也是 2，基于之前的背包状态，在这个物品决策完之后，不同的状态有 3 个，背包中物品总重量分别是 0(0+0)，2(0+2 or 2+0)，4(2+2)。我们用 states[1][0]=true，states[1][2]=true，states[1][4]=true 来表示这三种状态。

以此类推，直到考察完所有的物品后，整个 states 状态数组就都计算好了。我把整个计算的过程画了出来，你可以看看。图中 0 表示 false，1 表示 true。我们只需要在最后一层，找一个值为 true 的最接近 w（这里是 9）的值，就是背包中物品总重量的最大值。



文字描述可能还不够清楚。我把上面的过程，翻译成代码，你可以结合着一块看下。

weight: 物品重量，n: 物品个数，w: 背包可承载重量
public int knapsack(int[] weight, int n, int w) {
  boolean[][] states = new boolean[n][w+1]; // 默认值 false
  states[0][0] = true;  // 第一行的数据要特殊处理，可以利用哨兵优化
  if (weight[0] <= w) {
    states[0][weight[0]] = true;
  }
  for (int i = 1; i < n; ++i) { // 动态规划状态转移
    for (int j = 0; j <= w; ++j) {// 不把第 i 个物品放入背包
      if (states[i-1][j] == true) states[i][j] = states[i-1][j];
    }
    for (int j = 0; j <= w-weight[i]; ++j) {// 把第 i 个物品放入背包
      if (states[i-1][j]==true) states[i][j+weight[i]] = true;
    }
  }
  for (int i = w; i >= 0; --i) { // 输出结果
    if (states[n-1][i] == true) return i;
  }
  return 0;
}
实际上，这就是一种用动态规划解决问题的思路。我们把问题分解为多个阶段，每个阶段对应一个决策。我们记录每一个阶段可达的状态集合（去掉重复的），然后通过当前阶段的状态集合，来推导下一个阶段的状态集合，动态地往前推进。这也是动态规划这个名字的由来，你可以自己体会一下，是不是还挺形象的？

前面我们讲到，用回溯算法解决这个问题的时间复杂度 O(2^n)，是指数级的。那动态规划解决方案的时间复杂度是多少呢？我来分析一下。

这个代码的时间复杂度非常好分析，耗时最多的部分就是代码中的两层 for 循环，所以时间复杂度是 O(n*w)。n 表示物品个数，w 表示背包可以承载的总重量。

从理论上讲，指数级的时间复杂度肯定要比 O(n*w) 高很多，但是为了让你有更加深刻的感受，我来举一个例子给你比较一下。

我们假设有 10000 个物品，重量分布在 1 到 15000 之间，背包可以承载的总重量是 30000。如果我们用回溯算法解决，用具体的数值表示出时间复杂度，就是 2^10000，这是一个相当大的一个数字。如果我们用动态规划解决，用具体的数值表示出时间复杂度，就是 10000*30000。虽然看起来也很大，但是和 2^10000 比起来，要小太多了。

尽管动态规划的执行效率比较高，但是就刚刚的代码实现来说，我们需要额外申请一个 n 乘以 w+1 的二维数组，对空间的消耗比较多。所以，有时候，我们会说，动态规划是一种空间换时间的解决思路。你可能要问了，有什么办法可以降低空间消耗吗？

实际上，我们只需要一个大小为 w+1 的一维数组就可以解决这个问题。动态规划状态转移的过程，都可以基于这个一维数组来操作。具体的代码实现我贴在这里，你可以仔细看下。

public static int knapsack2(int[] items, int n, int w) {
  boolean[] states = new boolean[w+1]; // 默认值 false
  states[0] = true;  // 第一行的数据要特殊处理，可以利用哨兵优化
  if (items[0] <= w) {
    states[items[0]] = true;
  }
  for (int i = 1; i < n; ++i) { // 动态规划
    for (int j = w-items[i]; j >= 0; --j) {// 把第 i 个物品放入背包
      if (states[j]==true) states[j+items[i]] = true;
    }
  }
  for (int i = w; i >= 0; --i) { // 输出结果
    if (states[i] == true) return i;
  }
  return 0;
}
 
这里我特别强调一下代码中的第 8 行，j 需要从大到小来处理。如果我们按照 j 从小到大处理的话，会出现 for 循环重复计算的问题。你可以自己想一想，这里我就不详细说了。

0-1 背包问题升级版
我们继续升级难度。我改造了一下刚刚的背包问题。你看这个问题又该如何用动态规划解决？

我们刚刚讲的背包问题，只涉及背包重量和物品重量。我们现在引入物品价值这一变量。对于一组不同重量、不同价值、不可分割的物品，我们选择将某些物品装入背包，在满足背包最大重量限制的前提下，背包中可装入物品的总价值最大是多少呢？

这个问题依旧可以用回溯算法来解决。这个问题并不复杂，所以具体的实现思路，我就不用文字描述了，直接给你看代码。

private int maxV = Integer.MIN_VALUE; // 结果放到 maxV 中
private int[] items = {2，2，4，6，3};  // 物品的重量
private int[] value = {3，4，8，9，6}; // 物品的价值
private int n = 5; // 物品个数
private int w = 9; // 背包承受的最大重量
public void f(int i, int cw, int cv) { // 调用 f(0, 0, 0)
  if (cw == w || i == n) { // cw==w 表示装满了，i==n 表示物品都考察完了
    if (cv > maxV) maxV = cv;
    return;
  }
  f(i+1, cw, cv); // 选择不装第 i 个物品
  if (cw + weight[i] <= w) {
    f(i+1,cw+weight[i], cv+value[i]); // 选择装第 i 个物品
  }
}
针对上面的代码，我们还是照例画出递归树。在递归树中，每个节点表示一个状态。现在我们需要 3 个变量（i, cw, cv）来表示一个状态。其中，i 表示即将要决策第 i 个物品是否装入背包，cw 表示当前背包中物品的总重量，cv 表示当前背包中物品的总价值。



我们发现，在递归树中，有几个节点的 i 和 cw 是完全相同的，比如 f(2,2,4) 和 f(2,2,3)。在背包中物品总重量一样的情况下，f(2,2,4) 这种状态对应的物品总价值更大，我们可以舍弃 f(2,2,3) 这种状态，只需要沿着 f(2,2,4) 这条决策路线继续往下决策就可以。

也就是说，对于 (i, cw) 相同的不同状态，那我们只需要保留 cv 值最大的那个，继续递归处理，其他状态不予考虑。

思路说完了，但是代码如何实现呢？如果用回溯算法，这个问题就没法再用“备忘录”解决了。所以，我们就需要换一种思路，看看动态规划是不是更容易解决这个问题？

我们还是把整个求解过程分为 n 个阶段，每个阶段会决策一个物品是否放到背包中。每个阶段决策完之后，背包中的物品的总重量以及总价值，会有多种情况，也就是会达到多种不同的状态。

我们用一个二维数组 states[n][w+1]，来记录每层可以达到的不同状态。不过这里数组存储的值不再是 boolean 类型的了，而是当前状态对应的最大总价值。我们把每一层中 (i, cw) 重复的状态（节点）合并，只记录 cv 值最大的那个状态，然后基于这些状态来推导下一层的状态。

我们把这个动态规划的过程翻译成代码，就是下面这个样子：

public static int knapsack3(int[] weight, int[] value, int n, int w) {
  int[][] states = new int[n][w+1];
  for (int i = 0; i < n; ++i) { // 初始化 states
    for (int j = 0; j < w+1; ++j) {
      states[i][j] = -1;
    }
  }
  states[0][0] = 0;
  if (weight[0] <= w) {
    states[0][weight[0]] = value[0];
  }
  for (int i = 1; i < n; ++i) { // 动态规划，状态转移
    for (int j = 0; j <= w; ++j) { // 不选择第 i 个物品
      if (states[i-1][j] >= 0) states[i][j] = states[i-1][j];
    }
    for (int j = 0; j <= w-weight[i]; ++j) { // 选择第 i 个物品
      if (states[i-1][j] >= 0) {
        int v = states[i-1][j] + value[i];
        if (v > states[i][j+weight[i]]) {
          states[i][j+weight[i]] = v;
        }
      }
    }
  }
  // 找出最大值
  int maxvalue = -1;
  for (int j = 0; j <= w; ++j) {
    if (states[n-1][j] > maxvalue) maxvalue = states[n-1][j];
  }
  return maxvalue;
}
关于这个问题的时间、空间复杂度的分析，跟上一个例子大同小异，所以我就不赘述了。我直接给出答案，时间复杂度是 O(n*w)，空间复杂度也是 O(n*w)。跟上一个例子类似，空间复杂度也是可以优化的，你可以自己写一下。

解答开篇
掌握了今天讲的两个问题之后，你是不是觉得，开篇的问题很简单？

对于这个问题，你当然可以利用回溯算法，穷举所有的排列组合，看大于等于 200 并且最接近 200 的组合是哪一个？但是，这样效率太低了点，时间复杂度非常高，是指数级的。当 n 很大的时候，可能“双十一”已经结束了，你的代码还没有运行出结果，这显然会让你在女朋友心中的形象大大减分。

实际上，它跟第一个例子中讲的 0-1 背包问题很像，只不过是把“重量”换成了“价格”而已。购物车中有 n 个商品。我们针对每个商品都决策是否购买。每次决策之后，对应不同的状态集合。我们还是用一个二维数组 states[n][x]，来记录每次决策之后所有可达的状态。不过，这里的 x 值是多少呢？

0-1 背包问题中，我们找的是小于等于 w 的最大值，x 就是背包的最大承载重量 w+1。对于这个问题来说，我们要找的是大于等于 200（满减条件）的值中最小的，所以就不能设置为 200 加 1 了。就这个实际的问题而言，如果要购买的物品的总价格超过 200 太多，比如 1000，那这个羊毛“薅”得就没有太大意义了。所以，我们可以限定 x 值为 1001。

不过，这个问题不仅要求大于等于 200 的总价格中的最小的，我们还要找出这个最小总价格对应都要购买哪些商品。实际上，我们可以利用 states 数组，倒推出这个被选择的商品序列。我先把代码写出来，待会再照着代码给你解释。

// items 商品价格，n 商品个数, w 表示满减条件，比如 200
public static void double11advance(int[] items, int n, int w) {
  boolean[][] states = new boolean[n][3*w+1];// 超过 3 倍就没有薅羊毛的价值了
  states[0][0] = true;  // 第一行的数据要特殊处理
  if (items[0] <= 3*w) {
    states[0][items[0]] = true;
  }
  for (int i = 1; i < n; ++i) { // 动态规划
    for (int j = 0; j <= 3*w; ++j) {// 不购买第 i 个商品
      if (states[i-1][j] == true) states[i][j] = states[i-1][j];
    }
    for (int j = 0; j <= 3*w-items[i]; ++j) {// 购买第 i 个商品
      if (states[i-1][j]==true) states[i][j+items[i]] = true;
    }
  }
 
  int j;
  for (j = w; j < 3*w+1; ++j) { 
    if (states[n-1][j] == true) break; // 输出结果大于等于 w 的最小值
  }
  if (j == 3*w+1) return; // 没有可行解
  for (int i = n-1; i >= 1; --i) { // i 表示二维数组中的行，j 表示列
    if(j-items[i] >= 0 && states[i-1][j-items[i]] == true) {
      System.out.print(items[i] + " "); // 购买这个商品
      j = j - items[i];
    } // else 没有购买这个商品，j 不变。
  }
  if (j != 0) System.out.print(items[0]);
}
代码的前半部分跟 0-1 背包问题没有什么不同，我们着重看后半部分，看它是如何打印出选择购买哪些商品的。

状态 (i, j) 只有可能从 (i-1, j) 或者 (i-1, j-value[i]) 两个状态推导过来。所以，我们就检查这两个状态是否是可达的，也就是 states[i-1][j] 或者 states[i-1][j-value[i]] 是否是 true。

如果 states[i-1][j] 可达，就说明我们没有选择购买第 i 个商品，如果 states[i-1][j-value[i]] 可达，那就说明我们选择了购买第 i 个商品。我们从中选择一个可达的状态（如果两个都可达，就随意选择一个），然后，继续迭代地考察其他商品是否有选择购买。

内容小结
动态规划的第一节到此就讲完了。内容比较多，你可能需要多一点时间来消化。为了帮助你有的放矢地学习，我来强调一下，今天你应该掌握的重点内容。

今天的内容不涉及动态规划的理论，我通过两个例子，给你展示了动态规划是如何解决问题的，并且一点一点详细给你讲解了动态规划解决问题的思路。这两个例子都是非常经典的动态规划问题，只要你真正搞懂这两个问题，基本上动态规划已经入门一半了。所以，你要多花点时间，真正弄懂这两个问题。

从例子中，你应该能发现，大部分动态规划能解决的问题，都可以通过回溯算法来解决，只不过回溯算法解决起来效率比较低，时间复杂度是指数级的。动态规划算法，在执行效率方面，要高很多。尽管执行效率提高了，但是动态规划的空间复杂度也提高了，所以，很多时候，我们会说，动态规划是一种空间换时间的算法思想。

我前面也说了，今天的内容并不涉及理论的知识。这两个例子的分析过程，我并没有涉及任何高深的理论方面的东西。而且，我个人觉得，贪心、分治、回溯、动态规划，这四个算法思想有关的理论知识，大部分都是“后验性”的，也就是说，在解决问题的过程中，我们往往是先想到如何用某个算法思想解决问题，然后才用算法理论知识，去验证这个算法思想解决问题的正确性。所以，你大可不必过于急于寻求动态规划的理论知识。

课后思考
“杨辉三角”不知道你听说过吗？我们现在对它进行一些改造。每个位置的数字可以随意填写，经过某个数字只能到达下面一层相邻的两个数字。

假设你站在第一层，往下移动，我们把移动到最底层所经过的所有数字之和，定义为路径的长度。请你编程求出从最高层移动到最底层的最短路径长度。



欢迎留言和我分享，也欢迎点击“请朋友读”，把今天的内容分享给你的好友，和他一起讨论、学习。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(123)

zixuan
贪心：一条路走到黑，就一次机会，只能哪边看着顺眼走哪边
回溯：一条路走到黑，无数次重来的机会，还怕我走不出来 (Snapshot View)
动态规划：拥有上帝视角，手握无数平行宇宙的历史存档， 同时发展出无数个未来 (Versioned Archive View)
2018-12-30

2

212

🌀🐑hfy🐣
首先得有个女朋友
2018-12-26


42

茴香根
我理解的动态规划，就是从全遍历的递归树为出发点，广度优先遍历，在遍历完每一层之后对每层结果进行合并（结果相同的）或舍弃（已经超出限制条件的），确保下一层遍历的数量不会超过限定条件数完W，通过这个操作达到大大减少不必要遍历的目的。
在空间复杂度优化上，通过在计算中只保留最优结果的目的重复利用内存空间。
2018-12-26


41

郭霖
王争老师动态规划讲得确实精彩，就是课后练习没有答案，有时候解不出来会很难受。我是看了下一篇文章的讲解然后明白了这篇文章的课后习题解法，这里分享一下吧，希望对大家有帮助。

int[][] matrix = {{5},{7,8},{2,3,4},{4,9,6,1},{2,7,9,4,5}};

public int yanghuiTriangle(int[][] matrix) {
    int[][] state = new int[matrix.length][matrix.length];
    state[0][0] = matrix[0][0];
    for (int i = 1; i < matrix.length; i++) {
        for (int j = 0; j < matrix[i].length; j++) {
            if (j == 0) state[i][j] = state[i - 1][j] + matrix[i][j];
            else if (j == matrix[i].length - 1) state[i][j] = state[i - 1][j - 1] + matrix[i][j];
            else {
                int top1 = state[i - 1][j - 1];
                int top2 = state[i - 1][j];
                state[i][j] = Math.min(top1, top2) + matrix[i][j];
            }
        }
    }
    int minDis = Integer.MAX_VALUE;
    for (int i = 0; i < matrix[matrix.length - 1].length; i++) {
        int distance = state[matrix.length - 1][i];
        if (distance < minDis) minDis = distance;
    }
    return minDis;
}
2019-01-02


35

煦暖
老师你好，您在专栏里提到好几次哨兵，啥时候给我们讲解一下呢？
2018-12-28

1

13

P@tricK
老师你这个只能精确到元，女朋友羊毛精说要求精确到0.01元，时间空间复杂度增大100倍🐶
作者回复: 👍 说的没错

2018-12-26


13

Monday
1、这里我特别强调一下代码中的第 6 行，j 需要从大到小来处理。
这里自己写代码调试完才恍然大悟，第i轮循环中新设置的值会干扰到后面的设值。

2、特别感谢争哥今天让其他的课程的老师来客串了一节课，让我有了更多的时间学习本节。
作者回复: 不着急你慢慢学就是了 不用非得跟的那么紧

2018-12-28


10

feifei
这个动态规划学习了三天了，把老师的代码都手练了一遍，感觉对动态规划有点感觉了！然后在写这个课后题，我也练了一遍，我练了这么多，但我觉得动态规则这个最重要的是每层可达的状态这个怎么计算的，这是重点，我开始的时候，用纸和笔，把老师的第一例子，中的状态都画了出来，然后再来看代码，感觉很有帮助！

杨晖三角的代码我我也贴出来，希望对其他童鞋有帮助，老师，也麻烦你帮忙看下，看我的实现是否存在问题，谢谢！

由于这个限制，限制长度，没有贴出来倒推出路径，可查看我的git
https://github.com/kkzfl22/datastruct/blob/master/src/main/java/com/liujun/datastruct/algorithm/dynamicProgramming/triangle/Triangle.java


int[][] status = new int[triangles.length][triangles[triangles.length - 1].length];

    int startPoint = triangles.length - 1;
    int maxpoint = triangles[triangles.length - 1].length;

    // 初始化相关的数据
    for (int i = 0; i <= startPoint; i++) {
      for (int j = 0; j < maxpoint; j++) {
        status[i][j] = -1;
      }
    }

    // 初始化杨晖三解的第一个顶点
    status[0][startPoint] = triangles[0][startPoint];

    // 开始求解第二个三角形顶点
    // 按层级遍历
    for (int i = 1; i <= startPoint; i++) {
      // 加入当前的位置节点
      int currIndex = 0;
      while (currIndex < maxpoint) {
        if (status[i - 1][currIndex] > 0) {
          // 计算左节点
          int leftValue = status[i - 1][currIndex] + triangles[i][currIndex - 1];

          // 1,检查当前左节点是否已经设置，如果没有，则直接设置
          if (status[i][currIndex - 1] == -1) {
            status[i][currIndex - 1] = leftValue;
          } else {
            if (leftValue < status[i][currIndex - 1]) {
              status[i][currIndex - 1] = leftValue;
            }
          }
          // 计算右节点
          int rightValue = status[i - 1][currIndex] + triangles[i][currIndex + 1];

          if (status[i][currIndex + 1] == -1) {
            status[i][currIndex + 1] = rightValue;
          }
          currIndex++;
        }
        currIndex++;
      }
    }

    int minValue = Integer.MAX_VALUE;
    for (int i = 0; i < maxpoint; i++) {
      if (minValue > status[startPoint][i] && status[startPoint][i] != -1) {
        minValue = status[startPoint][i];
      }
    }
    System.out.println("最短路径结果为:" + minValue);

2018-12-28


6

失火的夏天
杨辉三角的动态规划转移方程是：S[i][j] = min(S[i-1][j],S[i-1][j-1]) + a[i][j]。
其中a表示到这个点的value值，S表示到a[i][j]这个点的最短路径值。
这里没有做边界条件限制，只是列出一个方程通式。边界条件需要在代码里具体处理。个人感觉动态规划的思想关键在于如何列出动态规划方程，有了方程，代码基本就是水到渠成了。
2018-12-27


6

Andylee
老师，倒数第二段的代码(背包升级版)的12行的if条件判断是不是写错了
作者回复: 是的 我改下

2018-12-26


6

G.S.K
关于knapsack2函数
1 states表示当前背包总重量所有可能取值的集合
2 如果将第i个物品放入背包，我们需要在当前背包总重量的所有取值中，找到小于等于j的（j=w-items[i]）
3 为什么第6行j需要从大到小来处理？因为循环的目的是在当前背包总重量的所有可能取值中，找到小于等于j的，如果j从小到大来处理，states[j+items[i]] = true;这个赋值会影响后续的处理
public static int knapsack2(int[] items, int n, int w) {
  boolean[] states = new boolean[w+1]; // 默认值 false
  states[0] = true; // 第一行的数据要特殊处理，可以利用哨兵优化
  states[items[0]] = true;
  for (int i = 1; i < n; ++i) { // 动态规划
    for (int j = w-items[i]; j >= 0; --j) {// 把第 i 个物品放入背包
      if (states[j]==true) states[j+items[i]] = true;
    }
  }
  for (int i = w; i >= 0; --i) { // 输出结果
    if (states[i] == true) return i;
  }
  return 0;
}
2019-03-04


4

德尼
解答开篇代码的19行那的判断为什么是 j==-1？在上面的循环中假设从 w 到 3*w+1 没有可解的话，那么 j 的结果不应该是 3*w+2 吗？
2019-01-30


4

不上进的码农
关于课后杨辉三角最短路径的问题，应该用动态规划的两种方式都可以实现。1，状态转移，和背包问题升级版类似，同样使用二维数组记录，一维表示行，二维表示列，值保存最短路径，两种途径到达同一节点，我们只保存路径最短的值，然后一行一行遍历完，最后把最后一行进行排序，选择最小的即可。需要注意的是，在生成二维数组的时候最好是每行遍历生成，如第一行只有一个，第二行两个，这样可以节省一半的空间。2，方程转移，也就是从下往上来，每一个节点只有上层的两个节点能到达，也就是(i,j)节点，要么途径(i-1,j-1)节点,要么途径(i-1,j)节点，那么选择二者的最小值加上当前节点的数字，就是当前节点的最小值了，最后把最后一行排序选最小就OK了
2019-01-05


4

像玉一样的石头
老师，请教个问题，想了好久不知道该如何求解
关于汇率方面的，比如手里有100人民币，设计一个汇率转换的环，比如人民币-》美元-》日元-》韩元-》人民币，兑换一圈后，手里的钱一直在增加，这个问题该如何求解呢
2018-12-27


3

mαnajay
记录一下自己的 swift 版本一维数组动态规划装东西
/*
 *
 * 动态规划
 
 * 注意 Source 里面应该是 public, 运行时才不好报错
 **/
public struct DynamicProgramming {
    init() {
    }
    
    public static func knapsack2(_ items: Array<Int>, _ maxWeight: Int ) -> Void {
        let count = items.count
        var states = Array<Bool>.init(repeating: false, count: count + 1)
        // 首个没有放入
        states[0] = true
        // 首个放入了
        states[items[0]] = true
        for i in 1..<count { // 动态规划
            // 从去除已经计算过重量的最大的重量开始算起i, 把第 i 个物品放入背包
            for j in 0 ... (maxWeight - items[i]) {// 除了第 i 个物品, 剩余重量,如果有计算过的, 那么再加上第 i 个物品, 记录此时总重量的状态
                if (states[j] == true) {
                    let total = j + items[i]
                    states[total] = true
                }
            }
        }
        for v in (0 ... maxWeight).reversed() {
            if states[v] {
                print("maxWeight index: \(v)")
                break
            }
        }
    }
}
2019-04-19


2

黄均鹏
解开这道题的前提是首先得先有个女朋友
作者回复: 男朋友也可以的：）

2019-02-25


2

春去春又来
老师，这是我基于理解动态规划之后写出的优化版斐波那契数列，是否算是动态规划入门了 - -
function faibonacci(n) {
    //可以基于动态规划的思想去优化
    //存储每一个步骤的值，然后推导出之后的值
    let hash = {};
    const calcu = (n) => {
        if (n === 1 || n === 2) return 1;
        let a = hash[n - 1] || calcu(n - 1);
        let b = hash[n - 2] || calcu(n - 2);
        return a + b;
    }
    for (let i = 1; i <= n; i++) {
        hash[i] = calcu(i)
    }
    return hash[n]
}
作者回复: 👍 你还得把我文章里涉及的所有题目都搞明白、会默写才算入门呢

2019-02-15


2

Monday
思考题，杨辉三角，思路（Java版）：
记入参的数据结构是List<List<Integer>> list
状态转移方程为f(i,j)=list.get(i).get(j)+min(list.get(i - 1).get(j - 1)),list.get(i-1).get(j))
注意：需要注意数组越界问题。
2019-01-09


2

任悦
思考题这个杨辉三角有点巧了，最短路径就是最左边一列
2018-12-28


2

@
第三部分的代码，第11行是不是有问题？根据代码推不出states[4][3]=true???
2018-12-26


2
收起评论

99+99+






# 不定期福利第四期 | 刘超：我是怎么学习《数据结构与算法之美》的？



数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



不定期福利第四期 | 刘超：我是怎么学习《数据结构与算法之美》的？
刘超 2018-12-28



08:16
讲述：刘超 大小：7.59M
你好，我是刘超，是隔壁《趣谈网络协议》专栏的作者。今天来“串个门儿”，讲讲我学习《数据结构与算法之美》这个专栏的一些体会和感受。

《数据结构与算法之美》是目前“极客时间”订阅量最多的专栏，我也是其中最早购买的一员。我之所以一看就心动了，源于王争老师在开篇词里面说的那段话：

基础知识就像是一座大楼的地基，它决定了我们的技术高度。那技术人究竟都需要修炼哪些“内功”呢？我觉得，无外乎就是大学里的那些基础课程，操作系统、计算机网络、编译原理等等，当然还有数据结构和算法。

这个也是我写《趣谈网络协议》的时候，在开篇词里反复强调的观点。我为什么这么说呢？因为，我们作为面试官，在招人的时候，往往发现，使用框架速成的人很多，基础知识扎实的人少见，而基础不扎实会影响你以后学习新技术的速度和职业发展的广度。

和“极客时间”编辑聊的时候，我也多次表达，希望我们讲的东西和一般的培训机构有所区别，希望“极客时间”能做真正对程序员的技能提升和职业发展有价值的内容，希望“极客时间”能够成为真正帮助程序员成长的助手。

所以，当“极客时间”相继推出《Java 核心技术 36 讲》《零基础学 Python》《从 0 开始学架构》《MySQL 实战 45 讲》这些课程的时候，我非常开心。我希望将来能够继续覆盖到编译原理、操作系统、计算机组成原理等等。在这些课程里，算法是基础的基础，也是我本人很想精进的部分。

当然，除了长远的职业发展需要，搞定算法还有一个看得见、摸得着的好处，面试。

我经常讲，越是薪资低的企业，面试的时候，它们往往越注重你会不会做网站，甚至会要求你现场做出个东西来。你要注意了，这其实是在找代码熟练工。相反，越是薪资高的企业，越是重视考察基础知识。基础好，说明可塑性强，培养起来也比较快。而最牛的公司，考的往往是算法和思路。

相信很多购买《数据结构与算法之美》专栏的同学，下单的时候，已经想象自己面试的时候，在白板上挥洒代码，面试官频频点头的场景，想着自己马上就能“进驻牛公司，迎娶白富美”了。

然而，事实却是，武功套路容易学，扎马步基本功难练，编程也是一样。框架容易学，基本功难。你没办法讨巧，你要像郭靖学习降龙十八掌那样，一掌一掌劈下去才行。

于是，咱们这个专栏就开始了，你见到的仍然是困难的复杂度计算，指针指来指去，烧脑的逻辑，小心翼翼的边界条件判断。你发现，数据结构和算法好像并不是你上下班时间顺便听一听就能攻克的问题。你需要静下心来仔细想，拿个笔画一画，甚至要写一写代码，Debug 一下，才能够理解。是的，的确不轻松，那你坚持下来了吗？

我在这里分享一下我的学习思路，我将这个看起来困难的过程分成了几部分来完成。

第一部分，数据结构和算法的基础知识部分。如果在大学学过这门课，在专栏里，你会看到很多熟悉的描述。有些基础比较好的同学会质疑写这些知识的必要性。这大可不必，因为每个人的基础不一样，为了专栏内容的系统性和完整性，老师肯定要把这些基础知识重新讲述一遍的。对于这一部分内容，如果你的基础比较好，可以像学其他课程一样，在上下班或者午休的时候进行学习，主要是起到温习的作用。

第二部分，需要代码练习的部分。由于王争老师面试过很多人，所以在专栏里，他会列举一些他在面试中常常会问的题目。很多情况下，这些题目需要当场就能在白板上写出来。这些问题对于想要提升自己面试能力的同学来说，应该是很有帮助的。

我这里列举几个，你可以看看，是不是都能回答出来呢？

在链表这一节：单链表反转，链表中环的检测，两个有序的链表合并，删除链表倒数第 n 个结点，求链表的中间结点等。

在栈这一节，在函数调用中的应用，在表达式求值中的应用，在括号匹配中的应用。

在排序这一节，如何在 O(n) 的时间复杂度内查找一个无序数组中的第 K 大元素？

在二分查找这一节，二分查找的四个变体。

这些问题你都应该上手写写代码，或者在面试之前拿来练练手，而且，不仅仅只是实现主要功能。大公司的面试很多情况下都会考虑边界条件。只要被面试官抓住漏洞，就会被扣分，所以你最好事先写写。

第三部分，对于海量数据的处理思路问题。现在排名靠前的大公司，大都存在海量数据的处理问题。对于这一类问题，在面试的时候，也是经常会问到的。由于这类问题复杂度比较高，很少让当场就写代码，但是基本上会让你说一个思路，或者写写伪代码。想要解决海量数据的问题，你会的就不能只是基础的数据结构和算法了，你需要综合应用。如果平时没有想过这部分问题，临时被问，肯定会懵。

在专栏里，王争老师列举了大量这类问题，你要重点思考这类问题背后的思路，然后平时自己处理问题的时候，也多想想，如果这个问题数据量大的话，应该怎么办。这样多思考，面试的时候，思路很容易就来了。

比如，我这里随便列了几个，都是很经典的问题。你要是想不起来，就赶紧去复习吧！

比如说，我们有 10GB 的订单数据，我们希望按订单金额（假设金额都是正整数）进行排序，但是我们的内存有限，只有几百 MB，没办法一次性把 10GB 的数据都加载到内存中。这个时候该怎么办呢？

如果你所在的省有 50 万考生，如何通过成绩快速排序得出名次呢？

假设我们有 10 万个手机号码，希望将这 10 万个手机号码从小到大排序，你有什么比较快速的排序方法呢？

假设我们有 1000 万个整型数据，每个数据占 8 个字节，如何设计数据结构和算法，快速判断某个整数是否出现在这 1000 万数据中？ 我们希望这个功能不要占用太多的内存空间，最多不要超过 100MB，你会怎么做呢？

第四部分，工业实践部分。在每种数据结构的讲解中，老师会重点分析一些这些数据结构在工业上的实践，封装在库里面的，一般人不注意的。

我看王争老师也是个代码分析控。一般同学可能遇到问题，查一查有没有开源软件或者现成的库，可以用就完了。而王争老师会研究底层代码的实现，解析为什么这些在工业中大量使用的库，应该这样实现。这部分不但对于面试有帮助，对于实际开发也有很大的帮助。普通程序员和高手的差距，就是一个用完了就完了，一个用完了要看看为啥这样用。

例如，老师解析了 Glibc 中的 qsort() 函数，Java 中的 HashMap 如何实现工业级的散列表，Redis 中的有序集合（Sorted Set）的实现，工程上使用的红黑树等等。

尤其是对于哈希算法，老师解析了安全加密、数据校验、唯一标识、散列函数，负载均衡、数据分片、分布式存储等应用。如果你同时订阅了架构、微服务的课程，你会发现这些算法在目前最火的架构设计中，都有使用。

师傅领进门，修行在个人。尽管老师只是解析了其中一部分，但是咱们在平时使用开源软件和库的时候，也要多问个为什么。写完了程序，看看官方文档，看看原理解析的书，看看源代码，然后映射到算法与数据结构中，你会发现，这些知识和思路到处都在使用。

最后，我还想说一句，坚持，别放弃，啃下来。基础越扎实，路走得越远，走得越宽。加油！



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(51)

Monster
我感觉不定期福利可以让基础比较差的同学跟上进度，又可以根据文章中提到的点加强练习。感谢分享，我刚开始不懂数据结构，现在已经逐渐掌握了一些，虽然很吃力，很烧脑，但是要坚持！
2018-12-28


30

老杨同志
两位老师的课都订阅了，收获很多。算法课，最后的动态规划有点掉队，元旦动手写一下。
刻意练习，投入时间，一定要不这些基础拿下。给一起学习的小伙伴一点建议：对自己宽容一点，不要给自己定太高的目标，比如，读一遍文章就学会，读二遍就学会，只要不放弃，肯定能学会。会了以后，一次学会的和十次学会的区别并不大。太高的目标会影响心情，自我否定进而放弃。要学会自我激励。怕什么真理无穷, 进一寸有一寸的欢喜
2018-12-28


20

Jerry银银
王争老师，诚恳地请教一个问题：如何才能进Google，达到什么的水平才能进Google，烦请抽点时间指点迷津
——来自一个想精进的真得想做点不一样的事情的程序员


可能你的指点，会给这个普通的程序员指名一条阳光大道。人不怕吃苦，怕的是没有明确的方向
作者回复: 这个话题有点大 我可以搞个知识星球 分享分享😄

2018-12-30


9

www.xnsms.com小鸟接码
目前就就字段串算法 中下 以及后面有一个基于这个字符串算法的掉队了，被里面什么前缀后缀子串的名词绕晕了，直接跳过这几章，今天刚看到动态规划第一天，还能跟上，有被字符串算法那几章绕晕的点个赞，我相信不止我一个人
作者回复: 我觉得，能看懂70%就已经是高手了吧：）

2019-01-07


6

不一样的烟火
我三十岁了 学算法不知道还有没有前途
作者回复: 我也30了，职场才刚开始啊

2019-06-25


4

許敲敲
我是准备换行的，计算机小白，看了一遍下来，现在感觉了解一些概念，打算冲头开始复习一下，再配合leetco练习，也希望老师说下，每个内容，面试都要掌握到什么程度是写出来，还是讲出思路就好
2018-12-28


4

王宝
都是高人，你们的课我都买了
2018-12-28


4

涂
边看边忘真蓝瘦
2019-03-21


3

Cyen2018
都是高人
2018-12-28


3

令
还在排序那里扎实啃基础，每篇文章涉及的知识都在LeetCode做题练习，一遍看不懂就多看几遍，几遍看不懂就找相关文章相关书，一直慢慢的蜗牛般进行着，不认为自己掉队，为了进度快速的学不是自己想要的，来了就是为了学一节会一个知识点，认认真真学完对老师是一种尊重，对自己也有最大的交待，同时学习过程中深深感受到了老师的真诚，谢谢你。
2018-12-30


2

未来小鬼
红黑树那章实在看不懂，，，很期待专栏的linux 系统内核方面的原理课程！
2018-12-30


2

liangjf
数据结构与算法之美 掉队了，不过老师的网络课坚持下来了，收获良多。
2018-12-28


2

黑子
老师真是操碎了心…不断的鼓励我们，还有什么理由不坚持下去呢？
2018-12-28


2

Monster
感谢刘超老师的分享，趣谈网络协议我也订阅了，写的很生动形象。每期的不定期福利中提到的内容，我都会花时间再去重新看一遍，都会有新的体会和理解。希望看完掌握了这些课程，可以助我拿到高薪职位。
2018-12-28


2

CathyLin
谢谢刘超老师和王争老师的分享！看到发新文了就来看了一下，又有了前进的动力！
不好意思，我掉队了，因为一个很忙很忙的学期，几乎开学过后就再也没有看过专栏了。现在在补前面的，但我相信我会赶上来的。我也有一种很强烈的想把算法学好的愿望！我也想成为老师所说的那种高级程序员，不仅仅是用就完了，还要了解为什么这么用。
所以加油加油再加油！！！没有任何借口！！！
2018-12-28


2

小智e
看了很久的专栏，每一篇都认真看了，很有收获，感谢老师。
2019-03-28


1

qinggeouye
数据结构和算法基础、代码练习、海量数据处理、底层实现原理，路漫漫其修远兮...
2018-12-31


1

毛祥
我也掉队了！咬紧牙关重头再来，非常感谢老师们的指引点拨。
2018-12-28


1

传说中的成大大
看了 这篇文章 我觉得 这门课程 必须得随时都要复习 还有上一篇关于王争老师写的基础检测文章 都可以随时拿来复习 然后回答问题 如果那部分不会 就赶紧调到对应章节去复习
2018-12-28


1

JingZ
目前跟了9节课的《数据分析》，最近每天早上第一件事是打开手机扫一眼专栏，坚持留言问问题～考虑实际面试其实需要考察数据结构和算法基本功，恰巧看到这门课和《从0学习python》，订阅了～当做辅助数据分析的助手课程～祝自己从”化学化工+金融咨询”转型成为擅长数据分析的”行业研究员”～坚持～专栏每日留言1次～
2018-12-28


1
收起评论

5199+





# 41 | 动态规划理论：一篇文章带你彻底搞懂最优子结构、无后效性和重复子问题




数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



41 | 动态规划理论：一篇文章带你彻底搞懂最优子结构、无后效性和重复子问题
王争 2018-12-31



16:23
讲述：修阳 大小：15.01M
上一节，我通过两个非常经典的问题，向你展示了用动态规划解决问题的过程。现在你对动态规划应该有了一个初步的认识。

今天，我主要讲动态规划的一些理论知识。学完这节内容，可以帮你解决这样几个问题：什么样的问题可以用动态规划解决？解决动态规划问题的一般思考过程是什么样的？贪心、分治、回溯、动态规划这四种算法思想又有什么区别和联系？

理论的东西都比较抽象，不过你不用担心，我会结合具体的例子来讲解，争取让你这次就能真正理解这些知识点，也为后面的应用和实战做好准备。

“一个模型三个特征”理论讲解
什么样的问题适合用动态规划来解决呢？换句话说，动态规划能解决的问题有什么规律可循呢？实际上，动态规划作为一个非常成熟的算法思想，很多人对此已经做了非常全面的总结。我把这部分理论总结为“一个模型三个特征”。

首先，我们来看，什么是“一个模型”？它指的是动态规划适合解决的问题的模型。我把这个模型定义为“多阶段决策最优解模型”。下面我具体来给你讲讲。

我们一般是用动态规划来解决最优问题。而解决问题的过程，需要经历多个决策阶段。每个决策阶段都对应着一组状态。然后我们寻找一组决策序列，经过这组决策序列，能够产生最终期望求解的最优值。

现在，我们再来看，什么是“三个特征”？它们分别是最优子结构、无后效性和重复子问题。这三个概念比较抽象，我来逐一详细解释一下。

1. 最优子结构
最优子结构指的是，问题的最优解包含子问题的最优解。反过来说就是，我们可以通过子问题的最优解，推导出问题的最优解。如果我们把最优子结构，对应到我们前面定义的动态规划问题模型上，那我们也可以理解为，后面阶段的状态可以通过前面阶段的状态推导出来。

2. 无后效性
无后效性有两层含义，第一层含义是，在推导后面阶段的状态的时候，我们只关心前面阶段的状态值，不关心这个状态是怎么一步一步推导出来的。第二层含义是，某阶段状态一旦确定，就不受之后阶段的决策影响。无后效性是一个非常“宽松”的要求。只要满足前面提到的动态规划问题模型，其实基本上都会满足无后效性。

3. 重复子问题
这个概念比较好理解。前面一节，我已经多次提过。如果用一句话概括一下，那就是，不同的决策序列，到达某个相同的阶段时，可能会产生重复的状态。

“一个模型三个特征”实例剖析
“一个模型三个特征”这部分是理论知识，比较抽象，你看了之后可能还是有点懵，有种似懂非懂的感觉，没关系，这个很正常。接下来，我结合一个具体的动态规划问题，来给你详细解释。

假设我们有一个 n 乘以 n 的矩阵 w[n][n]。矩阵存储的都是正整数。棋子起始位置在左上角，终止位置在右下角。我们将棋子从左上角移动到右下角。每次只能向右或者向下移动一位。从左上角到右下角，会有很多不同的路径可以走。我们把每条路径经过的数字加起来看作路径的长度。那从左上角移动到右下角的最短路径长度是多少呢？



我们先看看，这个问题是否符合“一个模型”？

从 (0, 0) 走到 (n-1, n-1)，总共要走 2*(n-1) 步，也就对应着 2*(n-1) 个阶段。每个阶段都有向右走或者向下走两种决策，并且每个阶段都会对应一个状态集合。

我们把状态定义为 min_dist(i, j)，其中 i 表示行，j 表示列。min_dist 表达式的值表示从 (0, 0) 到达 (i, j) 的最短路径长度。所以，这个问题是一个多阶段决策最优解问题，符合动态规划的模型。



我们再来看，这个问题是否符合“三个特征”？

我们可以用回溯算法来解决这个问题。如果你自己写一下代码，画一下递归树，就会发现，递归树中有重复的节点。重复的节点表示，从左上角到节点对应的位置，有多种路线，这也能说明这个问题中存在重复子问题。



如果我们走到 (i, j) 这个位置，我们只能通过 (i-1, j)，(i, j-1) 这两个位置移动过来，也就是说，我们想要计算 (i, j) 位置对应的状态，只需要关心 (i-1, j)，(i, j-1) 两个位置对应的状态，并不关心棋子是通过什么样的路线到达这两个位置的。而且，我们仅仅允许往下和往右移动，不允许后退，所以，前面阶段的状态确定之后，不会被后面阶段的决策所改变，所以，这个问题符合“无后效性”这一特征。

刚刚定义状态的时候，我们把从起始位置 (0, 0) 到 (i, j) 的最小路径，记作 min_dist(i, j)。因为我们只能往右或往下移动，所以，我们只有可能从 (i, j-1) 或者 (i-1, j) 两个位置到达 (i, j)。也就是说，到达 (i, j) 的最短路径要么经过 (i, j-1)，要么经过 (i-1, j)，而且到达 (i, j) 的最短路径肯定包含到达这两个位置的最短路径之一。换句话说就是，min_dist(i, j) 可以通过 min_dist(i, j-1) 和 min_dist(i-1, j) 两个状态推导出来。这就说明，这个问题符合“最优子结构”。

min_dist(i, j) = w[i][j] + min(min_dist(i, j-1), min_dist(i-1, j))
两种动态规划解题思路总结
刚刚我讲了，如何鉴别一个问题是否可以用动态规划来解决。现在，我再总结一下，动态规划解题的一般思路，让你面对动态规划问题的时候，能够有章可循，不至于束手无策。

我个人觉得，解决动态规划问题，一般有两种思路。我把它们分别叫作，状态转移表法和状态转移方程法。

1. 状态转移表法
一般能用动态规划解决的问题，都可以使用回溯算法的暴力搜索解决。所以，当我们拿到问题的时候，我们可以先用简单的回溯算法解决，然后定义状态，每个状态表示一个节点，然后对应画出递归树。从递归树中，我们很容易可以看出来，是否存在重复子问题，以及重复子问题是如何产生的。以此来寻找规律，看是否能用动态规划解决。

找到重复子问题之后，接下来，我们有两种处理思路，第一种是直接用回溯加“备忘录”的方法，来避免重复子问题。从执行效率上来讲，这跟动态规划的解决思路没有差别。第二种是使用动态规划的解决方法，状态转移表法。第一种思路，我就不讲了，你可以看看上一节的两个例子。我们重点来看状态转移表法是如何工作的。

我们先画出一个状态表。状态表一般都是二维的，所以你可以把它想象成二维数组。其中，每个状态包含三个变量，行、列、数组值。我们根据决策的先后过程，从前往后，根据递推关系，分阶段填充状态表中的每个状态。最后，我们将这个递推填表的过程，翻译成代码，就是动态规划代码了。

尽管大部分状态表都是二维的，但是如果问题的状态比较复杂，需要很多变量来表示，那对应的状态表可能就是高维的，比如三维、四维。那这个时候，我们就不适合用状态转移表法来解决了。一方面是因为高维状态转移表不好画图表示，另一方面是因为人脑确实很不擅长思考高维的东西。

现在，我们来看一下，如何套用这个状态转移表法，来解决之前那个矩阵最短路径的问题？

从起点到终点，我们有很多种不同的走法。我们可以穷举所有走法，然后对比找出一个最短走法。不过如何才能无重复又不遗漏地穷举出所有走法呢？我们可以用回溯算法这个比较有规律的穷举算法。

回溯算法的代码实现如下所示。代码很短，而且我前面也分析过很多回溯算法的例题，这里我就不多做解释了，你自己来看看。

private int minDist = Integer.MAX_VALUE; // 全局变量或者成员变量
// 调用方式：minDistBacktracing(0, 0, 0, w, n);
public void minDistBT(int i, int j, int dist, int[][] w, int n) {
  // 到达了 n-1, n-1 这个位置了，这里看着有点奇怪哈，你自己举个例子看下
  if (i == n && j == n) {
    if (dist < minDist) minDist = dist;
    return;
  }
  if (i < n) { // 往下走，更新 i=i+1, j=j
    minDistBT(i + 1, j, dist+w[i][j], w, n);
  }
  if (j < n) { // 往右走，更新 i=i, j=j+1
    minDistBT(i, j+1, dist+w[i][j], w, n);
  }
}
有了回溯代码之后，接下来，我们要画出递归树，以此来寻找重复子问题。在递归树中，一个状态（也就是一个节点）包含三个变量 (i, j, dist)，其中 i，j 分别表示行和列，dist 表示从起点到达 (i, j) 的路径长度。从图中，我们看出，尽管 (i, j, dist) 不存在重复的，但是 (i, j) 重复的有很多。对于 (i, j) 重复的节点，我们只需要选择 dist 最小的节点，继续递归求解，其他节点就可以舍弃了。



既然存在重复子问题，我们就可以尝试看下，是否可以用动态规划来解决呢？

我们画出一个二维状态表，表中的行、列表示棋子所在的位置，表中的数值表示从起点到这个位置的最短路径。我们按照决策过程，通过不断状态递推演进，将状态表填好。为了方便代码实现，我们按行来进行依次填充。



弄懂了填表的过程，代码实现就简单多了。我们将上面的过程，翻译成代码，就是下面这个样子。结合着代码、图和文字描述，应该更容易理解我讲的内容。

public int minDistDP(int[][] matrix, int n) {
  int[][] states = new int[n][n];
  int sum = 0;
  for (int j = 0; j < n; ++j) { // 初始化 states 的第一行数据
    sum += matrix[0][j];
    states[0][j] = sum;
  }
  sum = 0;
  for (int i = 0; i < n; ++i) { // 初始化 states 的第一列数据
    sum += matrix[i][0];
    states[i][0] = sum;
  }
  for (int i = 1; i < n; ++i) {
    for (int j = 1; j < n; ++j) {
      states[i][j] = 
            matrix[i][j] + Math.min(states[i][j-1], states[i-1][j]);
    }
  }
  return states[n-1][n-1];
}
2. 状态转移方程法
状态转移方程法有点类似递归的解题思路。我们需要分析，某个问题如何通过子问题来递归求解，也就是所谓的最优子结构。根据最优子结构，写出递归公式，也就是所谓的状态转移方程。有了状态转移方程，代码实现就非常简单了。一般情况下，我们有两种代码实现方法，一种是递归加“备忘录”，另一种是迭代递推。

我们还是拿刚才的例子来举例。最优子结构前面已经分析过了，你可以回过头去再看下。为了方便你查看，我把状态转移方程放到这里。

min_dist(i, j) = w[i][j] + min(min_dist(i, j-1), min_dist(i-1, j))
这里我强调一下，状态转移方程是解决动态规划的关键。如果我们能写出状态转移方程，那动态规划问题基本上就解决一大半了，而翻译成代码非常简单。但是很多动态规划问题的状态本身就不好定义，状态转移方程也就更不好想到。

下面我用递归加“备忘录”的方式，将状态转移方程翻译成来代码，你可以看看。对于另一种实现方式，跟状态转移表法的代码实现是一样的，只是思路不同。

private int[][] matrix = 
         {{1，3，5，9}, {2，1，3，4}，{5，2，6，7}，{6，8，4，3}};
private int n = 4;
private int[][] mem = new int[4][4];
public int minDist(int i, int j) { // 调用 minDist(n-1, n-1);
  if (i == 0 && j == 0) return matrix[0][0];
  if (mem[i][j] > 0) return mem[i][j];
  int minLeft = Integer.MAX_VALUE;
  if (j-1 >= 0) {
    minLeft = minDist(i, j-1);
  }
  int minUp = Integer.MAX_VALUE;
  if (i-1 >= 0) {
    minUp = minDist(i-1, j);
  }
  
  int currMinDist = matrix[i][j] + Math.min(minLeft, minUp);
  mem[i][j] = currMinDist;
  return currMinDist;
}
两种动态规划解题思路到这里就讲完了。我要强调一点，不是每个问题都同时适合这两种解题思路。有的问题可能用第一种思路更清晰，而有的问题可能用第二种思路更清晰，所以，你要结合具体的题目来看，到底选择用哪种解题思路。

四种算法思想比较分析
到今天为止，我们已经学习了四种算法思想，贪心、分治、回溯和动态规划。今天的内容主要讲些理论知识，我正好一块儿也分析一下这四种算法，看看它们之间有什么区别和联系。

如果我们将这四种算法思想分一下类，那贪心、回溯、动态规划可以归为一类，而分治单独可以作为一类，因为它跟其他三个都不大一样。为什么这么说呢？前三个算法解决问题的模型，都可以抽象成我们今天讲的那个多阶段决策最优解模型，而分治算法解决的问题尽管大部分也是最优解问题，但是，大部分都不能抽象成多阶段决策模型。

回溯算法是个“万金油”。基本上能用的动态规划、贪心解决的问题，我们都可以用回溯算法解决。回溯算法相当于穷举搜索。穷举所有的情况，然后对比得到最优解。不过，回溯算法的时间复杂度非常高，是指数级别的，只能用来解决小规模数据的问题。对于大规模数据的问题，用回溯算法解决的执行效率就很低了。

尽管动态规划比回溯算法高效，但是，并不是所有问题，都可以用动态规划来解决。能用动态规划解决的问题，需要满足三个特征，最优子结构、无后效性和重复子问题。在重复子问题这一点上，动态规划和分治算法的区分非常明显。分治算法要求分割成的子问题，不能有重复子问题，而动态规划正好相反，动态规划之所以高效，就是因为回溯算法实现中存在大量的重复子问题。

贪心算法实际上是动态规划算法的一种特殊情况。它解决问题起来更加高效，代码实现也更加简洁。不过，它可以解决的问题也更加有限。它能解决的问题需要满足三个条件，最优子结构、无后效性和贪心选择性（这里我们不怎么强调重复子问题）。

其中，最优子结构、无后效性跟动态规划中的无异。“贪心选择性”的意思是，通过局部最优的选择，能产生全局的最优选择。每一个阶段，我们都选择当前看起来最优的决策，所有阶段的决策完成之后，最终由这些局部最优解构成全局最优解。

内容小结
今天的内容到此就讲完了，我带你来复习一下。

我首先讲了什么样的问题适合用动态规划解决。这些问题可以总结概括为“一个模型三个特征”。其中，“一个模型”指的是，问题可以抽象成分阶段决策最优解模型。“三个特征”指的是最优子节、无后效性和重复子问题。

然后，我讲了两种动态规划的解题思路。它们分别是状态转移表法和状态转移方程法。其中，状态转移表法解题思路大致可以概括为，回溯算法实现 - 定义状态 - 画递归树 - 找重复子问题 - 画状态转移表 - 根据递推关系填表 - 将填表过程翻译成代码。状态转移方程法的大致思路可以概括为，找最优子结构 - 写状态转移方程 - 将状态转移方程翻译成代码。

最后，我们对比了之前讲过的四种算法思想。贪心、回溯、动态规划可以解决的问题模型类似，都可以抽象成多阶段决策最优解模型。尽管分治算法也能解决最优问题，但是大部分问题的背景都不适合抽象成多阶段决策模型。

今天的内容比较偏理论，可能会不好理解。很多理论知识的学习，单纯的填鸭式讲给你听，实际上效果并不好。要想真的把这些理论知识理解透，化为己用，还是需要你自己多思考，多练习。等你做了足够多的题目之后，自然就能自己悟出一些东西，这样再回过头来看理论，就会非常容易看懂。

所以，在今天的内容中，如果有哪些地方你还不能理解，那也没关系，先放一放。下一节，我会运用今天讲到的理论，再解决几个动态规划的问题。等你学完下一节，可以再回过头来看下今天的理论知识，可能就会有一种顿悟的感觉。

课后思考
硬币找零问题，我们在贪心算法那一节中讲过一次。我们今天来看一个新的硬币找零问题。假设我们有几种不同币值的硬币 v1，v2，……，vn（单位是元）。如果我们要支付 w 元，求最少需要多少个硬币。比如，我们有 3 种不同的硬币，1 元、3 元、5 元，我们要支付 9 元，最少需要 3 个硬币（3 个 3 元的硬币）。

欢迎留言和我分享，也欢迎点击“请朋友读”，把今天的内容分享给你的好友，和他一起讨论、学习。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(59)

yaya
可以看做爬阶梯问题，分别可以走1.3.5步，怎么最少走到9步，动态转移方程为f(9)=1+min(f(8),f(6),f(4))
作者回复: 👍

2019-01-03

1

75

郭霖
动态规划状态转移表解法：

public int minCoins(int money) {
  if (money == 1 || money == 3 || money == 5) return 1;
  boolean [][] state = new boolean[money][money + 1];
  if (money >= 1) state[0][1] = true;
  if (money >= 3) state[0][3] = true;
  if (money >= 5) state[0][5] = true;
  for (int i = 1; i < money; i++) {
    for (int j = 1; j <= money; j++) {
      if (state[i - 1][j]) {
        if (j + 1 <= money) state[i][j + 1] = true;
        if (j + 3 <= money) state[i][j + 3] = true;
        if (j + 5 <= money) state[i][j + 5] = true;
        if (state[i][money]) return i + 1;
      }
    }
  }
  return money;
}
2019-01-03

1

26

煦暖
状态转移表法，二维状态表的图中，第一行下面的表达式：
文中“min(4+3, 8+3)”应该是“min(4+3, 9+3)”
作者回复: 嗯嗯 是的 笔误 抱歉

2019-01-03


11

Alpha.
回溯算法实现矩阵最短路径会有边界问题，下面是修改后的代码。
private static int MIN_DIS = Integer.MAX_VALUE;
public static void minDisByBT(int i, int j, int[][] w, int n, int distance) {
        distance += w[i][j];
        if (i == n - 1 && j == n - 1) {
            if (distance < MIN_DIS) MIN_DIS = distance;
            return;
        }
        if (i < n - 1) {
            minDisByBT(i + 1, j, w, n, distance);
        }
        if (j < n - 1) {
            minDisByBT(i, j + 1, w, n, distance);
        }
    }
2019-02-22


8

feifei
经过一个星期的努力，这个动态规划终于有点感觉了，今天来做题，我也来试试解这个题目，在看了第一个童鞋的解法后，感觉这个写的太死了，再就是没有反推出哪些币的组合，我就自己来实现了下！
我也想说动态规划的解，真不容易啊，我按照老师提供的方法，先使用回塑写出了暴力搜索，然后再画出了递归树，找到状态组合，然后才来写这个动态规划，感觉好复杂，不过吧，这个使用状态转移方程，我感觉更难，比这个递归还难写。。。。。。，最主要是这个状态想不到，但这个动态规划代码写完了，我又感觉能写方程了，我想哭。。。。。。。


public int countMoneyMin(int[] moneyItems, int resultMemory) {

    if (null == moneyItems || moneyItems.length < 1) {
      return -1;
    }

    if (resultMemory < 1) {
      return -1;
    }

    // 计算遍历的层数，此按最小金额来支付即为最大层数
    int levelNum = resultMemory / moneyItems[0];
    int leng = moneyItems.length;

    int[][] status = new int[levelNum][resultMemory + 1];

    // 初始化状态数组
    for (int i = 0; i < levelNum; i++) {
      for (int j = 0; j < resultMemory + 1; j++) {
        status[i][j] = -1;
      }
    }

    // 将第一层的数数据填充
    for (int i = 0; i < leng; i++) {
      status[0][moneyItems[i]] = moneyItems[i];
    }

    int minNum = -1;

    // 计算推导状态
    for (int i = 1; i < levelNum; i++) {
      // 推导出当前状态
      for (int j = 0; j < resultMemory; j++) {
        if (status[i - 1][j] != -1) {
          // 遍历元素,进行累加
          for (int k = 0; k < leng; k++) {
            if (j + moneyItems[k] <= resultMemory) {
              status[i][j + moneyItems[k]] = moneyItems[k];
            }
          }
        }

        // 找到最小的张数
        if (status[i][resultMemory] >= 0) {
          minNum = i + 1;
          break;
        }
      }

      if (minNum > 0) {
        break;
      }
    }

    int befValue = resultMemory;

    // 进行反推出，币的组合
    for (int i = minNum - 1; i >= 0; i--) {
      for (int j = resultMemory; j >= 0; j--) {
        if (j == befValue) {
          System.out.println("当前的为:" + status[i][j]);
          befValue = befValue - status[i][j];
          break;
        }
      }
    }

    return minNum;
  }
作者回复: 👍 都有这个似懂非懂的过程的 多练习 慢慢就有感觉了

2019-01-06


8

攻玉

```
# 1. 回溯 : 太慢了
coin = 0
def minCoin(money):
    global coin
    if money == 1: return 1
    if money == 2: return 2
    if money == 3: return 1
    if money == 4: return 2
    if money == 5: return 1
# if money <= 0: return

    coin = 1 + min(minCoin(money-1) , minCoin(money-3) , minCoin(money-5))
    print(money , coin)
    return coin

print(minCoin(10))


# 2.写备忘录, 记录重复的递归项:
# 速度提升不知道几十万倍 ! 缺点就是有递归层数的限制 , 超过最大递归层数(几百?)会报错
import numpy as np
map = {} # 初始化一个 dict
coin = 0
def minCoin(money):
    global coin
    # 先查表 :
    if money in map: # 如果在 map 的第一列里面 , 说明记录过.
        return map[money] # 直接返回 minCoin
    if money == 1: return 1
    if money == 2: return 2
    if money == 3: return 1
    if money == 4: return 2
    if money == 5: return 1
# if money <= 0: return

    coin = 1 + min(minCoin(money-1) , minCoin(money-3) , minCoin(money-5))
    map[money] = coin # 放入map

    return coin
    
print(minCoin(100))
print(map)


'''

# 3.DP .
### 备忘录有了, 我们尝试根据递推公式 :
# coin = 1 + min(minCoin(money-1) , minCoin(money-3) , minCoin(money-5))
### 书写状态转移方程 :

s = {} # 设 s 为状态数组 :
s[1] ,s[2] ,s[3] ,s[4] ,s[5] = 1,2,1,2,1

def minCoinDP(money):
    for i in range(6,money+1):
        s[i] = 1+ min(s[i-1],s[i-3],s[i-5])

    return s[money]


print(minCoinDP(10000))
2019-03-13


```

2

猫头鹰爱拿铁
看了这一篇豁然开朗，上一篇的习题也会做了。感觉这些涉及多决策的习题基本上第一眼都能想到回溯法，但是用动态规划法就要好好想一想，关键还是老师说的动态转移方程式。我尝试用两种方法做了一遍，回溯法和动态规划法。

int minNum = Integer.MAX_VALUE;

/**
* 使用回溯法获取给定金额最小的硬币数量，调用时num为0
*
* @param coinVal
* 硬币值数组
* @param total
* 指定的金额
* @param num
* 每个解法所得到的硬币数量
*/
public void getLeastCoinNumByBackTracking(int[] coinVal, int total, int num) {
if (total == 0) {
if (num < minNum)
minNum = num;
return;
}
for (int i = 0; i < coinVal.length; i++) {
if (total - coinVal[i] >= 0) {
getLeastCoinNumByBackTracking(coinVal, total - coinVal[i],
num + 1);
}
}
}

/**
* 使用动态规划法获取给定金额下最小的硬币数量
*
* @param coinVal
* 硬币值数组
* @param total
* 给定金额
* @return 给定金额下最小的硬币数量
*/
public int getLeastCoinNumByDP(int[] coinVal, int total) {
// coinNum存放的是每个对应金额下最少硬币的最优解
int coinNum[] = new int[total + 1];
coinNum[0] = 0;
//初始化coinNum数组，硬币值数组对应的值的硬币数量都为1
for (int i = 0; i < coinVal.length; i++) {
coinNum[coinVal[i]] = 1;
}

for (int i = 1; i <= total; i++) {
if (coinNum[i] == 0) {
int minTemp = Integer.MAX_VALUE; // 获取每个i对应的最小硬币数值
for (int j = 0; j < coinVal.length; j++) {
if (i - coinVal[j] > 0) {
int v1 = coinNum[i - coinVal[j]] + 1;
if (v1 < minTemp) {
minTemp = v1;
}
}
}
coinNum[i] = minTemp;
}
}
return coinNum[total];
}
2019-01-08


2

blacknhole
状态转移方程法的代码实现有问题：
1，int minUp = Integer.MIN_VALUE;语句应赋值为Integer.MAX_VALUE。
2，返回前应将返回值赋值给mem[i][j]。
作者回复: 已改 多谢指正

2018-12-31


2

想当上帝的司机
放假了还在更新 赞
2018-12-31


2

攻玉
import numpy as np
老师 , 那个回溯法的代码好像不太对 , 我用 python 写了一个
import sys
minDist = sys.maxsize
n = 4 # 这是个 4*4 的矩阵 .
w = np.array([[0,3,5,9],[2,1,3,4],[5,2,6,7],[6,8,4,3]])
 dist = np.zeros((4,4)) # 定义 dist(i, j) 为到达点 (i,j) 的路径长度
 dist[i, j] = w[i,j] + min(dist[i-1, j] , dist[i, j-1])

def minDistBackTrace(i, j, dist, w, n):
    global minDist
    dist += w[i][j]
    if i==n -1 and j == n-1 :
        if dist < minDist: minDist = dist
        return

    if i < n-1:
        minDistBackTrace(i + 1, j, dist, w, n)
    if j < n-1:
        minDistBackTrace(i , j + 1, dist, w, n)

2019-03-12

2

1

菜菜
老师，回溯法求矩阵最短路径的代码会出错，边界条件的问题
2019-03-05


1

Zix
经测试，状态转移表法与状态转移方程法的代码均无误。
但是此问题最开始用的回溯法，会出现数组越界的问题，边界还需要再判断，请老师解答。
2019-02-26


1

Zix
老师，回溯的那种解法，代码有问题，会出现数组越界，边界的问题。
作者回复: 嗯嗯 我再去看下

2019-02-26


1

春去春又来
老师，我按照文章里面的代码敲了一遍，
状态转移表法的那个代码运行结果等于 等于19
状态转移方程法的那个代码运行结果等于 18

不知道大家是不是这样的？？？？？？
作者回复: 我擦，我研究下

2019-02-21


1

随风

看了这么久，很少留言、很多思考题也只停留在想的层面，很少去实现。刚好有点时间，把动态规则这个思考题想了一下，顺便用Java实现出来。
思考题：如上面值{1,3,5}凑9块钱的最小张数、我们可以分成3个阶段。
第一阶段：用1块钱，那么1块钱可以有1、2、3...9张这几种可能。
第二阶段：在第一阶段的金额还有张数上增加3元的
第三阶段：在第二阶段总金额上载增加5元的。
状态转移方程:Sum(n) = Sum(n-1) + v * num ,v表示当前阶段的面值，num表示当前阶段的张数。
代码实现如下：
public class DynMoney {
private static int minNum = Integer.MAX_VALUE;
/**
* Sum(n) = Sum(n-1) + v * num
* @param sum 凑的总额
* @param v 钱的面额
* @return
*/
public static int minMoney(int sum,int v[]) {
nextStep(0, 0, 0, sum, v);
return minNum;
}
/**
* @param n 钱的张数.
* @param c 到那个阶段
* @param cv 凑的钱数
* @param sum 要凑的钱的总数
* @param v 面额
*/
public static void nextStep(int n,int c, int cv,int sum,int v[]) {
//金额凑够了
if (cv == sum) {
minNum = Math.min(minNum, n);
return;
}
//或者凑到最后阶段，没凑够总金额
if(c == v.length) {
return;
}
//每个阶段，钱的张数，张数应该小与等于 凑的金额/面额
for(int j=0; j <= sum/v[c]; j++) {
if(cv + v[c]*j <= sum) {
//当前阶段凑的不超额，下阶段继续凑
nextStep(n+j, c+1,cv + v[c]*j, sum,v);
}
}
}

public static void main(String arg[]) {
System.out.println(minMoney(8, new int[]{1,3,5}));
}
}
2019-02-14


1

Kudo
思考题解答：
动态规划解法（python实现）
状态转移方程：min_count[i] = min(min_count[j] + 1) for any j < i
import sys
def minCoinCount(values, amount):
    '''
    values: 硬币面值数组
    amount: 要凑的总价值
    '''
    min_count = [sys.maxsize] * (amount+1) # 初始化
    min_count[0] = 0
    for i in range(1, amount+1): # [1, amount+1)左闭右开
        for j in range(i): # [0,i)左闭右开
            for v in values: # 依次考察每种币值
                if j + v == i and min_count[j] + 1 < min_count[i]: # 能凑齐且最小
                    min_count[i] = min_count[j] + 1
    
    print(min_count[amount]) # 输出结果
    
使用方法
values = [1,3,5]
minCoinCount(values, 9)
2019-01-05


1

Kudo
思考题解答
使用回溯法（python实现）：
import sys
min_count = sys.maxsize # 用于追踪最小值

def minCoinCount(i, values, amount, ca):
    '''
    i: 硬币数量
    values: 硬币面值数组
    amount: 要凑的总价值
    ca: current amount 当前价值
    '''
    global min_count
    if ca == amount or i == amount: # 总共amount步
        if ca == amount and i < min_count:
            min_count = i
        return
        
    for v in values: # 依次考察每种币值
        if ca + v <= amount: # 保证不超总值价
            minCoinCount(i+1, values, amount, ca+v)
            
使用方法
values = [1,3,5]
minCoinCount(0, values, 9, 0)
print(min_count)
2019-01-04


1

farFlight
用动态规划的方法，初始化那些等于币值的价值，然后从1开始一步一步推到w元，f(k)代表k元时最少的硬币数量，状态方程是：
f(k) = min(f(k-vi)) + 1, i需要遍历所有的币种。

另外，请问老师之后会多讲一些回溯的技巧吗？回溯方法虽然本身复杂度比较高，但是可以用一些剪枝技巧branch and bound，这样实际运行时间也能很快，而且很多复杂的问题用回溯法思路会比较简单。
作者回复: 高级篇会讲到

2018-12-31


1

Monday
2018最后一次更新，我通读三遍跟上打卡了。本节理论归纳的很精简，适合动态规划求解的问题的特性：一个模型，三个特征。
一个模型：多阶段决策最优解
三个特征：最优子结构，无后效性，重复子问题。
2018-12-31


1

frogoscar
动态规划的课太帅了。老师厉害
2018-12-31


1
收起评论

5999+






# 42 | 动态规划实战：如何实现搜索引擎中的拼写纠错功能？


在Trie 树那节我们讲过，利用 Trie 树，可以实现搜索引擎的关键词提示功能，这样可以节省用户输入搜索关键词的时间。实际上，搜索引擎在用户体验方面的优化还有很多，比如你可能经常会用的拼写纠错功能。

当你在搜索框中，一不小心输错单词时，搜索引擎会非常智能地检测出你的拼写错误，并且用对应的正确单词来进行搜索。作为一名软件开发工程师，你是否想过，这个功能是怎么实现的呢？



如何量化两个字符串的相似度？
计算机只认识数字，所以要解答开篇的问题，我们就要先来看，如何量化两个字符串之间的相似程度呢？有一个非常著名的量化方法，那就是编辑距离（Edit Distance）。

顾名思义，编辑距离指的就是，将一个字符串转化成另一个字符串，需要的最少编辑操作次数（比如增加一个字符、删除一个字符、替换一个字符）。编辑距离越大，说明两个字符串的相似程度越小；相反，编辑距离就越小，说明两个字符串的相似程度越大。对于两个完全相同的字符串来说，编辑距离就是 0。

根据所包含的编辑操作种类的不同，编辑距离有多种不同的计算方式，比较著名的有莱文斯坦距离（Levenshtein distance）和最长公共子串长度（Longest common substring length）。其中，莱文斯坦距离允许增加、删除、替换字符这三个编辑操作，最长公共子串长度只允许增加、删除字符这两个编辑操作。

而且，莱文斯坦距离和最长公共子串长度，从两个截然相反的角度，分析字符串的相似程度。莱文斯坦距离的大小，表示两个字符串差异的大小；而最长公共子串的大小，表示两个字符串相似程度的大小。

关于这两个计算方法，我举个例子给你说明一下。这里面，两个字符串 mitcmu 和 mtacnu 的莱文斯坦距离是 3，最长公共子串长度是 4。



了解了编辑距离的概念之后，我们来看，如何快速计算两个字符串之间的编辑距离？

如何编程计算莱文斯坦距离？
之前我反复强调过，思考过程比结论更重要，所以，我现在就给你展示一下，解决这个问题，我的完整的思考过程。

这个问题是求把一个字符串变成另一个字符串，需要的最少编辑次数。整个求解过程，涉及多个决策阶段，我们需要依次考察一个字符串中的每个字符，跟另一个字符串中的字符是否匹配，匹配的话如何处理，不匹配的话又如何处理。所以，这个问题符合多阶段决策最优解模型。

我们前面讲了，贪心、回溯、动态规划可以解决的问题，都可以抽象成这样一个模型。要解决这个问题，我们可以先看一看，用最简单的回溯算法，该如何来解决。

回溯是一个递归处理的过程。如果 a[i] 与 b[j] 匹配，我们递归考察 a[i+1] 和 b[j+1]。如果 a[i] 与 b[j] 不匹配，那我们有多种处理方式可选：

可以删除 a[i]，然后递归考察 a[i+1] 和 b[j]；

可以删除 b[j]，然后递归考察 a[i] 和 b[j+1]；

可以在 a[i] 前面添加一个跟 b[j] 相同的字符，然后递归考察 a[i] 和 b[j+1];

可以在 b[j] 前面添加一个跟 a[i] 相同的字符，然后递归考察 a[i+1] 和 b[j]；

可以将 a[i] 替换成 b[j]，或者将 b[j] 替换成 a[i]，然后递归考察 a[i+1] 和 b[j+1]。

我们将上面的回溯算法的处理思路，翻译成代码，就是下面这个样子：

private char[] a = "mitcmu".toCharArray();
private char[] b = "mtacnu".toCharArray();
private int n = 6;
private int m = 6;
private int minDist = Integer.MAX_VALUE; // 存储结果
// 调用方式 lwstBT(0, 0, 0);
public lwstBT(int i, int j, int edist) {
  if (i == n || j == m) {
    if (i < n) edist += (n-i);
    if (j < m) edist += (m - j);
    if (edist < minDist) minDist = edist;
    return;
  }
  if (a[i] == b[j]) { // 两个字符匹配
    lwstBT(i+1, j+1, edist);
  } else { // 两个字符不匹配
    lwstBT(i + 1, j, edist + 1); // 删除 a[i] 或者 b[j] 前添加一个字符
    lwstBT(i, j + 1, edist + 1); // 删除 b[j] 或者 a[i] 前添加一个字符
    lwstBT(i + 1, j + 1, edist + 1); // 将 a[i] 和 b[j] 替换为相同字符
  }
}
根据回溯算法的代码实现，我们可以画出递归树，看是否存在重复子问题。如果存在重复子问题，那我们就可以考虑能否用动态规划来解决；如果不存在重复子问题，那回溯就是最好的解决方法。



在递归树中，每个节点代表一个状态，状态包含三个变量 (i, j, edist)，其中，edist 表示处理到 a[i] 和 b[j] 时，已经执行的编辑操作的次数。

在递归树中，(i, j) 两个变量重复的节点很多，比如 (3, 2) 和 (2, 3)。对于 (i, j) 相同的节点，我们只需要保留 edist 最小的，继续递归处理就可以了，剩下的节点都可以舍弃。所以，状态就从 (i, j, edist) 变成了 (i, j, min_edist)，其中 min_edist 表示处理到 a[i] 和 b[j]，已经执行的最少编辑次数。

看到这里，你有没有觉得，这个问题跟上两节讲的动态规划例子非常相似？不过，这个问题的状态转移方式，要比之前两节课中讲到的例子都要复杂很多。上一节我们讲的矩阵最短路径问题中，到达状态 (i, j) 只能通过 (i-1, j) 或 (i, j-1) 两个状态转移过来，而今天这个问题，状态 (i, j) 可能从 (i-1, j)，(i, j-1)，(i-1, j-1) 三个状态中的任意一个转移过来。



基于刚刚的分析，我们可以尝试着将把状态转移的过程，用公式写出来。这就是我们前面讲的状态转移方程。

如果：a[i]!=b[j]，那么：min_edist(i, j) 就等于：
min(min_edist(i-1,j)+1, min_edist(i,j-1)+1, min_edist(i-1,j-1)+1)
 
如果：a[i]==b[j]，那么：min_edist(i, j) 就等于：
min(min_edist(i-1,j)+1, min_edist(i,j-1)+1，min_edist(i-1,j-1))
 
其中，min 表示求三数中的最小值。     
了解了状态与状态之间的递推关系，我们画出一个二维的状态表，按行依次来填充状态表中的每个值。



我们现在既有状态转移方程，又理清了完整的填表过程，代码实现就非常简单了。我将代码贴在下面，你可以对比着文字解释，一起看下。

public int lwstDP(char[] a, int n, char[] b, int m) {
  int[][] minDist = new int[n][m];
  for (int j = 0; j < m; ++j) { // 初始化第 0 行:a[0..0] 与 b[0..j] 的编辑距离
    if (a[0] == b[j]) minDist[0][j] = j;
    else if (j != 0) minDist[0][j] = minDist[0][j-1]+1;
    else minDist[0][j] = 1;
  }
  for (int i = 0; i < n; ++i) { // 初始化第 0 列:a[0..i] 与 b[0..0] 的编辑距离
    if (a[i] == b[0]) minDist[i][0] = i;
    else if (i != 0) minDist[i][0] = minDist[i-1][0]+1;
    else minDist[i][0] = 1;
  }
  for (int i = 1; i < n; ++i) { // 按行填表
    for (int j = 1; j < m; ++j) {
      if (a[i] == b[j]) minDist[i][j] = min(
          minDist[i-1][j]+1, minDist[i][j-1]+1, minDist[i-1][j-1]);
      else minDist[i][j] = min(
          minDist[i-1][j]+1, minDist[i][j-1]+1, minDist[i-1][j-1]+1);
    }
  }
  return minDist[n-1][m-1];
}
 
private int min(int x, int y, int z) {
  int minv = Integer.MAX_VALUE;
  if (x < minv) minv = x;
  if (y < minv) minv = y;
  if (z < minv) minv = z;
  return minv;
}
你可能会说，我虽然能看懂你讲的思路，但是遇到新的问题的时候，我还是会感觉到无从下手。这种感觉是非常正常的。关于复杂算法问题的解决思路，我还有一些经验、小技巧，可以分享给你。

当我们拿到一个问题的时候，我们可以先不思考，计算机会如何实现这个问题，而是单纯考虑“人脑”会如何去解决这个问题。人脑比较倾向于思考具象化的、摸得着看得见的东西，不适合思考过于抽象的问题。所以，我们需要把抽象问题具象化。那如何具象化呢？我们可以实例化几个测试数据，通过人脑去分析具体实例的解，然后总结规律，再尝试套用学过的算法，看是否能够解决。

除此之外，我还有一个非常有效、但也算不上技巧的东西，我也反复强调过，那就是多练。实际上，等你做多了题目之后，自然就会有感觉，看到问题，立马就能想到能否用动态规划解决，然后直接就可以寻找最优子结构，写出动态规划方程，然后将状态转移方程翻译成代码。

如何编程计算最长公共子串长度？
前面我们讲到，最长公共子串作为编辑距离中的一种，只允许增加、删除字符两种编辑操作。从名字上，你可能觉得它看起来跟编辑距离没什么关系。实际上，从本质上来说，它表征的也是两个字符串之间的相似程度。

这个问题的解决思路，跟莱文斯坦距离的解决思路非常相似，也可以用动态规划解决。我刚刚已经详细讲解了莱文斯坦距离的动态规划解决思路，所以，针对这个问题，我直接定义状态，然后写状态转移方程。

每个状态还是包括三个变量 (i, j, max_lcs)，max_lcs 表示 a[0…i] 和 b[0…j] 的最长公共子串长度。那 (i, j) 这个状态都是由哪些状态转移过来的呢？

我们先来看回溯的处理思路。我们从 a[0] 和 b[0] 开始，依次考察两个字符串中的字符是否匹配。

如果 a[i] 与 b[j] 互相匹配，我们将最大公共子串长度加一，并且继续考察 a[i+1] 和 b[j+1]。

如果 a[i] 与 b[j] 不匹配，最长公共子串长度不变，这个时候，有两个不同的决策路线：

删除 a[i]，或者在 b[j] 前面加上一个字符 a[i]，然后继续考察 a[i+1] 和 b[j]；

删除 b[j]，或者在 a[i] 前面加上一个字符 b[j]，然后继续考察 a[i] 和 b[j+1]。

反过来也就是说，如果我们要求 a[0…i] 和 b[0…j] 的最长公共长度 max_lcs(i, j)，我们只有可能通过下面三个状态转移过来：

(i-1, j-1, max_lcs)，其中 max_lcs 表示 a[0…i-1] 和 b[0…j-1] 的最长公共子串长度；

(i-1, j, max_lcs)，其中 max_lcs 表示 a[0…i-1] 和 b[0…j] 的最长公共子串长度；

(i, j-1, max_lcs)，其中 max_lcs 表示 a[0…i] 和 b[0…j-1] 的最长公共子串长度。

如果我们把这个转移过程，用状态转移方程写出来，就是下面这个样子：

如果：a[i]==b[j]，那么：max_lcs(i, j) 就等于：
max(max_lcs(i-1,j-1)+1, max_lcs(i-1, j), max_lcs(i, j-1))；
 
如果：a[i]!=b[j]，那么：max_lcs(i, j) 就等于：
max(max_lcs(i-1,j-1), max_lcs(i-1, j), max_lcs(i, j-1))；
 
其中 max 表示求三数中的最大值。
有了状态转移方程，代码实现就简单多了。我把代码贴到了下面，你可以对比着文字一块儿看。

public int lcs(char[] a, int n, char[] b, int m) {
  int[][] maxlcs = new int[n][m];
  for (int j = 0; j < m; ++j) {// 初始化第 0 行：a[0..0] 与 b[0..j] 的 maxlcs
    if (a[0] == b[j]) maxlcs[0][j] = 1;
    else if (j != 0) maxlcs[0][j] = maxlcs[0][j-1];
    else maxlcs[0][j] = 0;
  }
  for (int i = 0; i < n; ++i) {// 初始化第 0 列：a[0..i] 与 b[0..0] 的 maxlcs
    if (a[i] == b[0]) maxlcs[i][0] = 1;
    else if (i != 0) maxlcs[i][0] = maxlcs[i-1][0];
    else maxlcs[i][0] = 0;
  }
  for (int i = 1; i < n; ++i) { // 填表
    for (int j = 1; j < m; ++j) {
      if (a[i] == b[j]) maxlcs[i][j] = max(
          maxlcs[i-1][j], maxlcs[i][j-1], maxlcs[i-1][j-1]+1);
      else maxlcs[i][j] = max(
          maxlcs[i-1][j], maxlcs[i][j-1], maxlcs[i-1][j-1]);
    }
  }
  return maxlcs[n-1][m-1];
}
 
private int max(int x, int y, int z) {
  int maxv = Integer.MIN_VALUE;
  if (x > maxv) maxv = x;
  if (y > maxv) maxv = y;
  if (z > maxv) maxv = z;
  return maxv;
}
解答开篇
今天的内容到此就讲完了，我们来看下开篇的问题。

当用户在搜索框内，输入一个拼写错误的单词时，我们就拿这个单词跟词库中的单词一一进行比较，计算编辑距离，将编辑距离最小的单词，作为纠正之后的单词，提示给用户。

这就是拼写纠错最基本的原理。不过，真正用于商用的搜索引擎，拼写纠错功能显然不会就这么简单。一方面，单纯利用编辑距离来纠错，效果并不一定好；另一方面，词库中的数据量可能很大，搜索引擎每天要支持海量的搜索，所以对纠错的性能要求很高。

针对纠错效果不好的问题，我们有很多种优化思路，我这里介绍几种。

我们并不仅仅取出编辑距离最小的那个单词，而是取出编辑距离最小的 TOP 10，然后根据其他参数，决策选择哪个单词作为拼写纠错单词。比如使用搜索热门程度来决定哪个单词作为拼写纠错单词。

我们还可以用多种编辑距离计算方法，比如今天讲到的两种，然后分别编辑距离最小的 TOP 10，然后求交集，用交集的结果，再继续优化处理。

我们还可以通过统计用户的搜索日志，得到最常被拼错的单词列表，以及对应的拼写正确的单词。搜索引擎在拼写纠错的时候，首先在这个最长被拼错单词列表中查找。如果一旦找到，直接返回对应的正确的单词。这样纠错的效果非常好。

我们还有更加高级一点的做法，引入个性化因素。针对每个用户，维护这个用户特有的搜索喜好，也就是常用的搜索关键词。当用户输入错误的单词的时候，我们首先在这个用户常用的搜索关键词中，计算编辑距离，查找编辑距离最小的单词。

针对纠错性能方面，我们也有相应的优化方式。我讲两种分治的优化思路。

如果纠错功能的 TPS 不高，我们可以部署多台机器，每台机器运行一个独立的纠错功能。当有一个纠错请求的时候，我们通过负载均衡，分配到其中一台机器，来计算编辑距离，得到纠错单词。

如果纠错系统的响应时间太长，也就是，每个纠错请求处理时间过长，我们可以将纠错的词库，分割到很多台机器。当有一个纠错请求的时候，我们就将这个拼写错误的单词，同时发送到这多台机器，让多台机器并行处理，分别得到编辑距离最小的单词，然后再比对合并，最终决定出一个最优的纠错单词。

真正的搜索引擎的拼写纠错优化，肯定不止我讲的这么简单，但是万变不离其宗。掌握了核心原理，就是掌握了解决问题的方法，剩下就靠你自己的灵活运用和实战操练了。

内容小结
动态规划的三节内容到此就全部讲完了，不知道你掌握得如何呢？

动态规划的理论尽管并不复杂，总结起来就是“一个模型三个特征”。但是，要想灵活应用并不简单。要想能真正理解、掌握动态规划，你只有多练习。

这三节中，加上课后思考题，总共有 8 个动态规划问题。这 8 个问题都非常经典，是我精心筛选出来的。很多动态规划问题其实都可以抽象成这几个问题模型，所以，你一定要多看几遍，多思考一下，争取真正搞懂它们。

只要弄懂了这几个问题，一般的动态规划问题，你应该都可以应付。对于动态规划这个知识点，你就算是入门了，再学习更加复杂的就会简单很多。

课后思考
我们有一个数字序列包含 n 个不同的数字，如何求出这个序列中的最长递增子序列长度？比如 2, 9, 3, 6, 5, 1, 7 这样一组数字序列，它的最长递增子序列就是 2, 3, 5, 7，所以最长递增子序列的长度是 4。

欢迎留言和我分享，也欢迎点击“请朋友读”，把今天的内容分享给你的好友，和他一起讨论、学习。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(92)

ext4
Trie树和编辑距离，很多年前我去Google面试的时候都被考过。还记得Trie树是问我怎么存储美国的10位电话号码，可以最快速查找一个号码是否是空号，我答上来了；不过关于编辑距离我当时没想出来用dp。
2019-01-02


47

zixuan
补充一下，中文纠错很多时候是通过拼音进行的，比如 "刘得花"->"liudehua"->"刘德华". 拼音检索方法也有很多，比如可以把热门词汇的拼音字母组织成Trie树，每个热词的结尾汉字的最后一个拼音字母就是叶子，整体性能就是O(n)的，n为query的拼音总长度. 除了拼音外也有根据字形（二维文字版的编辑距离？）甚至语义等做的纠错策略。
传统搜索引擎中的查询词智能提示、纠错、同义词、近义词、同好词、相关搜索、知识图谱等系列功能统称为用户的意图识别模块。
作者回复: 👍好厉害

2019-01-03


33

王超
老师，能帮忙解释下这个公式吗，有一点费解， a[i]==b[j] 时，为什么是：
min(min_edist(i-1,j)+1, min_edist(i,j-1)+1，min_edist(i-1,j-1)) 而不是
min(min_edist(i-1,j), min_edist(i,j-1)，min_edist(i-1,j-1))
为什么要 + 1 啊
2019-01-25

3

15

Sharry
思考题的解法还是很精妙的
递推公式:
a[0...i] 的最长子序列为: a[i] 之前所有比它小的元素中子序列长度最大的 + 1

代码实现:
```
#include<iostream>

using namespace std;

// 动态规划求 a 的最上升长子序列长度
#include<iostream>

using namespace std;

// 动态规划求 a 的最上升长子序列长度
int longestSubsequence(int *a, int n) {
// 创建一个数组, 索引 i 对应考察元素的下标, 存储 arr[0...i] 的最长上升子序列大小
int *lss_lengths = new int[n];
// 第一个元素哨兵处理
lss_lengths[0] = 1;
// 动态规划求解最长子序列
int i, j, max;
for (i = 1; i < n; i++) {
// 计算 arr[0...i] 的最长上升子序列
// 递推公式: lss_lengths[i] = max(condition: j < i && a[j] < a[i] value: lss_lengths[j] + 1)
max = 1;
for (j = 0; j < i; j++) {
if (a[i] > a[j] && lss_lengths[j] >= max) {
max = lss_lengths[j] + 1;
}
}
lss_lengths[i] = max;
}
int lss_length = lss_lengths[n - 1];
delete[]lss_lengths;
return lss_length;
}

void main() {
const int n = 7;
int arr[n] = { 2, 9, 3, 6, 5, 1, 7 };;
cout << longestSubsequence(arr, n) << endl;
getchar();
}
```
2019-01-03

1

11

blacknhole
有个疑问：
以下内容涉及“如何编程计算莱文斯坦距离？”一节。

（1）文中对递归树中的状态三元组(i, j, edist)的解释是，“状态包含三个变量 (i, j, edist)，其中，edist表示处理到 a[i] 和 b[j] 时，已经执行的编辑操作的次数。”这里的“处理到a[i]和b[j]时”，其实是在说将要处理但还并未处理a[i]和b[j]。edist并不包括对a[i]和[j]的编辑操作。递归树图片后紧接着的图片中，(i, j, min_edist)的min_edist也并不包括对a[i]和[j]的编辑操作。

（2）而二维状态表图片中每格的值和动态规划的实现代码中minDist[i][j]两者均代表：到处理完a[i]和b[j]之后为止，已经执行的编辑操作的最少次数。根据这个意思，可知状态转移方程中的min_edist(i, j)也是包括对a[i]和[j]的编辑操作的。如果按照（1）中的意思，状态转移方程中的min_edist(i, j)就不应该包括对a[i]和[j]的编辑操作，也不应该判断a[i]和b[j]是否相等，而应该判断的是a[i - 1]和b[j - 1]是否相等；并且动态规划的实现代码中循环终止条件就不应是小于n或m，而应是小于等于n或m。

为什么会有（1）与（2）这样的在文章前后表达上的不一致？
作者回复: 👍你说的没错 不仅这一节 前面两节课都是这样。递归树是根据回溯算法代码实现写的。但是动规代码用你讲到的另一种思路理解更容易。我当时写的时候 也想能不能统一。最后发现不好统一。你可以分割开来看 或者 把它们当作两种状态表示方法来看 不影响理解

2019-01-02

2

11

G.S.K
动态规划问题的思路总结：第一步：如果待解决的问题为func（n），自己可以假设func（n-1）、func（n-2）……func（1）都已经解出，然后就是如何利用这些结果来推导出func（n），经过这么分析就可以得出推导方程。第二步：设计dp数组来保存func（n）（一维数组、二维数组等）。第三步：从0开始遍历，按照状态转移方程计算出func（n）保存到dp数组
举例，以下这些leetcode动态规划相关的题都可以直接套用这个解题思路

一维dp数组的题目
322. Coin Change
121. Best Time to Buy and Sell Stock
53. Maximum Subarray
300. Longest Increasing Subsequence
152. Maximum Product Subarray

二维dp数组的题目
152. Maximum Product Subarray
120. Triangle
2019-03-22


9

Jack_Cui
老师 最长公共子串要求的是连续的 对于编辑距离应该是最长公关子序列吧
2019-01-17


9

G.S.K
第二遍学习，看留言有同学不理解状态转移表的填充过程，现总结一下状态转移表的填充详细过程和对应的字符编辑操作，望老师指正：
1 minDist[i][j]表示处理完a[i]和b[j]时（a[0...i]已全部转换到b[0...j]），需要的最小编辑次数
2 a[i]和b[j]不相等时，状态转移公式为：minDist[i][j]=min(minDist(i-1,j)+1, minDist(i,j-1)+1，minDist(i-1,j-1))
   1) 如果minDist[i][j]=minDist(i-1,j)+1，现分析一下这个状态转移的具体过程。minDist(i-1,j)表示a[0...i-1]已全部转换到b[0...j]，如何编辑字符才能从minDist(i-1,j)到达minDist[i][j]这个状态呢？要么将a[i]这个字符删除，要么在b[j]后边添加一个跟a[i]相同的字符（这里编辑的操作跟老师讲的回溯法的操作是不一样的）
   2）如果minDist[i][j]=minDist(i-1,j-1)，现分析一下这个状态转移的具体过程。如何编辑字符才能从minDist(i-1,j-1)到达minDist[i][j]这个状态呢？？将a[i]替换为b[j]或者将b[j]替换为a[i]即可
  3) 如果minDist[i][j]=minDist(i,j-1)+1，跟上边第一种情况类似
3 a[i]和b[j]相等时比较简单，不需要做字符的编辑
2019-03-24


8

郭霖
思考题java版解答：
public int longestIncreaseSubArrayDP(int[] array) {
    if (array.length < 2) return array.length;
    int[] state = new int[array.length];
    state[0] = 1;
    for (int i = 1; i < state.length; i++) {
        int max = 0;
        for (int j = 0; j < i; j++) {
            if (array[j] < array[i]) {
                if (state[j] > max) max = state[j];
            }
        }
        state[i] = max + 1;
    }
    int result = 0;
    for (int i = 0; i < state.length; i++) {
        if (state[i] > result) result = state[i];
    }
    return result;
}
2019-01-08


8

沉睡的木木夕
那个状态转移表是怎么填充的？我来回看了几遍还是不知道里面的值怎么来的，感觉跟前面分析的扯不上任何关系
2019-01-22


7

王者归来
老师，第一行初始化值，如何理解？
if (a[0] == b[j]) minDist[0][j] = j;
else if (j != 0) minDist[0][j] = minDist[0][j-1]+1;
else minDist[0][j] = 1;
2019-01-31


5

G.S.K
莱温斯坦距离状态表，初始化第0行和第0列代码逻辑有点复杂，可以简化一下，修改状态表为如下形式
∅ m t a c n u
∅ 0 1 2 3 4 5 6
m 1 0 1 2 3 4 5
i 2 1
t 3 2
c 4 3
m 5 4
u 6 5
代码就可以简化了
int[][] minDist = new int[n+1][m+1]
  for (int j = 0; j <= m; ++j) { 初始化第0行
    minDist[0][j] = j;
  }
  for (int i = 0; i <= n; ++i) { 初始化第0列
    minDist[i][0] = i;
  }
最终return minDist[n][m];
2019-03-24

1

4

传说中的成大大
if (a[i] == b[j]) minDist[i][j] = min(
minDist[i-1][j]+1,minDist[i][j-1]+1,minDist[i-1][j-1])不明白的是为什么minDist[i-1][j]或者mindist[i][j-1] 要+1呢？
作者回复: (i-1,j)这个状态转移到(i, j)这个状态，minDist要加一
(i, j)同上
(i-1, j-1)这个状态转移到(i, j)这个状态，minDist保持不变，因为a[i]==b[j]

2019-02-28

1

4

Kudo
思考题解答：
状态转移公式：maxLen[i] = max(maxLen[j]+(1 if j<i else 0)) for any j < i
python代码：
def maxOrderedSeq(seq):
    maxLen = [1] * len(seq) # 初始化为1
    
    for i in range(1, len(seq)): # i从1开始
        for j in range(i-1,-1,-1): # j从i-1到0
            if seq[j] <= seq[i]:
                maxLen[i] = maxLen[j] + 1
                break # 满足则退出
        if maxLen[i] == 1: # 比前面所有元素小
            maxLen[i] = maxLen[i-1]
            
    print(maxLen)
            
 usage
seq = [2, 9, 3, 6, 5, 1, 7]
maxOrderedSeq(seq)
2019-01-03


4

Kudo
选这个专栏的初衷就是为了学习动态规划，作者对这部分内容的讲解我还是比较满意的。两个月前，闲来无事刷了几天LeetCode，遇到一道字符串模式匹配的题，不是结果错误就是复杂度不达标，怎么也搞不定。看了论坛里给出的高赞解答，清一色采用了动态规划的解题方法，当时没有算法基础，真的是看不懂啊，遂放弃。现在经过几节课的学习理出一些思路来，收获颇丰，理论看得比较明白了，程序照着文中的例子也能写个大概，但感觉掌握得还是不牢靠，还需要多加练习。谢谢作者！
2019-01-02


4

细胞核
为什么到后面留言这么少？

在编辑距离里面， 状态转移方程，第二种case ,是不是可以改为：

如果：a[i]==b[j]，那么：min_edist(i, j) 就等于：min_edist(i-1,j-1)

a[i]==b[j]
a[0..i] 和 b[0..j] 的编辑距离就等价于 a[0..i-1] 和 b[0..j-1]的编辑距离
    
2019-01-31


3

菜菜
老师，为什么当a[i]==b[j]时，minDist[i][j]不能直接等于minDist[i-1][j-1],而要等于min(minDist[i-1][j]+1,minDist[i][j-1]+1,minDist[i-1][j-1])
2019-03-05


2

feifei
要自己思考这个问题，感觉真不容易，因为思路错误，走了不少弯路，花了5天的休息时间，终于解出来了，写出来了，感觉是容易了，但这个思考的过程，感觉自己收获不少，尝试了很多种的解法，然后都一一的否决！


这是我写的递归求解，

public int recursionCount4(int[] arrays, int index) {

    if (index == 0) {
      return 1;
    }
    int max = 0;
    //此问题的解，递归的核心就是在之前的序列中找到最大递增子序列加1
    //所以需要遍历此此之前的全部数据项
    for (int i = 0; i < index; i++) {
      //递归求解每项的最递增序列
      int value = recursionCount4(arrays, i);
      if (arrays[i] < arrays[index]) {
        if (value > max) {
          max = value;
        }
      }
    }

    return max + 1;
  }



public void countDynamic(int[] arrays) {
    int length = arrays.length;

    int[] status = new int[length];

    status[0] = 1;

    int commMax = 0;

    for (int i = 1; i < length; i++) {
      int max = 0;
      for (int j = 0; j < i; j++) {
        if (arrays[j] < arrays[i]) {
          if (status[j] > max) {
            max = status[j];
          }
        }
      }
      status[i] = max + 1;

      if (status[i] > commMax) {
        commMax = status[i];
      }
    }

    System.out.println("最大递增序列为 ：" + commMax);
    int maxComp = commMax;
    System.out.println("递增:" + Arrays.toString(status));

    for (int i = length - 1; i >= 0; i--) {
      if (status[i] == maxComp) {
        System.out.print("-->" + arrays[i]);
        maxComp = maxComp - 1;
      }
    }
  }


2019-01-11


2

Ricky
老师，您好，您这节内容讲的很清晰透彻，我以前做动态规划问题是直接寻找状态转移方程，基本只能处理一些简单的动态规划问题，没有形成系统的解题思路，听了您这一节后，我觉得将回溯简单思路逐步转化为动规思路让我受益匪浅，但是当我试着将这套思路应用于求解最长递增子序列时却感觉回溯更麻烦，不知能否指点一二
作者回复: 我的讲解并不是为了指导做题。所以，我讲解的时候，从为什么要动态规划讲起，所以废话比较多。实际上，你理解理论之后，解动态规划题目的时候，一般可以直接写最优子结构，也就是状态转移方程，不需要再从回溯解法开始。。。

2019-01-04


2

slvher
本文举例的 LCS 问题不要求字符连续，通常是指 longest common subsequence 吧？
作者回复: 是的








# 43 | 拓扑排序：如何确定代码源文件的编译依赖关系？





数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



43 | 拓扑排序：如何确定代码源文件的编译依赖关系？
王争 2019-01-04



09:37
讲述：修阳 大小：8.82M
从今天开始，我们就进入了专栏的高级篇。相对基础篇，高级篇涉及的知识点，都比较零散，不是太系统。所以，我会围绕一个实际软件开发的问题，在阐述具体解决方法的过程中，将涉及的知识点给你详细讲解出来。

所以，相较于基础篇“开篇问题 - 知识讲解 - 回答开篇 - 总结 - 课后思考”这样的文章结构，高级篇我稍作了些改变，大致分为这样几个部分：“问题阐述 - 算法解析 - 总结引申 - 课后思考”。

好了，现在，我们就进入高级篇的第一节，如何确定代码源文件的编译依赖关系？

我们知道，一个完整的项目往往会包含很多代码源文件。编译器在编译整个项目的时候，需要按照依赖关系，依次编译每个源文件。比如，A.cpp 依赖 B.cpp，那在编译的时候，编译器需要先编译 B.cpp，才能编译 A.cpp。

编译器通过分析源文件或者程序员事先写好的编译配置文件（比如 Makefile 文件），来获取这种局部的依赖关系。那编译器又该如何通过源文件两两之间的局部依赖关系，确定一个全局的编译顺序呢？



算法解析
这个问题的解决思路与“图”这种数据结构的一个经典算法“拓扑排序算法”有关。那什么是拓扑排序呢？这个概念很好理解，我们先来看一个生活中的拓扑排序的例子。

我们在穿衣服的时候都有一定的顺序，我们可以把这种顺序想成，衣服与衣服之间有一定的依赖关系。比如说，你必须先穿袜子才能穿鞋，先穿内裤才能穿秋裤。假设我们现在有八件衣服要穿，它们之间的两两依赖关系我们已经很清楚了，那如何安排一个穿衣序列，能够满足所有的两两之间的依赖关系？

这就是个拓扑排序问题。从这个例子中，你应该能想到，在很多时候，拓扑排序的序列并不是唯一的。你可以看我画的这幅图，我找到了好几种满足这些局部先后关系的穿衣序列。



弄懂了这个生活中的例子，开篇的关于编译顺序的问题，你应该也有思路了。开篇问题跟这个问题的模型是一样的，也可以抽象成一个拓扑排序问题。

拓扑排序的原理非常简单，我们的重点应该放到拓扑排序的实现上面。

我前面多次讲过，算法是构建在具体的数据结构之上的。针对这个问题，我们先来看下，如何将问题背景抽象成具体的数据结构？

我们可以把源文件与源文件之间的依赖关系，抽象成一个有向图。每个源文件对应图中的一个顶点，源文件之间的依赖关系就是顶点之间的边。

如果 a 先于 b 执行，也就是说 b 依赖于 a，那么就在顶点 a 和顶点 b 之间，构建一条从 a 指向 b 的边。而且，这个图不仅要是有向图，还要是一个有向无环图，也就是不能存在像 a->b->c->a 这样的循环依赖关系。因为图中一旦出现环，拓扑排序就无法工作了。实际上，拓扑排序本身就是基于有向无环图的一个算法。

public class Graph {
  private int v; // 顶点的个数
  private LinkedList<Integer> adj[]; // 邻接表
 
  public Graph(int v) {
    this.v = v;
    adj = new LinkedList[v];
    for (int i=0; i<v; ++i) {
      adj[i] = new LinkedList<>();
    }
  }
 
  public void addEdge(int s, int t) { // s 先于 t，边 s->t
    adj[s].add(t);
  }
}
数据结构定义好了，现在，我们来看，如何在这个有向无环图上，实现拓扑排序？

拓扑排序有两种实现方法，都不难理解。它们分别是Kahn 算法和DFS 深度优先搜索算法。我们依次来看下它们都是怎么工作的。

1.Kahn 算法
Kahn 算法实际上用的是贪心算法思想，思路非常简单、好懂。

定义数据结构的时候，如果 s 需要先于 t 执行，那就添加一条 s 指向 t 的边。所以，如果某个顶点入度为 0， 也就表示，没有任何顶点必须先于这个顶点执行，那么这个顶点就可以执行了。

我们先从图中，找出一个入度为 0 的顶点，将其输出到拓扑排序的结果序列中（对应代码中就是把它打印出来），并且把这个顶点从图中删除（也就是把这个顶点可达的顶点的入度都减 1）。我们循环执行上面的过程，直到所有的顶点都被输出。最后输出的序列，就是满足局部依赖关系的拓扑排序。

我把 Kahn 算法用代码实现了一下，你可以结合着文字描述一块看下。不过，你应该能发现，这段代码实现更有技巧一些，并没有真正删除顶点的操作。代码中有详细的注释，你自己来看，我就不多解释了。

public void topoSortByKahn() {
  int[] inDegree = new int[v]; // 统计每个顶点的入度
  for (int i = 0; i < v; ++i) {
    for (int j = 0; j < adj[i].size(); ++j) {
      int w = adj[i].get(j); // i->w
      inDegree[w]++;
    }
  }
  LinkedList<Integer> queue = new LinkedList<>();
  for (int i = 0; i < v; ++i) {
    if (inDegree[i] == 0) queue.add(i);
  }
  while (!queue.isEmpty()) {
    int i = queue.remove();
    System.out.print("->" + i);
    for (int j = 0; j < adj[i].size(); ++j) {
      int k = adj[i].get(j);
      inDegree[k]--;
      if (inDegree[k] == 0) queue.add(k);
    }
  }
}
2.DFS 算法
图上的深度优先搜索我们前面已经讲过了，实际上，拓扑排序也可以用深度优先搜索来实现。不过这里的名字要稍微改下，更加确切的说法应该是深度优先遍历，遍历图中的所有顶点，而非只是搜索一个顶点到另一个顶点的路径。

关于这个算法的实现原理，我先把代码贴在下面，下面给你具体解释。

public void topoSortByDFS() {
  // 先构建逆邻接表，边 s->t 表示，s 依赖于 t，t 先于 s
  LinkedList<Integer> inverseAdj[] = new LinkedList[v];
  for (int i = 0; i < v; ++i) { // 申请空间
    inverseAdj[i] = new LinkedList<>();
  }
  for (int i = 0; i < v; ++i) { // 通过邻接表生成逆邻接表
    for (int j = 0; j < adj[i].size(); ++j) {
      int w = adj[i].get(j); // i->w
      inverseAdj[w].add(i); // w->i
    }
  }
  boolean[] visited = new boolean[v];
  for (int i = 0; i < v; ++i) { // 深度优先遍历图
    if (visited[i] == false) {
      visited[i] = true;
      dfs(i, inverseAdj, visited);
    }
  }
}
 
private void dfs(
    int vertex, LinkedList<Integer> inverseAdj[], boolean[] visited) {
  for (int i = 0; i < inverseAdj[vertex].size(); ++i) {
    int w = inverseAdj[vertex].get(i);
    if (visited[w] == true) continue;
    visited[w] = true;
    dfs(w, inverseAdj, visited);
  } // 先把 vertex 这个顶点可达的所有顶点都打印出来之后，再打印它自己
  System.out.print("->" + vertex);
}
这个算法包含两个关键部分。

第一部分是通过邻接表构造逆邻接表。邻接表中，边 s->t 表示 s 先于 t 执行，也就是 t 要依赖 s。在逆邻接表中，边 s->t 表示 s 依赖于 t，s 后于 t 执行。为什么这么转化呢？这个跟我们这个算法的实现思想有关。

第二部分是这个算法的核心，也就是递归处理每个顶点。对于顶点 vertex 来说，我们先输出它可达的所有顶点，也就是说，先把它依赖的所有的顶点输出了，然后再输出自己。

到这里，用 Kahn 算法和 DFS 算法求拓扑排序的原理和代码实现都讲完了。我们来看下，这两个算法的时间复杂度分别是多少呢？

从 Kahn 代码中可以看出来，每个顶点被访问了一次，每个边也都被访问了一次，所以，Kahn 算法的时间复杂度就是 O(V+E)（V 表示顶点个数，E 表示边的个数）。

DFS 算法的时间复杂度我们之前分析过。每个顶点被访问两次，每条边都被访问一次，所以时间复杂度也是 O(V+E)。

注意，这里的图可能不是连通的，有可能是有好几个不连通的子图构成，所以，E 并不一定大于 V，两者的大小关系不确定。所以，在表示时间复杂度的时候，V、E 都要考虑在内。

总结引申
在基础篇中，关于“图”，我们讲了图的定义和存储、图的广度和深度优先搜索。今天，我们又讲了一个关于图的算法，拓扑排序。

拓扑排序应用非常广泛，解决的问题的模型也非常一致。凡是需要通过局部顺序来推导全局顺序的，一般都能用拓扑排序来解决。除此之外，拓扑排序还能检测图中环的存在。对于 Kahn 算法来说，如果最后输出出来的顶点个数，少于图中顶点个数，图中还有入度不是 0 的顶点，那就说明，图中存在环。

关于图中环的检测，我们在递归那一节讲过一个例子，在查找最终推荐人的时候，可能会因为脏数据，造成存在循环推荐，比如，用户 A 推荐了用户 B，用户 B 推荐了用户 C，用户 C 又推荐了用户 A。如何避免这种脏数据导致的无限递归？这个问题，我当时留给你思考了，现在是时候解答了。

实际上，这就是环的检测问题。因为我们每次都只是查找一个用户的最终推荐人，所以，我们并不需要动用复杂的拓扑排序算法，而只需要记录已经访问过的用户 ID，当用户 ID 第二次被访问的时候，就说明存在环，也就说明存在脏数据。

HashSet<Integer> hashTable = new HashSet<>(); // 保存已经访问过的 actorId
long findRootReferrerId(long actorId) {
  if (hashTable.contains(actorId)) { // 存在环
    return;
  }
  hashTable.add(actorId);
  Long referrerId = 
       select referrer_id from [table] where actor_id = actorId;
  if (referrerId == null) return actorId;
  return findRootReferrerId(referrerId);
}
如果把这个问题改一下，我们想要知道，数据库中的所有用户之间的推荐关系了，有没有存在环的情况。这个问题，就需要用到拓扑排序算法了。我们把用户之间的推荐关系，从数据库中加载到内存中，然后构建成今天讲的这种有向图数据结构，再利用拓扑排序，就可以快速检测出是否存在环了。

课后思考
在今天的讲解中，我们用图表示依赖关系的时候，如果 a 先于 b 执行，我们就画一条从 a 到 b 的有向边；反过来，如果 a 先于 b，我们画一条从 b 到 a 的有向边，表示 b 依赖 a，那今天讲的 Kahn 算法和 DFS 算法还能否正确工作呢？如果不能，应该如何改造一下呢？

我们今天讲了两种拓扑排序算法的实现思路，Kahn 算法和 DFS 深度优先搜索算法，如果换做 BFS 广度优先搜索算法，还可以实现吗？

欢迎留言和我分享，也欢迎点击“请朋友读”，把今天的内容分享给你的好友，和他一起讨论、学习。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(39)

Jerry银银
老师，这门专栏快结束了，突然有点新的想法：如果老师在讲解算法的时候，多讲点算法的由来，也就是背景，那就更好了。

我想，如果能知道某个算法的创造者为什么会发明某个算法，怎么能够发明出某个算法，我想我们会掌握得更牢，学得应该也稍微轻松一点，关键是能跟随发明者回到原点，体会思考的过程

编辑回复: 这个有意思，我们想想。

2019-01-04

2

54

Jerry银银
思考题：
1. a先于b执行，也就说b依赖于a，b指向a，这样构建有向无环图时，要找到出度为0的顶点，然后删除

2. BFS也能实现，因为遍历只是实现拓扑排序的一个“辅助手段”，本质上是帮助找到优先执行的顶点
2019-01-04


19

Handongyang
@Jerry银银
针对你提的算法的由来与背景的问题，我想我们完全可以通过维基百科查看，一般都有其背景以及算法应用的场景，甚至有些算法在维基百科上有相应的文献引用，这些都可以参考。
作者回复: 银银同学要的显然不是这些

这就好比我在跟大家讲古诗 登黄鹤楼。银银同学想知道的是 怎么才能站在黄鹤楼上 作出登黄鹤楼这么牛逼的诗 诗人的脑回路是咋样的

而并不是想要历史性介绍 这首诗是谁谁谁 在某某年 某某地 历史背景下 做出来的

不知道我理解的对不

关于前者 我在讲解的时候已经尽量还原来龙去脉 但是可能学的并不明显 而且这本身就是很难说清楚的 说不定诗人自己都不知道自己咋写出这么牛逼的诗的

2019-01-07


10

Aaron
课后思考里“BFS 深度优先搜索算法”是否应该是“BFS 广度优先搜索算法”？BFS: Breadth-first Search
2019-01-05


5

纯洁的憎恶
1.kahn算法找出度为0的节点删除。dfs算法直接用正邻接表即可。

2. BFS也可以。其实与DFS一样，BFS也是从某个节点开始，找到所有与其相连通的节点。区别在于BFS是一层一层找（递归函数在for循环外），DFS是先一杆子插到底，再回来插第二条路、第三条路等等（递归函数在for循环内）。
2019-01-04


5

想当架构师
我怎么觉得这个kahn算法其实就是BFS算法
2019-01-26


4

你有资格吗？
老师，好像数据结构少了B+树的讲解啊，B+不准备讲吗？
2019-01-07


3

jueyoq
老师什么时候再出课程呀。 按照咱们这销量，可以开始新专栏预告辣
2019-02-12


2

蓝天
刚解决完工作中类似的问题 老师的文章就来了，然后才知道那个算法叫kahn
2019-01-07


2

Edward
老师你好。我在做一道动态规划题的时候，不借助其他启发性线索时，在纸上演算一遍后，发现自己如果不能直觉地从演算中推演出解答的关键，就会产生强烈的自我怀疑。会有一层对自己智力水平的怀疑，如果没有一定的智商，是不适合做这事情的。请问老师你有什么方法，可以克服这种自我的质疑？
作者回复: 多练习 多思考 多总结 慢慢就好了 都有这么一个过程的

2019-01-05


2

NeverMore
1、反过来的话计算的就不是入度了，可以用出度来判断；
2、BFS的话，则需要记录上一个节点是哪个，可以实现，但是比DFS要麻烦些。
还请老师指点。
老师之后能不能给思考题一个答疑？
作者回复: 专栏结束的时候吧 也算是一个回顾 现在年底忙 没啥时间写呢

2019-01-04


2

www.xnsms.com小鸟接码
DFS 算法 ，里面的递归差点就被绕进去了，这个递归终止条件太隐蔽了……不仔细看代码，还以为没有终止条件会死循环……好巧妙，打算我也想不出这样写代码
2019-01-08

1

1

Jerry银银
如果 a 先于 b，我们画一条从 b 到 a 的有向边，表示 b 依赖 a

我个人更喜欢这种构建图的方式，觉得这种更符合“惯性思维方式”
2019-01-04


1

farFlight
老师，我觉得这里BFS和Kahn算法基本可以说是一样的，本身Kahn贪婪算法运用queue实现的过程就是一个典型的BFS范式。采用BFS就应该按照入度一层一层遍历，一层遍历完了的同时把下一层的顶点push进入queue中。
2019-01-04


1

不一样的烟火
我常常陷入问题都看不懂的迷思中
2019-08-14



Paul Shan
思考题2
广度优先在拓扑排序中不行，因为如果第一次选中了中间的节点，遍历的顺序就无法保证根部节点在中间节点之前。Kahn 算法是利用了出度信息来保证，根节点在其子节点之前。深度优先是利用了子节点必然比根节点先结束的特点来逆序处理。广度优先没有什么保证。（这里的描述和文中的例子有所不同，是按照出度为0的节点优先的原则）
2019-07-31



Paul Shan
思考题1
当关系反转了，算法1只要把入度改为出度即可。
深度优先算法就在原图中进行，而不需要反转邻接表
2019-07-31



wordMan
思考题：
1.换方向，那统计入度的时候可以基于对应的逆邻接表
2019-07-21



黎波拉小建
A指向CD节点 B指向CD节点，这种情况下Kahn算法的入度自减一次那段会不会不工作呢，因为入度要减2才能打印剩下节点。
2019-07-18



lzh
DFS不一定要用逆邻接表吧，用栈也可以吧？算法导论上直接DFS，把遍历完的节点插到链表头，那和用栈一样一样的啊。用栈我个人感觉更直观
2019-07-01


收起评论

3973





# 44 | 最短路径：地图软件是如何计算出最优出行路径的？



数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



44 | 最短路径：地图软件是如何计算出最优出行路径的？
王争 2019-01-07



13:33
讲述：修阳 大小：12.42M
基础篇的时候，我们学习了图的两种搜索算法，深度优先搜索和广度优先搜索。这两种算法主要是针对无权图的搜索算法。针对有权图，也就是图中的每条边都有一个权重，我们该如何计算两点之间的最短路径（经过的边的权重和最小）呢？今天，我就从地图软件的路线规划问题讲起，带你看看常用的最短路径算法（Shortest Path Algorithm）。

像 Google 地图、百度地图、高德地图这样的地图软件，我想你应该经常使用吧？如果想从家开车到公司，你只需要输入起始、结束地址，地图就会给你规划一条最优出行路线。这里的最优，有很多种定义，比如最短路线、最少用时路线、最少红绿灯路线等等。作为一名软件开发工程师，你是否思考过，地图软件的最优路线是如何计算出来的吗？底层依赖了什么算法呢？

算法解析
我们刚提到的最优问题包含三个：最短路线、最少用时和最少红绿灯。我们先解决最简单的，最短路线。

解决软件开发中的实际问题，最重要的一点就是建模，也就是将复杂的场景抽象成具体的数据结构。针对这个问题，我们该如何抽象成数据结构呢？

我们之前也提到过，图这种数据结构的表达能力很强，显然，把地图抽象成图最合适不过了。我们把每个岔路口看作一个顶点，岔路口与岔路口之间的路看作一条边，路的长度就是边的权重。如果路是单行道，我们就在两个顶点之间画一条有向边；如果路是双行道，我们就在两个顶点之间画两条方向不同的边。这样，整个地图就被抽象成一个有向有权图。

具体的代码实现，我放在下面了。于是，我们要求解的问题就转化为，在一个有向有权图中，求两个顶点间的最短路径。

public class Graph { // 有向有权图的邻接表表示
  private LinkedList<Edge> adj[]; // 邻接表
  private int v; // 顶点个数
 
  public Graph(int v) {
    this.v = v;
    this.adj = new LinkedList[v];
    for (int i = 0; i < v; ++i) {
      this.adj[i] = new LinkedList<>();
    }
  }
 
  public void addEdge(int s, int t, int w) { // 添加一条边
    this.adj[s].add(new Edge(s, t, w));
  }
 
  private class Edge {
    public int sid; // 边的起始顶点编号
    public int tid; // 边的终止顶点编号
    public int w; // 权重
    public Edge(int sid, int tid, int w) {
      this.sid = sid;
      this.tid = tid;
      this.w = w;
    }
  }
  // 下面这个类是为了 dijkstra 实现用的
  private class Vertex {
    public int id; // 顶点编号 ID
    public int dist; // 从起始顶点到这个顶点的距离
    public Vertex(int id, int dist) {
      this.id = id;
      this.dist = dist;
    }
  }
}
想要解决这个问题，有一个非常经典的算法，最短路径算法，更加准确地说，是单源最短路径算法（一个顶点到一个顶点）。提到最短路径算法，最出名的莫过于 Dijkstra 算法了。所以，我们现在来看，Dijkstra 算法是怎么工作的。

这个算法的原理稍微有点儿复杂，单纯的文字描述，不是很好懂。所以，我还是结合代码来讲解。

// 因为 Java 提供的优先级队列，没有暴露更新数据的接口，所以我们需要重新实现一个
private class PriorityQueue { // 根据 vertex.dist 构建小顶堆
  private Vertex[] nodes;
  private int count;
  public PriorityQueue(int v) {
    this.nodes = new Vertex[v+1];
    this.count = v;
  }
  public Vertex poll() { // TODO: 留给读者实现... }
  public void add(Vertex vertex) { // TODO: 留给读者实现...}
  // 更新结点的值，并且从下往上堆化，重新符合堆的定义。时间复杂度 O(logn)。
  public void update(Vertex vertex) { // TODO: 留给读者实现...} 
  public boolean isEmpty() { // TODO: 留给读者实现...}
}
 
public void dijkstra(int s, int t) { // 从顶点 s 到顶点 t 的最短路径
  int[] predecessor = new int[this.v]; // 用来还原最短路径
  Vertex[] vertexes = new Vertex[this.v];
  for (int i = 0; i < this.v; ++i) {
    vertexes[i] = new Vertex(i, Integer.MAX_VALUE);
  }
  PriorityQueue queue = new PriorityQueue(this.v);// 小顶堆
  boolean[] inqueue = new boolean[this.v]; // 标记是否进入过队列
  vertexes[s].dist = 0;
  queue.add(vertexes[s]);
  inqueue[s] = true;
  while (!queue.isEmpty()) {
    Vertex minVertex= queue.poll(); // 取堆顶元素并删除
    if (minVertex.id == t) break; // 最短路径产生了
    for (int i = 0; i < adj[minVertex.id].size(); ++i) {
      Edge e = adj[minVertex.id].get(i); // 取出一条 minVetex 相连的边
      Vertex nextVertex = vertexes[e.tid]; // minVertex-->nextVertex
      if (minVertex.dist + e.w < nextVertex.dist) { // 更新 next 的 dist
        nextVertex.dist = minVertex.dist + e.w;
        predecessor[nextVertex.id] = minVertex.id;
        if (inqueue[nextVertex.id] == true) {
          queue.update(nextVertex); // 更新队列中的 dist 值
        } else {
          queue.add(nextVertex);
          inqueue[nextVertex.id] = true;
        }
      }
    }
  }
  // 输出最短路径
  System.out.print(s);
  print(s, t, predecessor);
}
 
private void print(int s, int t, int[] predecessor) {
  if (s == t) return;
  print(s, predecessor[t], predecessor);
  System.out.print("->" + t);
}
我们用 vertexes 数组，记录从起始顶点到每个顶点的距离（dist）。起初，我们把所有顶点的 dist 都初始化为无穷大（也就是代码中的 Integer.MAX_VALUE）。我们把起始顶点的 dist 值初始化为 0，然后将其放到优先级队列中。

我们从优先级队列中取出 dist 最小的顶点 minVertex，然后考察这个顶点可达的所有顶点（代码中的 nextVertex）。如果 minVertex 的 dist 值加上 minVertex 与 nextVertex 之间边的权重 w 小于 nextVertex 当前的 dist 值，也就是说，存在另一条更短的路径，它经过 minVertex 到达 nextVertex。那我们就把 nextVertex 的 dist 更新为 minVertex 的 dist 值加上 w。然后，我们把 nextVertex 加入到优先级队列中。重复这个过程，直到找到终止顶点 t 或者队列为空。

以上就是 Dijkstra 算法的核心逻辑。除此之外，代码中还有两个额外的变量，predecessor 数组和 inqueue 数组。

predecessor 数组的作用是为了还原最短路径，它记录每个顶点的前驱顶点。最后，我们通过递归的方式，将这个路径打印出来。打印路径的 print 递归代码我就不详细讲了，这个跟我们在图的搜索中讲的打印路径方法一样。如果不理解的话，你可以回过头去看下那一节。

inqueue 数组是为了避免将一个顶点多次添加到优先级队列中。我们更新了某个顶点的 dist 值之后，如果这个顶点已经在优先级队列中了，就不要再将它重复添加进去了。

看完了代码和文字解释，你可能还是有点懵，那我就举个例子，再给你解释一下。



理解了 Dijkstra 的原理和代码实现，我们来看下，Dijkstra 算法的时间复杂度是多少？

在刚刚的代码实现中，最复杂就是 while 循环嵌套 for 循环那部分代码了。while 循环最多会执行 V 次（V 表示顶点的个数），而内部的 for 循环的执行次数不确定，跟每个顶点的相邻边的个数有关，我们分别记作 E0，E1，E2，……，E(V-1)。如果我们把这 V 个顶点的边都加起来，最大也不会超过图中所有边的个数 E（E 表示边的个数）。

for 循环内部的代码涉及从优先级队列取数据、往优先级队列中添加数据、更新优先级队列中的数据，这样三个主要的操作。我们知道，优先级队列是用堆来实现的，堆中的这几个操作，时间复杂度都是 O(logV)（堆中的元素个数不会超过顶点的个数 V）。

所以，综合这两部分，再利用乘法原则，整个代码的时间复杂度就是 O(E*logV)。

弄懂了 Dijkstra 算法，我们再来回答之前的问题，如何计算最优出行路线？

从理论上讲，用 Dijkstra 算法可以计算出两点之间的最短路径。但是，你有没有想过，对于一个超级大地图来说，岔路口、道路都非常多，对应到图这种数据结构上来说，就有非常多的顶点和边。如果为了计算两点之间的最短路径，在一个超级大图上动用 Dijkstra 算法，遍历所有的顶点和边，显然会非常耗时。那我们有没有什么优化的方法呢？

做工程不像做理论，一定要给出个最优解。理论上算法再好，如果执行效率太低，也无法应用到实际的工程中。对于软件开发工程师来说，我们经常要根据问题的实际背景，对解决方案权衡取舍。类似出行路线这种工程上的问题，我们没有必要非得求出个绝对最优解。很多时候，为了兼顾执行效率，我们只需要计算出一个可行的次优解就可以了。

有了这个原则，你能想出刚刚那个问题的优化方案吗？

虽然地图很大，但是两点之间的最短路径或者说较好的出行路径，并不会很“发散”，只会出现在两点之间和两点附近的区块内。所以我们可以在整个大地图上，划出一个小的区块，这个小区块恰好可以覆盖住两个点，但又不会很大。我们只需要在这个小区块内部运行 Dijkstra 算法，这样就可以避免遍历整个大图，也就大大提高了执行效率。

不过你可能会说了，如果两点距离比较远，从北京海淀区某个地点，到上海黄浦区某个地点，那上面的这种处理方法，显然就不工作了，毕竟覆盖北京和上海的区块并不小。

我给你点提示，你可以现在打开地图 App，缩小放大一下地图，看下地图上的路线有什么变化，然后再思考，这个问题该怎么解决。

对于这样两点之间距离较远的路线规划，我们可以把北京海淀区或者北京看作一个顶点，把上海黄浦区或者上海看作一个顶点，先规划大的出行路线。比如，如何从北京到上海，必须要经过某几个顶点，或者某几条干道，然后再细化每个阶段的小路线。

这样，最短路径问题就解决了。我们再来看另外两个问题，最少时间和最少红绿灯。

前面讲最短路径的时候，每条边的权重是路的长度。在计算最少时间的时候，算法还是不变，我们只需要把边的权重，从路的长度变成经过这段路所需要的时间。不过，这个时间会根据拥堵情况时刻变化。如何计算车通过一段路的时间呢？这是一个蛮有意思的问题，你可以自己思考下。

每经过一条边，就要经过一个红绿灯。关于最少红绿灯的出行方案，实际上，我们只需要把每条边的权值改为 1 即可，算法还是不变，可以继续使用前面讲的 Dijkstra 算法。不过，边的权值为 1，也就相当于无权图了，我们还可以使用之前讲过的广度优先搜索算法。因为我们前面讲过，广度优先搜索算法计算出来的两点之间的路径，就是两点的最短路径。

不过，这里给出的所有方案都非常粗糙，只是为了给你展示，如何结合实际的场景，灵活地应用算法，让算法为我们所用，真实的地图软件的路径规划，要比这个复杂很多。而且，比起 Dijkstra 算法，地图软件用的更多的是类似 A* 的启发式搜索算法，不过也是在 Dijkstra 算法上的优化罢了，我们后面会讲到，这里暂且不展开。

总结引申
今天，我们学习了一种非常重要的图算法，Dijkstra 最短路径算法。实际上，最短路径算法还有很多，比如 Bellford 算法、Floyd 算法等等。如果感兴趣，你可以自己去研究。

关于 Dijkstra 算法，我只讲了原理和代码实现。对于正确性，我没有去证明。之所以这么做，是因为证明过程会涉及比较复杂的数学推导。这个并不是我们的重点，你只要掌握这个算法的思路就可以了。

这些算法实现思路非常经典，掌握了这些思路，我们可以拿来指导、解决其他问题。比如 Dijkstra 这个算法的核心思想，就可以拿来解决下面这个看似完全不相关的问题。这个问题是我之前工作中遇到的真实的问题，为了在较短的篇幅里把问题介绍清楚，我对背景做了一些简化。

我们有一个翻译系统，只能针对单个词来做翻译。如果要翻译一整个句子，我们需要将句子拆成一个一个的单词，再丢给翻译系统。针对每个单词，翻译系统会返回一组可选的翻译列表，并且针对每个翻译打一个分，表示这个翻译的可信程度。



针对每个单词，我们从可选列表中，选择其中一个翻译，组合起来就是整个句子的翻译。每个单词的翻译的得分之和，就是整个句子的翻译得分。随意搭配单词的翻译，会得到一个句子的不同翻译。针对整个句子，我们希望计算出得分最高的前 k 个翻译结果，你会怎么编程来实现呢？



当然，最简单的办法还是借助回溯算法，穷举所有的排列组合情况，然后选出得分最高的前 k 个翻译结果。但是，这样做的时间复杂度会比较高，是 O(m^n)，其中，m 表示平均每个单词的可选翻译个数，n 表示一个句子中包含多少个单词。这个解决方案，你可以当作回溯算法的练习题，自己编程实现一下，我就不多说了。

实际上，这个问题可以借助 Dijkstra 算法的核心思想，非常高效地解决。每个单词的可选翻译是按照分数从大到小排列的，所以 a0b0c0 肯定是得分最高组合结果。我们把 a0b0c0 及得分作为一个对象，放入到优先级队列中。

我们每次从优先级队列中取出一个得分最高的组合，并基于这个组合进行扩展。扩展的策略是每个单词的翻译分别替换成下一个单词的翻译。比如 a0b0c0 扩展后，会得到三个组合，a1b0c0、a0b1c0、a0b0c1。我们把扩展之后的组合，加到优先级队列中。重复这个过程，直到获取到 k 个翻译组合或者队列为空。



我们来看，这种实现思路的时间复杂度是多少？

假设句子包含 n 个单词，每个单词平均有 m 个可选的翻译，我们求得分最高的前 k 个组合结果。每次一个组合出队列，就对应着一个组合结果，我们希望得到 k 个，那就对应着 k 次出队操作。每次有一个组合出队列，就有 n 个组合入队列。优先级队列中出队和入队操作的时间复杂度都是 O(logX)，X 表示队列中的组合个数。所以，总的时间复杂度就是 O(k*n*logX)。那 X 到底是多少呢？

k 次出入队列，队列中的总数据不会超过 k*n，也就是说，出队、入队操作的时间复杂度是 O(log(k*n))。所以，总的时间复杂度就是 O(k*n*log(k*n))，比之前的指数级时间复杂度降低了很多。

课后思考
在计算最短时间的出行路线中，如何获得通过某条路的时间呢？这个题目很有意思，我之前面试的时候也被问到过，你可以思考看看。

今天讲的出行路线问题，我假设的是开车出行，那如果是公交出行呢？如果混合地铁、公交、步行，又该如何规划路线呢？

欢迎留言和我分享，也欢迎点击“请朋友读”，把今天的内容分享给你的好友，和他一起讨论、学习。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(47)

五岳寻仙
课后思考题，自己能想到的。

1.获取通过某条路的时间：通过某条路的时间与①路长度②路况(是否平坦等)③拥堵情况④红绿灯个数等因素相关。获取这些因素后就可以建立一个回归模型(比如线性回归)来估算时间。其中①②④因素比较固定，容易获得。③是动态的，但也可以通过a.与交通部门合作获得路段拥堵情况；b.联合其他导航软件获得在该路段的在线人数；c.通过现在时间段正好在次路段的其他用户的真实情况等方式估算。

2.混合公交、地铁和步行时：地铁时刻表是固定的，容易估算。公交虽然没那么准时，大致时间是可以估计的，步行时间受路拥堵状况小，基本与道路长度成正比，也容易估算。总之，感觉公交、地铁、步行，时间估算会比开车更容易，也更准确些。
2019-01-07


42

徐凯
@五岳寻仙的答案太棒了 👏 我感觉每条道路应该还有限速，这个因素也要考察。
2019-01-07


15

林大涛
用小顶堆，就是为了确保每个阶段，堆顶的节点都是目前阶段的最短路径的节点。
2019-02-13


6

Liam
有2个疑问：

1 Dijkstra就是贪心算法吧？
2 它的解可能不是最优解
作者回复: Dijkstra实际上可以看做动态规划：）

2019-01-08


5

yongxiang
王老师，我输入代码运行后，实际出队列的顺序跟图中的不一样，实际（15，0）出队列 在（13，3）出队列前面。我看了代码，应该是修改（25，1）为 （13，3）的时候，小顶堆不会自动更新顺序。需要对22行进行如下修改，更新已经在队列中，又改了dist的Vertex的优先级：
                   if (inQueue[nextVertex.id] == false){
                        queue.add(nextVertex);
                        inQueue[nextVertex.id] = true;
                    }
                    else { // 更新已经在队列中，又改了dist的Vertex的优先级
                        queue.remove(nextVertex);
                        queue.add(nextVertex);
                    }
作者回复: 嗯嗯 我更新下代码

2019-01-12


3

xuery
构建优先队列的update函数时，时间复杂度应该是O(n)，因为小顶堆查找的时间复杂度是O(n)，虽然查找之后向上堆化的时间复杂度时O（logn）
2019-03-22


2

許敲敲
类似的python代码也会更新嘛，还不熟悉java的
2019-01-07


2

Monday
Dijkstra算法的最后到例子-那张图，各个节点的(0,无), (10,0)等等代表什么意思
2019-08-30

1

1

mαnajay
最开始以为是贪心算法, 再看了一遍,才发现优先级队列的作用(拥有类似回溯的功能),按照已添加队列中最短距离进行小顶堆, 每次 poll 的过程中,都有可能将之前已经计算过的顶点再拿出来, 遍历邻接表,重复到目的顶点
2019-05-18


1

诚实村的村长
我实现了一下老师让自己实现的代码并做了测试在这里分享给大家，对大家有帮助的话可以给个star哦
https://github.com/zzmJava1/Zhimiao-Zhang/tree/master
2019-05-02


1

李东勇
有兴趣的可以看下LeetCode 上这道题： https://leetcode.com/problems/network-delay-time/
用到的就是Dijkstra 算法
2019-01-13


1

Geek_dddebb
亲测更新vertex后对象在队列中的位置不变
作者回复: 代码已经改正，你再看下？；）

2019-01-07


1

魏全运
vertex compareTo有问题吧，怎么没有相等的分支呀？
作者回复: 有也可以 没有也可以的

2019-01-07


1

hughieyu
更新vertex后是否要更新一下对象在优先级队列中的位置，否则会预期更晚弹出优先级队列，会影响查找的速度，除此之外还没有可能出现其他的问题
作者回复: 会自动更新位置的 相当于堆中更新一个节点的值

2019-01-07


1

张三
在图的搜索算法那一节只是提到一句广度优先搜索算法的结果是最短路径，并没有说原因😂
作者回复: 好像有讲到

2019-09-03

2


i 星星
老师，如果这个要是取权重最大该怎么设计呢？
作者回复: 😅，这个需求就不是最短路径问题了

2019-08-31



Monday
说实话没感觉到dijkstra算法使用优先级队列的用处，，，
2019-08-30



美美
思考题中，计算最短时间的，如果考虑道路情况时动态变化的话，就不能使用Dijkstra算法了，Dijkstra可以看做是动态规划，但是道路情况时动态变换的（根据时间），该问题是不满足无后效性的，所以不能单纯的使用Dijkstra算法。
2019-08-27



Paul Shan
思考题2
地铁，公交和步行，就是三类边，这三类边的类型不同，步行可以从任一点到任一点，只是效率有点低，地铁和公交都是指定点到指定点有效而且有时间限制。最短路径就以这三类边消耗的时间和等待时间来找。
2019-07-31



Paul Shan
思考题1 通过某条路的时间和距离有关，车流量和路的宽度有关。距离和路宽是一个固定的变量，假设可以查到，动态的因素就只有车流量了，车流量又和物理位置和时间有关，所以可以以距离，路宽，位置和时间建立一个简单线性模型来估算。
2019-07-31


收起评论

4793






# 45 | 位图：如何实现网页爬虫中的URL去重功能？




数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



45 | 位图：如何实现网页爬虫中的URL去重功能？
王争 2019-01-09



15:13
讲述：修阳 大小：13.95M
网页爬虫是搜索引擎中的非常重要的系统，负责爬取几十亿、上百亿的网页。爬虫的工作原理是，通过解析已经爬取页面中的网页链接，然后再爬取这些链接对应的网页。而同一个网页链接有可能被包含在多个页面中，这就会导致爬虫在爬取的过程中，重复爬取相同的网页。如果你是一名负责爬虫的工程师，你会如何避免这些重复的爬取呢？

最容易想到的方法就是，我们记录已经爬取的网页链接（也就是 URL），在爬取一个新的网页之前，我们拿它的链接，在已经爬取的网页链接列表中搜索。如果存在，那就说明这个网页已经被爬取过了；如果不存在，那就说明这个网页还没有被爬取过，可以继续去爬取。等爬取到这个网页之后，我们将这个网页的链接添加到已经爬取的网页链接列表了。

思路非常简单，我想你应该很容易就能想到。不过，我们该如何记录已经爬取的网页链接呢？需要用什么样的数据结构呢？

算法解析
关于这个问题，我们可以先回想下，是否可以用我们之前学过的数据结构来解决呢？

这个问题要处理的对象是网页链接，也就是 URL，需要支持的操作有两个，添加一个 URL 和查询一个 URL。除了这两个功能性的要求之外，在非功能性方面，我们还要求这两个操作的执行效率要尽可能高。除此之外，因为我们处理的是上亿的网页链接，内存消耗会非常大，所以在存储效率上，我们要尽可能地高效。

我们回想一下，满足这些条件的数据结构有哪些呢？显然，散列表、红黑树、跳表这些动态数据结构，都能支持快速地插入、查找数据，但是对内存消耗方面，是否可以接受呢？

我们拿散列表来举例。假设我们要爬取 10 亿个网页（像 Google、百度这样的通用搜索引擎，爬取的网页可能会更多），为了判重，我们把这 10 亿网页链接存储在散列表中。你来估算下，大约需要多少内存？

假设一个 URL 的平均长度是 64 字节，那单纯存储这 10 亿个 URL，需要大约 60GB 的内存空间。因为散列表必须维持较小的装载因子，才能保证不会出现过多的散列冲突，导致操作的性能下降。而且，用链表法解决冲突的散列表，还会存储链表指针。所以，如果将这 10 亿个 URL 构建成散列表，那需要的内存空间会远大于 60GB，有可能会超过 100GB。

当然，对于一个大型的搜索引擎来说，即便是 100GB 的内存要求，其实也不算太高，我们可以采用分治的思想，用多台机器（比如 20 台内存是 8GB 的机器）来存储这 10 亿网页链接。这种分治的处理思路，我们讲过很多次了，这里就不详细说了。

对于爬虫的 URL 去重这个问题，刚刚讲到的分治加散列表的思路，已经是可以实实在在工作的了。不过，作为一个有追求的工程师，我们应该考虑，在添加、查询数据的效率以及内存消耗方面，我们是否还有进一步的优化空间呢？

你可能会说，散列表中添加、查找数据的时间复杂度已经是 O(1)，还能有进一步优化的空间吗？实际上，我们前面也讲过，时间复杂度并不能完全代表代码的执行时间。大 O 时间复杂度表示法，会忽略掉常数、系数和低阶，并且统计的对象是语句的频度。不同的语句，执行时间也是不同的。时间复杂度只是表示执行时间随数据规模的变化趋势，并不能度量在特定的数据规模下，代码执行时间的多少。

如果时间复杂度中原来的系数是 10，我们现在能够通过优化，将系数降为 1，那在时间复杂度没有变化的情况下，执行效率就提高了 10 倍。对于实际的软件开发来说，10 倍效率的提升，显然是一个非常值得的优化。

如果我们用基于链表的方法解决冲突问题，散列表中存储的是 URL，那当查询的时候，通过哈希函数定位到某个链表之后，我们还需要依次比对每个链表中的 URL。这个操作是比较耗时的，主要有两点原因。

一方面，链表中的结点在内存中不是连续存储的，所以不能一下子加载到 CPU 缓存中，没法很好地利用到 CPU 高速缓存，所以数据访问性能方面会打折扣。

另一方面，链表中的每个数据都是 URL，而 URL 不是简单的数字，是平均长度为 64 字节的字符串。也就是说，我们要让待判重的 URL，跟链表中的每个 URL，做字符串匹配。显然，这样一个字符串匹配操作，比起单纯的数字比对，要慢很多。所以，基于这两点，执行效率方面肯定是有优化空间的。

对于内存消耗方面的优化，除了刚刚这种基于散列表的解决方案，貌似没有更好的法子了。实际上，如果要想内存方面有明显的节省，那就得换一种解决方案，也就是我们今天要着重讲的这种存储结构，布隆过滤器（Bloom Filter）。

在讲布隆过滤器前，我要先讲一下另一种存储结构，位图（BitMap）。因为，布隆过滤器本身就是基于位图的，是对位图的一种改进。

我们先来看一个跟开篇的问题非常类似，但稍微简单的问题。我们有 1 千万个整数，整数的范围在 1 到 1 亿之间。如何快速查找某个整数是否在这 1 千万个整数中呢？

当然，这个问题还是可以用散列表来解决。不过，我们可以使用一种比较“特殊”的散列表，那就是位图。我们申请一个大小为 1 亿、数据类型为布尔类型（true 或者 false）的数组。我们将这 1 千万个整数作为数组下标，将对应的数组值设置成 true。比如，整数 5 对应下标为 5 的数组值设置为 true，也就是 array[5]=true。

当我们查询某个整数 K 是否在这 1 千万个整数中的时候，我们只需要将对应的数组值 array[K] 取出来，看是否等于 true。如果等于 true，那说明 1 千万整数中包含这个整数 K；相反，就表示不包含这个整数 K。

不过，很多语言中提供的布尔类型，大小是 1 个字节的，并不能节省太多内存空间。实际上，表示 true 和 false 两个值，我们只需要用一个二进制位（bit）就可以了。那如何通过编程语言，来表示一个二进制位呢？

这里就要用到位运算了。我们可以借助编程语言中提供的数据类型，比如 int、long、char 等类型，通过位运算，用其中的某个位表示某个数字。文字描述起来有点儿不好理解，我把位图的代码实现写了出来，你可以对照着代码看下，应该就能看懂了。

public class BitMap { // Java 中 char 类型占 16bit，也即是 2 个字节
  private char[] bytes;
  private int nbits;
  
  public BitMap(int nbits) {
    this.nbits = nbits;
    this.bytes = new char[nbits/16+1];
  }
 
  public void set(int k) {
    if (k > nbits) return;
    int byteIndex = k / 16;
    int bitIndex = k % 16;
    bytes[byteIndex] |= (1 << bitIndex);
  }
 
  public boolean get(int k) {
    if (k > nbits) return false;
    int byteIndex = k / 16;
    int bitIndex = k % 16;
    return (bytes[byteIndex] & (1 << bitIndex)) != 0;
  }
}
从刚刚位图结构的讲解中，你应该可以发现，位图通过数组下标来定位数据，所以，访问效率非常高。而且，每个数字用一个二进制位来表示，在数字范围不大的情况下，所需要的内存空间非常节省。

比如刚刚那个例子，如果用散列表存储这 1 千万的数据，数据是 32 位的整型数，也就是需要 4 个字节的存储空间，那总共至少需要 40MB 的存储空间。如果我们通过位图的话，数字范围在 1 到 1 亿之间，只需要 1 亿个二进制位，也就是 12MB 左右的存储空间就够了。

关于位图，我们就讲完了，是不是挺简单的？不过，这里我们有个假设，就是数字所在的范围不是很大。如果数字的范围很大，比如刚刚那个问题，数字范围不是 1 到 1 亿，而是 1 到 10 亿，那位图的大小就是 10 亿个二进制位，也就是 120MB 的大小，消耗的内存空间，不降反增。

这个时候，布隆过滤器就要出场了。布隆过滤器就是为了解决刚刚这个问题，对位图这种数据结构的一种改进。

还是刚刚那个例子，数据个数是 1 千万，数据的范围是 1 到 10 亿。布隆过滤器的做法是，我们仍然使用一个 1 亿个二进制大小的位图，然后通过哈希函数，对数字进行处理，让它落在这 1 到 1 亿范围内。比如我们把哈希函数设计成 f(x)=x%n。其中，x 表示数字，n 表示位图的大小（1 亿），也就是，对数字跟位图的大小进行取模求余。

不过，你肯定会说，哈希函数会存在冲突的问题啊，一亿零一和 1 两个数字，经过你刚刚那个取模求余的哈希函数处理之后，最后的结果都是 1。这样我就无法区分，位图存储的是 1 还是一亿零一了。

为了降低这种冲突概率，当然我们可以设计一个复杂点、随机点的哈希函数。除此之外，还有其他方法吗？我们来看布隆过滤器的处理方法。既然一个哈希函数可能会存在冲突，那用多个哈希函数一块儿定位一个数据，是否能降低冲突的概率呢？我来具体解释一下，布隆过滤器是怎么做的。

我们使用 K 个哈希函数，对同一个数字进行求哈希值，那会得到 K 个不同的哈希值，我们分别记作 X1，X2，X3，…，XK。我们把这 K 个数字作为位图中的下标，将对应的 BitMap[X1]，BitMap[X2]，BitMap[X3]，…，BitMap[XK] 都设置成 true，也就是说，我们用 K 个二进制位，来表示一个数字的存在。

当我们要查询某个数字是否存在的时候，我们用同样的 K 个哈希函数，对这个数字求哈希值，分别得到 Y1，Y2，Y3，…，YK。我们看这 K 个哈希值，对应位图中的数值是否都为 true，如果都是 true，则说明，这个数字存在，如果有其中任意一个不为 true，那就说明这个数字不存在。



对于两个不同的数字来说，经过一个哈希函数处理之后，可能会产生相同的哈希值。但是经过 K 个哈希函数处理之后，K 个哈希值都相同的概率就非常低了。尽管采用 K 个哈希函数之后，两个数字哈希冲突的概率降低了，但是，这种处理方式又带来了新的问题，那就是容易误判。我们看下面这个例子。



布隆过滤器的误判有一个特点，那就是，它只会对存在的情况有误判。如果某个数字经过布隆过滤器判断不存在，那说明这个数字真的不存在，不会发生误判；如果某个数字经过布隆过滤器判断存在，这个时候才会有可能误判，有可能并不存在。不过，只要我们调整哈希函数的个数、位图大小跟要存储数字的个数之间的比例，那就可以将这种误判的概率降到非常低。

尽管布隆过滤器会存在误判，但是，这并不影响它发挥大作用。很多场景对误判有一定的容忍度。比如我们今天要解决的爬虫判重这个问题，即便一个没有被爬取过的网页，被误判为已经被爬取，对于搜索引擎来说，也并不是什么大事情，是可以容忍的，毕竟网页太多了，搜索引擎也不可能 100% 都爬取到。

弄懂了布隆过滤器，我们今天的爬虫网页去重的问题，就很简单了。

我们用布隆过滤器来记录已经爬取过的网页链接，假设需要判重的网页有 10 亿，那我们可以用一个 10 倍大小的位图来存储，也就是 100 亿个二进制位，换算成字节，那就是大约 1.2GB。之前我们用散列表判重，需要至少 100GB 的空间。相比来讲，布隆过滤器在存储空间的消耗上，降低了非常多。

那我们再来看下，利用布隆过滤器，在执行效率方面，是否比散列表更加高效呢？

布隆过滤器用多个哈希函数对同一个网页链接进行处理，CPU 只需要将网页链接从内存中读取一次，进行多次哈希计算，理论上讲这组操作是 CPU 密集型的。而在散列表的处理方式中，需要读取散列冲突拉链的多个网页链接，分别跟待判重的网页链接，进行字符串匹配。这个操作涉及很多内存数据的读取，所以是内存密集型的。我们知道 CPU 计算可能是要比内存访问更快速的，所以，理论上讲，布隆过滤器的判重方式，更加快速。

总结引申
今天，关于搜索引擎爬虫网页去重问题的解决，我们从散列表讲到位图，再讲到布隆过滤器。布隆过滤器非常适合这种不需要 100% 准确的、允许存在小概率误判的大规模判重场景。除了爬虫网页去重这个例子，还有比如统计一个大型网站的每天的 UV 数，也就是每天有多少用户访问了网站，我们就可以使用布隆过滤器，对重复访问的用户，进行去重。

我们前面讲到，布隆过滤器的误判率，主要跟哈希函数的个数、位图的大小有关。当我们往布隆过滤器中不停地加入数据之后，位图中不是 true 的位置就越来越少了，误判率就越来越高了。所以，对于无法事先知道要判重的数据个数的情况，我们需要支持自动扩容的功能。

当布隆过滤器中，数据个数与位图大小的比例超过某个阈值的时候，我们就重新申请一个新的位图。后面来的新数据，会被放置到新的位图中。但是，如果我们要判断某个数据是否在布隆过滤器中已经存在，我们就需要查看多个位图，相应的执行效率就降低了一些。

位图、布隆过滤器应用如此广泛，很多编程语言都已经实现了。比如 Java 中的 BitSet 类就是一个位图，Redis 也提供了 BitMap 位图类，Google 的 Guava 工具包提供了 BloomFilter 布隆过滤器的实现。如果你感兴趣，你可以自己去研究下这些实现的源码。

课后思考
假设我们有 1 亿个整数，数据范围是从 1 到 10 亿，如何快速并且省内存地给这 1 亿个数据从小到大排序？

还记得我们在哈希函数（下）讲过的利用分治思想，用散列表以及哈希函数，实现海量图库中的判重功能吗？如果我们允许小概率的误判，那是否可以用今天的布隆过滤器来解决呢？你可以参照我们当时的估算方法，重新估算下，用布隆过滤器需要多少台机器？

欢迎留言和我分享，也欢迎点击“请朋友读”，把今天的内容分享给你的好友，和他一起讨论、学习。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(53)

DreamYe
bloom filter: False is always false. True is maybe true.
2019-01-09


66

五岳寻仙
课后思考题1

传统的做法：1亿个整数，存储需要400M空间，排序时间复杂度最优 N×log(N)

使用位图算法：数字范围是1到10亿，用位图存储125M就够了，然后将1亿个数字依次添加到位图中，然后再将位图按下标从小到大输出值为1的下标，排序就完成了，时间复杂度为 N
2019-01-09

1

37

www.xnsms.com小鸟接码
位图代码的实现一开始没看懂，请教了下身边一位大神同事才搞懂，原来char类型存储数字的时候，只占1个字节，也就是8位。所以计算的时候都是除8或者模8。希望我的回答可以帮助其他跟我一样基础薄弱的同学，共同进步
2019-01-09

1

21

越过山丘
第一题，数字重复了，有什么好方法处理吗
作者回复: 对于重复的 可以再维护一个小的散列表 记录出现次数超过1次的数据以及对应的个数

2019-01-10

2

13

ban
这个char代码最好还是用图解比较好理解，纯代码看不懂。
我这里有另外一个位的图解计算过程，再去看代码，你就会秒懂
https://mp.weixin.qq.com/s/xxauNrJY9HlVNvLrL5j2hg
2019-01-11


12

猫头鹰爱拿铁
思考题1的java实现。
import java.util.Random;

public class BitMap {
private int[] bits;
private int[] input;

public BitMap(int n, int[] input) {
bits = new int[n];
this.input = input;
}

public void setBit(int n) {
int offset = n / 32;
int value = n % 32;
bits[offset] |= (1 << value);
}

public boolean getBit(int n) {
int offset = n / 32;
int value = n % 32;
return (bits[offset] & (1 << value)) != 0;
}

/**
* 排序
*
* @param n
* 是数组的存储整数范围
* @param input
* 输入的未排序数组
* @return 有序的数组范围
*/
public int sort(int n, int[] input) {
int j = 0;
for (int i = 1; i <= 10 * n; i++) {
if (getBit(i)) {
input[j++] = i;
}
}
return j;
}

public static void main(String[] args) {
int n = 1000000000;
int[] input = new int[n];
Random r = new Random();
for (int i = 0; i < n; i++) {
input[i] = r.nextInt(10 * n - 1) + 1;
}
BitMap bitMap = new BitMap(10 * n, input);
for (int i = 0; i < n; i++) {
bitMap.setBit(input[i]);
}
int size = bitMap.sort(n, input);
for (int i = 0; i < size; i++)
System.out.print(input[i] + ",");
}
}
2019-01-09


4

传说中的成大大
1亿个整数 如果完全读入内存大约是0.4G的样子 可以直接快排排序
通过位图方式开辟一个十亿大小的位图缩小到0.125g的样子,虽然数字只有一亿个,但是我们却要检查1到10亿之间的数字是否存在再输出即可达到排序
2019-01-09


4

Kudo
直观上感觉位图有点像学排序时桶的概念，所以使用位图也可以实现类似于桶排序的效率。
2019-01-09


4

Sharry
这个位图很精妙，因为编程语言没有提供bit类型，所以使用byte进行位运算的方式，巧妙的利用每一位，以达到减少内存开辟的消耗的问题
2019-01-09


4

Flash
争哥，我想到了通过hash算法将String转换为int类型数据，然后再将int数据位运算存储到位图上，可是这个hash算法，也可能会出现散列冲突啊，不同的String有可能是同一个int，然后反应到位图上就是相同的bit位了。
2019-03-29


2

曹金霖
将数字 A 的第 k 位设置为1：A = A | (1 << (k - 1))
将数字 A 的第 k 位设置为0：A = A & ~(1 << (k - 1))
检测数字 A 的第 k 位：A & (1 << (k - 1)) != 0
用于理解bitmap中代码
2019-03-12


2

公号-代码荣耀
在线上环境，我们采用redis的set进行去重，效果还是不错的
2019-01-12


2

煦暖
争哥，位图的代码理解了好久还没懂(；′⌒`)，能加几行注释吗？？
作者回复: 好的 我去补充下

2019-01-11


2

阮雅
王争哥，您好。你画这个图，用的啥软件画的啊？ 比普通的黑白图更容易理解。望求解！感激不尽！
作者回复: ipad paper

2019-01-09


2

marvinle
老师，按照你的讲解我写了一个简单的布隆过滤器， 使用了3个简单的哈希函数，判错率在0.9左右
不知道是否是属于偏高了，这是代码，可以的话帮忙看看是否正确https://github.com/MarvinLe/tools/tree/master/BloomFilter
作者回复: 判错旅太高了 哈希函数不够随机均匀？位图不够大？

2019-01-09


2

Costar
有个问题怎么解决的？Bloom filter删除数据时，不能把bit位置0
作者回复: 一般不用来删除，如果非要支持删除，可以再弄个数据结构记录删除的数据。

2019-07-02


1

雍鹏亮
思考题1和桶排序一样吧，把对应的的桐位置1，然后依次读取
2019-01-22


1

www.xnsms.com小鸟接码
思考题1:用10亿个位的位图存储这1亿个数，然后直接按脚标从0到10亿顺序遍历整个位图，如果位为1，则打印脚标，打印出来的就是排好序的1亿个数字

思考题2:用位图的话。一个机器应该就够了
2019-01-09


1

张三
感觉布隆过滤器里边的数组类似动态规划里边的状态表
2019-09-03



拉环
位图的那个如果是java之类的语言 想设置某个位置为false 有办法吗
2019-08-08


收起评论

5391






# 46 | 概率统计：如何利用朴素贝叶斯算法过滤垃圾短信？




数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



46 | 概率统计：如何利用朴素贝叶斯算法过滤垃圾短信？
王争 2019-01-11



14:31
讲述：修阳 大小：13.30M
上一节我们讲到，如何用位图、布隆过滤器，来过滤重复的数据。今天，我们再讲一个跟过滤相关的问题，如何过滤垃圾短信？

垃圾短信和骚扰电话，我想每个人都收到过吧？买房、贷款、投资理财、开发票，各种垃圾短信和骚扰电话，不胜其扰。如果你是一名手机应用开发工程师，让你实现一个简单的垃圾短信过滤功能以及骚扰电话拦截功能，该用什么样的数据结构和算法实现呢？

算法解析
实际上，解决这个问题并不会涉及很高深的算法。今天，我就带你一块看下，如何利用简单的数据结构和算法，解决这种看似非常复杂的问题。

1. 基于黑名单的过滤器
我们可以维护一个骚扰电话号码和垃圾短信发送号码的黑名单。这个黑名单的搜集，有很多途径，比如，我们可以从一些公开的网站上下载，也可以通过类似“360 骚扰电话拦截”的功能，通过用户自主标记骚扰电话来收集。对于被多个用户标记，并且标记个数超过一定阈值的号码，我们就可以定义为骚扰电话，并将它加入到我们的黑名单中。

如果黑名单中的电话号码不多的话，我们可以使用散列表、二叉树等动态数据结构来存储，对内存的消耗并不会很大。如果我们把每个号码看作一个字符串，并且假设平均长度是 16 个字节，那存储 50 万个电话号码，大约需要 10MB 的内存空间。即便是对于手机这样的内存有限的设备来说，这点内存的消耗也是可以接受的。

但是，如果黑名单中的电话号码很多呢？比如有 500 万个。这个时候，如果再用散列表存储，就需要大约 100MB 的存储空间。为了实现一个拦截功能，耗费用户如此多的手机内存，这显然有点儿不合理。

上一节我们讲了，布隆过滤器最大的特点就是比较省存储空间，所以，用它来解决这个问题再合适不过了。如果我们要存储 500 万个手机号码，我们把位图大小设置为 10 倍数据大小，也就是 5000 万，那也只需要使用 5000 万个二进制位（5000 万 bits），换算成字节，也就是不到 7MB 的存储空间。比起散列表的解决方案，内存的消耗减少了很多。

实际上，我们还有一种时间换空间的方法，可以将内存的消耗优化到极致。

我们可以把黑名单存储在服务器端上，把过滤和拦截的核心工作，交给服务器端来做。手机端只负责将要检查的号码发送给服务器端，服务器端通过查黑名单，判断这个号码是否应该被拦截，并将结果返回给手机端。

用这个解决思路完全不需要占用手机内存。不过，有利就有弊。我们知道，网络通信是比较慢的，所以，网络延迟就会导致处理速度降低。而且，这个方案还有个硬性要求，那就是只有在联网的情况下，才能正常工作。

基于黑名单的过滤器我就讲完了，不过，你可能还会说，布隆过滤器会有判错的概率呀！如果它把一个重要的电话或者短信，当成垃圾短信或者骚扰电话拦截了，对于用户来说，这是无法接受的。你说的没错，这是一个很大的问题。不过，我们现在先放一放，等三种过滤器都讲完之后，我再来解答。

2. 基于规则的过滤器
刚刚讲了一种基于黑名单的垃圾短信过滤方法，但是，如果某个垃圾短信发送者的号码并不在黑名单中，那这种方法就没办法拦截了。所以，基于黑名单的过滤方式，还不够完善，我们再继续看一种基于规则的过滤方式。

对于垃圾短信来说，我们还可以通过短信的内容，来判断某条短信是否是垃圾短信。我们预先设定一些规则，如果某条短信符合这些规则，我们就可以判定它是垃圾短信。实际上，规则可以有很多，比如下面这几个：

短信中包含特殊单词（或词语），比如一些非法、淫秽、反动词语等；

短信发送号码是群发号码，非我们正常的手机号码，比如 +60389585；

短信中包含回拨的联系方式，比如手机号码、微信、QQ、网页链接等，因为群发短信的号码一般都是无法回拨的；

短信格式花哨、内容很长，比如包含各种表情、图片、网页链接等；

符合已知垃圾短信的模板。垃圾短信一般都是重复群发，对于已经判定为垃圾短信的短信，我们可以抽象成模板，将获取到的短信与模板匹配，一旦匹配，我们就可以判定为垃圾短信。

当然，如果短信只是满足其中一条规则，如果就判定为垃圾短信，那会存在比较大的误判的情况。我们可以综合多条规则进行判断。比如，满足 2 条以上才会被判定为垃圾短信；或者每条规则对应一个不同的得分，满足哪条规则，我们就累加对应的分数，某条短信的总得分超过某个阈值，才会被判定为垃圾短信。

不过，我只是给出了一些制定规则的思路，具体落实到执行层面，其实还有很大的距离，还有很多细节需要处理。比如，第一条规则中，我们该如何定义特殊单词；第二条规则中，我们该如何定义什么样的号码是群发号码等等。限于篇幅，我就不一一详细展开来讲了。我这里只讲一下，如何定义特殊单词？

如果我们只是自己盘脑袋想，哪些单词属于特殊单词，那势必有比较大的主观性，也很容易漏掉某些单词。实际上，我们可以基于概率统计的方法，借助计算机强大的计算能力，找出哪些单词最常出现在垃圾短信中，将这些最常出现的单词，作为特殊单词，用来过滤短信。

不过这种方法的前提是，我们有大量的样本数据，也就是说，要有大量的短信（比如 1000 万条短信），并且我们还要求，每条短信都做好了标记，它是垃圾短信还是非垃圾短信。

我们对这 1000 万条短信，进行分词处理（借助中文或者英文分词算法），去掉“的、和、是”等没有意义的停用词（Stop words），得到 n 个不同的单词。针对每个单词，我们统计有多少个垃圾短信出现了这个单词，有多少个非垃圾短信会出现这个单词，进而求出每个单词出现在垃圾短信中的概率，以及出现在非垃圾短信中的概率。如果某个单词出现在垃圾短信中的概率，远大于出现在非垃圾短信中的概率，那我们就把这个单词作为特殊单词，用来过滤垃圾短信。

文字描述不好理解，我举个例子来解释一下。



3. 基于概率统计的过滤器
基于规则的过滤器，看起来很直观，也很好理解，但是它也有一定的局限性。一方面，这些规则受人的思维方式局限，规则未免太过简单；另一方面，垃圾短信发送者可能会针对规则，精心设计短信，绕过这些规则的拦截。对此，我们再来看一种更加高级的过滤方式，基于概率统计的过滤方式。

这种基于概率统计的过滤方式，基础理论是基于朴素贝叶斯算法。为了让你更好地理解下面的内容，我们先通过一个非常简单的例子来看下，什么是朴素贝叶斯算法？

假设事件 A 是“小明不去上学”，事件 B 是“下雨了”。我们现在统计了一下过去 10 天的下雨情况和小明上学的情况，作为样本数据。



我们来分析一下，这组样本有什么规律。在这 10 天中，有 4 天下雨，所以下雨的概率 P(B)=4/10。10 天中有 3 天，小明没有去上学，所以小明不去上学的概率 P(A)=3/10。在 4 个下雨天中，小明有 2 天没去上学，所以下雨天不去上学的概率 P(A|B)=2/4。在小明没有去上学的 3 天中，有 2 天下雨了，所以小明因为下雨而不上学的概率是 P(B|A)=2/3。实际上，这 4 个概率值之间，有一定的关系，这个关系就是朴素贝叶斯算法，我们用公式表示出来，就是下面这个样子。



朴素贝叶斯算法是不是非常简单？我们用一个公式就可以将它概括。弄懂了朴素贝叶斯算法，我们再回到垃圾短信过滤这个问题上，看看如何利用朴素贝叶斯算法，来做垃圾短信的过滤。

基于概率统计的过滤器，是基于短信内容来判定是否是垃圾短信。而计算机没办法像人一样理解短信的含义。所以，我们需要把短信抽象成一组计算机可以理解并且方便计算的特征项，用这一组特征项代替短信本身，来做垃圾短信过滤。

我们可以通过分词算法，把一个短信分割成 n 个单词。这 n 个单词就是一组特征项，全权代表这个短信。因此，判定一个短信是否是垃圾短信这样一个问题，就变成了，判定同时包含这几个单词的短信是否是垃圾短信。

不过，这里我们并不像基于规则的过滤器那样，非黑即白，一个短信要么被判定为垃圾短信、要么被判定为非垃圾短息。我们使用概率，来表征一个短信是垃圾短信的可信程度。如果我们用公式将这个概率表示出来，就是下面这个样子：



尽管我们有大量的短信样本，但是我们没法通过样本数据统计得到这个概率。为什么不可以呢？你可能会说，我只需要统计同时包含 W1，W2，W3，…，Wn 这 n 个单词的短信有多少个（我们假设有 x 个），然后看这里面属于垃圾短信的有几个（我们假设有 y 个），那包含 W1，W2，W3，…，Wn 这 n 个单词的短信是垃圾短信的概率就是 y/x。

理想很丰满，但现实往往很骨感。你忽视了非常重要的一点，那就是样本的数量再大，毕竟也是有限的，样本中不会有太多同时包含 W1，W2，W3，…，Wn 的短信的，甚至很多时候，样本中根本不存在这样的短信。没有样本，也就无法计算概率。所以这样的推理方式虽然正确，但是实践中并不好用。

这个时候，朴素贝叶斯公式就可以派上用场了。我们通过朴素贝叶斯公式，将这个概率的求解，分解为其他三个概率的求解。你可以看我画的图。那转化之后的三个概率是否可以通过样本统计得到呢？



P（W1，W2，W3，…，Wn 同时出现在一条短信中 | 短信是垃圾短信）这个概率照样无法通过样本来统计得到。但是我们可以基于下面这条著名的概率规则来计算。

独立事件发生的概率计算公式：P(A*B) = P(A)*P(B)

如果事件 A 和事件 B 是独立事件，两者的发生没有相关性，事件 A 发生的概率 P(A) 等于 p1，事件 B 发生的概率 P(B) 等于 p2，那两个同时发生的概率 P(A*B) 就等于 P(A)*P(B)。

基于这条独立事件发生概率的计算公式，我们可以把 P（W1，W2，W3，…，Wn 同时出现在一条短信中 | 短信是垃圾短信）分解为下面这个公式：



其中，P（Wi 出现在短信中 | 短信是垃圾短信）表示垃圾短信中包含 Wi 这个单词的概率有多大。这个概率值通过统计样本很容易就能获得。我们假设垃圾短信有 y 个，其中包含 Wi 的有 x 个，那这个概率值就等于 x/y。

P（W1，W2，W3，…，Wn 同时出现在一条短信中 | 短信是垃圾短信）这个概率值，我们就计算出来了，我们再来看下剩下两个。

P（短信是垃圾短信）表示短信是垃圾短信的概率，这个很容易得到。我们把样本中垃圾短信的个数除以总样本短信个数，就是短信是垃圾短信的概率。

不过，P（W1，W2，W3，…，Wn 同时出现在一条短信中）这个概率还是不好通过样本统计得到，原因我们前面说过了，样本空间有限。不过，我们没必要非得计算这一部分的概率值。为什么这么说呢？

实际上，我们可以分别计算同时包含 W1，W2，W3，…，Wn 这 n 个单词的短信，是垃圾短信和非垃圾短信的概率。假设它们分别是 p1 和 p2。我们并不需要单纯地基于 p1 值的大小来判断是否是垃圾短信，而是通过对比 p1 和 p2 值的大小，来判断一条短信是否是垃圾短信。更细化一点讲，那就是，如果 p1 是 p2 的很多倍（比如 10 倍），我们才确信这条短信是垃圾短信。



基于这两个概率的倍数来判断是否是垃圾短信的方法，我们就可以不用计算 P（W1，W2，W3，…，Wn 同时出现在一条短信中）这一部分的值了，因为计算 p1 与 p2 的时候，都会包含这个概率值的计算，所以在求解 p1 和 p2 倍数（p1/p2）的时候，我们也就不需要这个值。

总结引申
今天，我们讲了基于黑名单、规则、概率统计三种垃圾短信的过滤方法，实际上，今天讲的这三种方法，还可以应用到很多类似的过滤、拦截的领域，比如垃圾邮件的过滤等等。

在讲黑名单过滤的时候，我讲到布隆过滤器可能会存在误判情况，可能会导致用户投诉。实际上，我们可以结合三种不同的过滤方式的结果，对同一个短信处理，如果三者都表明这个短信是垃圾短信，我们才把它当作垃圾短信拦截过滤，这样就会更精准。

当然，在实际的工程中，我们还需要结合具体的场景，以及大量的实验，不断去调整策略，权衡垃圾短信判定的准确率（是否会把不是垃圾的短信错判为垃圾短信）和召回率（是否能把所有的垃圾短信都找到），来实现我们的需求。

课后思考
关于垃圾短信过滤和骚扰电话的拦截，我们可以一块儿头脑风暴一下，看看你还有没有其他方法呢？

欢迎留言和我分享，也欢迎点击“请朋友读”，把今天的内容分享给你的好友，和他一起讨论、学习。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(24)

slvher
对于短信文本，机器学习尤其是 NLP 方向的很多算法可用于 anti-spam。文本分类任务，特征工程做得稍用心的话，判别式模型（典型如 logistic regression）的效果通常好于生成式模型（典型如 naive-bayes）。

对于电话号码数字，感觉用正则或定时拉取黑名单比 ml 模型简单可靠。
2019-01-11


15

木木匠
我觉得这种分类过滤，最好的可能是机器学习，通过大量的垃圾短信样本来训练特征，最后可以达到过滤短信和邮件的目的，而且这种方法应该效果更好，至于电话拦截，实际上就是电话号码黑名单的问题，我觉得用布隆过滤器可以满足通用场景，一般实际场景中，对于这种电话是提示谨慎接听，但是我们可以本地和云端结合处理，解决部分的误报问题，当判断是黑名单的时候再去云端查，确认是否是真的黑名单。这样用布隆过滤器+云端也是一种方式
2019-01-11


12

C_love
为啥P(W1W2...Wn|垃圾短信)是独立事件，能够拆成乘积，而P(W1W2...Wn)不是独立事件？
作者回复: 也是也是。

2019-01-14


7

纯洁的憎恶
黑名单过滤法基于经验判断，难以确保及时性。基于内容规则的过滤法容易被针对，而且动态调整规则的成本较高。基于朴素贝叶斯算法的内容概率过滤法，既可以确保及时性，又能够较好的基于实际情况的变化而变化，具备初步智能特性。因为贝叶斯方法是基于先验判断，然后根据现实反馈动态调整判断的算法。

当绝对值不好计算时，可以结合场景需要，合理使用相对值代替绝对值，以简化计算难度、消除无法计算的因子。
2019-01-11


4

ldd
请问，基于黑名单的过滤方式，用布隆过滤器只能存储Bool值，即是否存储，但是还要实现“标记次数来判断是否达到阈值”，就需要额外的散列表了，需要的内存空间依然很大，方案上还不如直接用散列表来的更好吧？
作者回复: 你说的这是一种情况，大部分情况，都不会命中，也就说，都不是骚扰电话。

2019-04-08


2

loda
朴素贝叶斯讲的很好
2019-04-06


2

Clement
图片上的数据和公式使用什么软件画出来的？
编辑回复: iPad Paper

2019-01-21


2

墨禾
其实这个问题就是个分类预测问题，传统的机器学习方法中的分类预测算法都可以用
2019-01-11


2

小新村小学扛霸子
P（W1,W2...Wn同时出现在一条短信中） = P（W1出现在短信中） * P（W2出现在短信中） *....* P（Wn出现在短信中）这样计算应该就可以吧
2019-04-25


1

🐱您的好友William🐱
1.为啥叫naive：因为假设了条件分布中各个feature是独立出现的，feature之间啥关系没有！所以很naive，很朴素，很“傻”，但是效果真的不一定差，而且在没开发出更好的模型之前直接进行统计计算就能得出结果，且可以做成online的，怎么看都不亏啊（反正你也得用统计数据做其他的事，顺道做了呗老弟）！

2.如果概率为0了怎么办！可以使用laplacian smoothing，简单的来说就是在分子分母上面加数来保证不会有0的出现。直接使用很小的数是可以的（遵循频率学派频率为大），但更精确的在分母分子上加什么，这个其实是与贝叶斯学派所认为的先验分布有关，就是在不看sample时，我们的先验知识对这种情况的估计是多少（比如我在不统计工科学校男女比例的时候就有了一定的先验知识：7:1，之后我再统计其实是对我的先验估计的一种调整）。
2019-01-21


1

ban
https://www.jianshu.com/p/5cf3a155b2f0
找到另外一个相亲的例子
2019-01-13


1

Paul Shan
现在基于有监督的深度学习的检测算法比较流行，也就是通过标注样本来检测。这种方法的好处是准确率高，而且可以与时俱进，动态调整。缺点是训练模型时间长，消耗运算量大，需要标注的样本多。
2019-08-05



ferry
将短信内容中的分词假设为完全独立是不是不太符合实际情况呢？是否应该使用多元文法，假设为分词与前若干个分词相关呢？
作者回复: 你说的也没错，不过那样就复杂了。

2019-06-11



danvid
评分模型中BM25模型中的二元独立模型也是基于这个来做的～一模一样～，这个东西加上词频就是BM25模型了
2019-05-29



磊爷
高频点击判断为骚扰短信，中奖，打钱，送东西
2019-04-29



ppingfann
有一问题：

短信中出现的单词w1、w2、…、wn应该不是独立事件吧。很多输入法也是依据用户前面输入的单词来推荐后面用户可能会想输入的单词的。这个应该就能说明单词输入之间不应该是独立事件的。

就算为了解决问题方便，假设事件为独立事件，那么

P(w1、w2、…、wn同时出现在短信中)，这个概率是可以拆分成P(w1)、P(w2)、…、P(wn)相乘计算出来的。也就没有后面那些步骤了。

（btw后面这个思想确实很智慧）
2019-04-02



lttzzlll
上一节我们讲了，布隆过滤器最大的特点就是比较省存储空间，所以，用它来解决这个问题再合适不过了。如果我们要存储 500 万个手机号码，我们把位图大小设置为 10 倍数据大小，也就是 5000 万，那也只需要使用 5000 万个二进制位（5000 万 bits），换算成字节，也就是不到 7MB 的存储空间。比起散列表的解决方案，内存的消耗减少了很多。

这段话中：对于需要使用的内存空间有疑问，按照上一节的处理方式，把手机号码转换为整数，使用的内存空间应该是整数的范围 * 10 bits, 而不是手机号的数量 * 10 bits? 或者，这里不把手机号码转化为整数，用其他的哈希方法，把这500w个手机号映射到[0, 500W)这个区间内？
作者回复: 布隆过滤器本身就是解决位图消耗空间比较多的问题。位图的大小是数据的范围。而布隆过滤器的大小应该是小于位图大小的，所以肯定就是数据的范围了。

2019-02-17



楚
请问怎么确定分词后的哪些词是W，怎么选择。
作者回复: 去掉无意义的“的”“是”等词，都可以作为w

2019-01-15



www.xnsms.com小鸟接码
前段时间刚看概率论与数理统计，看了2/3，这么经典的公式现在居然忘完了……
2019-01-14



Alexis何春光
请问具体要如何用位图存储手机号码呢？之前的例子是存储数字，可以直接使用数字的值作为下标。那么这里也要用手机号作为下标吗？还是要再做一次hash处理呢？会需要额外维护手机号与下表的hashmap吗？
2019-01-13


收起评论

2470






# 47 | 向量空间：如何实现一个简单的音乐推荐系统？



数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



47 | 向量空间：如何实现一个简单的音乐推荐系统？
王争 2019-01-14



08:23
讲述：修阳 大小：7.69M
很多人都喜爱听歌，以前我们用 MP3 听歌，现在直接通过音乐 App 在线就能听歌。而且，各种音乐 App 的功能越来越强大，不仅可以自己选歌听，还可以根据你听歌的口味偏好，给你推荐可能会喜爱的音乐，而且有时候，推荐的音乐还非常适合你的口味，甚至会惊艳到你！如此智能的一个功能，你知道它是怎么实现的吗？

算法解析
实际上，要解决这个问题，并不需要特别高深的理论。解决思路的核心思想非常简单、直白，用两句话就能总结出来。

找到跟你口味偏好相似的用户，把他们爱听的歌曲推荐给你；

找出跟你喜爱的歌曲特征相似的歌曲，把这些歌曲推荐给你。

接下来，我就分别讲解一下这两种思路的具体实现方法。

1. 基于相似用户做推荐
如何找到跟你口味偏好相似的用户呢？或者说如何定义口味偏好相似呢？实际上，思路也很简单，我们把跟你听类似歌曲的人，看做口味相似的用户。你可以看我下面画的这个图。我用“1”表示“喜爱”，用“0”笼统地表示“不发表意见”。从图中我们可以看出，你跟小明共同喜爱的歌曲最多，有 5 首。于是，我们就可以说，小明跟你的口味非常相似。



我们只需要遍历所有的用户，对比每个用户跟你共同喜爱的歌曲个数，并且设置一个阈值，如果你和某个用户共同喜爱的歌曲个数超过这个阈值，我们就把这个用户看作跟你口味相似的用户，把这个用户喜爱但你还没听过的歌曲，推荐给你。

不过，刚刚的这个解决方案中有一个问题，我们如何知道用户喜爱哪首歌曲呢？也就是说，如何定义用户对某首歌曲的喜爱程度呢？

实际上，我们可以通过用户的行为，来定义这个喜爱程度。我们给每个行为定义一个得分，得分越高表示喜爱程度越高。



还是刚刚那个例子，我们如果把每个人对每首歌曲的喜爱程度表示出来，就是下面这个样子。图中，某个人对某首歌曲是否喜爱，我们不再用“1”或者“0”来表示，而是对应一个具体的分值。



有了这样一个用户对歌曲的喜爱程度的对应表之后，如何来判断两个用户是否口味相似呢？

显然，我们不能再像之前那样，采用简单的计数来统计两个用户之间的相似度。还记得我们之前讲字符串相似度度量时，提到的编辑距离吗？这里的相似度度量，我们可以使用另外一个距离，那就是欧几里得距离（Euclidean distance）。欧几里得距离是用来计算两个向量之间的距离的。这个概念中有两个关键词，向量和距离，我来给你解释一下。

一维空间是一条线，我们用 1，2，3……这样单个的数，来表示一维空间中的某个位置；二维空间是一个面，我们用（1，3）（4，2）（2，2）……这样的两个数，来表示二维空间中的某个位置；三维空间是一个立体空间，我们用（1，3，5）（3，1，7）（2，4，3）……这样的三个数，来表示三维空间中的某个位置。一维、二维、三维应该都不难理解，那更高维中的某个位置该如何表示呢？

类比一维、二维、三维的表示方法，K 维空间中的某个位置，我们可以写作（X1，X2，X3，…，XK）。这种表示方法就是向量（vector）。我们知道，二维、三维空间中，两个位置之间有距离的概念，类比到高纬空间，同样也有距离的概念，这就是我们说的两个向量之间的距离。

那如何计算两个向量之间的距离呢？我们还是可以类比到二维、三维空间中距离的计算方法。通过类比，我们就可以得到两个向量之间距离的计算公式。这个计算公式就是欧几里得距离的计算公式：



我们把每个用户对所有歌曲的喜爱程度，都用一个向量表示。我们计算出两个向量之间的欧几里得距离，作为两个用户的口味相似程度的度量。从图中的计算可以看出，小明与你的欧几里得距离距离最小，也就是说，你俩在高维空间中靠得最近，所以，我们就断定，小明跟你的口味最相似。



2. 基于相似歌曲做推荐
刚刚我们讲了基于相似用户的歌曲推荐方法，但是，如果用户是一个新用户，我们还没有收集到足够多的行为数据，这个时候该如何推荐呢？我们现在再来看另外一种推荐方法，基于相似歌曲的推荐方法，也就是说，如果某首歌曲跟你喜爱的歌曲相似，我们就把它推荐给你。

如何判断两首歌曲是否相似呢？对于人来说，这个事情可能会比较简单，但是对于计算机来说，判断两首歌曲是否相似，那就需要通过量化的数据来表示了。我们应该通过什么数据来量化两个歌曲之间的相似程度呢？

最容易想到的是，我们对歌曲定义一些特征项，比如是伤感的还是愉快的，是摇滚还是民谣，是柔和的还是高亢的等等。类似基于相似用户的推荐方法，我们给每个歌曲的每个特征项打一个分数，这样每个歌曲就都对应一个特征项向量。我们可以基于这个特征项向量，来计算两个歌曲之间的欧几里得距离。欧几里得距离越小，表示两个歌曲的相似程度越大。

但是，要实现这个方案，需要有一个前提，那就是我们能够找到足够多，并且能够全面代表歌曲特点的特征项，除此之外，我们还要人工给每首歌标注每个特征项的得分。对于收录了海量歌曲的音乐 App 来说，这显然是一个非常大的工程。此外，人工标注有很大的主观性，也会影响到推荐的准确性。

既然基于歌曲特征项计算相似度不可行，那我们就换一种思路。对于两首歌，如果喜欢听的人群都是差不多的，那侧面就可以反映出，这两首歌比较相似。如图所示，每个用户对歌曲有不同的喜爱程度，我们依旧通过上一个解决方案中定义得分的标准，来定义喜爱程度。



你有没有发现，这个图跟基于相似用户推荐中的图几乎一样。只不过这里把歌曲和用户主次颠倒了一下。基于相似用户的推荐方法中，针对每个用户，我们将对各个歌曲的喜爱程度作为向量。基于相似歌曲的推荐思路中，针对每个歌曲，我们将每个用户的打分作为向量。

有了每个歌曲的向量表示，我们通过计算向量之间的欧几里得距离，来表示歌曲之间的相似度。欧几里得距离越小，表示两个歌曲越相似。然后，我们就在用户已经听过的歌曲中，找出他喜爱程度较高的歌曲。然后，我们找出跟这些歌曲相似度很高的其他歌曲，推荐给他。

总结引申
实际上，这个问题是推荐系统（Recommendation System）里最典型的一类问题。之所以讲这部分内容，主要还是想给你展示，算法的强大之处，利用简单的向量空间的欧几里得距离，就能解决如此复杂的问题。不过，今天，我只给你讲解了基本的理论，实践中遇到的问题还有很多，比如冷启动问题，产品初期积累的数据不多，不足以做推荐等等。这些更加深奥的内容，你可以之后自己在实践中慢慢探索。

课后思考
关于今天讲的推荐算法，你还能想到其他应用场景吗？

欢迎留言和我分享，也欢迎点击“请朋友读”，把今天的内容分享给你的好友，和他一起讨论、学习。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(31)

刑无刀
讲得好！对推荐系统感兴趣，可以订阅《推荐系统36式》，哈哈哈哈哈哈哈。
编辑回复: 给刑无刀老师打call！对这节内容感兴趣可以订阅《推荐系统36式》😄

2019-02-18


25

許敲敲
具体的基于用户相似来推荐的话，如果每个用户喜欢的歌曲数量很大，或者说用户数也很多的情况下，也就是考虑到老师画的表 行列都很多，是不是相当于矩阵的维数很大，这样找到两个向量的距离是有什么trick嘛？或者该用什么算法计算比较好？
作者回复: 你指出的这点很好，我会晚点再写一下，补充到文章里。

2019-01-14

3

10

莫弹弹
高级篇的人越来越少了……
我觉得，推荐可以看成一种选优，所以思维上可以跳出“推荐”两个字，进而扩展“相似”“热门”等等这类场景
例如搜索引擎关键词拼写错误的推荐词，导航app的推荐路径，电商的热门商品等，都可以用上推荐算法
2019-01-14


8

Kudo
推荐系统（Recommender System）是典型的机器学习应用场景。其核心就是通过算法得到用户偏好向量以及内容向量，两个向量的内积即为用户对内容的的评分预测（即用户对某内容的喜好程度）。推荐学习算法本质上就是学习这两个向量的过程。
通常有两种方法：
1. 已知内容向量，学习用户偏好向量的方法就是基于内容的推荐算法（content-based）；
2. 用户偏好向量和内容向量都未知，则适合使用联合过滤算法（collaborative filtering）同时学习两个向量。
2019-01-14


6

alic
其实就和nlp中计算两个句子之间的相似度类似。
2019-01-14


3

orcababyface
2.基于歌曲做推荐
问题：老师的方案的逻辑是：人们对一首歌喜爱程度越一致，那么两首歌越相似。这不是很好吧？难道现在一般音乐app基于歌曲推荐都是这么做的？
2019-01-18


1

李皮皮皮皮皮
抱歉老师，我之前可能理解有点偏差，判断两首歌曲是否是同一类型，向量是横向构造的。
2019-01-14


1

卡罗
基于相似用户做推荐，这一栏里。如果只有欧几里得距离作比较，应该不准确吧，用户，分享和收藏的是不同的歌曲，但是欧几里得距离相近。
2019-01-14


1

yongxiang
还可以用来推荐喜欢的商品
2019-01-14


1

张三
匿名社交app里边，基于各种标签来推荐好友
2019-09-05



$Jason
我看到这篇文章还是可以看懂的，但是对于海量的用户，我总不能一个个的计算他们的向量空间吧。那怎么做？
作者回复: 这个就复杂了 一句两句说不清了 建议看人工智能的书籍

2019-06-27



王楚然
弱弱的问，向量空间是求相似度的，朴素贝叶斯是分类的，但是分类到一起，是不是可以说相似度高？相似度高的，可不可以归为同一类？这俩方法算是解决同问题的方法吗？如果是有什么对比呢？如果不是为啥不是呢？
作者回复: 相似度可以归为一类。你如果对这方面感兴趣的话，可以看下机器学习相关的书籍。

2019-06-21



Geek_a0c415
老师，后面会讲到向量夹角余弦么？
作者回复: 不会了

2019-06-11



danvid
我觉得用余弦近似度来判断相似程度更合理些
2019-05-29



黑白尤文
集体智慧编程，感觉写的很好，整本书都在讲推荐算法，很容易懂，代码是python的。
2019-03-06



淡然一笑
购物、头条新闻、抖音短视频、旅游时酒店景点、找工作好像都是和这个类似，抱歉，菜鸟对算法理解不是很好，只能理解表面的，原理还在学习中😂😂
2019-02-18



睡痴儿😑
包括现在最火的抖音短视频系列的，腾讯看点，淘宝。
2019-01-26



sjz
相识图片识别技术也可以使用多维向量相似算法来分析
2019-01-25



yohann
越到后面越难理解，非科班的孩子好忧桑。一步一步来吧！
2019-01-15



Z7k
打卡，想问一下现在学习机器学习一般都是找推荐系统的工作吗？一般都是做什么，处理数据还是模型优化？
2019-01-14


收起评论

3152






# 48 | B+树：MySQL数据库索引是如何实现的？




数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



48 | B+树：MySQL数据库索引是如何实现的？
王争 2019-01-16



13:25
讲述：修阳 大小：12.30M
作为一个软件开发工程师，你对数据库肯定再熟悉不过了。作为主流的数据存储系统，它在我们的业务开发中，有着举足轻重的地位。在工作中，为了加速数据库中数据的查找速度，我们常用的处理思路是，对表中数据创建索引。那你是否思考过，数据库索引是如何实现的呢？底层使用的是什么数据结构和算法呢？

算法解析
思考的过程比结论更重要。跟着我学习了这么多节课，很多同学已经意识到这一点，比如 Jerry 银银同学。我感到很开心。所以，今天的讲解，我会尽量还原这个解决方案的思考过程，让你知其然，并且知其所以然。

1. 解决问题的前提是定义清楚问题
如何定义清楚问题呢？除了对问题进行详细的调研，还有一个办法，那就是，通过对一些模糊的需求进行假设，来限定要解决的问题的范围。

如果你对数据库的操作非常了解，针对我们现在这个问题，你就能把索引的需求定义得非常清楚。但是，对于大部分软件工程师来说，我们可能只了解一小部分常用的 SQL 语句，所以，这里我们假设要解决的问题，只包含这样两个常用的需求：

根据某个值查找数据，比如 select * from user where id=1234；

根据区间值来查找某些数据，比如 select * from user where id > 1234 and id < 2345。

除了这些功能性需求之外，这种问题往往还会涉及一些非功能性需求，比如安全、性能、用户体验等等。限于专栏要讨论的主要是数据结构和算法，对于非功能性需求，我们着重考虑性能方面的需求。性能方面的需求，我们主要考察时间和空间两方面，也就是执行效率和存储空间。

在执行效率方面，我们希望通过索引，查询数据的效率尽可能的高；在存储空间方面，我们希望索引不要消耗太多的内存空间。

2. 尝试用学过的数据结构解决这个问题
问题的需求大致定义清楚了，我们现在回想一下，能否利用已经学习过的数据结构解决这个问题呢？支持快速查询、插入等操作的动态数据结构，我们已经学习过散列表、平衡二叉查找树、跳表。

我们先来看散列表。散列表的查询性能很好，时间复杂度是 O(1)。但是，散列表不能支持按照区间快速查找数据。所以，散列表不能满足我们的需求。

我们再来看平衡二叉查找树。尽管平衡二叉查找树查询的性能也很高，时间复杂度是 O(logn)。而且，对树进行中序遍历，我们还可以得到一个从小到大有序的数据序列，但这仍然不足以支持按照区间快速查找数据。

我们再来看跳表。跳表是在链表之上加上多层索引构成的。它支持快速地插入、查找、删除数据，对应的时间复杂度是 O(logn)。并且，跳表也支持按照区间快速地查找数据。我们只需要定位到区间起点值对应在链表中的结点，然后从这个结点开始，顺序遍历链表，直到区间终点对应的结点为止，这期间遍历得到的数据就是满足区间值的数据。



这样看来，跳表是可以解决这个问题。实际上，数据库索引所用到的数据结构跟跳表非常相似，叫作 B+ 树。不过，它是通过二叉查找树演化过来的，而非跳表。为了给你还原发明 B+ 树的整个思考过程，所以，接下来，我还再从二叉查找树讲起，看它是如何一步一步被改造成 B+ 树的。

3. 改造二叉查找树来解决这个问题
为了让二叉查找树支持按照区间来查找数据，我们可以对它进行这样的改造：树中的节点并不存储数据本身，而是只是作为索引。除此之外，我们把每个叶子节点串在一条链表上，链表中的数据是从小到大有序的。经过改造之后的二叉树，就像图中这样，看起来是不是很像跳表呢？



改造之后，如果我们要求某个区间的数据。我们只需要拿区间的起始值，在树中进行查找，当查找到某个叶子节点之后，我们再顺着链表往后遍历，直到链表中的结点数据值大于区间的终止值为止。所有遍历到的数据，就是符合区间值的所有数据。



但是，我们要为几千万、上亿的数据构建索引，如果将索引存储在内存中，尽管内存访问的速度非常快，查询的效率非常高，但是，占用的内存会非常多。

比如，我们给一亿个数据构建二叉查找树索引，那索引中会包含大约 1 亿个节点，每个节点假设占用 16 个字节，那就需要大约 1GB 的内存空间。给一张表建立索引，我们需要 1GB 的内存空间。如果我们要给 10 张表建立索引，那对内存的需求是无法满足的。如何解决这个索引占用太多内存的问题呢？

我们可以借助时间换空间的思路，把索引存储在硬盘中，而非内存中。我们都知道，硬盘是一个非常慢速的存储设备。通常内存的访问速度是纳秒级别的，而磁盘访问的速度是毫秒级别的。读取同样大小的数据，从磁盘中读取花费的时间，是从内存中读取所花费时间的上万倍，甚至几十万倍。

这种将索引存储在硬盘中的方案，尽管减少了内存消耗，但是在数据查找的过程中，需要读取磁盘中的索引，因此数据查询效率就相应降低很多。

二叉查找树，经过改造之后，支持区间查找的功能就实现了。不过，为了节省内存，如果把树存储在硬盘中，那么每个节点的读取（或者访问），都对应一次磁盘 IO 操作。树的高度就等于每次查询数据时磁盘 IO 操作的次数。

我们前面讲到，比起内存读写操作，磁盘 IO 操作非常耗时，所以我们优化的重点就是尽量减少磁盘 IO 操作，也就是，尽量降低树的高度。那如何降低树的高度呢？

我们来看下，如果我们把索引构建成 m 叉树，高度是不是比二叉树要小呢？如图所示，给 16 个数据构建二叉树索引，树的高度是 4，查找一个数据，就需要 4 个磁盘 IO 操作（如果根节点存储在内存中，其他结点存储在磁盘中），如果对 16 个数据构建五叉树索引，那高度只有 2，查找一个数据，对应只需要 2 次磁盘操作。如果 m 叉树中的 m 是 100，那对一亿个数据构建索引，树的高度也只是 3，最多只要 3 次磁盘 IO 就能获取到数据。磁盘 IO 变少了，查找数据的效率也就提高了。



如果我们将 m 叉树实现 B+ 树索引，用代码实现出来，就是下面这个样子（假设我们给 int 类型的数据库字段添加索引，所以代码中的 keywords 是 int 类型的）：

/**
 * 这是 B+ 树非叶子节点的定义。
 *
 * 假设 keywords=[3, 5, 8, 10]
 * 4 个键值将数据分为 5 个区间：(-INF,3), [3,5), [5,8), [8,10), [10,INF)
 * 5 个区间分别对应：children[0]...children[4]
 *
 * m 值是事先计算得到的，计算的依据是让所有信息的大小正好等于页的大小：
 * PAGE_SIZE = (m-1)*4[keywordss 大小]+m*8[children 大小]
 */
public class BPlusTreeNode {
  public static int m = 5; // 5 叉树
  public int[] keywords = new int[m-1]; // 键值，用来划分数据区间
  public BPlusTreeNode[] children = new BPlusTreeNode[m];// 保存子节点指针
}
 
/**
 * 这是 B+ 树中叶子节点的定义。
 *
 * B+ 树中的叶子节点跟内部结点是不一样的,
 * 叶子节点存储的是值，而非区间。
 * 这个定义里，每个叶子节点存储 3 个数据行的键值及地址信息。
 *
 * k 值是事先计算得到的，计算的依据是让所有信息的大小正好等于页的大小：
 * PAGE_SIZE = k*4[keyw.. 大小]+k*8[dataAd.. 大小]+8[prev 大小]+8[next 大小]
 */
public class BPlusTreeLeafNode {
  public static int k = 3;
  public int[] keywords = new int[k]; // 数据的键值
  public long[] dataAddress = new long[k]; // 数据地址
 
  public BPlusTreeLeafNode prev; // 这个结点在链表中的前驱结点
  public BPlusTreeLeafNode next; // 这个结点在链表中的后继结点
}
我稍微解释一下这段代码。

对于相同个数的数据构建 m 叉树索引，m 叉树中的 m 越大，那树的高度就越小，那 m 叉树中的 m 是不是越大越好呢？到底多大才最合适呢？

不管是内存中的数据，还是磁盘中的数据，操作系统都是按页（一页大小通常是 4KB，这个值可以通过 getconfig PAGE_SIZE 命令查看）来读取的，一次会读一页的数据。如果要读取的数据量超过一页的大小，就会触发多次 IO 操作。所以，我们在选择 m 大小的时候，要尽量让每个节点的大小等于一个页的大小。读取一个节点，只需要一次磁盘 IO 操作。



尽管索引可以提高数据库的查询效率，但是，作为一名开发工程师，你应该也知道，索引有利也有弊，它也会让写入数据的效率下降。这是为什么呢？

数据的写入过程，会涉及索引的更新，这是索引导致写入变慢的主要原因。

对于一个 B+ 树来说，m 值是根据页的大小事先计算好的，也就是说，每个节点最多只能有 m 个子节点。在往数据库中写入数据的过程中，这样就有可能使索引中某些节点的子节点个数超过 m，这个节点的大小超过了一个页的大小，读取这样一个节点，就会导致多次磁盘 IO 操作。我们该如何解决这个问题呢？

实际上，处理思路并不复杂。我们只需要将这个节点分裂成两个节点。但是，节点分裂之后，其上层父节点的子节点个数就有可能超过 m 个。不过这也没关系，我们可以用同样的方法，将父节点也分裂成两个节点。这种级联反应会从下往上，一直影响到根节点。这个分裂过程，你可以结合着下面这个图一块看，会更容易理解（图中的 B+ 树是一个三叉树。我们限定叶子节点中，数据的个数超过 2 个就分裂节点；非叶子节点中，子节点的个数超过 3 个就分裂节点）。



正是因为要时刻保证 B+ 树索引是一个 m 叉树，所以，索引的存在会导致数据库写入的速度降低。实际上，不光写入数据会变慢，删除数据也会变慢。这是为什么呢？

我们在删除某个数据的时候，也要对应的更新索引节点。这个处理思路有点类似跳表中删除数据的处理思路。频繁的数据删除，就会导致某些结点中，子节点的个数变得非常少，长此以往，如果每个节点的子节点都比较少，势必会影响索引的效率。

我们可以设置一个阈值。在 B+ 树中，这个阈值等于 m/2。如果某个节点的子节点个数小于 m/2，我们就将它跟相邻的兄弟节点合并。不过，合并之后结点的子节点个数有可能会超过 m。针对这种情况，我们可以借助插入数据时候的处理方法，再分裂节点。

文字描述不是很直观，我举了一个删除操作的例子，你可以对比着看下（图中的 B+ 树是一个五叉树。我们限定叶子节点中，数据的个数少于 2 个就合并节点；非叶子节点中，子节点的个数少于 3 个就合并节点。）。



数据库索引以及 B+ 树的由来，到此就讲完了。你有没有发现，B+ 树的结构和操作，跟跳表非常类似。理论上讲，对跳表稍加改造，也可以替代 B+ 树，作为数据库的索引实现的。

B+ 树发明于 1972 年，跳表发明于 1989 年，我们可以大胆猜想下，跳表的作者有可能就是受了 B+ 树的启发，才发明出跳表来的。不过，这个也无从考证了。

总结引申
今天，我们讲解了数据库索引实现，依赖的底层数据结构，B+ 树。它通过存储在磁盘的多叉树结构，做到了时间、空间的平衡，既保证了执行效率，又节省了内存。

前面的讲解中，为了一步一步详细地给你介绍 B+ 树的由来，内容看起来比较零散。为了方便你掌握和记忆，我这里再总结一下 B+ 树的特点：

每个节点中子节点的个数不能超过 m，也不能小于 m/2；

根节点的子节点个数可以不超过 m/2，这是一个例外；

m 叉树只存储索引，并不真正存储数据，这个有点儿类似跳表；

通过链表将叶子节点串联在一起，这样可以方便按区间查找；

一般情况，根节点会被存储在内存中，其他节点存储在磁盘中。

除了 B+ 树，你可能还听说过 B 树、B- 树，我这里简单提一下。实际上，B- 树就是 B 树，英文翻译都是 B-Tree，这里的“-”并不是相对 B+ 树中的“+”，而只是一个连接符。这个很容易误解，所以我强调下。

而 B 树实际上是低级版的 B+ 树，或者说 B+ 树是 B 树的改进版。B 树跟 B+ 树的不同点主要集中在这几个地方：

B+ 树中的节点不存储数据，只是索引，而 B 树中的节点存储数据；

B 树中的叶子节点并不需要链表来串联。

也就是说，B 树只是一个每个节点的子节点个数不能小于 m/2 的 m 叉树。

课后思考
B+ 树中，将叶子节点串起来的链表，是单链表还是双向链表？为什么？

我们对平衡二叉查找树进行改造，将叶子节点串在链表中，就支持了按照区间来查找数据。我们在散列表（下）讲到，散列表也经常跟链表一块使用，如果我们把散列表中的结点，也用链表串起来，能否支持按照区间查找数据呢？

欢迎留言和我分享，也欢迎点击“请朋友读”，把今天的内容分享给你的好友，和他一起讨论、学习。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(70)

Jerry银银
听专栏，听到了自己的名字，不敢相信，看了文稿，确实是自己。真是受宠若惊！
2019-01-16

1

155

Jerry银银
个人觉得B+tree理解起来真不难，抓住几个要点就可以了：
1. 理解二叉查找树
2. 理解二叉查找树会出现不平衡的问题（红黑树理解了，对于平衡性这个关键点就理解了）
3. 磁盘IO访问太耗时
4. 当然，链表知识跑不了 —— 别小瞧这个简单的数据结构，它是链式结构之母
5. 最后，要知道典型的应用场景：数据库的索引结构的设计

还记得，在学生时代，不好好学数据结构的我，当看到这个高大尚的名词“B+tree”时，我心里无比惊慌：这东西貌似不简单。^_^ 那时，也有着王争老师说的这种情况：B-tree，这是B减树；肯定还有个正常的B树；B+tree，这是B加树；然后在我的脑海里面，想当然地认为，它们之间有着这样的大小关系：B-tree < B tree < B+tree
----------
对于思考题，@老杨 大哥的回答我觉得很到位了。 我只做一下补充：
第一题： 对于B+tree叶子节点，是用双向链表还是用单链表，得从具体的场景思考。我想，大部分同学在开发中遇到的数据库查询，都遇到过升序或降序问题，即类似这样的sql: select name,age, ... from where uid > startValue and uid < endValue order by uid asc(或者desc)，此时，数据底层实现有两种做法：
1）保证查出来的数据就是用户想要的顺序
2）不保证查出来的数据的有序性，查出来之后再排序
以上两种方案，不加思考，肯定选第一种，因为第二种做法浪费了时间（如果选用内存排序，还是考虑数据的量级）。那如何能保证查询出来的数据就是有序的呢？单链表肯定做不到，只能从头往后遍历，再想想，只能选择双向链表了。此时，可能有的同学又问了：双向链表，多出来了一倍的指针，不是会多占用空间嘛？ 答案是肯定的。可是，我们再细想下，数据库索引本身都已经在磁盘中了，对于磁盘来说，这点空间已经微不足道了，用这点空间换来时间肯定划算呀。顺便提一下：在实际工程应用中，双向链表应用的场景非常广泛，毕竟能大量减少链表的遍历时间

第二题：
答案是「肯定的」。如同@老杨 大哥说的，JDK中的LinkedHashMap为了能做到保持节点的顺序（插入顺序或者访问顺序），就是用双向链表将节点串起来的。 其实，王争老师在《散列表(下）》那一堂课中就已经深入讲解了LinkedHashMap，如果理解了那篇，这个问题应该不难。
-------
最后，我发现王争老师布置的这些课后思考题，都涉及到了之前学到的内容，不知道是有意还是无意的，嘻嘻！

这节的思考题花了蛮多时间进行思考，才能给出以上答案，希望王争老师帮看看是否有不对的地方，谢谢！


作者回复: 👍

2019-01-19


48

城
1.链表是双向链表，用以支持前后遍历
2.散列表的节点用链表串起来，并不能实现范围查询，因为散列表本身无序，而B+树是基于二叉查找树演变而成，是有序的
2019-01-16


47

老杨同志
问题一，双向链表，方便asc和desc。
问题二，可以支持区间查询。java中linkedHashMap就是链表链表+HashMap的组合，用于实现缓存的lru算法比较方便，不过要支持区间查询需要在插入时维持链表的有序性，复杂度O(n).效率比跳表和b+tree差
2019-01-17


15

Felix Envy
看到留言里很多同学都说第二题答案是肯定的，有点不同意。
如果区间边界值在在散列表中没有命中，那么就无法定位区间的起始节点。
如有错误望指出～
2019-02-18


11

feifei
老师，看了你的讲解，对于B+树的原理，我基本理解了，我又找了b+树的代码实现，也搞懂怎么回事了，当我看懂了，这个B+树的实现了之后，我就有个问题，这个B+树该如何保存到磁盘中呢？我搜索了好多，也没有找到相关的一个代码，你有这相关的资料吗？这种数据一般是如何保存的？谢谢
作者回复: 我懂你的意思。具体我没研究过。我觉得可以直接存到文件里。节点在文件里的位置表示指针。我瞎猜的：）等我研究研究再说：）

2019-01-24


4

朱东旭
这里讲的仅仅是单列索引，实际项目中组合索引使用应该比单列索引多，组合索引版的B+树是如何实现的，这个重要的知识点似乎被遗漏了。
2019-05-05


3

唯她命
老师，现在觉得 你画的图 都是B树 而不是B+树
作者回复: 好像不是吧

2019-01-30


3

唯她命
老师 网上查到的资料 说有k个子树的中间节点包含有k个元素（B树中是k-1个元素）
和你讲的不同
作者回复: 咱不要太教科书化啊。理解思想最重要啊。我觉得我讲的没问题啊。

2019-01-30


3

Monday
请问：
第一段代码，第9行：
PAGE_SIZE = (m-1)*4[keywordss 大小]+m*8[children 大小]
1，这个8指的是引用（指针）占的内存大小吗？
2，引用大小是怎么计算的？和机器是多少位的有什么关系吗？
望争哥回复，谢谢！
作者回复: 1. 是的
2. 有关系的，就是用多少位表示一个存储地址

2019-01-20


3

Monday
先回答思考题：
1. 双向链表，为了支持在O(logn)时间复杂度删除节点
2.支持按区间查找数据。那么问题来了，为什么mysql索引不采用散列表+双向链表的数据结果来实现呢？
2019-01-17

2

3

有朋自远方来
1.利用磁盘预读功能2.主簇索引
觉得这两点也很重要。
2019-01-16


3

茴香根
好开心，终于搞清楚经常见到的b+树结构了。从这一节看到对于大数据情况下，m的大小对查询速度有重要影响。如在一些一些特定场合是否可以通过增大内存页和磁盘页大小来进一步提升查询效率。对于思考题中hash做索引，我认为是可行的，但每次更新索引时，如果新进入的节点索引需要插入到相应的位置，要保持叶子链表的有序。
2019-01-16


3

yaya
1从图上来看，b+叶结点串起来的是双向链表
2不可以，因为散列表的是被mod后的，查询区间依然需要遍历所有结点
以前学b+树的时候，完全不知道它为什么这样设计，感觉很奇怪，今天才明白是为了提供区间查询，优化操作次数。
2019-01-16


3

Flash
对于第二题，觉得Jerry银银的答案有问题，可能会误导其他人。希望老师能指正一下，我觉得用链表将散列表节点串起来，不能支持按区间查找。因为散列表的节点是无序的，除非先遍历把散列表的节点放到数组中，进行排序，再用LinkedHashMap遍历存储，这样链表中串的节点才是有序的，直接用链表串散列表节点，是不支持按区间查找的。
2019-03-26


2

hnbc
老师，我想问一下100叉树为什么是3次io操作，不应该是4次吗，100的4次方是1亿
作者回复: 这...第一层索引节点可以放到内存里的，这样就3次了：）

2019-03-13

1

2

mrlay
维持b+树的特性的策略有了，但是如何实现这个策略 以及一些其他问题解决的策略的实现 我有些发怵的感觉，大家一般都是怎么过来的呢？
作者回复: 兄弟对自己要求太高了，你要是学操作系统，还得把操作系统实现一个啊；）

2019-07-02


1

H.L.
叶子节点的数据是如何存储的？比如mysql的b+树，key放在一堆，data放在一堆？
作者回复: 叶子节点存对象 对象包含key和data

2019-04-15


1

嗯嗯
对作者说的那个m云里雾里
2019-03-20


1

唯她命
应该是每个结点至少有[ceil(m / 2)]个孩子 而不是m / 2
2019-01-30


1
收起评论

7099+






# 49 | 搜索：如何用A*搜索算法实现游戏中的寻路功能？





数据结构与算法之美
王争
前Google工程师
查看详情
59586 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

开篇词 | 从今天起，跨过“数据结构与算法”这道坎
入门篇 (4讲)

01 | 为什么要学习数据结构和算法？
02 | 如何抓住重点，系统高效地学习数据结构与算法？
03 | 复杂度分析（上）：如何分析、统计算法的执行效率和资源消耗？
04 | 复杂度分析（下）：浅析最好、最坏、平均、均摊时间复杂度
基础篇 (38讲)

高级篇 (9讲)

实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



49 | 搜索：如何用A*搜索算法实现游戏中的寻路功能？
王争 2019-01-18



09:58
讲述：修阳 大小：9.13M
魔兽世界、仙剑奇侠传这类 MMRPG 游戏，不知道你有没有玩过？在这些游戏中，有一个非常重要的功能，那就是人物角色自动寻路。当人物处于游戏地图中的某个位置的时候，我们用鼠标点击另外一个相对较远的位置，人物就会自动地绕过障碍物走过去。玩过这么多游戏，不知你是否思考过，这个功能是怎么实现的呢？

算法解析
实际上，这是一个非常典型的搜索问题。人物的起点就是他当下所在的位置，终点就是鼠标点击的位置。我们需要在地图中，找一条从起点到终点的路径。这条路径要绕过地图中所有障碍物，并且看起来要是一种非常聪明的走法。所谓“聪明”，笼统地解释就是，走的路不能太绕。理论上讲，最短路径显然是最聪明的走法，是这个问题的最优解。

不过，在第 44 节最优出行路线规划问题中，我们也讲过，如果图非常大，那 Dijkstra 最短路径算法的执行耗时会很多。在真实的软件开发中，我们面对的是超级大的地图和海量的寻路请求，算法的执行效率太低，这显然是无法接受的。

实际上，像出行路线规划、游戏寻路，这些真实软件开发中的问题，一般情况下，我们都不需要非得求最优解（也就是最短路径）。在权衡路线规划质量和执行效率的情况下，我们只需要寻求一个次优解就足够了。那如何快速找出一条接近于最短路线的次优路线呢？

这个快速的路径规划算法，就是我们今天要学习的A* 算法。实际上，A* 算法是对 Dijkstra 算法的优化和改造。如何将 Dijkstra 算法改造成 A* 算法呢？为了更好地理解接下来要讲的内容，我建议你先温习下第 44 节中的 Dijkstra 算法的实现原理。

Dijkstra 算法有点儿类似 BFS 算法，它每次找到跟起点最近的顶点，往外扩展。这种往外扩展的思路，其实有些盲目。为什么这么说呢？我举一个例子来给你解释一下。下面这个图对应一个真实的地图，每个顶点在地图中的位置，我们用一个二维坐标（x，y）来表示，其中，x 表示横坐标，y 表示纵坐标。



在 Dijkstra 算法的实现思路中，我们用一个优先级队列，来记录已经遍历到的顶点以及这个顶点与起点的路径长度。顶点与起点路径长度越小，就越先被从优先级队列中取出来扩展，从图中举的例子可以看出，尽管我们找的是从 s 到 t 的路线，但是最先被搜索到的顶点依次是 1，2，3。通过肉眼来观察，这个搜索方向跟我们期望的路线方向（s 到 t 是从西向东）是反着的，路线搜索的方向明显“跑偏”了。

之所以会“跑偏”，那是因为我们是按照顶点与起点的路径长度的大小，来安排出队列顺序的。与起点越近的顶点，就会越早出队列。我们并没有考虑到这个顶点到终点的距离，所以，在地图中，尽管 1，2，3 三个顶点离起始顶点最近，但离终点却越来越远。

如果我们综合更多的因素，把这个顶点到终点可能还要走多远，也考虑进去，综合来判断哪个顶点该先出队列，那是不是就可以避免“跑偏”呢？

当我们遍历到某个顶点的时候，从起点走到这个顶点的路径长度是确定的，我们记作 g(i)（i 表示顶点编号）。但是，从这个顶点到终点的路径长度，我们是未知的。虽然确切的值无法提前知道，但是我们可以用其他估计值来代替。

这里我们可以通过这个顶点跟终点之间的直线距离，也就是欧几里得距离，来近似地估计这个顶点跟终点的路径长度（注意：路径长度跟直线距离是两个概念）。我们把这个距离记作 h(i)（i 表示这个顶点的编号），专业的叫法是启发函数（heuristic function）。因为欧几里得距离的计算公式，会涉及比较耗时的开根号计算，所以，我们一般通过另外一个更加简单的距离计算公式，那就是曼哈顿距离（Manhattan distance）。曼哈顿距离是两点之间横纵坐标的距离之和。计算的过程只涉及加减法、符号位反转，所以比欧几里得距离更加高效。

int hManhattan(Vertex v1, Vertex v2) { // Vertex 表示顶点，后面有定义
  return Math.abs(v1.x - v2.x) + Math.abs(v1.y - v2.y);
}
原来只是单纯地通过顶点与起点之间的路径长度 g(i)，来判断谁先出队列，现在有了顶点到终点的路径长度估计值，我们通过两者之和 f(i)=g(i)+h(i)，来判断哪个顶点该最先出队列。综合两部分，我们就能有效避免刚刚讲的“跑偏”。这里 f(i) 的专业叫法是估价函数（evaluation function）。

从刚刚的描述，我们可以发现，A* 算法就是对 Dijkstra 算法的简单改造。实际上，代码实现方面，我们也只需要稍微改动几行代码，就能把 Dijkstra 算法的代码实现，改成 A* 算法的代码实现。

在 A* 算法的代码实现中，顶点 Vertex 类的定义，跟 Dijkstra 算法中的定义，稍微有点儿区别，多了 x，y 坐标，以及刚刚提到的 f(i) 值。图 Graph 类的定义跟 Dijkstra 算法中的定义一样。为了避免重复，我这里就没有再贴出来了。

private class Vertex {
  public int id; // 顶点编号 ID
  public int dist; // 从起始顶点，到这个顶点的距离，也就是 g(i)
  public int f; // 新增：f(i)=g(i)+h(i)
  public int x, y; // 新增：顶点在地图中的坐标（x, y）
  public Vertex(int id, int x, int y) {
    this.id = id;
    this.x = x;
    this.y = y;
    this.f = Integer.MAX_VALUE;
    this.dist = Integer.MAX_VALUE;
  }
}
// Graph 类的成员变量，在构造函数中初始化
Vertex[] vertexes = new Vertex[this.v];
// 新增一个方法，添加顶点的坐标
public void addVetex(int id, int x, int y) {
  vertexes[id] = new Vertex(id, x, y)
}
A* 算法的代码实现的主要逻辑是下面这段代码。它跟 Dijkstra 算法的代码实现，主要有 3 点区别：

优先级队列构建的方式不同。A* 算法是根据 f 值（也就是刚刚讲到的 f(i)=g(i)+h(i)）来构建优先级队列，而 Dijkstra 算法是根据 dist 值（也就是刚刚讲到的 g(i)）来构建优先级队列；

A* 算法在更新顶点 dist 值的时候，会同步更新 f 值；

循环结束的条件也不一样。Dijkstra 算法是在终点出队列的时候才结束，A* 算法是一旦遍历到终点就结束。

public void astar(int s, int t) { // 从顶点 s 到顶点 t 的路径
  int[] predecessor = new int[this.v]; // 用来还原路径
  // 按照 vertex 的 f 值构建的小顶堆，而不是按照 dist
  PriorityQueue queue = new PriorityQueue(this.v);
  boolean[] inqueue = new boolean[this.v]; // 标记是否进入过队列
  vertexes[s].dist = 0;
  vertexes[s].f = 0;
  queue.add(vertexes[s]);
  inqueue[s] = true;
  while (!queue.isEmpty()) {
    Vertex minVertex = queue.poll(); // 取堆顶元素并删除
    for (int i = 0; i < adj[minVertex.id].size(); ++i) {
      Edge e = adj[minVertex.id].get(i); // 取出一条 minVetex 相连的边
      Vertex nextVertex = vertexes[e.tid]; // minVertex-->nextVertex
      if (minVertex.dist + e.w < nextVertex.dist) { // 更新 next 的 dist,f
        nextVertex.dist = minVertex.dist + e.w;
        nextVertex.f 
           = nextVertex.dist+hManhattan(nextVertex, vertexes[t]);
        predecessor[nextVertex.id] = minVertex.id;
        if (inqueue[nextVertex.id] == true) {
          queue.update(nextVertex);
        } else {
          queue.add(nextVertex);
          inqueue[nextVertex.id] = true;
        }
      }
      if (nextVertex.id == t) { // 只要到达 t 就可以结束 while 了
        queue.clear(); // 清空 queue，才能推出 while 循环
        break; 
      }
    }
  }
  // 输出路径
  System.out.print(s);
  print(s, t, predecessor); // print 函数请参看 Dijkstra 算法的实现
}
尽管 A* 算法可以更加快速的找到从起点到终点的路线，但是它并不能像 Dijkstra 算法那样，找到最短路线。这是为什么呢？

要找出起点 s 到终点 t 的最短路径，最简单的方法是，通过回溯穷举所有从 s 到达 t 的不同路径，然后对比找出最短的那个。不过很显然，回溯算法的执行效率非常低，是指数级的。



Dijkstra 算法在此基础之上，利用动态规划的思想，对回溯搜索进行了剪枝，只保留起点到某个顶点的最短路径，继续往外扩展搜索。动态规划相较于回溯搜索，只是换了一个实现思路，但它实际上也考察到了所有从起点到终点的路线，所以才能得到最优解。



A* 算法之所以不能像 Dijkstra 算法那样，找到最短路径，主要原因是两者的 while 循环结束条件不一样。刚刚我们讲过，Dijkstra 算法是在终点出队列的时候才结束，A* 算法是一旦遍历到终点就结束。对于 Dijkstra 算法来说，当终点出队列的时候，终点的 dist 值是优先级队列中所有顶点的最小值，即便再运行下去，终点的 dist 值也不会再被更新了。对于 A* 算法来说，一旦遍历到终点，我们就结束 while 循环，这个时候，终点的 dist 值未必是最小值。

A* 算法利用贪心算法的思路，每次都找 f 值最小的顶点出队列，一旦搜索到终点就不在继续考察其他顶点和路线了。所以，它并没有考察所有的路线，也就不可能找出最短路径了。

搞懂了 A* 算法，我们再来看下，如何借助 A* 算法解决今天的游戏寻路问题？

要利用 A* 算法解决这个问题，我们只需要把地图，抽象成图就可以了。不过，游戏中的地图跟第 44 节中讲的我们平常用的地图是不一样的。因为游戏中的地图并不像我们现实生活中那样，存在规划非常清晰的道路，更多的是宽阔的荒野、草坪等。所以，我们没法利用 44 节中讲到的抽象方法，把岔路口抽象成顶点，把道路抽象成边。

实际上，我们可以换一种抽象的思路，把整个地图分割成一个一个的小方块。在某一个方块上的人物，只能往上下左右四个方向的方块上移动。我们可以把每个方块看作一个顶点。两个方块相邻，我们就在它们之间，连两条有向边，并且边的权值都是 1。所以，这个问题就转化成了，在一个有向有权图中，找某个顶点到另一个顶点的路径问题。将地图抽象成边权值为 1 的有向图之后，我们就可以套用 A* 算法，来实现游戏中人物的自动寻路功能了。

总结引申
我们今天讲的 A* 算法属于一种启发式搜索算法（Heuristically Search Algorithm）。实际上，启发式搜索算法并不仅仅只有 A* 算法，还有很多其他算法，比如 IDA* 算法、蚁群算法、遗传算法、模拟退火算法等。如果感兴趣，你可以自行研究下。

启发式搜索算法利用估价函数，避免“跑偏”，贪心地朝着最有可能到达终点的方向前进。这种算法找出的路线，并不是最短路线。但是，实际的软件开发中的路线规划问题，我们往往并不需要非得找最短路线。所以，鉴于启发式搜索算法能很好地平衡路线质量和执行效率，它在实际的软件开发中的应用更加广泛。实际上，在第 44 节中，我们讲到的地图 App 中的出行路线规划问题，也可以利用启发式搜索算法来实现。

课后思考
我们之前讲的“迷宫问题”是否可以借助 A* 算法来更快速地找到一个走出去的路线呢？如果可以，请具体讲讲该怎么来做；如果不可以，请说说原因。

欢迎留言和我分享，也欢迎点击“请朋友读”，把今天的内容分享给你的好友，和他一起讨论、学习。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(31)

hua168
我之前是打算生管理，去个小公司，发现也要会开发，去年就毅然去学java，维护懂java会有帮助，也可以搞下大数据……再学一门本职运维开发需要python……
我就是这样打算的…
同学说我们学历低只要大专，问我要大家考研究生不？我感觉我不去大公司的话没什么用吧？但一想很多要求本科，自考研究生不知道承认不？尤其公司，再说就算看完都老了吧……意义有多大？
作者回复: 看得到@hua168同学对职业规划很迷茫。

我来逐一回答一下你的问题：

1. 自考学历对你来说没用。绝大部分卡学历的公司，只看第一学历；不卡学历的那部分公司，你自考本科也没必要。自考学历对一小部分人有用，具体哪部分人适合我就不展开讲了，总之不适合你。但是，你没有因为学历自卑，公司这么多，总有不卡学历的。我见过很多大专文凭，技术去贼拉子好的，照样去大公司。

2. 不管是大公司还是小公司，都会卡年龄。不过所谓的卡年龄并不是说年龄大了就没人要了。而是能力跟年龄不符，年龄一大把却跟人家工作两三年经验能力差不多，要钱还贼高，那估计确实没人要。

3. 不要再去学java了。如果你还想走技术路线，那就要专精尖，这个我前一条回复说过了。

4. 我还是说了，对于技术一般的人来说，如果要升管理岗，还是那句话“要有领导气质”，另外，你要包装一下简历，一些很小公司的领导是识别不出来的：）听起来是不入流的建议，但是，我确实是认真的。

5. 实际上，年龄大了，技术没有太大竞争力，去个安稳的公司很好，比如国企性质的一些互联网保险公司，具体你自己搜搜吧，我这里不方便说公司名字。

以上建议只针对你本人的情况，并且是我的个人建议。如有不投，你自己斟酌。

2019-01-19


20

传说中的成大大
今天看了A*算法 反而对dijkstra算法理解得更透彻了....
2019-01-18


13

hua168
大神，能问一个题外话吗，关于自己人生规划，水平和眼界所限，想不通，
都说大神级见识很广也多，能给我这个35岁只维护过四五十台linux服务器的运维指条路吗？
现在很迷茫和压力大~~
能力如下：
一.网络：CCNA水平，自过了CCNP忘记了，当过2年网管
二、维护过asp.net电商网站，3年，只有简单的，兼职网管
三、linux运维，只在一家电商做了3年多，会
1.web：nginx、tomcat配置（少用）+php:nignx的rewirte和反代
2.数据库：mysql、mongoDB、redis 配置及主从，不会mycat、Cetus之类
3.反代：会nginx、haproxy简单配置
4.存储：NFS、fastDFS、hadoop简单看了一下
5.版本控制：只会git及搭建gitlab+jenkins（简单的CI/CD）
6.监控：简单配置zabbix+shell脚本
7.虚拟化：kvm安装及配置、docker(k8s还没学)
8.云计算：openstack只会安装做过实验
9.测试：只会ab工具
10.日志：ELK安装配置，还没结合java（在学中）
11.大数据：没使用过（不会flume、storm、spark、flink、kafka）
12.脚本：主要是shell为主、会点python

四、编程能力：自学，没项目经验
1.前端：
  1）HTML（HTML5不怎看）
  2）css（laiui、学了一下vue）
  3) js、jquery框架、ES6简单看了一下
2.PHP：语法简单的thinkphp5框架
3.java：考虑要维护java web在学
只看了java、jsp及servet、spring、springMVC、spring Boot（这个为主）
4.python：考虑运维用到
python：会简单的脚本
django：只会官网简单的

问题是：现在已35岁了，失业，怎办？年龄摆在那里，能力好像不强，学历大专。
能给个建议吗？非常感谢~~
作者回复: 我下面说的话，可能会伤害到你，不过，我是非常认真的。

从你对运维相关的技术点的描述上，可以看出，你应该没有在一个稍微大点的公司工作过吧，所以，很多技术都用的不够深，都只是略知一二，没有自己拿得出手的东西。

建议你去稍微大点公司锻炼一下技术，同时，也能给你的履历加分。

不过，以你的年龄和履历，去稍微大点的公司可能也不现实了，因为现在好点的公司都卡学历、背景，更别说技术了。

所以，我建议你找一个运维领域的风口技术去研究，比如你提到的k8s。这种技术才兴起，会的人不多，所以招聘公司都不会太卡学历、经历，只要会，是个人都要，可以借机去个大点的公司。这会是你的一个转折点。

而且。现在，经济下行，互联网行业都压缩招聘。你正好利用这1、2年，沉下心来，抓住一个技术方向，研究深、研究透。

还有一条路，那就是做管理岗位。这个要看你有没有领导气质了：）如果有领导范，年龄大，工作经历多，也可以忽悠到一些小公司的管理岗。实际上，对你来说，这条路也是不错的。

还有一条路，那就是靠去天使轮的创业公司逆袭。这条路有点赌博的意思。不过，如果公司搞大了，你也会青云直上，这辈子都不愁了：）

2019-01-19


6

yongxiang
王争老师，我把代码输入运行，并把过程打印出来，发现代码运行的过程跟您说的A*算法的三点区别中的第三点不一样，不会在遍历到目标顶点时退出while循环。您看是不是27行的break只是退出了for循环，无法退出while循环，是不是需要增加以下的修改：
                if (nextVertex.id == t) {
                    queue.clear();
                    break;
                }
作者回复: 嗯嗯 我更新下，是个bug：）

2019-01-19


4

且听疯吟
仔细阅读了下代码，感觉代码中存在错误点，每次应该是取最小的 min(e.w + e.f)，但是在下面的代码中只看到了计算出了估值量f，并没有看到对其进行比较大小，不知道争哥觉得对不对？


if (minVertex.dist + e.w < nextVertex.dist) { // 更新 next 的 dist,f
        nextVertex.dist = minVertex.dist + e.w;
        nextVertex.f = nextVertex.dist+hManhattan(nextVertex, vertexes[t]);
        predecessor[nextVertex.id] = minVertex.id;

        if (inqueue[nextVertex.id] == true) {
          queue.update(nextVertex);
        } else {
          queue.add(nextVertex);
          inqueue[nextVertex.id] = true;
        }
      }
作者回复: 你搞错了，f=g+h， g=dist, h=hManhattan

2019-03-19


2

皇家救星
我记得以前看过的a*算法介绍还有close和open表，这里好像没提到？
作者回复: 那就是俩人造的概念 并没有太大意义。

2019-01-18


2

1
有一点不明白，希望老师能解答一下。实际上，我们可以换一种抽象的思路，把整个地图分割成一个一个的小方块。在某一个方块上的人物，只能往上下左右四个方向的方块上移动。请问障碍物是怎么绕过的呢？
作者回复: 也可以，你这个抽象成二维数组喽，那就是邻接矩阵的表示方法，可以站人的用1表示，不能站人的方块用0表示，bfs就能得到最优解。

2019-08-20


1

Bryce
我来解释一下更新条件仍然和 dijkstra 算法一致的原因，有错误还请大家指出
实际上不管当前点从哪一个点经过，它与终点的曼哈顿距离都是不变的，所以这部分不需要管，具体到不等式里就是左右都有这一项，故可以消去：
if ( minVertex.dist + e.w + nextVertex.g < nextVertex.dist + nextVertex.g )
2019-04-07


1

隆隆
优化a*的话 是走扩大方块好 还是设置中转点好呢？
作者回复: 这个各有利弊，要具体看呢

2019-02-13


1

纯洁的憎恶
对于有大片无变化的地形环境，是否可以采用更大的方块表示，同时增加其与邻接顶点的权值，已表示距离更远。这样可以减少顶点数，简化图的复杂程度，提高执行效率。不过可能造成行走路线中折线过多，不够平滑。
2019-01-18


1

『LHCY』
真实游戏中也是用的小方块来做的吗？比如要往(1，1)方向走，先把模型角度调整，然后移动是一个个小方格走的，因为方格太小使肉眼分辨不出？
作者回复: 是的，你说的没错！

2019-01-18


1

Paul Shan
Dijkstra复杂度分为两部分，一部分是顶点，每个顶点最多入队列和出队列一次，复杂度是Vlog V，每条边最多更新一次，复杂度是E log V，和起来是(V+E)logV ,老师这样的分析是否正确？
2019-08-07



Paul Shan
思考题
迷宫算法不适合A＊算法，A＊算法的本质是利用了终点的距离这一信息来辅助解决问题。离终点的距离对于能否走出迷宫不是一个有效信息。迷宫问题还是采用经典的遍历算法。
2019-08-07



mrlay
A* 算法得到的结果不一定是最优解的原因是构建最小优先队列的条件从 dist 变成了 f(i), f(i)的大小是由 dist 和 Manhattan 共同决定的。
2019-07-21



Geek_54edc1
回头路：如果顶点之间路径是双向的，某个顶点的下一步有可能走到之前已经访问过的顶点
2019-06-04



Geek_54edc1
个人感觉迷宫问题，可以把A*算法稍微改造下：不用再求f值了，直接用dist就行，构建优先队列也用dist，循环结束条件同A*算法，遍历到终点就结束
2019-05-31



Geek_54edc1
老师您好，if (minVertex.dist + e.w < nextVertex.dist)这个条件是不是可以避免走回头路？？
作者回复: 回头路怎么定义的呢？

2019-05-31



xuery
迷宫问题应该也是可以借助A*算法。
首先建模让其能够使用A*算法，迷宫跟游戏地图我感觉还是有区别，对于迷宫的每个拐角抽象成一个顶点，相邻拐点之间的距离作为边；然后画一个（x,y）的坐标计算出每个点的坐标，这样就抽象成图了，
之后就可以使用A*算法快速的求解一条出路
2019-04-09



ldd
课后思考：
可以。迷宫问题原型是个二维数组 a[n][m]，0代表可以走通，1代表走不通；
第一步：先把二维数组转化带序号的二维数组 b[n][m]，a[i][j] 等于0，在b[n][m] 用序号表示，比如：a[0][1] = 0，a[1][1] = 0，那么 b[0][1] = 1，b[1][1] = 2；依次类推；
第二步：把数组b转化成图结构；因为“A*算法”实际是一种针对“图”的算法；比如 b[0][1] = 1，b[1][1] = 2，b[0][1] 跟 b[1][1] 是通的，就建立 1->2、2->1 的有向边；
第三步：给每个图的顶点构建坐标系，因为每一步的权重都是一样的，所以构建坐标系的时候直接用二维数组的下标即可。比如：顶点1 的坐标系 {0, 1}；顶点2 的坐标系 {1, 1}
至此，”迷宫问题“就转化成了“图的路径问题”，带入“A*算法”即可

不知道对不对，思考不对的地方，往争哥指出
2019-04-09



eleven
看了多遍代码，发现@且听疯吟说的问题确实存在，在更新next 的 dist,f时的if判断应该是minVertex.f + e.w < nextVertex.f，这样才符合a*算法的根据f 值（也就是刚刚讲到的 f(i)=g(i)+h(i)）来构建优先级队列吧，希望王争老师解答
作者回复: 不是的，f用来构建小顶堆用的，更新dist值还是要通过原来dijkstra的松弛函数，也就是我的if判断语句

2019-04-01


收起评论

3154





# 50 | 索引：如何在海量数据中快速查找某个数据？



数据结构与算法之美
王争
前Google工程师
查看详情
59587 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

入门篇 (4讲)

基础篇 (38讲)

高级篇 (9讲)

43 | 拓扑排序：如何确定代码源文件的编译依赖关系？
44 | 最短路径：地图软件是如何计算出最优出行路径的？
45 | 位图：如何实现网页爬虫中的URL去重功能？
46 | 概率统计：如何利用朴素贝叶斯算法过滤垃圾短信？
47 | 向量空间：如何实现一个简单的音乐推荐系统？
48 | B+树：MySQL数据库索引是如何实现的？
49 | 搜索：如何用A*搜索算法实现游戏中的寻路功能？
50 | 索引：如何在海量数据中快速查找某个数据？
51 | 并行算法：如何利用并行处理提高算法的执行效率？
实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



50 | 索引：如何在海量数据中快速查找某个数据？
王争 2019-01-21



10:12
讲述：修阳 大小：9.36M
在第 48 节中，我们讲了 MySQL 数据库索引的实现原理。MySQL 底层依赖的是 B+ 树这种数据结构。留言里有同学问我，那类似 Redis 这样的 Key-Value 数据库中的索引，又是怎么实现的呢？底层依赖的又是什么数据结构呢？

今天，我就来讲一下索引这种常用的技术解决思路，底层往往会依赖哪些数据结构。同时，通过索引这个应用场景，我也带你回顾一下，之前我们学过的几种支持动态集合的数据结构。

为什么需要索引？
在实际的软件开发中，业务纷繁复杂，功能千变万化，但是，万变不离其宗。如果抛开这些业务和功能的外壳，其实它们的本质都可以抽象为“对数据的存储和计算”。对应到数据结构和算法中，那“存储”需要的就是数据结构，“计算”需要的就是算法。

对于存储的需求，功能上无外乎增删改查。这其实并不复杂。但是，一旦存储的数据很多，那性能就成了这些系统要关注的重点，特别是在一些跟存储相关的基础系统（比如 MySQL 数据库、分布式文件系统等）、中间件（比如消息中间件 RocketMQ 等）中。

“如何节省存储空间、如何提高数据增删改查的执行效率”，这样的问题就成了设计的重点。而这些系统的实现，都离不开一个东西，那就是索引。不夸张地说，索引设计得好坏，直接决定了这些系统是否优秀。

索引这个概念，非常好理解。你可以类比书籍的目录来理解。如果没有目录，我们想要查找某个知识点的时候，就要一页一页翻。通过目录，我们就可以快速定位相关知识点的页数，查找的速度也会有质的提高。

索引的需求定义
索引的概念不难理解，我想你应该已经搞明白。接下来，我们就分析一下，在设计索引的过程中，需要考虑到的一些因素，换句话说就是，我们该如何定义清楚需求呢？

对于系统设计需求，我们一般可以从功能性需求和非功能性需求两方面来分析，这个我们之前也说过。因此，这个问题也不例外。

1. 功能性需求
对于功能性需求需要考虑的点，我把它们大致概括成下面这几点。

数据是格式化数据还是非格式化数据？要构建索引的原始数据，类型有很多。我把它分为两类，一类是结构化数据，比如，MySQL 中的数据；另一类是非结构化数据，比如搜索引擎中网页。对于非结构化数据，我们一般需要做预处理，提取出查询关键词，对关键词构建索引。

数据是静态数据还是动态数据？如果原始数据是一组静态数据，也就是说，不会有数据的增加、删除、更新操作，所以，我们在构建索引的时候，只需要考虑查询效率就可以了。这样，索引的构建就相对简单些。不过，大部分情况下，我们都是对动态数据构建索引，也就是说，我们不仅要考虑到索引的查询效率，在原始数据更新的同时，我们还需要动态地更新索引。支持动态数据集合的索引，设计起来相对也要更加复杂些。

索引存储在内存还是硬盘？如果索引存储在内存中，那查询的速度肯定要比存储在磁盘中的高。但是，如果原始数据量很大的情况下，对应的索引可能也会很大。这个时候，因为内存有限，我们可能就不得不将索引存储在磁盘中了。实际上，还有第三种情况，那就是一部分存储在内存，一部分存储在磁盘，这样就可以兼顾内存消耗和查询效率。

单值查找还是区间查找？所谓单值查找，也就是根据查询关键词等于某个值的数据。这种查询需求最常见。所谓区间查找，就是查找关键词处于某个区间值的所有数据。你可以类比 MySQL 数据库的查询需求，自己想象一下。实际上，不同的应用场景，查询的需求会多种多样。

单关键词查找还是多关键词组合查找？比如，搜索引擎中构建的索引，既要支持一个关键词的查找，比如“数据结构”，也要支持组合关键词查找，比如“数据结构 AND 算法”。对于单关键词的查找，索引构建起来相对简单些。对于多关键词查询来说，要分多种情况。像 MySQL 这种结构化数据的查询需求，我们可以实现针对多个关键词的组合，建立索引；对于像搜索引擎这样的非结构数据的查询需求，我们可以针对单个关键词构建索引，然后通过集合操作，比如求并集、求交集等，计算出多个关键词组合的查询结果。

实际上，不同的场景，不同的原始数据，对于索引的需求也会千差万别。我这里只列举了一些比较有共性的需求。

2. 非功能性需求
讲完了功能性需求，我们再来看，索引设计的非功能性需求。

不管是存储在内存中还是磁盘中，索引对存储空间的消耗不能过大。如果存储在内存中，索引对占用存储空间的限制就会非常苛刻。毕竟内存空间非常有限，一个中间件启动后就占用几个 GB 的内存，开发者显然是无法接受的。如果存储在硬盘中，那索引对占用存储空间的限制，稍微会放宽一些。但是，我们也不能掉以轻心。因为，有时候，索引对存储空间的消耗会超过原始数据。

在考虑索引查询效率的同时，我们还要考虑索引的维护成本。索引的目的是提高查询效率，但是，基于动态数据集合构建的索引，我们还要考虑到，索引的维护成本。因为在原始数据动态增删改的同时，我们也需要动态的更新索引。而索引的更新势必会影响到增删改操作的性能。

构建索引常用的数据结构有哪些？
我刚刚从很宏观的角度，总结了在索引设计的过程中，需要考虑的一些共性因素。现在，我们就来看，对于不同需求的索引结构，底层一般使用哪种数据结构。

实际上，常用来构建索引的数据结构，就是我们之前讲过的几种支持动态数据集合的数据结构。比如，散列表、红黑树、跳表、B+ 树。除此之外，位图、布隆过滤器可以作为辅助索引，有序数组可以用来对静态数据构建索引。

我们知道，散列表增删改查操作的性能非常好，时间复杂度是 O(1)。一些键值数据库，比如 Redis、Memcache，就是使用散列表来构建索引的。这类索引，一般都构建在内存中。

红黑树作为一种常用的平衡二叉查找树，数据插入、删除、查找的时间复杂度是 O(logn)，也非常适合用来构建内存索引。Ext 文件系统中，对磁盘块的索引，用的就是红黑树。

B+ 树比起红黑树来说，更加适合构建存储在磁盘中的索引。B+ 树是一个多叉树，所以，对相同个数的数据构建索引，B+ 树的高度要低于红黑树。当借助索引查询数据的时候，读取 B+ 树索引，需要的磁盘 IO 次数非常更少。所以，大部分关系型数据库的索引，比如 MySQL、Oracle，都是用 B+ 树来实现的。

跳表也支持快速添加、删除、查找数据。而且，我们通过灵活调整索引结点个数和数据个数之间的比例，可以很好地平衡索引对内存的消耗及其查询效率。Redis 中的有序集合，就是用跳表来构建的。

除了散列表、红黑树、B+ 树、跳表之外，位图和布隆过滤器这两个数据结构，也可以用于索引中，辅助存储在磁盘中的索引，加速数据查找的效率。我们来看下，具体是怎么做的？

我们知道，布隆过滤器有一定的判错率。但是，我们可以规避它的短处，发挥它的长处。尽管对于判定存在的数据，有可能并不存在，但是对于判定不存在的数据，那肯定就不存在。而且，布隆过滤器还有一个更大的特点，那就是内存占用非常少。我们可以针对数据，构建一个布隆过滤器，并且存储在内存中。当要查询数据的时候，我们可以先通过布隆过滤器，判定是否存在。如果通过布隆过滤器判定数据不存在，那我们就没有必要读取磁盘中的索引了。对于数据不存在的情况，数据查询就更加快速了。

实际上，有序数组也可以被作为索引。如果数据是静态的，也就是不会有插入、删除、更新操作，那我们可以把数据的关键词（查询用的）抽取出来，组织成有序数组，然后利用二分查找算法来快速查找数据。

总结引申
今天这节算是一节总结课。我从索引这个非常常用的技术方案，给你展示了散列表、红黑树、跳表、位图、布隆过滤器、有序数组这些数据结构的应用场景。学习完这节课之后，不知道你对这些数据结构以及索引，有没有更加清晰的认识呢？

从这一节内容中，你应该可以看出，架构设计离不开数据结构和算法。要想成长为一个优秀的业务架构师、基础架构师，数据结构和算法的根基一定要打稳。因为，那些看似很惊艳的架构设计思路，实际上，都是来自最常用的数据结构和算法。

课后思考
你知道基础系统、中间件、开源软件等系统中，有哪些用到了索引吗？这些系统的索引是如何实现的呢？

欢迎留言和我分享，也欢迎点击“请朋友读”，把今天的内容分享给你的好友，和他一起讨论、学习。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(17)

Jerry银银
我对索引的理解
------------
索引真是个好东西。索引的英文名字叫：index，记住这个英文单词，会让我们更容易记忆和联想它到底是什么。在实际的编程中，index这个单词，真是到处可见。例如：数组的下标就是index

如果用一句话描述“索引”的作用，那会是什么？我想是这样：索引是用来辅助查找，用计算机专业术语叫：Addressing(寻址）

现实世界中，我们的查找会存在两种场景：
1. 从局部信息，查询与其相关的整体信息
2. 从整体信息中查询局部信息
怎么理解呢？
搜索引擎需要查询一个网页中是否存在某个关键词以及通过某个关键词查询包含它的所有网页。

索引的应用
--------
正是因为计算机大部分工作都是在Addressing，所以，在计算机中，索引到处存在。小到操作系统虚拟内存到真实内存的映射，就是索引嘛，大到分布式系统、网络，都是这个原理。

以上，我对索引的理解有点“广义”。我觉得数据结构和算法如此重要，它体现计算机精髓的地方便在于此。




2019-01-21


34

freeland
es中的单排索引其实用了trie树，对每个需要索引的key维护了一个trie树，用于定位到这个key在文件中的位置， 然后直接用有序列表直接去访问对应的documents ，区块链拿以太坊来说吧，存储用的leveldb，数据存储用的数据结构是帕特利夏树，是一种高级的trie树，很好的做了数据的压缩， 消息中间件像kafka这种，会去做持久化，每个partition都会有很多数据，会有大量数据存储在磁盘中，所以每个partition也会有个索引，方便去做快速访问
2019-01-21


13

往事随风，顺其自然
可以讲讲es 到排序索引结构原理和数据结构？
2019-01-22


4

Jerry银银
今天音频朗读帅哥把MySQL读成了 my s q l ，早上起来听音频，萌了\(//∇//)\
编辑回复: 官方读法就是 S Q L 哈

2019-01-21


4

one
希望老师能讲讲二级索引（从V查K）这块，一直搞不清楚，没有自己写过。还有空间数据结构的range现在也很火，比如uber，滴滴常用的，面试常考。
2019-01-21


4

三木子
everything
2019-01-21

1

2

万里有云
把数据的关键词（查询用的）抽取出来，组织成有序数组。如果关键词是整型，那索引就是整形数组，关键词是字符串，那索引就是字符串指针数组吗？
作者回复: 是的

2019-04-12


1

纯洁的憎恶
理论联系实际，融会贯通。
2019-01-21


1

胡小禾
我以前只是人云亦云地认同“数据结构和算法”十分重要。看完本节，豁然开朗。似乎庞大的计算机体系，将其本质，半隐半现地展示在我面前
2019-08-02



无形
最近在用的是倒排索引和roaring bitmap，用在广告检索中简直无敌搬的存在
2019-07-05



xuery
索引的底层数据结构实现很多，有些时候可以结合使用，比如王争老师说的，查询某个数据是否存在，可以先通过布隆过滤器的不存在的一定不存在判断，在这一层可以拦截掉不存在的数据
2019-04-09



xiao皮孩。。
理论 结合 应用场景，very good！
2019-03-11



QQ怪
想听es的倒排索引
2019-03-07



天王
索引，软件的本质是对数据的存储和计算，数据结构是存储，算法是计算。节省存储的空间和提高增删改查的执行效率效率，索引是最重要的一环。1为什么需要索引2 索引的功能性需求和非功能性需求3底层用到的数据结构
2019-03-05



在路边鼓掌的人
昨天刚学了操作系统的多级页表，应该是比较经典的索引了😂
2019-01-22



传说中的成大大
这一节就高深了....
2019-01-21



『LHCY』
es的倒排索引
2019-01-21


收起评论

1775





# 51 | 并行算法：如何利用并行处理提高算法的执行效率？



数据结构与算法之美
王争
前Google工程师
查看详情
59587 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

入门篇 (4讲)

基础篇 (38讲)

高级篇 (9讲)

43 | 拓扑排序：如何确定代码源文件的编译依赖关系？
44 | 最短路径：地图软件是如何计算出最优出行路径的？
45 | 位图：如何实现网页爬虫中的URL去重功能？
46 | 概率统计：如何利用朴素贝叶斯算法过滤垃圾短信？
47 | 向量空间：如何实现一个简单的音乐推荐系统？
48 | B+树：MySQL数据库索引是如何实现的？
49 | 搜索：如何用A*搜索算法实现游戏中的寻路功能？
50 | 索引：如何在海量数据中快速查找某个数据？
51 | 并行算法：如何利用并行处理提高算法的执行效率？
实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



51 | 并行算法：如何利用并行处理提高算法的执行效率？
王争 2019-01-23



09:55
讲述：修阳 大小：9.10M
时间复杂度是衡量算法执行效率的一种标准。但是，时间复杂度并不能跟性能划等号。在真实的软件开发中，即便在不降低时间复杂度的情况下，也可以通过一些优化手段，提升代码的执行效率。毕竟，对于实际的软件开发来说，即便是像 10%、20% 这样微小的性能提升，也是非常可观的。

算法的目的就是为了提高代码执行的效率。那当算法无法再继续优化的情况下，我们该如何来进一步提高执行效率呢？我们今天就讲一种非常简单但又非常好用的优化方法，那就是并行计算。今天，我就通过几个例子，给你展示一下，如何借助并行计算的处理思想对算法进行改造？

并行排序
假设我们要给大小为 8GB 的数据进行排序，并且，我们机器的内存可以一次性容纳这么多数据。对于排序来说，最常用的就是时间复杂度为 O(nlogn) 的三种排序算法，归并排序、快速排序、堆排序。从理论上讲，这个排序问题，已经很难再从算法层面优化了。而利用并行的处理思想，我们可以很轻松地将这个给 8GB 数据排序问题的执行效率提高很多倍。具体的实现思路有下面两种。

第一种是对归并排序并行化处理。我们可以将这 8GB 的数据划分成 16 个小的数据集合，每个集合包含 500MB 的数据。我们用 16 个线程，并行地对这 16 个 500MB 的数据集合进行排序。这 16 个小集合分别排序完成之后，我们再将这 16 个有序集合合并。

第二种是对快速排序并行化处理。我们通过扫描一遍数据，找到数据所处的范围区间。我们把这个区间从小到大划分成 16 个小区间。我们将 8GB 的数据划分到对应的区间中。针对这 16 个小区间的数据，我们启动 16 个线程，并行地进行排序。等到 16 个线程都执行结束之后，得到的数据就是有序数据了。

对比这两种处理思路，它们利用的都是分治的思想，对数据进行分片，然后并行处理。它们的区别在于，第一种处理思路是，先随意地对数据分片，排序之后再合并。第二种处理思路是，先对数据按照大小划分区间，然后再排序，排完序就不需要再处理了。这个跟归并和快排的区别如出一辙。

这里我还要多说几句，如果要排序的数据规模不是 8GB，而是 1TB，那问题的重点就不是算法的执行效率了，而是数据的读取效率。因为 1TB 的数据肯定是存在硬盘中，无法一次性读取到内存中，这样在排序的过程中，就会有频繁地磁盘数据的读取和写入。如何减少磁盘的 IO 操作，减少磁盘数据读取和写入的总量，就变成了优化的重点。不过这个不是我们这节要讨论的重点，你可以自己思考下。

并行查找
我们知道，散列表是一种非常适合快速查找的数据结构。

如果我们是给动态数据构建索引，在数据不断加入的时候，散列表的装载因子就会越来越大。为了保证散列表性能不下降，我们就需要对散列表进行动态扩容。对如此大的散列表进行动态扩容，一方面比较耗时，另一方面比较消耗内存。比如，我们给一个 2GB 大小的散列表进行扩容，扩展到原来的 1.5 倍，也就是 3GB 大小。这个时候，实际存储在散列表中的数据只有不到 2GB，所以内存的利用率只有 60%，有 1GB 的内存是空闲的。

实际上，我们可以将数据随机分割成 k 份（比如 16 份），每份中的数据只有原来的 1/k，然后我们针对这 k 个小数据集合分别构建散列表。这样，散列表的维护成本就变低了。当某个小散列表的装载因子过大的时候，我们可以单独对这个散列表进行扩容，而其他散列表不需要进行扩容。

还是刚才那个例子，假设现在有 2GB 的数据，我们放到 16 个散列表中，每个散列表中的数据大约是 150MB。当某个散列表需要扩容的时候，我们只需要额外增加 150*0.5=75MB 的内存（假设还是扩容到原来的 1.5 倍）。不管从扩容的执行效率还是内存的利用率上，这种多个小散列表的处理方法，都要比大散列表高效。

当我们要查找某个数据的时候，我们只需要通过 16 个线程，并行地在这 16 个散列表中查找数据。这样的查找性能，比起一个大散列表的做法，也并不会下降，反倒有可能提高。

当往散列表中添加数据的时候，我们可以选择将这个新数据放入装载因子最小的那个散列表中，这样也有助于减少散列冲突。

并行字符串匹配
我们前面学过，在文本中查找某个关键词这样一个功能，可以通过字符串匹配算法来实现。我们之前学过的字符串匹配算法有 KMP、BM、RK、BF 等。当在一个不是很长的文本中查找关键词的时候，这些字符串匹配算法中的任何一个，都可以表现得非常高效。但是，如果我们处理的是超级大的文本，那处理的时间可能就会变得很长，那有没有办法加快匹配速度呢？

我们可以把大的文本，分割成 k 个小文本。假设 k 是 16，我们就启动 16 个线程，并行地在这 16 个小文本中查找关键词，这样整个查找的性能就提高了 16 倍。16 倍效率的提升，从理论的角度来说并不多。但是，对于真实的软件开发来说，这显然是一个非常可观的优化。

不过，这里还有一个细节要处理，那就是原本包含在大文本中的关键词，被一分为二，分割到两个小文本中，这就会导致尽管大文本中包含这个关键词，但在这 16 个小文本中查找不到它。实际上，这个问题也不难解决，我们只需要针对这种特殊情况，做一些特殊处理就可以了。

我们假设关键词的长度是 m。我们在每个小文本的结尾和开始各取 m 个字符串。前一个小文本的末尾 m 个字符和后一个小文本的开头 m 个字符，组成一个长度是 2m 的字符串。我们再拿关键词，在这个长度为 2m 的字符串中再重新查找一遍，就可以补上刚才的漏洞了。

并行搜索
前面我们学习过好几种搜索算法，它们分别是广度优先搜索、深度优先搜索、Dijkstra 最短路径算法、A* 启发式搜索算法。对于广度优先搜索算法，我们也可以将其改造成并行算法。

广度优先搜索是一种逐层搜索的搜索策略。基于当前这一层顶点，我们可以启动多个线程，并行地搜索下一层的顶点。在代码实现方面，原来广度优先搜索的代码实现，是通过一个队列来记录已经遍历到但还没有扩展的顶点。现在，经过改造之后的并行广度优先搜索算法，我们需要利用两个队列来完成扩展顶点的工作。

假设这两个队列分别是队列 A 和队列 B。多线程并行处理队列 A 中的顶点，并将扩展得到的顶点存储在队列 B 中。等队列 A 中的顶点都扩展完成之后，队列 A 被清空，我们再并行地扩展队列 B 中的顶点，并将扩展出来的顶点存储在队列 A。这样两个队列循环使用，就可以实现并行广度优先搜索算法。

总结引申
上一节，我们通过实际软件开发中的“索引”这一技术点，回顾了之前学过的一些支持动态数据集合的数据结构。今天，我们又通过“并行算法”这个话题，回顾了之前学过的一些算法。

今天的内容比较简单，没有太复杂的知识点。我通过一些例子，比如并行排序、查找、搜索、字符串匹配，给你展示了并行处理的实现思路，也就是对数据进行分片，对没有依赖关系的任务，并行地执行。

并行计算是一个工程上的实现思路，尽管跟算法关系不大，但是，在实际的软件开发中，它确实可以非常巧妙地提高程序的运行效率，是一种非常好用的性能优化手段。

特别是，当要处理的数据规模达到一定程度之后，我们无法通过继续优化算法，来提高执行效率 的时候，我们就需要在实现的思路上做文章，利用更多的硬件资源，来加快执行的效率。所以，在很多超大规模数据处理中，并行处理的思想，应用非常广泛，比如 MapReduce 实际上就是一种并行计算框架。

课后思考
假设我们有 n 个任务，为了提高执行的效率，我们希望能并行执行任务，但是各个任务之间又有一定的依赖关系，如何根据依赖关系找出可以并行执行的任务？

欢迎留言和我分享，也欢迎点击“请朋友读”，把今天的内容分享给你的好友，和他一起讨论、学习。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(24)

失火的夏天
思考题用一个有向图来存储任务之间的依赖关系，然后用拓扑排序的思想来执行任务，每次都找到入度为0的，放在队列里，启动线程池开始执行，队列里的任务并行执行完毕，再次调用拓扑排序找到入度为0的人，放入队列，直到所以任务跑完
2019-01-23


56

Jerry银银
一看到依赖，就想到了拓扑。

这种感觉好是还是不好呢？
2019-01-23


10

hua168
老师，我就问一个题外问题：
大专学历，想直接自学考本科或研究生，自考学历IT类公司承认的吗？
很多都要求全日制本科~~
2019-01-23


8

🐱您的好友William🐱
使用拓扑关系来构建图安排计算顺序，这个spark，tensorflow都是这么安排的，效率比最开始的MapReduce还要高很多。
2019-02-08


4

茴香根
思考题讲的够直白了，n个任务有互相依赖。那么并行处理的方法就要采用流水线的思想了。创建n个线程，每个线程完成一个任务。每个线程在它的上游线程结束输出结果后启动，完成之后把结果传递给下游任务线程继续流程。整个工作场景像工厂里面的流水线一样，每一个线程都努力地重复着某一阶段的任务，提高整体资源利用率。
2019-01-23


4

DFighting
现在才明白，其实最底层的数据结构是<addr,value>，按照存储介质是否连续、是否显示制定key又可以分为数组、链表和hash，其中数组可以认为是一种<index,arr[index]>，链表是<p,*p>，然后在这基础之上衍生出了一维的线性表、栈、队列，散列表，二维的树(平衡二叉树、红黑树、跳表)，三维的图，还有就是各种数据结构灵活组合的数据结构，这里的跳表可以算是组合类型的，但是它的使用范围很多，所以划到了二维中。这些是存储
然后是算法：排序、分治、贪心、回溯、动态规划
第一次真正感觉到了数据结构和算法的关联，好神奇的感觉。至少现在觉得那些难记的算法、数据结构没那么困难了，多思考、实践总会能够像写代码般应用到实际中。
2019-08-13


3

Geek_46cdcd
请问老师，广度优先搜索中用两个队列是为了解决多线程的并发问题吗？
作者回复: 是的

2019-05-09

1

1

牧民牛仔
既然有依赖关系，我条件反射想到拓扑排序算法，根据依赖关系把任务分组，各组任务按照依赖关系排序。没有依赖关系的任务组可以并行执行，有依赖关系的任务组内则按依赖关系有序的执行。
2019-01-24


1

Smallfly
并行搜索只用一个队列不可以么？
作者回复: 也可以的。不过就有可能导致没法找到最短路径了。

2019-01-23


1

子嘉
思考题是：拓扑排序么。。
2019-01-23


1

纯洁的憎恶
并行与分治的区别是什么？前者偏工程，后者偏算法么？还是前者在并发环境中，后者在单核串行环境中？
作者回复: 并行是一种工程思路。分治是一种算法思想。感觉差不多哈；）你理解就好，不要太纠结；）

2019-01-23


1

mrlay
我觉得能够并行执行多少个任务，是取决于这些任务之间的依赖关系；采用拓扑只是为了确认任务的先后执行。 最坏的情况下还是会变成串行的。
2019-07-21



Geek_54edc1
利用两个队列A和B，多线程并行处理A队列中的顶点（入度为0），并将入度为0的扩展顶点（扩展顶点的入度减1）入队B，A队列中顶点都处理完，队列A清空，再并行处理B队列中顶点，并将入度为0的扩展顶点（扩展顶点的入度减1）入队A，如此两个队列循环使用
2019-06-01



朱东旭
老师，并行搜索在你的描述中是先操作队列A,再操作队列B,这是有先后顺序，这意味着是串行的不是并行呀。
作者回复: 是并行处理完队列a，然后并行处理队列b这个样子的。并不是a、b的处理是并行的。

2019-05-10



xuery
想到的第一个思路就是前面所讲的拓扑排序，任务之间的关系用有向图表示，如果是采用khan遍历，则每次找到入度为0的，同时多线程执行，等他们执行完（java可以通过CountDownLatch来模拟实现），然后同理找到入度为0的任务，继续同理执行，直到全部执行完
2019-04-09



yaya
将各任务通过依赖关系做成图，然后进行并行计算
2019-02-20



睡痴儿😑
使用的是拓扑排序，刚开始还以为太简单。不可能是这样
2019-01-27



才才
打卡，继续学习。
2019-01-25



小苏饼
spark，oozie的有向无环图
2019-01-24



绿茶
计算机不一定都是n核的，怎么实现性能提升n倍呢
作者回复: 即便是n核也不一定提高n倍，毕竟还共享内存呢：）

我这里本就是粗略的表示:)

2019-01-23


收起评论

2446






# 52 | 算法实战（一）：剖析Redis常用数据类型对应的数据结构



数据结构与算法之美
王争
前Google工程师
查看详情
59587 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

入门篇 (4讲)

基础篇 (38讲)

高级篇 (9讲)

43 | 拓扑排序：如何确定代码源文件的编译依赖关系？
44 | 最短路径：地图软件是如何计算出最优出行路径的？
45 | 位图：如何实现网页爬虫中的URL去重功能？
46 | 概率统计：如何利用朴素贝叶斯算法过滤垃圾短信？
47 | 向量空间：如何实现一个简单的音乐推荐系统？
48 | B+树：MySQL数据库索引是如何实现的？
49 | 搜索：如何用A*搜索算法实现游戏中的寻路功能？
50 | 索引：如何在海量数据中快速查找某个数据？
51 | 并行算法：如何利用并行处理提高算法的执行效率？
实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



52 | 算法实战（一）：剖析Redis常用数据类型对应的数据结构
王争 2019-01-25



12:00
讲述：修阳 大小：11.01M
到此为止，专栏前三部分我们全部讲完了。从今天开始，我们就正式进入实战篇的部分。这部分我主要通过一些开源项目、经典系统，真枪实弹地教你，如何将数据结构和算法应用到项目中。所以这部分的内容，更多的是知识点的回顾，相对于基础篇、高级篇的内容，其实这部分会更加容易看懂。

不过，我希望你不要只是看懂就完了。你要多举一反三地思考，自己接触过的开源项目、基础框架、中间件中，都用过哪些数据结构和算法。你也可以想一想，在自己做的项目中，有哪些可以用学过的数据结构和算法进一步优化。这样的学习效果才会更好。

好了，今天我就带你一块儿看下，经典数据库 Redis 中的常用数据类型，底层都是用哪种数据结构实现的？

Redis 数据库介绍
Redis 是一种键值（Key-Value）数据库。相对于关系型数据库（比如 MySQL），Redis 也被叫作非关系型数据库。

像 MySQL 这样的关系型数据库，表的结构比较复杂，会包含很多字段，可以通过 SQL 语句，来实现非常复杂的查询需求。而 Redis 中只包含“键”和“值”两部分，只能通过“键”来查询“值”。正是因为这样简单的存储结构，也让 Redis 的读写效率非常高。

除此之外，Redis 主要是作为内存数据库来使用，也就是说，数据是存储在内存中的。尽管它经常被用作内存数据库，但是，它也支持将数据存储在硬盘中。这一点，我们后面会介绍。

Redis 中，键的数据类型是字符串，但是为了丰富数据存储的方式，方便开发者使用，值的数据类型有很多，常用的数据类型有这样几种，它们分别是字符串、列表、字典、集合、有序集合。

“字符串（string）”这种数据类型非常简单，对应到数据结构里，就是字符串。你应该非常熟悉，这里我就不多介绍了。我们着重看下，其他四种比较复杂点的数据类型，看看它们底层都依赖了哪些数据结构。

列表（list）
我们先来看列表。列表这种数据类型支持存储一组数据。这种数据类型对应两种实现方法，一种是压缩列表（ziplist），另一种是双向循环链表。

当列表中存储的数据量比较小的时候，列表就可以采用压缩列表的方式实现。具体需要同时满足下面两个条件：

列表中保存的单个数据（有可能是字符串类型的）小于 64 字节；

列表中数据个数少于 512 个。

关于压缩列表，我这里稍微解释一下。它并不是基础数据结构，而是 Redis 自己设计的一种数据存储结构。它有点儿类似数组，通过一片连续的内存空间，来存储数据。不过，它跟数组不同的一点是，它允许存储的数据大小不同。具体的存储结构也非常简单，你可以看我下面画的这幅图。



现在，我们来看看，压缩列表中的“压缩”两个字该如何理解？

听到“压缩”两个字，直观的反应就是节省内存。之所以说这种存储结构节省内存，是相较于数组的存储思路而言的。我们知道，数组要求每个元素的大小相同，如果我们要存储不同长度的字符串，那我们就需要用最大长度的字符串大小作为元素的大小（假设是 20 个字节）。那当我们存储小于 20 个字节长度的字符串的时候，便会浪费部分存储空间。听起来有点儿拗口，我画个图解释一下。



压缩列表这种存储结构，一方面比较节省内存，另一方面可以支持不同类型数据的存储。而且，因为数据存储在一片连续的内存空间，通过键来获取值为列表类型的数据，读取的效率也非常高。

当列表中存储的数据量比较大的时候，也就是不能同时满足刚刚讲的两个条件的时候，列表就要通过双向循环链表来实现了。

在链表里，我们已经讲过双向循环链表这种数据结构了，如果不记得了，你可以先回去复习一下。这里我们着重看一下 Redis 中双向链表的编码实现方式。

Redis 的这种双向链表的实现方式，非常值得借鉴。它额外定义一个 list 结构体，来组织链表的首、尾指针，还有长度等信息。这样，在使用的时候就会非常方便。

// 以下是 C 语言代码，因为 Redis 是用 C 语言实现的。
typedef struct listnode {
  struct listNode *prev;
  struct listNode *next;
  void *value;
} listNode;
 
 
typedef struct list {
  listNode *head;
  listNode *tail;
  unsigned long len;
  // .... 省略其他定义
} list;
字典（hash）
字典类型用来存储一组数据对。每个数据对又包含键值两部分。字典类型也有两种实现方式。一种是我们刚刚讲到的压缩列表，另一种是散列表。

同样，只有当存储的数据量比较小的情况下，Redis 才使用压缩列表来实现字典类型。具体需要满足两个条件：

字典中保存的键和值的大小都要小于 64 字节；

字典中键值对的个数要小于 512 个。

当不能同时满足上面两个条件的时候，Redis 就使用散列表来实现字典类型。Redis 使用MurmurHash2这种运行速度快、随机性好的哈希算法作为哈希函数。对于哈希冲突问题，Redis 使用链表法来解决。除此之外，Redis 还支持散列表的动态扩容、缩容。

当数据动态增加之后，散列表的装载因子会不停地变大。为了避免散列表性能的下降，当装载因子大于 1 的时候，Redis 会触发扩容，将散列表扩大为原来大小的 2 倍左右（具体值需要计算才能得到，如果感兴趣，你可以去阅读源码）。

当数据动态减少之后，为了节省内存，当装载因子小于 0.1 的时候，Redis 就会触发缩容，缩小为字典中数据个数的大约 2 倍大小（这个值也是计算得到的，如果感兴趣，你也可以去阅读源码）。

我们前面讲过，扩容缩容要做大量的数据搬移和哈希值的重新计算，所以比较耗时。针对这个问题，Redis 使用我们在散列表（中）讲的渐进式扩容缩容策略，将数据的搬移分批进行，避免了大量数据一次性搬移导致的服务停顿。

集合（set）
集合这种数据类型用来存储一组不重复的数据。这种数据类型也有两种实现方法，一种是基于有序数组，另一种是基于散列表。

当要存储的数据，同时满足下面这样两个条件的时候，Redis 就采用有序数组，来实现集合这种数据类型。

存储的数据都是整数；

存储的数据元素个数不超过 512 个。

当不能同时满足这两个条件的时候，Redis 就使用散列表来存储集合中的数据。

有序集合（sortedset）
有序集合这种数据类型，我们在跳表里已经详细讲过了。它用来存储一组数据，并且每个数据会附带一个得分。通过得分的大小，我们将数据组织成跳表这样的数据结构，以支持快速地按照得分值、得分区间获取数据。

实际上，跟 Redis 的其他数据类型一样，有序集合也并不仅仅只有跳表这一种实现方式。当数据量比较小的时候，Redis 会用压缩列表来实现有序集合。具体点说就是，使用压缩列表来实现有序集合的前提，有这样两个：

所有数据的大小都要小于 64 字节；

元素个数要小于 128 个。

数据结构持久化
尽管 Redis 经常会被用作内存数据库，但是，它也支持数据落盘，也就是将内存中的数据存储到硬盘中。这样，当机器断电的时候，存储在 Redis 中的数据也不会丢失。在机器重新启动之后，Redis 只需要再将存储在硬盘中的数据，重新读取到内存，就可以继续工作了。

刚刚我们讲到，Redis 的数据格式由“键”和“值”两部分组成。而“值”又支持很多数据类型，比如字符串、列表、字典、集合、有序集合。像字典、集合等类型，底层用到了散列表，散列表中有指针的概念，而指针指向的是内存中的存储地址。 那 Redis 是如何将这样一个跟具体内存地址有关的数据结构存储到磁盘中的呢？

实际上，Redis 遇到的这个问题并不特殊，很多场景中都会遇到。我们把它叫作数据结构的持久化问题，或者对象的持久化问题。这里的“持久化”，你可以笼统地可以理解为“存储到磁盘”。

如何将数据结构持久化到硬盘？我们主要有两种解决思路。

第一种是清除原有的存储结构，只将数据存储到磁盘中。当我们需要从磁盘还原数据到内存的时候，再重新将数据组织成原来的数据结构。实际上，Redis 采用的就是这种持久化思路。

不过，这种方式也有一定的弊端。那就是数据从硬盘还原到内存的过程，会耗用比较多的时间。比如，我们现在要将散列表中的数据存储到磁盘。当我们从磁盘中，取出数据重新构建散列表的时候，需要重新计算每个数据的哈希值。如果磁盘中存储的是几 GB 的数据，那重构数据结构的耗时就不可忽视了。

第二种方式是保留原来的存储格式，将数据按照原有的格式存储在磁盘中。我们拿散列表这样的数据结构来举例。我们可以将散列表的大小、每个数据被散列到的槽的编号等信息，都保存在磁盘中。有了这些信息，我们从磁盘中将数据还原到内存中的时候，就可以避免重新计算哈希值。

总结引申
今天，我们学习了 Redis 中常用数据类型底层依赖的数据结构，总结一下大概有这五种：压缩列表（可以看作一种特殊的数组）、有序数组、链表、散列表、跳表。实际上，Redis 就是这些常用数据结构的封装。

你有没有发现，有了数据结构和算法的基础之后，再去阅读 Redis 的源码，理解起来就容易多了？很多原来觉得很深奥的设计思想，是不是就都会觉得顺理成章了呢？

还是那句话，夯实基础很重要。同样是看源码，有些人只能看个热闹，了解一些皮毛，无法形成自己的知识结构，不能化为己用，过不几天就忘了。而有些人基础很好，不但能知其然，还能知其所以然，从而真正理解作者设计的动机。这样不但能有助于我们理解所用的开源软件，还能为我们自己创新添砖加瓦。

课后思考
你有没有发现，在数据量比较小的情况下，Redis 中的很多数据类型，比如字典、有序集合等，都是通过多种数据结构来实现的，为什么会这样设计呢？用一种固定的数据结构来实现，不是更加简单吗？

我们讲到数据结构持久化有两种方法。对于二叉查找树这种数据结构，我们如何将它持久化到磁盘中呢？

欢迎留言和我分享，也欢迎点击“请朋友读”，把今天的内容分享给你的好友，和他一起讨论、学习。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(38)

在路上
思考题1：redis的数据结构由多种数据结构来实现，主要是出于时间和空间的考虑，当数据量小的时候通过数组下标访问最快、占用内存最小，而压缩列表只是数组的升级版；
因为数组需要占用连续的内存空间，所以当数据量大的时候，就需要使用链表了，同时为了保证速度又需要和数组结合，也就有了散列表。
对于数据的大小和多少采用哪种数据结构，相信redis团队一定是根据大多数的开发场景而定的。

思考题2：二叉查找树的存储，我倾向于存储方式一，通过填充叶子节点形成完全二叉树，然后以数组的形式存储到硬盘，数据还原过程也是非常高效的。如果用存储方式二就比较复杂了。
2019-01-25


29

郑晨Cc
老师 关于redis的压缩列表有个地方不太明白
虽然压缩列表看起来想数组 但他能像数组一样支持按照下标进行直接随机访问吗？比如我要访问下标为n的数据我启不是需要知道之前从0到n-1的所有数据的长度才能找到n，那这跟链表的时间复杂读没啥区别啊，而且还占用了连续的内存空间？ 还是说压缩列表中的每个元素的长度都记录在它的头部可以一次性的获取？
作者回复: 哈哈，你说的没错。压缩列表不支持随机访问。有点类似链表。但是比较省存储空间啊。Redis一般都是通过key获取整个value的值，也就是整个压缩列表的数据，并不需要随机访问。

2019-01-25


17

Jerry银银
发现一个功能：左滑进入上一篇，右滑进入下一篇
编辑回复: 看来是没少刷专栏😄

2019-01-25


10

李靖峰
数据量小时采用连续内存的数据结构是为了CPU缓存读取连续内存来提高命中率，而限制数据数量和数据大小应该是考虑到CPU缓存的大小
2019-02-02


7

张淼
问题1: 压缩列表优点：访问存取快速，节省内存。但是受到操作系统空闲内存限制。越大的连续内存空间越不容易申请到。所以用了其他数据结构比如链表替代。
2019-01-26


5

田伟 คิดถึง
看完前边的课程，当知识点连成线和面之后，才发现原来是这么回事，再来看redis确认是豁然开朗。知识成体系之后记忆会更深刻，不过也带来了更多的思考和发现-----知识边界扩大了
2019-01-25


5

来碗绿豆汤
压缩列表每个元素所占用的空间大小是不一定的，所以当想要随机访问某个元素的时候还是要像列表那样从头开始遍历，所以不能太大。理解对吗？
作者回复: 是的 没错

2019-04-10


2

wei
老师，如果字典保存的键和值的大小都小于 64 字节，并且键值对的个数小于 512 个，Redis 用压缩列表实现。从 [源码](https://github.com/antirez/redis/blob/unstable/src/ziplist.c) （ziplist.c ziplistFind） 来看压缩列表根据键查找值的方式，就是一个个遍历。如果有几百个键值对，这么查找比散列表快吗？
2019-01-26


2

readyao
老师您好，有这样一个场景，A关注了B,这样的操作会同时写两个链表一个是A的关注列表，另一个是B的粉丝列表，比如用redis 的sortset来存储。现在要检查所有不一致的情况(比如，A的关注列表有B，但是B的粉丝列表没有A，或者A的关注列表没有B，但是B的粉丝列表有A)。这种情况有什么好的方法吗?
2019-01-26


2

锦
常常听人说可以使用Redis作为消息队列，这是为什么呢？
作者回复: 😂 自己看看redis官方文档吧

2019-06-13


1

Geek_54edc1
思考题2：对二叉搜索树进行前序遍历，得到的结果以数组的形式存储到磁盘，还原的过程就是顺序遍历数组，构建二叉搜索树
2019-06-01


1

xuery
1. 这个是因为每种数据结构都有适合自己的场景，比如压缩列表（特殊的有序数组）比较适合查询操作，删除新增的时间复杂度较高为O（n）,数据量小的时候可以使用，因为结构简单，数据量大的时候删除新增的效率非常低；所以量大的时候要考虑增删改查都比较快的数据结构，比如散列表、跳表、二叉树、红黑树等等数据结构了
2. 二叉树可以通过前序+中序写入磁盘，之后通过前序+中序还原；或者类似于将堆的时候，将数据按层遍历存入数组中，从下标1开始存储，下标i的左右子树存储在(2*i,2*i+1)下标中，然后顺序写入磁盘，这个的缺点是会产生空洞，因为不一定是满二叉树
2019-04-10


1

青铜5 周群力
我猜压缩列表的好处是能利用l2缓存?
作者回复: 是的，有这么个好处。越小越有利于CPU缓存。

2019-02-06


1

三木子
有个疑问，比如对于有序集合，这个数据量可能会逐步增加，那么数据量达到阈值时就会切换成跳表吗？是数据全部移动到跳表，然后删除列表吗？
2019-01-25


1

z.l
压缩列表虽然省内存，但是随机插入删除需要做内存拷贝，所以数据量大了之后影响性能
2019-09-07



勿忘初心
redis里的字符串，用的是数组存储的吧？和java里的ArrayList 很像，支持动态扩容的
2019-08-17



rm -rf .
跳表和B+数既然大部分场景下可以互换，为什么redis没有使用B+树而选择跳表？
作者回复: 跳表更灵活 更容易实现

2019-08-08



Paul Shan
思考题二
二叉查找树存储的时候，可以分两部分存储，所有节点可以在一个数组中。相互连接关系可以节点数组下标作为索引的方式存在另一个数组中。
2019-08-08



Paul Shan
思考题1
选择两种数据结构可能是因为问题规模不同，最佳方案也不同。存储量少的时候，数组的弊端不明显，因为这时整块的内存比较容易得到，数据的搬运代价不大。数组的存储紧凑，遍历的时候可以充分利用CPU的缓存等优点可以给系统带来时间空间两方面的效率。当数据量变大，整块的大内存变的稀缺，数据搬运代价巨大，这个时候用扩展性好的双向链表或者哈希表，即使付出了一些指针的代价，牺牲了缓存的效率之后还是更划算一些。
2019-08-08



danvid
数据不需要存储太多的其他引用字段，减少内存空间，但是很多结构需要对数组遍历才能满足功能所以大数据量时会导致效率低，所以才这样设计
2019-06-05


收起评论

3896





# 53 | 算法实战（二）：剖析搜索引擎背后的经典数据结构和算法



数据结构与算法之美
王争
前Google工程师
查看详情
59587 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

入门篇 (4讲)

基础篇 (38讲)

高级篇 (9讲)

43 | 拓扑排序：如何确定代码源文件的编译依赖关系？
44 | 最短路径：地图软件是如何计算出最优出行路径的？
45 | 位图：如何实现网页爬虫中的URL去重功能？
46 | 概率统计：如何利用朴素贝叶斯算法过滤垃圾短信？
47 | 向量空间：如何实现一个简单的音乐推荐系统？
48 | B+树：MySQL数据库索引是如何实现的？
49 | 搜索：如何用A*搜索算法实现游戏中的寻路功能？
50 | 索引：如何在海量数据中快速查找某个数据？
51 | 并行算法：如何利用并行处理提高算法的执行效率？
实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



53 | 算法实战（二）：剖析搜索引擎背后的经典数据结构和算法
王争 2019-01-28



18:44
讲述：修阳 大小：17.16M
像百度、Google 这样的搜索引擎，在我们平时的工作、生活中，几乎天天都会用到。如果我们把搜索引擎也当作一个互联网产品的话，那它跟社交、电商这些类型的产品相比，有一个非常大的区别，那就是，它是一个技术驱动的产品。所谓技术驱动是指，搜索引擎实现起来，技术难度非常大，技术的好坏直接决定了这个产品的核心竞争力。

在搜索引擎的设计与实现中，会用到大量的算法。有很多针对特定问题的算法，也有很多我们专栏中讲到的基础算法。所以，百度、Google 这样的搜索引擎公司，在面试的时候，会格外重视考察候选人的算法能力。

今天我就借助搜索引擎，这样一个非常有技术含量的产品，来给你展示一下，数据结构和算法是如何应用在其中的。

整体系统介绍
像 Google 这样的大型商用搜索引擎，有成千上万的工程师，十年如一日地对它进行优化改进，所以，它所包含的技术细节非常多。我很难、也没有这个能力，通过一篇文章把所有细节都讲清楚，当然这也不是我们专栏所专注的内容。

所以，接下来的讲解，我主要给你展示，如何在一台机器上（假设这台机器的内存是 8GB， 硬盘是 100 多 GB），通过少量的代码，实现一个小型搜索引擎。不过，麻雀虽小，五脏俱全。跟大型搜索引擎相比，实现这样一个小型搜索引擎所用到的理论基础是相通的。

搜索引擎大致可以分为四个部分：搜集、分析、索引、查询。其中，搜集，就是我们常说的利用爬虫爬取网页。分析，主要负责网页内容抽取、分词，构建临时索引，计算 PageRank 值这几部分工作。索引，主要负责通过分析阶段得到的临时索引，构建倒排索引。查询，主要负责响应用户的请求，根据倒排索引获取相关网页，计算网页排名，返回查询结果给用户。

接下来，我就按照网页处理的生命周期，从这四个阶段，依次来给你讲解，一个网页从被爬取到最终展示给用户，这样一个完整的过程。与此同时，我会穿插讲解，这个过程中需要用到哪些数据结构和算法。

搜集
现在，互联网越来越发达，网站越来越多，对应的网页也就越来越多。对于搜索引擎来说，它事先并不知道网页都在哪里。打个比方来说就是，我们只知道海里面有很多鱼，但却并不知道鱼在哪里。那搜索引擎是如何爬取网页的呢？

搜索引擎把整个互联网看作数据结构中的有向图，把每个页面看作一个顶点。如果某个页面中包含另外一个页面的链接，那我们就在两个顶点之间连一条有向边。我们可以利用图的遍历搜索算法，来遍历整个互联网中的网页。

我们前面介绍过两种图的遍历方法，深度优先和广度优先。搜索引擎采用的是广度优先搜索策略。具体点讲的话，那就是，我们先找一些比较知名的网页（专业的叫法是权重比较高）的链接（比如新浪主页网址、腾讯主页网址等），作为种子网页链接，放入到队列中。爬虫按照广度优先的策略，不停地从队列中取出链接，然后取爬取对应的网页，解析出网页里包含的其他网页链接，再将解析出来的链接添加到队列中。

基本的原理就是这么简单。但落实到实现层面，还有很多技术细节。我下面借助搜集阶段涉及的几个重要文件，来给你解释一下搜集工程都有哪些关键技术细节。

1. 待爬取网页链接文件：links.bin
在广度优先搜索爬取页面的过程中，爬虫会不停地解析页面链接，将其放到队列中。于是，队列中的链接就会越来越多，可能会多到内存放不下。所以，我们用一个存储在磁盘中的文件（links.bin）来作为广度优先搜索中的队列。爬虫从 links.bin 文件中，取出链接去爬取对应的页面。等爬取到网页之后，将解析出来的链接，直接存储到 links.bin 文件中。

这样用文件来存储网页链接的方式，还有其他好处。比如，支持断点续爬。也就是说，当机器断电之后，网页链接不会丢失；当机器重启之后，还可以从之前爬取到的位置继续爬取。

关于如何解析页面获取链接，我额外多说几句。我们可以把整个页面看作一个大的字符串，我们可以利用字符串匹配算法，在这个大字符串中，搜索这样一个网页标签，然后顺序读取之间的字符串。这其实就是网页链接。

2. 网页判重文件：bloom_filter.bin
如何避免重复爬取相同的网页呢？这个问题我们在位图那一节已经讲过了。使用布隆过滤器，我们就可以快速并且非常节省内存地实现网页的判重。

不过，还是刚刚那个问题，如果我们把布隆过滤器存储在内存中，那机器宕机重启之后，布隆过滤器就被清空了。这样就可能导致大量已经爬取的网页会被重复爬取。

这个问题该怎么解决呢？我们可以定期地（比如每隔半小时）将布隆过滤器持久化到磁盘中，存储在 bloom_filter.bin 文件中。这样，即便出现机器宕机，也只会丢失布隆过滤器中的部分数据。当机器重启之后，我们就可以重新读取磁盘中的 bloom_filter.bin 文件，将其恢复到内存中。

3. 原始网页存储文件：doc_raw.bin
爬取到网页之后，我们需要将其存储下来，以备后面离线分析、索引之用。那如何存储海量的原始网页数据呢？

如果我们把每个网页都存储为一个独立的文件，那磁盘中的文件就会非常多，数量可能会有几千万，甚至上亿。常用的文件系统显然不适合存储如此多的文件。所以，我们可以把多个网页存储在一个文件中。每个网页之间，通过一定的标识进行分隔，方便后续读取。具体的存储格式，如下图所示。其中，doc_id 这个字段是网页的编号，我们待会儿再解释。



当然，这样的一个文件也不能太大，因为文件系统对文件的大小也有一定的限制。所以，我们可以设置每个文件的大小不能超过一定的值（比如 1GB）。随着越来越多的网页被添加到文件中，文件的大小就会越来越大，当超过 1GB 的时候，我们就创建一个新的文件，用来存储新爬取的网页。

假设一台机器的硬盘大小是 100GB 左右，一个网页的平均大小是 64KB。那在一台机器上，我们可以存储 100 万到 200 万左右的网页。假设我们的机器的带宽是 10MB，那下载 100GB 的网页，大约需要 10000 秒。也就是说，爬取 100 多万的网页，也就是只需要花费几小时的时间。

4. 网页链接及其编号的对应文件：doc_id.bin
刚刚我们提到了网页编号这个概念，我现在解释一下。网页编号实际上就是给每个网页分配一个唯一的 ID，方便我们后续对网页进行分析、索引。那如何给网页编号呢？

我们可以按照网页被爬取的先后顺序，从小到大依次编号。具体是这样做的：我们维护一个中心的计数器，每爬取到一个网页之后，就从计数器中拿一个号码，分配给这个网页，然后计数器加一。在存储网页的同时，我们将网页链接跟编号之间的对应关系，存储在另一个 doc_id.bin 文件中。

爬虫在爬取网页的过程中，涉及的四个重要的文件，我就介绍完了。其中，links.bin 和 bloom_filter.bin 这两个文件是爬虫自身所用的。另外的两个（doc_raw.bin、doc_id.bin）是作为搜集阶段的成果，供后面的分析、索引、查询用的。

分析
网页爬取下来之后，我们需要对网页进行离线分析。分析阶段主要包括两个步骤，第一个是抽取网页文本信息，第二个是分词并创建临时索引。我们逐一来讲解。

1. 抽取网页文本信息
网页是半结构化数据，里面夹杂着各种标签、JavaScript 代码、CSS 样式。对于搜索引擎来说，它只关心网页中的文本信息，也就是，网页显示在浏览器中时，能被用户肉眼看到的那部分信息。我们如何从半结构化的网页中，抽取出搜索引擎关系的文本信息呢？

我们之所以把网页叫作半结构化数据，是因为它本身是按照一定的规则来书写的。这个规则就是HTML 语法规范。我们依靠 HTML 标签来抽取网页中的文本信息。这个抽取的过程，大体可以分为两步。

第一步是去掉 JavaScript 代码、CSS 格式以及下拉框中的内容（因为下拉框在用户不操作的情况下，也是看不到的）。也就是<style></style>，<script></script>，<option></option>这三组标签之间的内容。我们可以利用 AC 自动机这种多模式串匹配算法，在网页这个大字符串中，一次性查找<style>, <script>, <option>这三个关键词。当找到某个关键词出现的位置之后，我们只需要依次往后遍历，直到对应结束标签（</style>, </script>, </option）为止。而这期间遍历到的字符串连带着标签就应该从网页中删除。

第二步是去掉所有 HTML 标签。这一步也是通过字符串匹配算法来实现的。过程跟第一步类似，我就不重复讲了。

2. 分词并创建临时索引
经过上面的处理之后，我们就从网页中抽取出了我们关心的文本信息。接下来，我们要对文本信息进行分词，并且创建临时索引。

对于英文网页来说，分词非常简单。我们只需要通过空格、标点符号等分隔符，将每个单词分割开来就可以了。但是，对于中文来说，分词就复杂太多了。我这里介绍一种比较简单的思路，基于字典和规则的分词方法。

其中，字典也叫词库，里面包含大量常用的词语（我们可以直接从网上下载别人整理好的）。我们借助词库并采用最长匹配规则，来对文本进行分词。所谓最长匹配，也就是匹配尽可能长的词语。我举个例子解释一下。

比如要分词的文本是“中国人民解放了”，我们词库中有“中国”“中国人”“中国人民”“中国人民解放军”这几个词，那我们就取最长匹配，也就是“中国人民”划为一个词，而不是把“中国”、“中国人“划为一个词。具体到实现层面，我们可以将词库中的单词，构建成 Trie 树结构，然后拿网页文本在 Trie 树中匹配。

每个网页的文本信息在分词完成之后，我们都得到一组单词列表。我们把单词与网页之间的对应关系，写入到一个临时索引文件中（tmp_Index.bin），这个临时索引文件用来构建倒排索引文件。临时索引文件的格式如下：



在临时索引文件中，我们存储的是单词编号，也就是图中的 term_id，而非单词本身。这样做的目的主要是为了节省存储的空间。那这些单词的编号是怎么来的呢？

给单词编号的方式，跟给网页编号类似。我们维护一个计数器，每当从网页文本信息中分割出一个新的单词的时候，我们就从计数器中取一个编号，分配给它，然后计数器加一。

在这个过程中，我们还需要使用散列表，记录已经编过号的单词。在对网页文本信息分词的过程中，我们拿分割出来的单词，先到散列表中查找，如果找到，那就直接使用已有的编号；如果没有找到，我们再去计数器中拿号码，并且将这个新单词以及编号添加到散列表中。

当所有的网页处理（分词及写入临时索引）完成之后，我们再将这个单词跟编号之间的对应关系，写入到磁盘文件中，并命名为 term_id.bin。

经过分析阶段，我们得到了两个重要的文件。它们分别是临时索引文件（tmp_index.bin）和单词编号文件（term_id.bin）。

索引
索引阶段主要负责将分析阶段产生的临时索引，构建成倒排索引。倒排索引（ Inverted index）中记录了每个单词以及包含它的网页列表。文字描述比较难理解，我画了一张倒排索引的结构图，你一看就明白。



我们刚刚讲到，在临时索引文件中，记录的是单词跟每个包含它的文档之间的对应关系。那如何通过临时索引文件，构建出倒排索引文件呢？这是一个非常典型的算法问题，你可以先自己思考一下，再看我下面的讲解。

解决这个问题的方法有很多。考虑到临时索引文件很大，无法一次性加载到内存中，搜索引擎一般会选择使用多路归并排序的方法来实现。

我们先对临时索引文件，按照单词编号的大小进行排序。因为临时索引很大，所以一般基于内存的排序算法就没法处理这个问题了。我们可以用之前讲到的归并排序的处理思想，将其分割成多个小文件，先对每个小文件独立排序，最后再合并在一起。当然，实际的软件开发中，我们其实可以直接利用 MapReduce 来处理。

临时索引文件排序完成之后，相同的单词就被排列到了一起。我们只需要顺序地遍历排好序的临时索引文件，就能将每个单词对应的网页编号列表找出来，然后把它们存储在倒排索引文件中。具体的处理过程，我画成了一张图。通过图，你应该更容易理解。



除了倒排文件之外，我们还需要一个文件，来记录每个单词编号在倒排索引文件中的偏移位置。我们把这个文件命名为 term_offset.bin。这个文件的作用是，帮助我们快速地查找某个单词编号在倒排索引中存储的位置，进而快速地从倒排索引中读取单词编号对应的网页编号列表。



经过索引阶段的处理，我们得到了两个有价值的文件，它们分别是倒排索引文件（index.bin）和记录单词编号在索引文件中的偏移位置的文件（term_offset.bin）。

查询
前面三个阶段的处理，只是为了最后的查询做铺垫。因此，现在我们就要利用之前产生的几个文件，来实现最终的用户搜索功能。

doc_id.bin：记录网页链接和编号之间的对应关系。

term_id.bin：记录单词和编号之间的对应关系。

index.bin：倒排索引文件，记录每个单词编号以及对应包含它的网页编号列表。

term_offsert.bin：记录每个单词编号在倒排索引文件中的偏移位置。

这四个文件中，除了倒排索引文件（index.bin）比较大之外，其他的都比较小。为了方便快速查找数据，我们将其他三个文件都加载到内存中，并且组织成散列表这种数据结构。

当用户在搜索框中，输入某个查询文本的时候，我们先对用户输入的文本进行分词处理。假设分分词之后，我们得到 k 个单词。

我们拿这 k 个单词，去 term_id.bin 对应的散列表中，查找对应的单词编号。经过这个查询之后，我们得到了这 k 个单词对应的单词编号。

我们拿这 k 个单词编号，去 term_offset.bin 对应的散列表中，查找每个单词编号在倒排索引文件中的偏移位置。经过这个查询之后，我们得到了 k 个偏移位置。

我们拿这 k 个偏移位置，去倒排索引（index.bin）中，查找 k 个单词对应的包含它的网页编号列表。经过这一步查询之后，我们得到了 k 个网页编号列表。

我们针对这 k 个网页编号列表，统计每个网页编号出现的次数。具体到实现层面，我们可以借助散列表来进行统计。统计得到的结果，我们按照出现次数的多少，从小到大排序。出现次数越多，说明包含越多的用户查询单词（用户输入的搜索文本，经过分词之后的单词）。

经过这一系列查询，我们就得到了一组排好序的网页编号。我们拿着网页编号，去 doc_id.bin 文件中查找对应的网页链接，分页显示给用户就可以了。

总结引申
今天，我给你展示了一个小型搜索引擎的设计思路。这只是一个搜索引擎设计的基本原理，有很多优化、细节我们并未涉及，比如计算网页权重的PageRank算法、计算查询结果排名的tf-idf模型等等。

在讲解的过程中，我们涉及的数据结构和算法有：图、散列表、Trie 树、布隆过滤器、单模式字符串匹配算法、AC 自动机、广度优先遍历、归并排序等。如果对其中哪些内容不清楚，你可以回到对应的章节进行复习。

最后，如果有时间的话，我强烈建议你，按照我的思路，自己写代码实现一个简单的搜索引擎。这样写出来的，即便只是一个 demo，但对于你深入理解数据结构和算法，也是很有帮助的。

课后思考
图的遍历方法有两种，深度优先和广度优先。我们讲到，搜索引擎中的爬虫是通过广度优先策略来爬取网页的。搜索引擎为什么选择广度优先策略，而不是深度优先策略呢？

大部分搜索引擎在结果显示的时候，都支持摘要信息和网页快照。实际上，你只需要对我今天讲的设计思路，稍加改造，就可以支持这两项功能。你知道如何改造吗？

欢迎留言和我分享，也欢迎点击“请朋友读”，把今天的内容分享给你的好友，和他一起讨论、学习。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(27)

wei
思考题 1:

因为搜索引擎要优先爬取权重较高的页面，离种子网页越近，较大可能权重更高，广度优先更合适。

思考题 2:

摘要信息：
增加 summary.bin 和 summary_offset.bin。在抽取网页文本信息后，取出前 80-160 个字作为摘要，写入到 summary.bin，并将偏移位置写入到 summary_offset.bin。
summary.bin 格式：
doc_id \t summary_size \t summary \r\n\r\n
summary_offset.bin 格式：
doc_id \t offset \r\n
Google 搜索结果中显示的摘要是搜索词附近的文本。如果要实现这种效果，可以保存全部网页文本，构建搜索结果时，在网页文本中查找搜索词位置，截取搜索词附近文本。

网页快照：
可以把 doc_raw.bin 当作快照，增加 doc_raw_offset.bin 记录 doc_id 在 doc_raw.bin 中的偏移位置。
doc_raw_offset.bin 格式：
doc_id \t offset \r\n
2019-01-28


30

天凉好个秋
倒排索引中记录了每个单词以及包含它的网页列表，想问一下“倒排索引”这个名字是怎么来的？其中的“倒排”体现在哪里呢？
作者回复: 正排-》文档包含哪些单词
倒排-》单词被哪些文档包含

2019-01-28


21

Jerry银银
经过深入研究了一把，第一题终于有了比较清晰的答案：
从时间复杂度这个维度来考虑，BFS和DFS爬取互联网上所有的内容所需的时间是一样的。但是，我们设计爬虫系统的时候，不可能想着一次性爬完所有的网页，因为「量」太大了。所以，必须有一个优先级，不难想到：每一个网站的首页优先级最高，所以，我们肯定要先爬取每个网站的首页。从这一点出发，我们肯定要选取BFS。
但是，这里还有另外一个问题：如果我们爬完一个网站的首页之后，再爬取另外一个网站的首页，每次和不同网站服务器都要建立网络连接(TCP三次握手、HTTPs网站还要建立SSL握手等）都要花费大量的时间。如果总是按照BFS的策略来爬取，这中间花费的时间成本又太大了。所以，我想，中间肯定也是需要用DFS的。
我想到，可以使用一个优先级队列来维护需要爬取的网页。剩下的问题就是：该如何评估所需要爬取的网页的优先级呢？ 这个问题想了很久，依然不知道该如何计算机网页的优先级，难道这里也用PageRank类似的算法？
2019-01-30

1

7

纯洁的憎恶
搜集：将广度优先搜索的优先队列存储在磁盘文件links.bin（如何解析网页内的链接？），有布隆过滤器判重并定期写入磁盘文件bloom_filter.bin，将访问到的原始网页数据存入磁盘文件doc_raw.bin，计数分配网页编号并与其链接对应关系存入磁盘文件doc_id.bin。

分析：首先抽取网页文本信息，依据HTML语法规范，通过AC自动机多模式串匹配算法，去除网页中格式化部分，提取文本内容。然后分词并创建临时索引，分词的目的是找到能够标识网页文本“身份”的特征，可借助词库（通过Trie树实现）搜索文本中与词库匹配的最长词语，因为一般情况下越长信息越多，越剧有表征能力（为什么英文简单？）。分词完成后得到一组用于表征网页的单词列表，与其对应的网页编号存入磁盘文件tmp_index.bin作为临时索引，为节省空间单词是以单词编号的形式写入，单词文本与编号的对应关系写入磁盘文本term_id.bin。

索引：通过临时索引构建倒排索引文件index.bin。倒排索引其实是以单词为主键，将临时索引中的多个相同单词行合并为一行。通过以单词为主键的排序算法，可以将相同单词的行连续排列在一起，之后只要将单词相同的连续行合并为一行即可。由于数据量大，应采用分治策略。最后建立所有单词在倒排索引文件中位置的索引文件term_offset.bin，以方便快速查找。

查询：先对搜索条件文本做分词处理，然后去term_id.bin查单词们的编号，再查term_offset.bin找到单词们在倒排索引中的位置，到index.bin找到每个单词对应的网页编号，通过网页出现次数、预评权重和统计算法（如pagerank、tf-idf）计算网页的优先次序并输出。最后在doc_in.bin中找到网页链接按序输出显示给用户。

这样理解对不？
作者回复: 赞

2019-01-28


7

『LHCY』
作者讲的基本和elasticsearch原理查不多，可见有了算法基础以后了解一些中间件原理会容易很多，我最开始看es原理时一脸懵逼。
2019-01-28


4

feifei
感谢争哥的分享，我按照你这个思路，使用java语言，将这个搜索引擎的代码实现了出来，现在我也分享给大家，希望对那些希望实现搜索引擎，遇到了问题，却又不知道如何解决的童鞋，有所帮助，我的github地址: https://github.com/kkzfl22/searchEngine.git
2019-07-15


3

alic
有没有代码实现的例子？
作者回复: 木有。等我有空了可以写下分享出来。

2019-01-28


3

往事随风，顺其自然
可以讲讲到排序索引和普通索引区别？
作者回复: 啥事排序索引和普通索引呢？我文中好像没讲到呢

2019-01-29


2

ub8
elasticsearch
2019-08-02


1

醉比
王老师，很惭愧在前一阵子落下了这门课程，平心而论您的课程真的是太优秀了，从我的角度来说真的极大地提升的见世面与知识基础。虽然停滞了很长一段时间没有学习，但我很相信这门课程是可以陪伴我很久然后学习两遍到三遍的，已经关注老师的公众号， 希望继续产出高质量的内容，祝好~
2019-03-14


1

王肖武
思考题1:深度优化借助栈这种数据结构，网页的深度是不可预测的，如果很深，栈大小会很大，内存可能会爆掉。
2019-01-29


1

小美
王老师，字典使用最长匹配？那例子中的”中国“”中国人“不就无法匹配到了吗
作者回复: 在这个例子中是的。“中国人好样的”这个句子分词就可以匹配到“中国人”

2019-01-28


1

Lukia
老师好，本文中好像没有看到ac自动机的应用
作者回复: 哦哦哦 你的意思是搜索引擎会用到ac自动机是吧

2019-09-01



Leon📷
毕业设计就是做的搜索引擎，十万个本地文档构建的倒排索引，不过我的倒排索引直接用单词了，没有编号，用开源库分词，实现了tf-idf和文档之间相似度的计算，用动态规划来实现文本纠错，可以纠正用户的搜索框的错误输入，用到的数据结构不多，主要是哈希表和vector，用内存缓存查询结果，不知道算不算快照，哈，离老师讲的似乎只有分布式爬虫和临时索引的合并没有实现，
https://github.com/chawlau/search_engine，其他人看了不要喷我
2019-08-27



Paul Shan
思考题2
网页的快照和摘要可以按照docId 存起来，查找的时候一块找。
2019-08-09



Paul Shan
思考题1
深度优先有以下问题
重要的网站遍历不全（假设网站和主要网站的距离越近越重要）
域名一样的网页没有一起下载，不利于缓存。
2019-08-09



xuesong Zhang
爬虫按照广度优先的策略，不停地从队列中取出链接，然后“取“ -> “去“ 爬取对应的网页，解析出网页里包含的其他网页链接，再将解析出来的链接添加到队列中。
上面这段话里面有个词不是很通， 不知道后面还能修正么。
作者回复: 编辑，麻烦修改下错别字，多谢。

2019-04-17



Jeson
如果可以，希望作者能整理下您那个5w+行的代码开源分享，或者推荐个不错的代码demo。
2019-03-22



超威丶
请问倒排索引这种结构比b树快是不是依赖于它的数据结构优势？
作者回复: 是的，两个东西的应用场景不大一样的。

2019-03-07



Kudo
原理是看懂了，实现起来肯定会遇到各种各样的问题，手动实现一遍是有必要的，如果老师能提供一个参考代码就更好了。
作者回复: 这个写起来比较多，我有个5万+行的C++代码，估计看起来也比较费劲！你还是自己写吧：）

2019-01-29


收起评论

2786





# 54 | 算法实战（三）：剖析高性能队列Disruptor背后的数据结构和算法



数据结构与算法之美
王争
前Google工程师
查看详情
59587 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

入门篇 (4讲)

基础篇 (38讲)

高级篇 (9讲)

43 | 拓扑排序：如何确定代码源文件的编译依赖关系？
44 | 最短路径：地图软件是如何计算出最优出行路径的？
45 | 位图：如何实现网页爬虫中的URL去重功能？
46 | 概率统计：如何利用朴素贝叶斯算法过滤垃圾短信？
47 | 向量空间：如何实现一个简单的音乐推荐系统？
48 | B+树：MySQL数据库索引是如何实现的？
49 | 搜索：如何用A*搜索算法实现游戏中的寻路功能？
50 | 索引：如何在海量数据中快速查找某个数据？
51 | 并行算法：如何利用并行处理提高算法的执行效率？
实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



54 | 算法实战（三）：剖析高性能队列Disruptor背后的数据结构和算法
王争 2019-01-30



11:59
讲述：修阳 大小：10.99M
Disruptor 你是否听说过呢？它是一种内存消息队列。从功能上讲，它其实有点儿类似 Kafka。不过，和 Kafka 不同的是，Disruptor 是线程之间用于消息传递的队列。它在 Apache Storm、Camel、Log4j 2 等很多知名项目中都有广泛应用。

之所以如此受青睐，主要还是因为它的性能表现非常优秀。它比 Java 中另外一个非常常用的内存消息队列 ArrayBlockingQueue（ABS）的性能，要高一个数量级，可以算得上是最快的内存消息队列了。它还因此获得过 Oracle 官方的 Duke 大奖。

如此高性能的内存消息队列，在设计和实现上，必然有它独到的地方。今天，我们就来一块儿看下，Disruptor 是如何做到如此高性能的？其底层依赖了哪些数据结构和算法？

基于循环队列的“生产者 - 消费者模型”
什么是内存消息队列？对很多业务工程师或者前端工程师来说，可能会比较陌生。不过，如果我说“生产者 - 消费者模型”，估计大部分人都知道。在这个模型中，“生产者”生产数据，并且将数据放到一个中心存储容器中。之后，“消费者”从中心存储容器中，取出数据消费。

这个模型非常简单、好理解，那你有没有思考过，这里面存储数据的中心存储容器，是用什么样的数据结构来实现的呢？

实际上，实现中心存储容器最常用的一种数据结构，就是我们在第 9 节讲的队列。队列支持数据的先进先出。正是这个特性，使得数据被消费的顺序性可以得到保证，也就是说，早被生产的数据就会早被消费。

我们在第 9 节讲过，队列有两种实现思路。一种是基于链表实现的链式队列，另一种是基于数组实现的顺序队列。不同的需求背景下，我们会选择不同的实现方式。

如果我们要实现一个无界队列，也就是说，队列的大小事先不确定，理论上可以支持无限大。这种情况下，我们适合选用链表来实现队列。因为链表支持快速地动态扩容。如果我们要实现一个有界队列，也就是说，队列的大小事先确定，当队列中数据满了之后，生产者就需要等待。直到消费者消费了数据，队列有空闲位置的时候，生产者才能将数据放入。

实际上，相较于无界队列，有界队列的应用场景更加广泛。毕竟，我们的机器内存是有限的。而无界队列占用的内存数量是不可控的。对于实际的软件开发来说，这种不可控的因素，就会有潜在的风险。在某些极端情况下，无界队列就有可能因为内存持续增长，而导致 OOM（Out of Memory）错误。

在第 9 节中，我们还讲过一种特殊的顺序队列，循环队列。我们讲过，非循环的顺序队列在添加、删除数据的工程中，会涉及数据的搬移操作，导致性能变差。而循环队列正好可以解决这个数据搬移的问题，所以，性能更加好。所以，大部分用到顺序队列的场景中，我们都选择用顺序队列中的循环队列。

实际上，循环队列这种数据结构，就是我们今天要讲的内存消息队列的雏形。我借助循环队列，实现了一个最简单的“生产者 - 消费者模型”。对应的代码我贴到这里，你可以看看。

为了方便你理解，对于生产者和消费者之间操作的同步，我并没有用到线程相关的操作。而是采用了“当队列满了之后，生产者就轮训等待；当队列空了之后，消费者就轮训等待”这样的措施。

public class Queue {
  private Long[] data;
  private int size = 0, head = 0, tail = 0;
  public Queue(int size) {
    this.data = new Long[size];
    this.size = size;
  }
 
  public boolean add(Long element) {
    if ((tail + 1) % size == head) return false;
    data[tail] = element;
    tail = (tail + 1) % size;
    return true;
  }
 
  public Long poll() {
    if (head == tail) return null;
    long ret = data[head];
    head = (head + 1) % size;
    return ret;
  }
}
 
public class Producer {
  private Queue queue;
  public Producer(Queue queue) {
    this.queue = queue;
  }
 
  public void produce(Long data) throws InterruptedException {
    while (!queue.add(data)) {
      Thread.sleep(100);
    }
  }
}
 
public class Consumer {
  private Queue queue;
  public Consumer(Queue queue) {
    this.queue = queue;
  }
 
  public void comsume() throws InterruptedException {
    while (true) {
      Long data = queue.poll();
      if (data == null) {
        Thread.sleep(100);
      } else {
        // TODO:... 消费数据的业务逻辑...
      }
    }
  }
}
基于加锁的并发“生产者 - 消费者模型”
实际上，刚刚的“生产者 - 消费者模型”实现代码，是不完善的。为什么这么说呢？

如果我们只有一个生产者往队列中写数据，一个消费者从队列中读取数据，那上面的代码是没有问题的。但是，如果有多个生产者在并发地往队列中写入数据，或者多个消费者并发地从队列中消费数据，那上面的代码就不能正确工作了。我来给你讲讲为什么。

在多个生产者或者多个消费者并发操作队列的情况下，刚刚的代码主要会有下面两个问题：

多个生产者写入的数据可能会互相覆盖；

多个消费者可能会读取重复的数据。

因为第一个问题和第二个问题产生的原理是类似的。所以，我着重讲解第一个问题是如何产生的以及该如何解决。对于第二个问题，你可以类比我对第一个问题的解决思路自己来想一想。

两个线程同时往队列中添加数据，也就相当于两个线程同时执行类 Queue 中的 add() 函数。我们假设队列的大小 size 是 10，当前的 tail 指向下标 7，head 指向下标 3，也就是说，队列中还有空闲空间。这个时候，线程 1 调用 add() 函数，往队列中添加一个值为 12 的数据；线程 2 调用 add() 函数，往队列中添加一个值为 15 的数据。在极端情况下，本来是往队列中添加了两个数据（12 和 15），最终可能只有一个数据添加成功，另一个数据会被覆盖。这是为什么呢？



为了方便你查看队列 Queue 中的 add() 函数，我把它从上面的代码中摘录出来，贴在这里。

public boolean add(Long element) {
  if ((tail + 1) % size == head) return false;
  data[tail] = element;
  tail = (tail + 1) % size;
  return true;
}
从这段代码中，我们可以看到，第 3 行给 data[tail] 赋值，然后第 4 行才给 tail 的值加一。赋值和 tail 加一两个操作，并非原子操作。这就会导致这样的情况发生：当线程 1 和线程 2 同时执行 add() 函数的时候，线程 1 先执行完了第 3 行语句，将 data[7]（tail 等于 7）的值设置为 12。在线程 1 还未执行到第 4 行语句之前，也就是还未将 tail 加一之前，线程 2 执行了第 3 行语句，又将 data[7] 的值设置为 15，也就是说，那线程 2 插入的数据覆盖了线程 1 插入的数据。原本应该插入两个数据（12 和 15）的，现在只插入了一个数据（15）。



那如何解决这种线程并发往队列中添加数据时，导致的数据覆盖、运行不正确问题呢？

最简单的处理方法就是给这段代码加锁，同一时间只允许一个线程执行 add() 函数。这就相当于将这段代码的执行，由并行改成了串行，也就不存在我们刚刚说的问题了。

不过，天下没有免费的午餐，加锁将并行改成串行，必然导致多个生产者同时生产数据的时候，执行效率的下降。当然，我们可以继续优化代码，用CAS（compare and swap，比较并交换）操作等减少加锁的粒度，但是，这不是我们这节的重点。我们直接看 Disruptor 的处理方法。

基于无锁的并发“生产者 - 消费者模型”
尽管 Disruptor 的源码读起来很复杂，但是基本思想其实非常简单。实际上，它是换了一种队列和“生产者 - 消费者模型”的实现思路。

之前的实现思路中，队列只支持两个操作，添加数据和读取并移除数据，分别对应代码中的 add() 函数和 poll() 函数，而 Disruptor 采用了另一种实现思路。

对于生产者来说，它往队列中添加数据之前，先申请可用空闲存储单元，并且是批量地申请连续的 n 个（n≥1）存储单元。当申请到这组连续的存储单元之后，后续往队列中添加元素，就可以不用加锁了，因为这组存储单元是这个线程独享的。不过，从刚刚的描述中，我们可以看出，申请存储单元的过程是需要加锁的。

对于消费者来说，处理的过程跟生产者是类似的。它先去申请一批连续可读的存储单元（这个申请的过程也是需要加锁的），当申请到这批存储单元之后，后续的读取操作就可以不用加锁了。

不过，还有一个需要特别注意的地方，那就是，如果生产者 A 申请到了一组连续的存储单元，假设是下标为 3 到 6 的存储单元，生产者 B 紧跟着申请到了下标是 7 到 9 的存储单元，那在 3 到 6 没有完全写入数据之前，7 到 9 的数据是无法读取的。这个也是 Disruptor 实现思路的一个弊端。

文字描述不好理解，我画了一个图，给你展示一下这个操作过程。



实际上，Disruptor 采用的是 RingBuffer 和 AvailableBuffer 这两个结构，来实现我刚刚讲的功能。不过，因为我们主要聚焦在数据结构和算法上，所以我对这两种结构做了简化，但是基本思想是一致的。如果你对 Disruptor 感兴趣，可以去阅读一下它的源码。

总结引申
今天，我讲了如何实现一个高性能的并发队列。这里的“并发”两个字，实际上就是多线程安全的意思。

常见的内存队列往往采用循环队列来实现。这种实现方法，对于只有一个生产者和一个消费者的场景，已经足够了。但是，当存在多个生产者或者多个消费者的时候，单纯的循环队列的实现方式，就无法正确工作了。

这主要是因为，多个生产者在同时往队列中写入数据的时候，在某些情况下，会存在数据覆盖的问题。而多个消费者同时消费数据，在某些情况下，会存在消费重复数据的问题。

针对这个问题，最简单、暴力的解决方法就是，对写入和读取过程加锁。这种处理方法，相当于将原来可以并行执行的操作，强制串行执行，相应地就会导致操作性能的下降。

为了在保证逻辑正确的前提下，尽可能地提高队列在并发情况下的性能，Disruptor 采用了“两阶段写入”的方法。在写入数据之前，先加锁申请批量的空闲存储单元，之后往队列中写入数据的操作就不需要加锁了，写入的性能因此就提高了。Disruptor 对消费过程的改造，跟对生产过程的改造是类似的。它先加锁申请批量的可读取的存储单元，之后从队列中读取数据的操作也就不需要加锁了，读取的性能因此也就提高了。

你可能会觉得这个优化思路非常简单。实际上，不管架构设计还是产品设计，往往越简单的设计思路，越能更好地解决问题。正所谓“大道至简”，就是这个意思。

课后思考
为了提高存储性能，我们往往通过分库分表的方式设计数据库表。假设我们有 8 张表用来存储用户信息。这个时候，每张用户表中的 ID 字段就不能通过自增的方式来产生了。因为这样的话，就会导致不同表之间的用户 ID 值重复。

为了解决这个问题，我们需要实现一个 ID 生成器，可以为所有的用户表生成唯一的 ID 号。那现在问题是，如何设计一个高性能、支持并发的、能够生成全局唯一 ID 的 ID 生成器呢？

欢迎留言和我分享，也欢迎点击“请朋友读”，把今天的内容分享给你的好友，和他一起讨论、学习。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(41)

Smallfly
没有读过 Disruptor 的源码，从老师的文章理解，一个线程申请了一组存储空间，如果这组空间还没有被完全填满之前，另一个线程又进来，在这组空间之后申请空间并添加数据，之后第一组空间又继续填充数据，那在消费时如何保证队列是按照添加顺序读取的呢？

即使控制读取时前面不能有空闲空间，是为了保证能按内存空间顺序消费，但是如果生产的时候没有保证顺序存储，似乎就不满足队列的条件了。
2019-01-30

1

16

老杨同志
尝试回答老师的思考题

1）分库分表也可以使用自增主键，可以设置增加的步长。8台机器分别从1、2、3。。开始，步长8.
     从1开始的下一个id是9，与其他的不重复就可以了。
2）上面同学说的redis或者zk应该也能生成自增主键，不过他们的写性能可能不能支持真正的高并发。
3）开放独立的id生成服务。最有名的算法应该是snowflake吧。snowflake的好处是基本有序，每秒钟可以生成很大的量，容易水平扩展。
    也可以把今天的disrupt用上，用自己生成id算法，提前生成id存入disrupt，预估一下峰值时业务需要的id量，比如提前生成50万；
2019-01-30


10

想当上帝的司机
为什么3到6没有完全写入前，7到9无法读取，不是两个写入操作吗
2019-01-30

5

10

Keep-Moving
思考题：加锁批量生成ID，使用时就不用加锁了
2019-01-30


7

彳
disruptor使用环的数据结构，内存连续，初始化时就申请并设置对象，将原本队列的头尾节点锁的争用转化为cas操作，并利用Java对象填充，解决cache line伪共享问题
2019-02-23


5

xuery
项目中有使用过分布式id生成器，但是不知道具体是怎么实现的，参考今天的Disruptor的思路：
1. id生成器相当于一个全局的生产者，可以提前生成一批id
2. 对于每一张表，可以类似于Disruptor的消费者思路，从id生成器中申请一批id，用作当前表的id使用，当然申请一批id对于id生成器来说是需要加锁操作的
2019-04-11

1

3

且听疯吟
__sync_fetch_and_add操作即可实现原子自增的操作。
2019-03-20


3

阳仔
后面有补充这门课的内容吗？我看到老师回复说会补充，为何没有在评论区中反馈呢？对后面学习这门课的学生很困惑啊

“生产者申请连续空间后，后续往队列添加元素就不需要加锁了，因为这个存储单元是这个线程独享的”

这个不好理解，添加元素的不是有可能多个线程吗？那不是会产生竞争资源吗？

希望得到解惑

2019-05-31


1

futute
弱弱地问一下，后来老师补充过这节课的内容吗？我看完后，跟以前留言的同学有相同的感觉。
2019-04-12


1

QQ怪
雪花算法可以根据不同机子生成不同的id
2019-03-08


1

belongcai蔡炳榕
看完还是有很多困惑（可能跟我不了解线程安全有关）
一是申请一段连续存储空间，怎么成为线程独享的呢？生产者ab分别申请后，消费者为啥无法跨区域读取呢
二是这种方法应该是有实验证明效率高的，私下去了解下。
作者回复: 这节课我抽空再补充下。不好意思。

2019-01-30

1

1

神盾局闹别扭
有个问题，按照老师所说，a线程只写1-3区块，b线程只写4-6块，假设a线程先写了块1，切换到线程b，b写块4，然后再切回线程a，a写块2。虽然没有数据覆盖问题，但是最终块1-6的顺序不是按写入先后顺序排布的，读取不是乱套了吗，怎么解决这个问题？求老师能说的详细点。
2019-01-30


1

Leon📷
zmq的内存池机制和批量读取和写入跟这个队列机制很相似，都是提前申请内存。不过zmq只有一个读线程和一个写线程，通过一个读指针r和写指针w还有一个原子操作的指针c和刷新指针f来控制，写指针一直批量写，不用关心内存是否分配，底层来接管内存分配，读指针一直用CAS来检查状态，写指针写好了，修改下w和f和c，然后读线程检查到这些指针和状态的变更，刷的一下全读出来了，我想问的是Disruptor 应该还有类似内存池的机制吧
2019-08-29



NeilMatthew
如果多个读线程到处消费数据，那么写线程如何再到这个循环队列里面申请连续的内存块呢
2019-08-28



DY
Disruptor的限制应该比较多吧，队列应该是无序的，对于充值投资这样的应该处理不了
2019-08-06



track
本质应该是吧每次操作都需要申请锁，改为了多次操作申请一次锁。减少了操作同一个空间的可能性
2019-08-01



小予
一个线程一次读取n个元素，那另外一个线程想要读取元素时，必须等前一个线程的n个元素读取完，本质上读取还是单线程的，不明白这样为何能提高性能，希望老师能解释一下其原理。🙏🙏
作者回复: 不用等的，可以直接读取后面的n个

2019-07-30



Geek_54edc1
思考题，ID生成器可以看做一个“生产者-消费者”模型的循环队列，与Disruptor的思路类似
2019-06-02



www.xnsms.com小鸟接码
感觉这个限流用的环形队列，又回到了上一节讲disrupter队列的问题一样，接口肯定是多线程，多个线程同时在往队列生产和消费，会出现生产和消费冲突，还是要解决这个问题……哈哈
2019-05-15



Geek_c33c8e
老师，线程池的实现是单个线程往队列插入任务，单个线程去队列去任务吗，所以不会处理并发控制吗
作者回复: 这里讲的时候没涉及并发问题，实际上会有的

2019-04-13


收起评论

4155





# 55 | 算法实战（四）：剖析微服务接口鉴权限流背后的数据结构和算法




数据结构与算法之美
王争
前Google工程师
查看详情
59587 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

入门篇 (4讲)

基础篇 (38讲)

高级篇 (9讲)

43 | 拓扑排序：如何确定代码源文件的编译依赖关系？
44 | 最短路径：地图软件是如何计算出最优出行路径的？
45 | 位图：如何实现网页爬虫中的URL去重功能？
46 | 概率统计：如何利用朴素贝叶斯算法过滤垃圾短信？
47 | 向量空间：如何实现一个简单的音乐推荐系统？
48 | B+树：MySQL数据库索引是如何实现的？
49 | 搜索：如何用A*搜索算法实现游戏中的寻路功能？
50 | 索引：如何在海量数据中快速查找某个数据？
51 | 并行算法：如何利用并行处理提高算法的执行效率？
实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



55 | 算法实战（四）：剖析微服务接口鉴权限流背后的数据结构和算法
王争 2019-02-01



15:47
讲述：修阳 大小：14.46M
微服务是最近几年才兴起的概念。简单点讲，就是把复杂的大应用，解耦拆分成几个小的应用。这样做的好处有很多。比如，这样有利于团队组织架构的拆分，毕竟团队越大协作的难度越大；再比如，每个应用都可以独立运维，独立扩容，独立上线，各个应用之间互不影响。不用像原来那样，一个小功能上线，整个大应用都要重新发布。

不过，有利就有弊。大应用拆分成微服务之后，服务之间的调用关系变得更复杂，平台的整体复杂熵升高，出错的概率、debug 问题的难度都高了好几个数量级。所以，为了解决这些问题，服务治理便成了微服务的一个技术重点。

所谓服务治理，简单点讲，就是管理微服务，保证平台整体正常、平稳地运行。服务治理涉及的内容比较多，比如鉴权、限流、降级、熔断、监控告警等等。这些服务治理功能的实现，底层依赖大量的数据结构和算法。今天，我就拿其中的鉴权和限流这两个功能，来带你看看，它们的实现过程中都要用到哪些数据结构和算法。

鉴权背景介绍
以防你之前可能对微服务没有太多了解，所以我对鉴权的背景做了简化。

假设我们有一个微服务叫用户服务（User Service）。它提供很多用户相关的接口，比如获取用户信息、注册、登录等，给公司内部的其他应用使用。但是，并不是公司内部所有应用，都可以访问这个用户服务，也并不是每个有访问权限的应用，都可以访问用户服务的所有接口。

我举了一个例子给你讲解一下，你可以看我画的这幅图。这里面，只有 A、B、C、D 四个应用可以访问用户服务，并且，每个应用只能访问用户服务的部分接口。



要实现接口鉴权功能，我们需要事先将应用对接口的访问权限规则设置好。当某个应用访问其中一个接口的时候，我们就可以拿应用的请求 URL，在规则中进行匹配。如果匹配成功，就说明允许访问；如果没有可以匹配的规则，那就说明这个应用没有这个接口的访问权限，我们就拒绝服务。

如何实现快速鉴权？
接口的格式有很多，有类似 Dubbo 这样的 RPC 接口，也有类似 Spring Cloud 这样的 HTTP 接口。不同接口的鉴权实现方式是类似的，我这里主要拿 HTTP 接口给你讲解。

鉴权的原理比较简单、好理解。那具体到实现层面，我们该用什么数据结构来存储规则呢？用户请求 URL 在规则中快速匹配，又该用什么样的算法呢？

实际上，不同的规则和匹配模式，对应的数据结构和匹配算法也是不一样的。所以，关于这个问题，我继续细化为三个更加详细的需求给你讲解。

1. 如何实现精确匹配规则？
我们先来看最简单的一种匹配模式。只有当请求 URL 跟规则中配置的某个接口精确匹配时，这个请求才会被接受、处理。为了方便你理解，我举了一个例子，你可以看一下。



不同的应用对应不同的规则集合。我们可以采用散列表来存储这种对应关系。我这里着重讲下，每个应用对应的规则集合，该如何存储和匹配。

针对这种匹配模式，我们可以将每个应用对应的权限规则，存储在一个字符串数组中。当用户请求到来时，我们拿用户的请求 URL，在这个字符串数组中逐一匹配，匹配的算法就是我们之前学过的字符串匹配算法（比如 KMP、BM、BF 等）。

规则不会经常变动，所以，为了加快匹配速度，我们可以按照字符串的大小给规则排序，把它组织成有序数组这种数据结构。当要查找某个 URL 能否匹配其中某条规则的时候，我们可以采用二分查找算法，在有序数组中进行匹配。

而二分查找算法的时间复杂度是 O(logn)（n 表示规则的个数），这比起时间复杂度是 O(n) 的顺序遍历快了很多。对于规则中接口长度比较长，并且鉴权功能调用量非常大的情况，这种优化方法带来的性能提升还是非常可观的 。

2. 如何实现前缀匹配规则？
我们再来看一种稍微复杂的匹配模式。只要某条规则可以匹配请求 URL 的前缀，我们就说这条规则能够跟这个请求 URL 匹配。同样，为了方便你理解这种匹配模式，我还是举一个例子说明一下。



不同的应用对应不同的规则集合。我们采用散列表来存储这种对应关系。我着重讲一下，每个应用的规则集合，最适合用什么样的数据结构来存储。

在Trie 树那节，我们讲到，Trie 树非常适合用来做前缀匹配。所以，针对这个需求，我们可以将每个用户的规则集合，组织成 Trie 树这种数据结构。

不过，Trie 树中的每个节点不是存储单个字符，而是存储接口被“/”分割之后的子目录（比如“/user/name”被分割为“user”“name”两个子目录）。因为规则并不会经常变动，所以，在 Trie 树中，我们可以把每个节点的子节点们，组织成有序数组这种数据结构。当在匹配的过程中，我们可以利用二分查找算法，决定从一个节点应该跳到哪一个子节点。



3. 如何实现模糊匹配规则？
如果我们的规则更加复杂，规则中包含通配符，比如“**”表示匹配任意多个子目录，“*”表示匹配任意一个子目录。只要用户请求 URL 可以跟某条规则模糊匹配，我们就说这条规则适用于这个请求。为了方便你理解，我举一个例子来解释一下。



不同的应用对应不同的规则集合。我们还是采用散列表来存储这种对应关系。这点我们刚才讲过了，这里不再重复说了。我们着重看下，每个用户对应的规则集合，该用什么数据结构来存储？针对这种包含通配符的模糊匹配，我们又该使用什么算法来实现呢？

还记得我们在回溯算法那节讲的正则表达式的例子吗？我们可以借助正则表达式那个例子的解决思路，来解决这个问题。我们采用回溯算法，拿请求 URL 跟每条规则逐一进行模糊匹配。如何用回溯算法进行模糊匹配，这部分我就不重复讲了。你如果忘记了，可以回到相应章节复习一下。

不过，这个解决思路的时间复杂度是非常高的。我们需要拿每一个规则，跟请求 URL 匹配一遍。那有没有办法可以继续优化一下呢？

实际上，我们可以结合实际情况，挖掘出这样一个隐形的条件，那就是，并不是每条规则都包含通配符，包含通配符的只是少数。于是，我们可以把不包含通配符的规则和包含通配符的规则分开处理。

我们把不包含通配符的规则，组织成有序数组或者 Trie 树（具体组织成什么结构，视具体的需求而定，是精确匹配，就组织成有序数组，是前缀匹配，就组织成 Trie 树），而这一部分匹配就会非常高效。剩下的是少数包含通配符的规则，我们只要把它们简单存储在一个数组中就可以了。尽管匹配起来会比较慢，但是毕竟这种规则比较少，所以这种方法也是可以接受的。

当接收到一个请求 URL 之后，我们可以先在不包含通配符的有序数组或者 Trie 树中查找。如果能够匹配，就不需要继续在通配符规则中匹配了；如果不能匹配，就继续在通配符规则中查找匹配。

限流背景介绍
讲完了鉴权的实现思路，我们再来看一下限流。

所谓限流，顾名思义，就是对接口调用的频率进行限制。比如每秒钟不能超过 100 次调用，超过之后，我们就拒绝服务。限流的原理听起来非常简单，但它在很多场景中，发挥着重要的作用。比如在秒杀、大促、双 11、618 等场景中，限流已经成为了保证系统平稳运行的一种标配的技术解决方案。

按照不同的限流粒度，限流可以分为很多种类型。比如给每个接口限制不同的访问频率，或者给所有接口限制总的访问频率，又或者更细粒度地限制某个应用对某个接口的访问频率等等。

不同粒度的限流功能的实现思路都差不多，所以，我今天主要针对限制所有接口总的访问频率这样一个限流需求来讲解。其他粒度限流需求的实现思路，你可以自己思考。

如何实现精准限流？
最简单的限流算法叫固定时间窗口限流算法。这种算法是如何工作的呢？首先我们需要选定一个时间起点，之后每当有接口请求到来，我们就将计数器加一。如果在当前时间窗口内，根据限流规则（比如每秒钟最大允许 100 次访问请求），出现累加访问次数超过限流值的情况时，我们就拒绝后续的访问请求。当进入下一个时间窗口之后，计数器就清零重新计数。



这种基于固定时间窗口的限流算法的缺点是，限流策略过于粗略，无法应对两个时间窗口临界时间内的突发流量。这是怎么回事呢？我举一个例子给你解释一下。

假设我们的限流规则是，每秒钟不能超过 100 次接口请求。第一个 1s 时间窗口内，100 次接口请求都集中在最后 10ms 内。在第二个 1s 的时间窗口内，100 次接口请求都集中在最开始的 10ms 内。虽然两个时间窗口内流量都符合限流要求（≤100 个请求），但在两个时间窗口临界的 20ms 内，会集中有 200 次接口请求。固定时间窗口限流算法并不能对这种情况做限制，所以，集中在这 20ms 内的 200 次请求就有可能压垮系统。



为了解决这个问题，我们可以对固定时间窗口限流算法稍加改造。我们可以限制任意时间窗口（比如 1s）内，接口请求数都不能超过某个阈值（ 比如 100 次）。因此，相对于固定时间窗口限流算法，这个算法叫滑动时间窗口限流算法。

流量经过滑动时间窗口限流算法整形之后，可以保证任意一个 1s 的时间窗口内，都不会超过最大允许的限流值，从流量曲线上来看会更加平滑。那具体到实现层面，我们该如何来做呢？

我们假设限流的规则是，在任意 1s 内，接口的请求次数都不能大于 K 次。我们就维护一个大小为 K+1 的循环队列，用来记录 1s 内到来的请求。注意，这里循环队列的大小等于限流次数加一，因为循环队列存储数据时会浪费一个存储单元。

当有新的请求到来时，我们将与这个新请求的时间间隔超过 1s 的请求，从队列中删除。然后，我们再来看循环队列中是否有空闲位置。如果有，则把新请求存储在队列尾部（tail 指针所指的位置）；如果没有，则说明这 1 秒内的请求次数已经超过了限流值 K，所以这个请求被拒绝服务。

为了方便你理解，我举一个例子，给你解释一下。在这个例子中，我们假设限流的规则是，任意 1s 内，接口的请求次数都不能大于 6 次。



即便滑动时间窗口限流算法可以保证任意时间窗口内，接口请求次数都不会超过最大限流值，但是仍然不能防止，在细时间粒度上访问过于集中的问题。

比如我刚刚举的那个例子，第一个 1s 的时间窗口内，100 次请求都集中在最后 10ms 中，也就是说，基于时间窗口的限流算法，不管是固定时间窗口还是滑动时间窗口，只能在选定的时间粒度上限流，对选定时间粒度内的更加细粒度的访问频率不做限制。

实际上，针对这个问题，还有很多更加平滑的限流算法，比如令牌桶算法、漏桶算法等。如果感兴趣，你可以自己去研究一下。

总结引申
今天，我们讲解了跟微服务相关的接口鉴权和限流功能的实现思路。现在，我稍微总结一下。

关于鉴权，我们讲了三种不同的规则匹配模式。不管是哪种匹配模式，我们都可以用散列表来存储不同应用对应的不同规则集合。对于每个应用的规则集合的存储，三种匹配模式使用不同的数据结构。

对于第一种精确匹配模式，我们利用有序数组来存储每个应用的规则集合，并且通过二分查找和字符串匹配算法，来匹配请求 URL 与规则。对于第二种前缀匹配模式，我们利用 Trie 树来存储每个应用的规则集合。对于第三种模糊匹配模式，我们采用普通的数组来存储包含通配符的规则，通过回溯算法，来进行请求 URL 与规则的匹配。

关于限流，我们讲了两种限流算法，第一种是固定时间窗口限流算法，第二种是滑动时间窗口限流算法。对于滑动时间窗口限流算法，我们用了之前学习过的循环队列来实现。比起固定时间窗口限流算法，它对流量的整形效果更好，流量更加平滑。

从今天的学习中，我们也可以看出，对于基础架构工程师来说，如果不精通数据结构和算法，我们就很难开发出性能卓越的基础架构、中间件。这其实就体现了数据结构和算法的重要性。

课后思考
除了用循环队列来实现滑动时间窗口限流算法之外，我们是否还可以用其他数据结构来实现呢？请对比一下这些数据结构跟循环队列在解决这个问题时的优劣之处。

分析一下鉴权那部分内容中，前缀匹配算法的时间复杂度和空间复杂度。

最后，有个消息提前通知你一下。本节是专栏的倒数第二节课了，不知道学到现在，你掌握得怎么样呢？为了帮你复习巩固，做到真正掌握这些知识，我针对专栏涉及的数据结构和算法，精心编制了一套练习题。从正月初一到初七，每天发布一篇。你要做好准备哦！



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(27)

suke 置顶
老师能对限流相关的算法和数据结构多讲一讲么
作者回复: 这是我之前开源的限流框架，你可以看看，比较详细了。而且里面还有一篇我发到infoq上的文章，讲设计思路。
https://github.com/wangzheng0822/ratelimiter4j

2019-02-01


11

Billylin
春节还想着加福利，这是一种什么精神。
2019-02-01


19

xuery
1. 还可以采用双向链表，每次请求往链表尾插入一个时间，插入之前先从链表头删除一秒之前的节点，之后看下链表的size是否大于等于N，大于等于N则拒绝本次访问，否则允许本次访问并插入链表尾；占用的空间比循环链表要大
2. 假设有n个规则，每个规则的单词个数平均为m，则时间复杂度为O(m*logn), 空间复杂度O(n*m)
时间复杂度分析下：平均搜索m层，每一层最多有n个单词，由于是采用有序数组存储，查找时间复杂度为O(logn),所以总的时间复杂度为O(m*logn)
2019-04-11


6

Williamzhang
感觉限流的思想中可以参考一下tcp的拥塞控制算法
2019-02-19


5

Flash
思考题1：可以用优先级队列（根据请求时间构建小顶堆），最早的请求时间的放在堆顶。然后每次进来一个请求，就判断这个时间跟堆顶的时间差是否小于1S，并且堆的大小小于请求限制的次数，如果是就插入队列，如果不是，就限制。
2019-04-01


4

何欢
给老师点个赞，敬业精神值得学习，春节期间也是给自己充电的好时期，加油。
2019-02-01


3

付坤
思考题1
还可以使用一个固定大小的小顶堆，以时间戳作为排序依据。
每次有请求时相当于要在小顶堆内插入数据，如果堆顶数据的时间跟本次时间差距小于1s，且堆已满的情况下，不允许继续插入。每次插入数据的时候，删除1s外的数据，重新排序，确定新的堆顶。
不过感觉跟循环队列比，都是劣势；插入数据，删除数据，时间复杂度都要更高。而且每次删除数据后还要重新排序一遍确定新的堆顶。
2019-03-16


2

Monday
鉴权的精确匹配用散列表的时间复杂度是O(1)，比顺序匹配O(n)和二分查找的效率都高啊。为什么不选用呢？
作者回复: 小数据量的情况下，散列表在存储和匹配上并不一定比二分查找高呢

2019-02-15


2

青铜5 周群力
请教老师一个问题哈，为啥鉴权算法里，每个应用的规则要放到有序数组呢，放hash set会更好吧?
比如一个应用有两个规则:/user/a和/user/b，把这俩规则放hash set岂不是时间复杂度更低、更好呢
作者回复: hash set对于小数据量也不一定比有序数组效率高呢。毕竟hash set还要计算哈希值、处理冲突等。

2019-02-07


2

言希
老师用心了
2019-02-01


2

向羽
太棒了，给老师点赞👍
2019-02-01


2

Ray
读您的文章就是一种享受!!!
2019-02-01


2

陈华应
给老师点赞
2019-02-01


2

lianlian
哇，老师优秀又热心(✪▽✪)，期待老师的题目(๑˙ー˙๑)
2019-02-01


2

Tattoo
“不同的应用对应不同的规则集合。我们可以采用散列表来存储这种对。。。”，这里如果匹配规则很多的话，不会发生很多的冲突的吗？

作者回复: 散列表本身就有解决冲突的机制的

2019-06-11


1

xyf
想问下如何对接口做数据域权限检验。比如调用方有权限调用查询项目接口，但是对于请求参数，如项目ID，鉴权系统能够判断调用者是否有权限访问这个项目。
作者回复: 可以把参数拼到url中 或者重新设计鉴权规则

2019-04-04


1

Joker
期待老师的题目，最近也在刷LeetCode，结合的效果肯定好！！！
编辑回复: 哈哈 看来会给你惊喜了

2019-02-02


1

halo
一直跟着走，回头再看几遍，真心赞
2019-02-02


1

水果刀
立个flag，正月初一到正月初七每天都做老师的题……
2019-02-01


1

牧民牛仔
春节加餐，每天一份习题大礼包
2019-02-01


1
收起评论

2763






# 56 | 算法实战（五）：如何用学过的数据结构和算法实现一个短网址系统？



数据结构与算法之美
王争
前Google工程师
查看详情
59587 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

入门篇 (4讲)

基础篇 (38讲)

高级篇 (9讲)

43 | 拓扑排序：如何确定代码源文件的编译依赖关系？
44 | 最短路径：地图软件是如何计算出最优出行路径的？
45 | 位图：如何实现网页爬虫中的URL去重功能？
46 | 概率统计：如何利用朴素贝叶斯算法过滤垃圾短信？
47 | 向量空间：如何实现一个简单的音乐推荐系统？
48 | B+树：MySQL数据库索引是如何实现的？
49 | 搜索：如何用A*搜索算法实现游戏中的寻路功能？
50 | 索引：如何在海量数据中快速查找某个数据？
51 | 并行算法：如何利用并行处理提高算法的执行效率？
实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



56 | 算法实战（五）：如何用学过的数据结构和算法实现一个短网址系统？
王争 2019-02-04



15:16
讲述：修阳 大小：13.99M
短网址服务你用过吗？如果我们在微博里发布一条带网址的信息，微博会把里面的网址转化成一个更短的网址。我们只要访问这个短网址，就相当于访问原始的网址。比如下面这两个网址，尽管长度不同，但是都可以跳转到我的一个 GitHub 开源项目里。其中，第二个网址就是通过新浪提供的短网址服务生成的。

原始网址：https://github.com/wangzheng0822/ratelimiter4j
短网址：http://t.cn/EtR9QEG
从功能上讲，短网址服务其实非常简单，就是把一个长的网址转化成一个短的网址。作为一名软件工程师，你是否思考过，这样一个简单的功能，是如何实现的呢？底层都依赖了哪些数据结构和算法呢？

短网址服务整体介绍
刚刚我们讲了，短网址服务的一个核心功能，就是把原始的长网址转化成短网址。除了这个功能之外，短网址服务还有另外一个必不可少的功能。那就是，当用户点击短网址的时候，短网址服务会将浏览器重定向为原始网址。这个过程是如何实现的呢？

为了方便你理解，我画了一张对比图，你可以看下。



从图中我们可以看出，浏览器会先访问短网址服务，通过短网址获取到原始网址，再通过原始网址访问到页面。不过这部分功能并不是我们今天要讲的重点。我们重点来看，如何将长网址转化成短网址？

如何通过哈希算法生成短网址？
我们前面学过哈希算法。哈希算法可以将一个不管多长的字符串，转化成一个长度固定的哈希值。我们可以利用哈希算法，来生成短网址。

前面我们已经提过一些哈希算法了，比如 MD5、SHA 等。但是，实际上，我们并不需要这些复杂的哈希算法。在生成短网址这个问题上，毕竟，我们不需要考虑反向解密的难度，所以我们只需要关心哈希算法的计算速度和冲突概率。

能够满足这样要求的哈希算法有很多，其中比较著名并且应用广泛的一个哈希算法，那就是MurmurHash 算法。尽管这个哈希算法在 2008 年才被发明出来，但现在它已经广泛应用到 Redis、MemCache、Cassandra、HBase、Lucene 等众多著名的软件中。

MurmurHash 算法提供了两种长度的哈希值，一种是 32bits，一种是 128bits。为了让最终生成的短网址尽可能短，我们可以选择 32bits 的哈希值。对于开头那个 GitHub 网址，经过 MurmurHash 计算后，得到的哈希值就是 181338494。我们再拼上短网址服务的域名，就变成了最终的短网址 http://t.cn/181338494（其中，http://t.cn 是短网址服务的域名）。

1. 如何让短网址更短？
不过，你可能已经看出来了，通过 MurmurHash 算法得到的短网址还是很长啊，而且跟我们开头那个网址的格式好像也不一样。别着急，我们只需要稍微改变一个哈希值的表示方法，就可以轻松把短网址变得更短些。

我们可以将 10 进制的哈希值，转化成更高进制的哈希值，这样哈希值就变短了。我们知道，16 进制中，我们用 A～E，来表示 10～15。在网址 URL 中，常用的合法字符有 0～9、a～z、A～Z 这样 62 个字符。为了让哈希值表示起来尽可能短，我们可以将 10 进制的哈希值转化成 62 进制。具体的计算过程，我写在这里了。最终用 62 进制表示的短网址就是http://t.cn/cgSqq。



2. 如何解决哈希冲突问题？
不过，我们前面讲过，哈希算法无法避免的一个问题，就是哈希冲突。尽管 MurmurHash 算法，冲突的概率非常低。但是，一旦冲突，就会导致两个原始网址被转化成同一个短网址。当用户访问短网址的时候，我们就无从判断，用户想要访问的是哪一个原始网址了。这个问题该如何解决呢？

一般情况下，我们会保存短网址跟原始网址之间的对应关系，以便后续用户在访问短网址的时候，可以根据对应关系，查找到原始网址。存储这种对应关系的方式有很多，比如我们自己设计存储系统或者利用现成的数据库。前面我们讲到的数据库有 MySQL、Redis。我们就拿 MySQL 来举例。假设短网址与原始网址之间的对应关系，就存储在 MySQL 数据库中。

当有一个新的原始网址需要生成短网址的时候，我们先利用 MurmurHash 算法，生成短网址。然后，我们拿这个新生成的短网址，在 MySQL 数据库中查找。

如果没有找到相同的短网址，这也就表明，这个新生成的短网址没有冲突。于是我们就将这个短网址返回给用户（请求生成短网址的用户），然后将这个短网址与原始网址之间的对应关系，存储到 MySQL 数据库中。

如果我们在数据库中，找到了相同的短网址，那也并不一定说明就冲突了。我们从数据库中，将这个短网址对应的原始网址也取出来。如果数据库中的原始网址，跟我们现在正在处理的原始网址是一样的，这就说明已经有人请求过这个原始网址的短网址了。我们就可以拿这个短网址直接用。如果数据库中记录的原始网址，跟我们正在处理的原始网址不一样，那就说明哈希算法发生了冲突。不同的原始网址，经过计算，得到的短网址重复了。这个时候，我们该怎么办呢？

我们可以给原始网址拼接一串特殊字符，比如“[DUPLICATED]”，然后跟再重新计算哈希值，两次哈希计算都冲突的概率，显然是非常低的。假设出现非常极端的情况，又发生冲突了，我们可以再换一个拼接字符串，比如“[OHMYGOD]”，再计算哈希值。然后把计算得到的哈希值，跟原始网址拼接了特殊字符串之后的文本，一并存储在 MySQL 数据库中。

当用户访问短网址的时候，短网址服务先通过短网址，在数据库中查找到对应的原始网址。如果原始网址有拼接特殊字符（这个很容易通过字符串匹配算法找到），我们就先将特殊字符去掉，然后再将不包含特殊字符的原始网址返回给浏览器。

3. 如何优化哈希算法生成短网址的性能？
为了判断生成的短网址是否冲突，我们需要拿生成的短网址，在数据库中查找。如果数据库中存储的数据非常多，那查找起来就会非常慢，势必影响短网址服务的性能。那有没有什么优化的手段呢？

还记得我们之前讲的 MySQL 数据库索引吗？我们可以给短网址字段添加 B+ 树索引。这样通过短网址查询原始网址的速度就提高了很多。实际上，在真实的软件开发中，我们还可以通过一个小技巧，来进一步提高速度。

在短网址生成的过程中，我们会跟数据库打两次交道，也就是会执行两条 SQL 语句。第一个 SQL 语句是通过短网址查询短网址与原始网址的对应关系，第二个 SQL 语句是将新生成的短网址和原始网址之间的对应关系存储到数据库。

我们知道，一般情况下，数据库和应用服务（只做计算不存储数据的业务逻辑部分）会部署在两个独立的服务器或者虚拟服务器上。那两条 SQL 语句的执行就需要两次网络通信。这种 IO 通信耗时以及 SQL 语句的执行，才是整个短网址服务的性能瓶颈所在。所以，为了提高性能，我们需要尽量减少 SQL 语句。那又该如何减少 SQL 语句呢？

我们可以给数据库中的短网址字段，添加一个唯一索引（不止是索引，还要求表中不能有重复的数据）。当有新的原始网址需要生成短网址的时候，我们并不会先拿生成的短网址，在数据库中查找判重，而是直接将生成的短网址与对应的原始网址，尝试存储到数据库中。如果数据库能够将数据正常写入，那说明并没有违反唯一索引，也就是说，这个新生成的短网址并没有冲突。

当然，如果数据库反馈违反唯一性索引异常，那我们还得重新执行刚刚讲过的“查询、写入”过程，SQL 语句执行的次数不减反增。但是，在大部分情况下，我们把新生成的短网址和对应的原始网址，插入到数据库的时候，并不会出现冲突。所以，大部分情况下，我们只需要执行一条写入的 SQL 语句就可以了。所以，从整体上看，总的 SQL 语句执行次数会大大减少。

实际上，我们还有另外一个优化 SQL 语句次数的方法，那就是借助布隆过滤器。

我们把已经生成的短网址，构建成布隆过滤器。我们知道，布隆过滤器是比较节省内存的一种存储结构，长度是 10 亿的布隆过滤器，也只需要 125MB 左右的内存空间。

当有新的短网址生成的时候，我们先拿这个新生成的短网址，在布隆过滤器中查找。如果查找的结果是不存在，那就说明这个新生成的短网址并没有冲突。这个时候，我们只需要再执行写入短网址和对应原始网页的 SQL 语句就可以了。通过先查询布隆过滤器，总的 SQL 语句的执行次数减少了。

到此，利用哈希算法来生成短网址的思路，我就讲完了。实际上，这种解决思路已经完全满足需求了，我们已经可以直接用到真实的软件开发中。不过，我们还有另外一种短网址的生成算法，那就是利用自增的 ID 生成器来生成短网址。我们接下来就看一下，这种算法是如何工作的？对于哈希算法生成短网址来说，它又有什么优势和劣势？

如何通过 ID 生成器生成短网址？
我们可以维护一个 ID 自增生成器。它可以生成 1、2、3…这样自增的整数 ID。当短网址服务接收到一个原始网址转化成短网址的请求之后，它先从 ID 生成器中取一个号码，然后将其转化成 62 进制表示法，拼接到短网址服务的域名（比如http://t.cn/）后面，就形成了最终的短网址。最后，我们还是会把生成的短网址和对应的原始网址存储到数据库中。

理论非常简单好理解。不过，这里有几个细节问题需要处理。

1. 相同的原始网址可能会对应不同的短网址
每次新来一个原始网址，我们就生成一个新的短网址，这种做法就会导致两个相同的原始网址生成了不同的短网址。这个该如何处理呢？实际上，我们有两种处理思路。

第一种处理思路是不做处理。听起来有点无厘头，我稍微解释下你就明白了。实际上，相同的原始网址对应不同的短网址，这个用户是可以接受的。在大部分短网址的应用场景里，用户只关心短网址能否正确地跳转到原始网址。至于短网址长什么样子，他其实根本就不关心。所以，即便是同一个原始网址，两次生成的短网址不一样，也并不会影响到用户的使用。

第二种处理思路是借助哈希算法生成短网址的处理思想，当要给一个原始网址生成短网址的时候，我们要先拿原始网址在数据库中查找，看数据库中是否已经存在相同的原始网址了。如果数据库中存在，那我们就取出对应的短网址，直接返回给用户。

不过，这种处理思路有个问题，我们需要给数据库中的短网址和原始网址这两个字段，都添加索引。短网址上加索引是为了提高用户查询短网址对应的原始网页的速度，原始网址上加索引是为了加快刚刚讲的通过原始网址查询短网址的速度。这种解决思路虽然能满足“相同原始网址对应相同短网址”这样一个需求，但是是有代价的：一方面两个索引会占用更多的存储空间，另一方面索引还会导致插入、删除等操作性能的下降。

2. 如何实现高性能的 ID 生成器？
实现 ID 生成器的方法有很多，比如利用数据库自增字段。当然我们也可以自己维护一个计数器，不停地加一加一。但是，一个计数器来应对频繁的短网址生成请求，显然是有点吃力的（因为计数器必须保证生成的 ID 不重复，笼统概念上讲，就是需要加锁）。如何提高 ID 生成器的性能呢？关于这个问题，实际上，有很多解决思路。我这里给出两种思路。

第一种思路是借助第 54 节中讲的方法。我们可以给 ID 生成器装多个前置发号器。我们批量地给每个前置发号器发送 ID 号码。当我们接受到短网址生成请求的时候，就选择一个前置发号器来取号码。这样通过多个前置发号器，明显提高了并发发号的能力。



第二种思路跟第一种差不多。不过，我们不再使用一个 ID 生成器和多个前置发号器这样的架构，而是，直接实现多个 ID 生成器同时服务。为了保证每个 ID 生成器生成的 ID 不重复。我们要求每个 ID 生成器按照一定的规则，来生成 ID 号码。比如，第一个 ID 生成器只能生成尾号为 0 的，第二个只能生成尾号为 1 的，以此类推。这样通过多个 ID 生成器同时工作，也提高了 ID 生成的效率。



总结引申
今天，我们讲了短网址服务的两种实现方法。我现在来稍微总结一下。

第一种实现思路是通过哈希算法生成短网址。我们采用计算速度快、冲突概率小的 MurmurHash 算法，并将计算得到的 10 进制数，转化成 62 进制表示法，进一步缩短短网址的长度。对于哈希算法的哈希冲突问题，我们通过给原始网址添加特殊前缀字符，重新计算哈希值的方法来解决。

第二种实现思路是通过 ID 生成器来生成短网址。我们维护一个 ID 自增的 ID 生成器，给每个原始网址分配一个 ID 号码，并且同样转成 62 进制表示法，拼接到短网址服务的域名之后，形成最终的短网址。

课后思考
如果我们还要额外支持用户自定义短网址功能（http//t.cn/{用户自定部分}），我们又该如何改造刚刚的算法呢?

我们在讲通过 ID 生成器生成短网址这种实现思路的时候，讲到相同的原始网址可能会对应不同的短网址。针对这个问题，其中一个解决思路就是，不做处理。但是，如果每个请求都生成一个短网址，并且存储在数据库中，那这样会不会撑爆数据库呢？我们又该如何解决呢？

今天是农历的大年三十，我们专栏的正文到这里也就全部结束了。从明天开始，我会每天发布一篇练习题，内容针对专栏涉及的数据结构和算法。从初一到初七，帮你复习巩固所学知识，拿下数据结构和算法，打响新年进步的第一枪！明天见！



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(38)

Smallfly
随着新年的到来，我们的算法专栏也到了尾声。有点怀念那段时间工作不忙，一天能有好几个小时，阅读和思考算法专栏。

专栏给我带来的收获不仅仅是数据结构和算法的知识。在这之前虽然也每天学习，但总是东一块西一块，没有系统和脉络，一段时间之后，看似学了很多，但并没有什么效果。

在学习算法课程的过程中，基本都在学习和思考专栏的内容。一般第一天过一遍概念，一边阅读一边手敲。第二天会把重点放在思考上，为什么需要这种数据结构和算法，它的利弊是什么，以及解答思考题。

真正有收获的是思考和实践而不是阅读，阅读只是表象；如果只是阅读，也没有生字，会很轻松，但效果甚微。

这让我切身体会到系统和专注的重要性。

这种经历帮助我在实际工作中解决不少问题，不是说用到了哪种算法，而是在遇到问题时善于花时间去思考解决方案，而不是一味地寻找替代方案，把问题绕过去。

紧跟着老师的脚步学下来了，不能说都掌握了，但有几点学习的心得想跟大家分享。

1、迈出第一步。很多事情不是我们不会做，而是不想开始。一想到前面可能会有重重困难，思想上就先败下阵来了。只要开始一点点的弄懂，重在培养兴趣。

2、慢一点，不贪多。可能有同学落下很多课，看看还有这么多没学，干脆就放弃了。其实并不需要掌握所有的，可以挑选自己感兴趣的内容，细嚼慢咽，先掌握一部分。再从已知探索未知，其实文章之间很多是有关联的，学习过程中可能自个儿就串起来了。

3、多动手。阅读和思考还是远远不够的，带着文章的思路，用自己熟悉的语言实现一遍，跑起来测一测，会更有成就感，也是自己学习的痕迹。

虽然专栏学完了，然而有些内容很快就会忘记，后面我还会偶尔拿出来读一读，回顾一下思路。我现在已经欣然接受，学习的东西很快会遗忘，但回顾的时候会迅速地想起来，印象也更深刻了。

最后，祝王争老师和编辑小姐姐新年快乐，辛苦了。(´▽`ʃ♡ƪ)
2019-02-04


42

Sharry
问题一:
- 尝试将用户 自定义后的短网址 和 原网址的映射关系 存入数据库
  - 插入成功, 则提示用户短网址生成成功
  - 若插入失败, 说明存在冲突, 则进行判重处理
     - 若数据库中短网址对应的原网址与当前正在处理的相同, 提示该短网址有效
     - 若数据库中短网址对应的原网址与当前正在处理的不相同, 提示该短网址已被占用

问题二:
可以使用布隆过滤器进行判重验证, 通过之后再插入
2019-02-11


8

李
以前觉得数据结构和算法很难，学了之后，确实也难，但通过系统学习，心中有了一张完整的地图，以后只要不断反复看，反复学习，反复练习，一定能真正融合贯通。
另外，最大的感受是学了数据结构和算法后，看其它中间件和框架的源代码，发现大部分底层就是数据结构和算法。感觉练了九阳神功一样，学习其它功夫快了很多
2019-02-04


8

微秒
坚持到了最后，虽然只看不写，但也加深了对数据结构的认识，接下来刷第二遍的时候再加深代码实践。最后祝大家新年快乐！顺便说句，老师的这个专栏真的很良心，谢谢了！
2019-02-04


6

TryTs
兴趣是最好的老师，这话没有错。如果没有兴趣那就去找。就我个人看法，很多时候一开始不一定非要搞那么枯燥的东西，做一些有趣的东西，慢慢培养自己的兴趣，自己就会有好奇心去往深处学习，如果以来就弄那些很“艰深”的东西，可能不能坚持多久，“从入门到放弃”。学习老师这个专栏，我最大的收获就在于老师把平时课上那些算法讲活了，应用到具体场景之中，相较于一些为了练习而联系的习题，这让我更能体会到算法之美。也在不断激发我的好奇心。我希望自己能够一直抱持这份好奇心。继续努力学习。
2019-02-04


5

小美
王老师短网址有什么作用吗？ 我上网查了下理由不能说服我？
可能网上说得比较浅显，王老师方便指导下吗？
作者回复: 比如微博里，网址如果很长，看起来不美观。缩短成短网址之后，短短的，不占空间，不是更好看些吗：）

2019-02-09


3

.&#47;+-@YOU
第二题:id生成器，不处理，会导致相同的长域名重复。有个解决方案，长域名设置唯一的限制，在重复的情况下，插入表失败后，查询已经存在的长域名，对应的短域名。返回该短域名
2019-03-17


2

一涛
1. 首先查询“用户自定义部分”是否与已经生成的短网址冲突，如果冲突，只能提示用户进行修改。如果不冲突，将“用户自定义部分”和对应的原始网址写入数据库即可。

2. 给原始网址加唯一索引。如果写入异常，说明原始网址已经存在，再根据原始网址查询一次，取出短网址返回给用户。

不知道回答对不对，请老师指正
2019-02-04


2

xuery
追到这里，终于有底气在简历上写上一行熟悉各种数据结构与算了^_^.
感谢王争老师，下一步就是利用leetcode进一步提升自己的算法功底，
将熟悉变成精通
2019-04-11


1

wahaha
16进制应该是A到F(不是E)表示10到15，文字和朗读中都弄错了
2019-03-09


1

实验室清洁工
应该是16进制吧，62进制？？？
作者回复: 是的，62进制会更短些

2019-02-13

1

1

纯洁的憎恶
1.短网址的自定义部分是要展示给用户的。是否可以把自定义部分作为第三个字段存入数据库。如果不同用户对相同原网址申请短网址自定义部分不同。要么不允许这种行为，否则就得把自定义部分与原网址拼接输入哈希函数，以实现区分。
2019-02-07


1

纯洁的憎恶
通过哈希函数，在长网址字符串基础上，生成短网址哈希值。将哈希值从10进制提升至62进制，进一步缩短短网址长度。为了通过短网址回溯到原网址，需要建立长短网址的对应关系，存入数据库。

为了避免散列冲突，需要在在建立新的对应关系时，查询数据库中是否已有短网址，若有再检查长网址是否一致，若不一致则发生冲突，需要给新的长网址字符串加前缀，再用哈希函数生成短网址，直到没有冲突，最终将前缀、对应关系均存入数据库。

为方便查询，需要在数据库中建立短网址的索引（B+树）。减少SQL语句数量也可以提高性能，把查询+写入两条语句，简化为写入一条。代价是设置短网址唯一索引，不允许出现重复，这样当重复写入时数据库才会报错，此时再通过查询、前缀、写入的方式解决散列冲突。也可以针对短网址建立布隆过滤器，当新的短网址不在过滤器中则正常写入，否则通过查询判重并解决冲突。

另一种方式是通过全局计数器，给每个请求的原网址分配一个序号，作为短网址的主要部分。但它可能造成同一个原网址对应多个短网址的现象（虽然不影响应用体验）。为提高给号的并发性能，可以针对不同号段设置多个发号器并行发号。
2019-02-07


1

与非
最后一课在一年的最后一天结束，这也算辞旧迎新了吧～希望老师能在最后能出个课后思考题的总结～
2019-02-04


1

想当上帝的司机
用户自定义的，可以将用户的id拼接到hash前的网址上
2019-02-04


1

Geek_18b741
思考题1 支持用户自定义和我们使用62进制思路一致，看自定义规则能否将A-Z对应的字符和对应起来。
思考题2 可以使用lru的思想，将很久很久没人访问的短链接记录删除。
2019-08-27



Paul Shan
思考题2
对于不是非常关键的应用可以循环计数，某些以前用过的网址，长期不用可以重新利用。对于不能重复的场景，如果只加不删，可以用两张非关系型数据表来处理，例如dynamodb，这些简单的数据库扩张性良好，支持海量数据，只是关联查询比较弱，但是对于这个问题还是合适的。
2019-08-13



Paul Shan
思考题1
自定义部分作为特殊字符串加成网址的一部分处理，这样可以用短网址拿到整个网页和自定义字符串，后续再次看提供的自定义部分是否匹配数据库存储的这一块数据.
2019-08-13



菜鸡程序员
打个卡，终于看到最后了
2019-07-19



Fstar
哦豁，终于看到这里了（太慢悠悠了）。数据结构大部分都用 js 实现了，还有一些比较复杂的近期打算都实现了。这里给个github地址给大家参考参考：https://github.com/F-star/js-Data-Structures-and-Algorithms
2019-06-27


收起评论

3865






# 春节7天练 | Day 1：数组和链表



数据结构与算法之美
王争
前Google工程师
查看详情
59587 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

入门篇 (4讲)

基础篇 (38讲)

高级篇 (9讲)

43 | 拓扑排序：如何确定代码源文件的编译依赖关系？
44 | 最短路径：地图软件是如何计算出最优出行路径的？
45 | 位图：如何实现网页爬虫中的URL去重功能？
46 | 概率统计：如何利用朴素贝叶斯算法过滤垃圾短信？
47 | 向量空间：如何实现一个简单的音乐推荐系统？
48 | B+树：MySQL数据库索引是如何实现的？
49 | 搜索：如何用A*搜索算法实现游戏中的寻路功能？
50 | 索引：如何在海量数据中快速查找某个数据？
51 | 并行算法：如何利用并行处理提高算法的执行效率？
实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



春节7天练 | Day 1：数组和链表
王争 2019-02-04



01:39
讲述：修阳 大小：1.53M
你好，我是王争。首先祝你新年快乐！

专栏的正文部分已经结束，相信这半年的时间，你学到了很多，究竟学习成果怎样呢？

我整理了数据结构和算法中必知必会的 30 个代码实现，从今天开始，分 7 天发布出来，供你复习巩固所用。你可以每天花一点时间，来完成测验。测验完成后，你可以根据结果，回到相应章节，有针对性地进行复习。

除此之外，@Smallfly 同学还整理了一份配套的 LeetCode 练习题，你也可以一起练习一下。在此，我谨代表我本人对 @Smallfly 表示感谢！

另外，我还为假期坚持学习的同学准备了丰厚的春节加油礼包。

2 月 5 日 -2 月 14 日，只要在专栏文章下的留言区写下你的答案，参与答题，并且留言被精选，即可获得极客时间 10 元无门槛优惠券。

7 篇中的所有题目，只要回答正确 3 道及以上，即可获得极客时间 99 元专栏通用阅码。

如果 7 天连续参与答题，并且每天的留言均被精选，还可额外获得极客时间价值 365 元的每日一课年度会员。

关于数组和链表的几个必知必会的代码实现
数组
实现一个支持动态扩容的数组

实现一个大小固定的有序数组，支持动态增删改操作

实现两个有序数组合并为一个有序数组

链表
实现单链表、循环链表、双向链表，支持增删操作

实现单链表反转

实现两个有序的链表合并为一个有序链表

实现求链表的中间结点

对应的 LeetCode 练习题（@Smallfly 整理）
数组
Three Sum（求三数之和）
英文版：https://leetcode.com/problems/3sum/

中文版：https://leetcode-cn.com/problems/3sum/

Majority Element（求众数）
英文版：https://leetcode.com/problems/majority-element/

中文版：https://leetcode-cn.com/problems/majority-element/

Missing Positive（求缺失的第一个正数）
英文版：https://leetcode.com/problems/first-missing-positive/

中文版：https://leetcode-cn.com/problems/first-missing-positive/

链表
Linked List Cycle I（环形链表）
英文版：https://leetcode.com/problems/linked-list-cycle/

中文版：https://leetcode-cn.com/problems/linked-list-cycle/

Merge k Sorted Lists（合并 k 个排序链表）
英文版：https://leetcode.com/problems/merge-k-sorted-lists/

中文版：https://leetcode-cn.com/problems/merge-k-sorted-lists/

做完题目之后，你可以点击“请朋友读”，把测试题分享给你的朋友，说不定就帮他解决了一个难题。

祝你取得好成绩！明天见！



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(90)

李皮皮皮皮皮
感谢分享，虽然工作很忙，每天下班就不想动了。但是还是要不断克服自己。数据结构和算法的重要性可能在面试的时候才能深刻感悟。如果平时多下点功夫，结果可能会大不一样。前面很多期因为各种原因没有跟上，庆幸的是后面慢慢追上了。现在养成每天做一道算法题的习惯。每天装着一道算法题在脑子里。这感觉其实也不错，不是任务，感觉像是习惯😄
2019-02-04


28

Jerry银银
早上起来拿出电脑，准备做题。
老妈说：今天就别工作了，玩一天吧，啥也别干，啥也别想。
我说：不行呀，老师布置了题目，必须得做呀。
老妈说：大过年的老师还在工作，真不容易，替我向你老师说声：🔥🔥新年好！！！
2019-02-05


23

Smallfly
哈哈，被提名了，谢谢老师。

有兴趣的同学可以把你的答案分享到 Github: https://github.com/iostalks/Algorithms

有问题也可以在 issue 中一起讨论。

新的一年跟大家一起进步，一起流弊。
2019-02-05

1

23

fancyyou
新年好！
leetcode的题都做过了😁。
2019-02-05


11

abner
Java语言实现一个大小固定的有序数组，支持动态增删改操作
代码如下:
public class Array {
    private String[] data;
    private int count;
    privvate int size;
    public Array(int capacity) {
        data = new String[capacity];
        count = 0;
        size = capacity;
    }
    public boolean insert(int index, String value) {
        if (count >= size) {
            return false;
        }
        if (index < 0 || index > count) {
            return false;
        }
        for (int i = count - 1;i >= index;i--) {
             data[i+1] = data[i];
        }
        data[index] = value;
        count++;
    }
    public String delete(int index, String value) {
        if (count == 0) {
            return false;
        }
        if (index < 0 || index >count) {
             return false;
         }
        value = data[index];
        for (int i = index;i <= count - 1;i++) {
            data[i - 1] = data[i];
        }
        count--;
        return value;
}
2019-02-05

1

4

峰
第三题，看这题，我就会想到用快排的思想在一堆数中求第n大。于是乎我就套，先把负数全部移掉，o(n)不影响。然后每轮迭代随机取个数n，比它小的放左边，比他大的放右边。比如说第一轮迭代，左边的数据个数小于n-1那么必然在左边。但这里有个问题是数据是可以重复的，怎么办，想呀想，我就选定n后，开始扫描，如果是1我就放第一个位置，如果是2我就放第二个位置，如果再有1，发现重复了，不用移动了，这样我就能计算小于n大于n的正整数有多少种了，然后就能迭代下去了。当然里面还有些细节，比如如果n很大已超过了数组长度，那说明那个数一定在左边。
编辑回复: 感谢您参与春节七天练的活动，为了表彰你在活动中的优秀表现，赠送您99元专栏通用阅码，我们会在3个工作日之内完成礼品发放，如有问题请咨询小明同学，微信geektime002。

2019-02-05


4

abner
java实现一个动态扩容的数组（扩容2倍）
代码如下:
package array;

public class DynamicArray {
    
    private String[] data;
    private int count;
    private int size;
    
    public DynamicArray(int capacity) {
        data = new String[capacity];
        count = 0;
        size = capacity;
    }
    
    public String[] expand(String[] data) {
        if (count >= size) {
            String[] newArray = new String[this.size * 2];
            this.size = this.size * 2;
            for (int i = 0;i < count;i++) {
                newArray[i] = this.data[i];
            }
            return newArray;
        } else {
            return this.data;
        }
    }
    
    public boolean append(String item) {
        if (count >= size) {
            this.data = expand(this.data);
        }
        this.data[count] = item;
        count++;
        return true;
    }
    
    public void printAll() {
        for (int i = 0;i < count;i++) {
            System.out.print(data[i] + " ");
        }
        System.out.println();
    }
    
    public static void main(String[] args) {
        DynamicArray dynamicArray = new DynamicArray(5);
        for (int i = 0;i < dynamicArray.size;i++) {
            dynamicArray.data[i] = "This value is " + i;
            dynamicArray.count++;
        }
        dynamicArray.append("This value is 5");
        System.out.println("Now the size of data is " + dynamicArray.size);
        dynamicArray.printAll();
    }
  
}
2019-02-13


3

_CountingStars
合并有序数组 go 语言实现
package main

import "fmt"

func mergeOrderedArray(a, b []int) (c []int) {
i, j, k := 0, 0, 0
mergedOrderedArrayLength := len(a) + len(b)
c = make([]int, mergedOrderedArrayLength)
for {
if i >= len(a) || j >= len(b) {
break
}

if a[i] <= b[j] {
c[k] = a[i]
i++
} else {
c[k] = b[j]
j++
}
k++
}

for ; i < len(a); i++ {
c[k] = a[i]
k++
}

for ; j < len(b); j++ {
c[k] = a[j]
k++
}

return
}

func main() {
a := []int{1, 3, 5, 7, 9, 10, 11, 13, 15}
b := []int{2, 4, 6, 8}
fmt.Println("ordered array a: ", a)
fmt.Println("ordered array b: ", b)
fmt.Println("merged ordered array: ", mergeOrderedArray(a, b))
}
2019-02-05


3

未来的胡先森
求众数
解题思路：将数组排序，统计每个数字出现的次数，当满足众数条件时返回。时间复杂度 nlogn

int compare(const void *a, const void *b)
{
return (*(int*)a - *(int*)b);
}
int majorityElement(int* nums, int numsSize) {
qsort(nums,numsSize,sizeof(int), compare);
int num = nums[0],flag=numsSize>>1,count=1;
for (int i = 1; i < numsSize; i++)
{
if (nums[i] != num)
{
num = nums[i]; count = 1;
}
else
{
count++;
}
if (count > flag)
break;
}
return num;
}
更优解

数组元素为奇数个，众数数量大于半数，所以相互抵消后最后剩余的一定为众数，时间复杂度 O(n)

int majorityElement(int* nums, int numsSize)
{
int count = 1,num=nums[0];
for (int i = 1; i < numsSize; i++)
if (count == 0 || num == nums[i])
{
count++; num = nums[i];
}
else
count--;
return num;
}
2019-02-16


2

kai
3. 实现求链表的中间结点
public class FindMidNode {

    // 1. T(n) = O(2*n) 遍历2次
    public static Node findMidNode(Node head) {
        if (head == null) {
            return null;
        }

        int len = 0;
        Node p = head;

        while(p != null) {
            len++;
            p = p.next;
        }

        p = head;
        for (int i = 0; i < len/2; i++) {
            p = p.next;
        }

        return p;
    }

    // 2. T(n) = O(n) 遍历1次
    // 快慢指针法
    public static Node findMidNodeFast(Node head) {
        if (head == null) {
            return null;
        }

        Node fast = head;
        Node slow = head;

        while (fast != null && fast.next != null) {
            fast = fast.next.next;
            slow = slow.next;
        }

        return slow;
    }


    public static Node createNode(int value) {
        return new Node(value, null);
    }

    public static class Node {
        public int data;
        public Node next;

        public Node(int data, Node next) {
            this.data = data;
            this.next = next;
        }
    }
}

4. Linked List Cycle I（环形链表）
/**
 * 141. Linked List Cycle
 * https://leetcode.com/problems/linked-list-cycle/
 */
public class LinkedListCycle {
    public boolean hasCycle(ListNode head) {
        if (head == null || head.next == null) {
            return false;
        }

        ListNode fast = head;
        ListNode slow = head;

        while (fast != null && fast.next != null) {
            fast = fast.next.next;
            slow = slow.next;
            if (fast == slow) return true;
        }

        return false;
    }

    public static class ListNode {
        int val;
        ListNode next;
        ListNode(int x) { val = x;}
    }
}
2019-02-11


2

kai
1. 实现单链表反转：
/**
 * 206. Reverse Linked List
 * https://leetcode.com/problems/reverse-linked-list/
 */
public class ReverseList {
    public ListNode reverseList(ListNode head) {
        if (head == null || head.next == null) return head;

        ListNode pre = null;
        ListNode next = null;

        while (head != null) {
            next = head.next;
            head.next = pre;
            pre = head;
            head = next;
        }

        return pre;
    }

    public static class ListNode {
        int val;
        ListNode next;
        ListNode(int x) {
            this.val = val;
        }
    }
}

2. 实现两个有序的链表合并为一个有序链表
/**
 * 21. Merge Two Sorted Lists
 * https://leetcode.com/problems/merge-two-sorted-lists/
 */
public class Merge2SortedLists {
    public ListNode mergeTwoLists(ListNode l1, ListNode l2) {
        if (l1 == null) return l2;
        if (l2 == null) return l1;

// 利用哨兵（前哨节点）简化实现难度
        ListNode outpost = new ListNode(-1);
        ListNode temp = outpost;

        while (l1 != null && l2 != null) {
            if (l1.val <= l2.val) {
                temp.next = l1;
                l1 = l1.next;
            } else {
                temp.next = l2;
                l2 = l2.next;
            }

            temp = temp.next;
        }

        if (l1 == null) {
            temp.next = l2;
        }

        if (l2 == null) {
            temp.next = l1;
        }

        return outpost.next;
    }

public ListNode mergeTwoListsRecur(ListNode l1, ListNode l2) {
        if (l1 == null) return l2;
        if (l2 == null) return l1;
if (l1.val < l2.val) {
l1.next = mergeTwoListsRecur(l1.next, l2);
return l1;
} else {
l2.next = mergeTwoListsRecur(l1, l2.next);
return l2;
}
}

    public static class ListNode {
        int val;
        ListNode next;
        ListNode(int x) { val = x;}
    }
}


2019-02-11


2

纯洁的憎恶
1.Three Sum：暴力匹配三元组，三层循环结束后打印保存三元组的数组即可，时间复杂度O（n^3），空间复杂度O（n）。简化一下，为减少比较次数先排序。外层循环i遍历数组，内层循环从数组两头元素（s、t）开始考察，找出使num【s】+num【t】=-num【i】的s和t，若大了t- -，若小了s++（内层要避开i）s大于等于t则匹配失败。这样两层循环就可以了，时间复杂度O（n^2）。

2.Majority Element：重点在于统计每个元素出现次数，可以先排序，然后顺序计算出每个数的出现次数，与阈值比较，大于则输出，时间复杂度O（nlogn）。也可以采用散列表，把每个元素存入散列表，并记录出现次数，最后把出现次数超过阈值的元素输出即可，时间复杂度O（n），空间复杂度O（n）。

3.Missing Positive：本来想用散列表，发现要求时间复杂度O（n），空间复杂度为常量，有点捉急。只能从原数组上做文章。假设数组A长度为n，若i为1到n的正整数，若i存在于A中，我们就把它的位置调整到A【i-1】处，这样通过A【i】是否为i+1即可知道i+1是否在数组中。那么A中不满足上述条件的最小下标+1即为缺失的最小正整数值。

4. Linked List Cycle I（环形链表）：用图的拓扑排序算法可以，但是要统计顶点出入度，空间复杂度无法达到O（1）。那可以用快慢指针，*fast以*slow的两倍速前进，如果fast和slow重合则说明有环。

5. Merge k Sorted Lists（合并 k 个排序链表）：两两硬生生合并，时间复杂度应该是O（kN），再高级的方法想不出来。ps：如果可以抛弃原来的链表，那么新建一个合并后链表的时间复杂度可以是O（N）吧？N是k个链表的总长。
2019-02-08


2

William
特地新开了一个git仓库，https://github.com/Si3ver/LeetCode。刷完5道题，思路大致写一下。1.数组三数之和，时间复杂度是O(n^2)，先排序，外层i遍历数组，内层左右双指针，寻找两数之和 = -nums[i]。 2. 求数组中出现次数大于一半的数字。复杂度O(n)，是利用摩尔投票法。3.求缺失的最小正整数，复杂度O(n)，思路是哈希表统计。4.环形链表用快慢指针。5.合并k个有序链表，用的是两两归并，据说用堆会更快，这个有待补充。
编辑回复: 感谢您参与春节七天练的活动，为了表彰你在活动中的优秀表现，赠送您99元专栏通用阅码，我们会在3个工作日之内完成礼品发放，如有问题请咨询小明同学，微信geektime002。

2019-02-06


2

菜菜
大小固定的有序数组，支持增删改：既然有序，则查询操作都可以用二分查询。增加操作，找到第一个大于新数据的值的位置，从最后一个有效数据往后移一个位置，目的是为了给新数据腾位置，然后插入。删除操作：找到第一个等于要删除的数据的值，然后将其后面的数据依次向前挪一个位置。改操作，查询再修改。要注意临界条件和找不到数据，以及数组满等情况。
2019-02-06


2

赵菁垚
王老师，请教您一个问题，想参加NOIP c++考这些算法吗？
作者回复: 也考的

2019-08-08

1

1

神盾局闹别扭
加油礼包的福利在哪里领呢？
编辑回复: 运营同学稍后会联系获奖同学哈

2019-02-18


1

Ben
class Solution(object):
    def threeSum(self, nums):
        """
        :type nums: List[int]
        :rtype: List[List[int]]
        通过hash结构缓存去重值及出现的次数

        将值按正负区分, 将正负列表中的数字求和, 判断和的相反数是否仍存在于字典中
        """
        #将输入列表的值作为索引, 对应出现的次数作为新的字典结构的值
        dic = {}
        for ele in nums:
            if ele not in dic:
                dic[ele] = 0
            dic[ele] += 1
        # 存在3个0的特殊情况
        if 0 in dic and dic[0] > 2:
            rst = [[0, 0, 0]]
        else:
            rst = []

        pos = [p for p in dic if p > 0]
        neg = [n for n in dic if n < 0]

        # 若全为正或负值, 不存在和为0的情况
        for p in pos:
            for n in neg:
                inverse = -(p + n)
                if inverse in dic:
                    if inverse == p and dic[p] > 1:
                        rst.append([n, p, p])
                    elif inverse == n and dic[n] > 1:
                        rst.append([n, n, p])
                    # 去重: 小于负值且大于正值可以排除掉重复使用二者之间的值
                    elif inverse < n or inverse > p or inverse == 0:
                        rst.append([n, inverse, p])
        return rst
    def majorityElement(self, nums):
        """
        :type nums: List[int]
        :rtype: int
        hash反存值和出现的次数
        """
        #利用字典表反存值:出现的次数
        dic = {}
        for i in nums:
            if i not in dic:
                dic[i] = 1
            else:
                dic[i] +=1
        
        #根据列表获取值最大的索引
        vs = list(dic.values())
        return list(dic.keys())[vs.index(max(vs))]
    def firstMissingPositiveFast(self, nums):
        """
        :type nums: List[int]
        :rtype: int
        """
        n = 1
        while n in nums:
            n +=1
        return n
编辑回复: 感谢您参与春节七天练的活动，为了表彰你在活动中的优秀表现，赠送您10元无门槛优惠券，我们会在3个工作日之内完成礼品发放，如有问题请咨询小明同学，微信geektime002。

2019-02-14


1

hopeful
//单链表反转（带头结点）
void reverse(struct node* head){
struct node* L;
struct node* p;
struct node* p2;
struct node* p3;
L = head->next;
if(head == NULL){
printf("链表未创建");
}else if(L->next==NULL){
printf("单链表只有一个节点，无需反转");
return;
}else if(L->next->next == NULL){
head->next = L->next;
head->next->next = L;
L->next = NULL;
printf("单链表反转成功");
}else{
p = L;
p2 = L->next;
p3 = L->next->next;
while(p3!=NULL){
p2->next = p;
p = p2;
p2 = p3;
p3 = p3->next;
}
p2->next = p;
L->next = NULL;
head->next = p2;
printf("单链表反转成功");
}
}
2019-02-13


1

Zoctopus
Three Sum（求三数之和）Go语言：
func threeSum(nums []int) [][]int {
    results := [][]int{}
n := len(nums)
if n == 0 || n < 3 {
return results
}
sort.Ints(nums) //首先，对数组进行排序
for i := 0; i < n-2; i++ {
if i > 0 && nums[i] == nums[i-1] { //如果相邻两个数相等
continue
}
target := -nums[i]
left := i + 1
right := n - 1
for left < right {
sum := nums[left] + nums[right]
if sum == target {
results = append(results, []int{nums[left], nums[right], nums[i]})
left++
right--
for left < right && nums[left] == nums[left-1] {
left++
}
for left < right && nums[right] == nums[right+1] {
right--
}
} else if sum > target {
right--
} else if sum < target {
left++
}
}

}
return results
}
编辑回复: 感谢您参与春节七天练的活动，为了表彰你在活动中的优秀表现，赠送您99元专栏通用阅码，我们会在3个工作日之内完成礼品发放，如有问题请咨询小明同学，微信geektime002。

2019-02-12


1

Sharry
链表篇
1. 翻转单链表
/*翻转单链表*/
void reversalList(Node<int>* head) {
Node<int>* p = head;
Node<int>* prev = NULL;
Node<int>* temp = NULL;
while (p) {
// 1. 保存要遍历的下一个结点
temp = p->next;
// 2. 将 node->next 指向前驱结点
p->next = prev;
// 3. 更新前驱结点
prev = p;
// 4. 更新下一个要遍历的结点
p = temp;
}
}

2. 将两个有序的单链表合并
/* 合并两个有序链表, 将 list2 合并到 list1 中 */
Node<int>* mergeOrderList(Node<int>* list1, Node<int>* list2) {
// 记录 list2 的头结点
Node<int>* head = list2;
// 创建哨兵, 用于处理将 list2 中的元素插入到 list1 头结点前面的情况
Node<int>* sentry = new Node<int>(-1);
sentry->next = list1;
// 记录 list1 要遍历的元素
Node<int>* node = sentry;
Node<int>* temp = NULL;
while (node->next && head) {
if (node->next->data > head->data) {
temp = head->next;
head->next = node->next;
node->next = head;
head = temp;
}
else {
node = node->next;
}
}
// 若 list2 的头结点不为 NULL, 则说明 list1 中的元素提前遍历结束了
// 剩下的 list2 中的元素均比 list1 中的大
// 直接将 list1 的尾结点连接到 list2 的首结点即可
if (head) {
node->next = head;
}
// 释放哨兵结点内存
list1 = sentry->next;
sentry->next = NULL;
delete(sentry);
return list1;
}

3. 求单链表的中间结点
/* 查询单链表的中间结点 */
template<typename E>
Node<E>* findMidNode(Node<E>* head, Node<E>** mid_node) {
if (!head) {
return NULL;
}
Node<E>* fast = head;
Node<E>* slow = head;
while (fast && fast->next && fast->next->next) {
// 快指针走两步
fast = fast->next->next;
// 慢指针走一步
slow = slow->next;
}
*mid_node = slow;
}
编辑回复: 感谢您参与春节七天练的活动，为了表彰你在活动中的优秀表现，赠送您99元专栏通用阅码，我们会在3个工作日之内完成礼品发放，如有问题请咨询小明同学，微信geektime002。

2019-02-12


1
收起评论

9096





# 春节7天练 | Day 2：栈、队列和递归



数据结构与算法之美
王争
前Google工程师
查看详情
59587 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

入门篇 (4讲)

基础篇 (38讲)

高级篇 (9讲)

43 | 拓扑排序：如何确定代码源文件的编译依赖关系？
44 | 最短路径：地图软件是如何计算出最优出行路径的？
45 | 位图：如何实现网页爬虫中的URL去重功能？
46 | 概率统计：如何利用朴素贝叶斯算法过滤垃圾短信？
47 | 向量空间：如何实现一个简单的音乐推荐系统？
48 | B+树：MySQL数据库索引是如何实现的？
49 | 搜索：如何用A*搜索算法实现游戏中的寻路功能？
50 | 索引：如何在海量数据中快速查找某个数据？
51 | 并行算法：如何利用并行处理提高算法的执行效率？
实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



春节7天练 | Day 2：栈、队列和递归
王争 2019-02-05



00:50
讲述：修阳 大小：803.06K
你好，我是王争。初二好！

为了帮你巩固所学，真正掌握数据结构和算法，我整理了数据结构和算法中，必知必会的 30 个代码实现，分 7 天发布出来，供你复习巩固所用。今天是第二篇。

和昨天一样，你可以花一点时间，来完成测验。测验完成后，你可以根据结果，回到相应章节，有针对性地进行复习。

关于栈、队列和递归的几个必知必会的代码实现
栈
用数组实现一个顺序栈

用链表实现一个链式栈

编程模拟实现一个浏览器的前进、后退功能

队列
用数组实现一个顺序队列

用链表实现一个链式队列

实现一个循环队列

递归
编程实现斐波那契数列求值 f(n)=f(n-1)+f(n-2)

编程实现求阶乘 n!

编程实现一组数据集合的全排列

对应的 LeetCode 练习题（@Smallfly 整理）
栈
Valid Parentheses（有效的括号）
英文版：https://leetcode.com/problems/valid-parentheses/

中文版：https://leetcode-cn.com/problems/valid-parentheses/

Longest Valid Parentheses（最长有效的括号）
英文版：https://leetcode.com/problems/longest-valid-parentheses/

中文版：https://leetcode-cn.com/problems/longest-valid-parentheses/

Evaluate Reverse Polish Notatio（逆波兰表达式求值）
英文版：https://leetcode.com/problems/evaluate-reverse-polish-notation/

中文版：https://leetcode-cn.com/problems/evaluate-reverse-polish-notation/

队列
Design Circular Deque（设计一个双端队列）
英文版：https://leetcode.com/problems/design-circular-deque/

中文版：https://leetcode-cn.com/problems/design-circular-deque/

Sliding Window Maximum（滑动窗口最大值）
英文版：https://leetcode.com/problems/sliding-window-maximum/

中文版：https://leetcode-cn.com/problems/sliding-window-maximum/

递归
Climbing Stairs（爬楼梯）
英文版：https://leetcode.com/problems/climbing-stairs/

中文版：https://leetcode-cn.com/problems/climbing-stairs/

昨天的第一篇，是关于数组和链表的，如果你错过了，点击文末的“上一篇”，即可进入测试。

祝你取得好成绩！明天见！



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(48)

李皮皮皮皮皮
基础数据结构和算法是基石，灵活运用是解题的关键。栈，队列这些数据结构说到底就是给顺序表添加约束，更便于解决某一类问题。学习中培养算法的设计思想是非常关键的。而且思想是可以通用的。之前读《暗时间》一书，收获颇深。书中介绍之正推反推我在做程序题时竟出奇的好用。
2019-02-05


4

abner
java用数组实现一个顺序栈
代码如下：
package stack;

public class ArrayStack {

    private String[] data;
    private int count;
    private int size;

    public ArrayStack(int n) {
        this.data = new String[n];
        this.count = 0;
        this.size = n;
    }
    
    public boolean push(String value) {
        if (count == size) {
            return false;
        } else {
            data[count] = value;
            count++;
            return true;
        }
    }

    public String pop() {
        if (count == 0) {
            return null;
        } else {
            count--;
            return data[count];
        }
    }
}
2019-02-11


2

abner
java用链表实现一个链式栈
代码如下：
package stack;

public class LinkedStack {
    
    private Node top = null;
    
    public static class Node {
        
        private String data;
        private Node next;
        
        public Node(String data, Node next) {
            this.data = data;
            this.next = next;
        }
        
        public String getData() {
            return data;
        }
    }
    
    public void push(String item) {
        Node newNode = new Node(item, null);
        if (top == null) {
            top = newNode;
        } else {
            newNode.next = top;
            top = newNode;
        }
    }
    
    public String pop() {
        if (top == null) {
            return null;
        }
        String value = top.data;
        top = top.next;
        return value;
    }
    
    public void printAll() {
        Node pNode = top;
        while (pNode != null) {
            System.out.print(pNode.data + " ");
            pNode = pNode.next;
        }
        System.out.println();
    }
    
    public static void main(String[] args) {
        LinkedStack linkedStack = new LinkedStack();
        linkedStack.push("haha");
        linkedStack.push("nihao");
        linkedStack.printAll();
    }
}
2019-02-12


1

abner
java用递归实现斐波那契数列
代码如下：
package recursion;

public class Fib {

    public long calFib(long n) {
        if (n == 0 || n == 1) {
            return 1;
        } else {
            return calFib(n - 1) + calFib(n - 2);
        }
    }
    
    public static void main(String[] args) {
        Fib fib = new Fib();
        long result = fib.calFib(5);
        System.out.println(result);
    }
}
2019-02-11


1

abner
java用递归实现求解n!
代码如下：
package recursion;

public class Fac {

    public long calFac(long n) {
        if (n == 0) {
            return 1;
        }
        return calFac(n - 1) * n;
    }

    public static void main(String[] args) {
        Fac fac = new Fac();
        long result = fac.calFac(10);
        System.out.println(result);
    }
}
2019-02-11


1

abner
java用数组实现一个顺序队列
代码如下：
package queue;

public class ArrayQueue {
    
    private String[] data;
    private int size;
    private int head;
    private int tail;
    
    public ArrayQueue(int capacity) {
        data = new String[capacity];
        size = capacity;
        head = 0;
        tail = 0;
    }
    
    public boolean enqueue(String value) {
        if (tail == size) {
            return false;
        }
        data[tail] = value;
        tail++;
        return true;
    }

    public String dequeue() {
        if (tail == 0) {
            return null;
        }
        String value = data[head];
        head++;
        return value;
    }
}
2019-02-11


1

kai
1. 编程实现斐波那契数列求值 f(n)=f(n-1)+f(n-2）
public class Fibonacci {
    public static int fib(int n) {
        if (n <= 0) {
            return 0;
        }
        if (n == 1) {
            return 1;
        }

        return fib(n-1) + fib(n-2);
    }
}

2. Climbing Stairs（爬楼梯）
public class ClimbStairs {
    public int climbFloor(int n) {
        if (n == 1 || n == 2) {
            return n;
        }

        return climbFloor(n - 1) + climbFloor(n - 2);
    }

    public int climbFloorIter(int n) {
        if (n == 1 || n == 2) {
            return n;
        }

        int jump1 = 1;
        int jump2 = 2;
        int jumpN = 0;

        for (int i = 3; i <= n; i++) {
            jumpN = jump1 + jump2;

            jump1 = jump2;
            jump2 = jumpN;
        }

        return jumpN;
    }
}

3. Sliding Window Maximum（滑动窗口最大值)
import java.util.ArrayList;
import java.util.LinkedList;

public class MaxNumOfSlidingWindow {
    public ArrayList<Integer> maxInWindows(int [] num, int size)
    {
        ArrayList<Integer> res = new ArrayList<>();

        if (num == null || num.length <= 0 || size <= 0 || size > num.length) {
            return res;
        }

        LinkedList<Integer> qMax = new LinkedList<>(); // 双端队列：左端更新max,右端添加数据

        int left = 0;

        for (int right = 0; right < num.length; right++) {
            // 更新右端数据
            while (!qMax.isEmpty() && num[qMax.peekLast()] <= num[right]) {
                qMax.pollLast();
            }

            qMax.addLast(right);

            // 更新max：如果max的索引不在窗口内,则更新
            if (qMax.peekFirst() == right - size) {
                qMax.pollFirst();
            }

            // 待窗口达到size，输出max
            if (right >= size-1) {
                res.add(num[qMax.peekFirst()]);
                left++;
            }
        }

        return res;
    }
}
2019-02-11


1

ALAN
import java.util.Arrays;

/**
 *
 *Stack 1 solution
 */
public class StackArray {

public Object[] arr = new Object[10];
public int count;

public void push(Object ele) {
if (count == arr.length) { // expand size
arr = Arrays.copyOf(arr, arr.length * 2);
}
arr[count] = ele;
count++;
}

public Object pop() {
if (count == 0)
return null;
if (count < arr.length / 2) {
arr = Arrays.copyOf(arr, arr.length / 2);
}
return arr[--count];

}
}

/**
 *
 *Stack 2 solution
 */
class StackLinked {
Node head;
Node tail;

public void push(Object ele) {

if (head == null) {
head = new Node(ele);
tail = head;
} else {
Node node = new Node(ele);
tail.next = node;
node.prev = tail;
tail = node;
}
}

public Object pop() {
if (tail == null)
return null;
Node node = tail;
if (tail == head) {
head = null;
tail = null;
} else
tail = tail.prev;
return node;

}
}
class Node {
Node prev;
Node next;
Object value;

public Node(Object ele) {
value = ele;
}
}
2019-02-08


1

TryTs
之前有个类似的题，走楼梯，装苹果，就是把苹果装入盘子，可以分为有一个盘子为空（递归），和全部装满没有空的情况，找出状态方程，递归就可以列出来了。我觉得最关键是要列出状态方程，之前老师类似于说的不需要关注特别细节，不要想把每一步都要想明白，快速排序与递归排序之类的算法，之前总是想把很细节的弄懂，却发现理解有困难。
2019-02-06


1

猫猫
全排列js
//9.一组数据集合的全排列 回溯（暴力枚举）
let count = 1

function permutation(nums, result = []) {
  if (nums.length == 0) {
    console.log(`${count}:${result}`)
    count++
    return
  }
  for (let i = 0; i < nums.length; i++) {
    permutation(nums.filter((value, index) => index != i), [...result, nums[i]])
  }
}
2019-08-26



懒猫
练完打卡
2019-05-22



Sharry
有意思, 递归的 LeeCode 题目, 使用简单粗暴的回溯法并没有办法通过, 还是得使用动态规划求解
2019-02-20



hopeful
#一组数据集合的全排列
def f(start , b):
    a = list(b)
    if start==len(a):
        print(b)
    else:
        for i in range(start , len(a)):
            a[start] , a[i] = a[i] , a[start]
            c = tuple(a)
            f(start+1 , c)
            a[start] , a[i] = a[i] , a[start]
2019-02-19



hopeful
#实现快速排序、归并排序
#---------快排(三数取中)---------
def QuickSort():
    array = Array(10000)
    qsort(0 , len(array)-1 , array)
    return array
def qsort(start , end , array):
    if start < end:
        key = partation(array , start , end)
        qsort(start , key-1 , array)
        qsort(key+1 , end , array)
def swap(array , start , end):
    temp = array[start]
    array[start] = array[end]
    array[end] = temp
def change(array , start , mid , end):
    if array[start] > array[mid]:
        swap(array , start , mid)
    if array[start]>array[end]:
        swap(array , start , end)
    if array[mid] > array[end]:
        swap(array , mid , end)
    swap(array , mid , start)
def partation(array , start , end):
    #mid = int((start+end)/2)
    #change(array , start , mid , end)
    temp = array[start]
    while start < end :
        while start<end and array[end]<=temp:
            end-=1
        swap(array , start , end)
        while start<end and array[start]>=temp:
            start+=1
        swap(array , start , end)
    return start
#---------------归并------------
def merge(a , b):
    c = []
    i = 0
    j = 0
    while i<len(a) and j<len(b):
        if a[i] > b[j]:
            c.append(a[i])
            i+=1
        else:
            c.append(b[j])
            j+=1
    if i>=len(a):
        for k in range(j , len(b)):
            c.append(b[k])
    if j>=len(b):
        for k in range(i , len(a)):
            c.append(a[k])
    return c
def devide(array):
    if len(array) == 1:
        return array
    else:
        mid = int((0 + len(array)) / 2)
        leftArray = devide(array[0:mid])
        rightArray = devide(array[mid:len(array)])
        return merge(leftArray , rightArray)
def mergesort():
    array = Array(100)
    m = devide(array)
    return m
2019-02-15



hopeful
#冒泡、选择、插入排序
import random
import time
def Array(n):
    a = []
    for i in range(n):
        a.append(random.randint(0 , n))
    return a
#插入排序
def insert():
    array = Array(100)
    time_start=time.time()
    for i in range(1 , len(array)):
        for j in range(i , 0 , -1):
            if array[j] > array[j-1]:
                temp = array[j]
                array[j] = array[j-1]
                array[j-1] = temp
            else:
                break
    time_end=time.time()
    print(array)
    print('totally cost',time_end-time_start)
def select():
    array = Array(100)
    time_start=time.time()
    for i in range(len(array)):
        for j in range(i+1 , len(array)):
            if array[j] > array[i]:
                temp = array[j]
                array[j] = array[i]
                array[i] = temp
    time_end=time.time()
    print(array)
    print('totally cost',time_end-time_start)
def bubble():
    array = Array(100)
    time_start=time.time()
    for i in range(len(array)-1 , 0 , -1):
        flag = False
        for j in range(i):
            if array[j] > array[j+1]:
                temp = array[j]
                array[j] = array[j+1]
                array[j+1] = temp
                flag = True
        if not flag:
            break
    time_end=time.time()
    print(array)
    print('totally cost',time_end-time_start)
2019-02-15



hopeful
//阶乘n!
def f(n):
    if(n<=1):
        return 1
    else:
        return f(n-1)*n
2019-02-15



hopeful
//斐波那契数列
def f(n):
    if(n<=0):
        return 0
    elif(n==1):
        return 1
    else:
        return f(n-1)+f(n-2)
2019-02-15



hopeful
//数组实现顺序队列
public class MyQueue {

private Object[] object;
private int count;

MyQueue(int size){
this.object = new Object[size];
count = 0;
}

@Override
public Object pop() {
// TODO Auto-generated method stub
if(count==0) {
return null;
}else {
Object temp = object[0];
count--;
for (int i = object.length-1; i > 0 ; i--) {
object[i-1] = object[i];
}
return temp;
}
}

@Override
public void push(Object h) {
// TODO Auto-generated method stub
if( (count+1) >= object.length) {
Object[] ob = new Object[2*object.length];
System.arraycopy(object, 0, ob, 0, count);
this.object = ob;
}
object[count] = h;
count++;
}

@Override
public Object getFirst() {
// TODO Auto-generated method stub
if(count==0)
return null;
else
return object[0];
}

@Override
public Object getLast() {
// TODO Auto-generated method stub
if(count==0)
return null;
else
return object[count-1];
}

@Override
public boolean empty() {
// TODO Auto-generated method stub
if(count==0) {
return true;
}else
return false;
}

@Override
public int size() {
// TODO Auto-generated method stub
return count;
}

}
2019-02-15



hopeful
//用链表实现顺序栈
#include<stdlib.h>
#define true 1
#define false 0
#define ok 1
#define error 0
#define infeasible 1
#define overflow 0
#define stack_size 50
typedef struct{
    int *base;
    int *top;
    int stacksize;
}sqstack;

//构造一个空栈
int create_stack(sqstack *s)
{
    s->base=(int *)malloc(5*sizeof(int)); //开始分配50个整形空间
    if(!s->base) exit(overflow);
    s->top=s->base;
    s->stacksize=5;
    return 0;
}

//插入新元素为栈顶元素
int stack_push(sqstack *s)
{
    int e;
    if(s->top - s->base>=5)
{ //栈满 ，追加存储空间
        s->base = (int *)realloc(s->base,(5+1)*sizeof(int));
    if(!s->base) exit(overflow);//存储分配失败
    s->top = s->base + 5;//新扩充空间后的栈顶指针位置
    s->stacksize += 1;
    }
    printf("请输入要入栈的值:");
    scanf("%d",&e);
    *s->top++ = e;
    return 0;
}

//出栈
int stack_pop(sqstack *s)
{
    if(s->base == s->top) {printf("栈为空！不能出栈！"); return error;}
    --s->top;
    return 0;
}

//打印栈
int stack_top(sqstack *s)
{
    int *w;
    printf("The stack is :");
    w=s->base;
    while(w!=s->top)
{
        printf(" %d ",*w++);
    }
    printf("\n");
}
2019-02-15



hopeful
//数组实现顺序栈
public class MyStack {
Object[] object;
private int count;
MyStack(int size){
this.object = new Object[size];
count = 0;
}
public void push(Object h) {
if( (count+1) >= object.length) {
Object[] ob = new Object[2*object.length];
System.arraycopy(object, 0, ob, 0, count);
this.object = ob;
}
object[count] = h;
count++;
}
public Object pop() {
if(count==0) {
return null;
}else {
count--;
return object[count-1];
}
}
public Object peek() {
if(count==0) {
return null;
}else {
return object[count-1];
}
}
public void removeAll() {
while(count!=0) {
this.pop();
count--;
}
}
public boolean empty() {
if(count==0) {
return true;
}else
return false;
}
public int getCount() {
return this.count;
}
2019-02-15


收起评论

4838






# 春节7天练 | Day 3：排序和二分查找




数据结构与算法之美
王争
前Google工程师
查看详情
59587 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

入门篇 (4讲)

基础篇 (38讲)

高级篇 (9讲)

43 | 拓扑排序：如何确定代码源文件的编译依赖关系？
44 | 最短路径：地图软件是如何计算出最优出行路径的？
45 | 位图：如何实现网页爬虫中的URL去重功能？
46 | 概率统计：如何利用朴素贝叶斯算法过滤垃圾短信？
47 | 向量空间：如何实现一个简单的音乐推荐系统？
48 | B+树：MySQL数据库索引是如何实现的？
49 | 搜索：如何用A*搜索算法实现游戏中的寻路功能？
50 | 索引：如何在海量数据中快速查找某个数据？
51 | 并行算法：如何利用并行处理提高算法的执行效率？
实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



春节7天练 | Day 3：排序和二分查找
王争 2019-02-06



00:54
讲述：修阳 大小：862.31K
你好，我是王争。初三好！

为了帮你巩固所学，真正掌握数据结构和算法，我整理了数据结构和算法中，必知必会的 30 个代码实现，分 7 天发布出来，供你复习巩固所用。今天是第三篇。

和昨天一样，你可以花一点时间，来完成测验。测验完成后，你可以根据结果，回到相应章节，有针对性地进行复习。

前两天的内容，是关于数组和链表、排序和二分查找的。如果你错过了，点击文末的“上一篇”，即可进入测试。

关于排序和二分查找的几个必知必会的代码实现
排序
实现归并排序、快速排序、插入排序、冒泡排序、选择排序

编程实现 O(n) 时间复杂度内找到一组数据的第 K 大元素

二分查找
实现一个有序数组的二分查找算法

实现模糊二分查找算法（比如大于等于给定值的第一个元素）

对应的 LeetCode 练习题（@Smallfly 整理）
Sqrt(x) （x 的平方根）
英文版：https://leetcode.com/problems/sqrtx/

中文版：https://leetcode-cn.com/problems/sqrtx/

做完题目之后，你可以点击“请朋友读”，把测试题分享给你的朋友，说不定就帮他解决了一个难题。

祝你取得好成绩！明天见！



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(29)

李皮皮皮皮皮
各种排序算法真要说起来实际中使用的最多的也就是快排了。然而各种编程语言内置的标准库都包含排序算法的实现，基本没有自己动手实现的必要。然后作为经典的算法，自己实现一遍，分析分析时间空间复杂度对自己的算法设计大有裨益。需要注意的是为了高效，在实际的实现中，多种排序算法往往是组合使用的。例如c标准库中总体上是快排，但当数据量小于一定程度，会转而使用选择或插入排序。
求平方根使用牛顿法二分逼近😄
2019-02-06


5

TryTs
虽然现在有很多排序算法自己不会亲自写，但是作为算法的基础，分治，归并，冒泡等排序算法在时间复杂度，空间复杂度以及原地排序这些算法知识上的理解非常有帮助。递归分治这些算法思想在简单的算法中也能体现出来，其实更多的是思维方式的训练。
编辑回复: 感谢您参与春节七天练的活动，为了表彰你在活动中的优秀表现，赠送您99元专栏通用阅码，我们会在3个工作日之内完成礼品发放，如有问题请咨询小明同学，微信geektime002。

2019-02-07


2

虎虎❤️
基本排序算法的关注点分为：
1. 时间复杂度。如n的平方（冒泡，选择，插入）；插入排序的优化希尔排序，则把复杂度降低到n的3/2次方；n乘以logn(快排，归并排序，堆排序）。
2. 是否为原地排序。如，归并排序需要额外的辅助空间。
3. 算法的稳定性。稳定排序（by nature）如冒泡，插入，归并。如果把次序考虑在内，可以把其他的排序（如快排，堆排序）也实现为稳定排序。
4. 算法的实现。同为时间复杂度同为n平方的算法中，插入排序的效率更高。但是如果算法实现的不好，可能会降低算法的效率，甚至让稳定的算法变得不稳定。又如，快速排序有不同的实现方式，如三路快排可以更好的应对待排序数组中有大量重复元素的情况。堆排序可以通过自上而下的递归方式实现，也可以通过自下而上的方式实现。
5. 不同算法的特点，如对于近乎有序的数组进行排序，首选插入排序，时间复杂度近乎是n，而快速排序则退化为n平方。

二分查找，需要注意 (l+r)/2可能存在越界问题。

leetcode题，用二分查找找到x*x > n 且(x-1)的平方小于n的数，则n-1就是结果。或者 x的平方小于n且x+1的平方大于n,则返回x。
2019-02-07


2

失火的夏天
牛顿法或者二分逼近都可以解决平方根问题，leetcode上有些大神的思路真的很厉害，经常醍醐灌顶
2019-02-06


2

hopeful
#O(n)时间复杂度时间复杂度内找到一组数据的第 n大元素
import random
import time

def Array(n):
    a = []
    for i in range(n):
        a.append(random.randint(0 , n))
    return a
def QuickSort(n):
    array = Array(100)
    if n > len(array) or n < 1:
        print("超出范围，找不到")
        return
    n = n-1
    a = qsort(0 , len(array)-1 , array , n)
    print(sorted(array))
    print("-----------------------------")
    print(a)

def qsort(start , end , array , n):
    if start == end:
        res = array[start]
    if start < end:
        key = partation(array , start , end)
        print(start , key , end)
        if key > n :
            res = qsort(start , key-1 , array , n)
        elif key < n:
            res = qsort(key+1 , end , array , n)
        else:
            res = array[key]
    return res

def swap(array , start , end):
    temp = array[start]
    array[start] = array[end]
    array[end] = temp

def partation(array , start , end):
    temp = array[start]
    while start < end :
        while start<end and array[end]<=temp:
            end-=1
        swap(array , start , end)
        while start<end and array[start]>=temp:
            start+=1
        swap(array , start , end)
    return start
2019-02-16


1

Monster
/**
 * O(n)时间复杂度内求无序数组中第K大元素
 */
public class TopK {

    public int findTopK(int[] arr, int k) {
        return findTopK(arr, 0, arr.length - 1, k);
    }

    private int findTopK(int[] arr, int left, int right, int k) {
        if (arr.length < k) {
            return -1;
        }
        int pivot = partition(arr, left, right);
        if (pivot + 1 < k) {
            findTopK(arr, pivot + 1, right, k);
        } else if (pivot + 1 > k) {
            findTopK(arr, left, pivot - 1, k);
        }
        return arr[pivot];
    }


    private int partition(int[] array, int left, int right) {
        int pivotValue = array[right];
        int i = left;

        //小于分区点放在左边 大于分区点放在右边
        for (int j = left; j < right; j++) {
            if (array[j] < pivotValue) {
                int tmp = array[i];
                array[i] = array[j];
                array[j] = tmp;
                i++;
            }
        }
        //与分区点交换
        int tmp = array[i];
        array[i] = array[right];
        array[right] = tmp;
        return i;
    }
}
编辑回复: 感谢您参与春节七天练的活动，为了表彰你在活动中的优秀表现，赠送您10元无门槛优惠券，我们会在3个工作日之内完成礼品发放，如有问题请咨询小明同学，微信geektime002。

2019-02-13


1

EidLeung
编程实现 O(n) 时间复杂度内找到一组数据的第 K 大元素。
这个的时间复杂路应该是n·logk吧？
2019-02-12


1

abner
java实现冒泡排序
代码如下：
package sort;

public class BubbleSort {

    public int[] bubbleSort(int[] array) {
        for (int i = 0;i < array.length - 1;i++) {
            for (int j = 0;j < array.length - i - 1;j++) {
                if (array[j] > array[j + 1]) {
                    int temp = array[j + 1];
                    array[j + 1] = array[j];
                    array[j] = temp;
                }
            }
        }
        return array;
    }

    public static void main(String[] args) {
        int[] array = {10, 9, 8, 7, 6, 5, 4, 3, 2, 1};
        BubbleSort bubbleSort = new BubbleSort();
        int[] result = bubbleSort.bubbleSort(array);
        for (int i = 0;i < result.length;i++) {
            System.out.print(result[i] + " ");
        }
    }

}
2019-02-11


1

kai
实现模糊二分查找算法2:

public class BinarySearch {
    // 3. 查找第一个大于等于给定值的元素
    public static int bsFistGE(int[] array, int target) {
        int lo = 0;
        int hi = array.length - 1;

        while (lo <= hi) {
            int mid = lo + ((hi - lo) >> 1);

            if (array[mid] >= target) {
                if (mid == 0 || array[mid-1] < target) {
                    return mid;
                } else {
                    hi = mid - 1;
                }
            } else {
                lo = mid + 1;
            }
        }

        return -1;
    }

    // 4. 查找最后一个小于等于给定值的元素
    public static int bsLastLE(int[] array, int target) {
        int lo = 0;
        int hi = array.length - 1;

        while (lo <= hi) {
            int mid = lo + ((hi - lo) >> 1);

            if (array[mid] <= target) {
                if (mid == hi || array[mid+1] > target) {
                    return mid;
                } else {
                    lo = mid + 1;
                }
            } else {
                hi = mid - 1;
            }
        }

        return -1;
    }
}
2019-02-11


1

kai
实现模糊二分查找算法1:

public class BinarySearch {
    
    // 1. 查找第一个值等于给定值的元素
    public static int bsFirst(int[] array, int target) {
        int lo = 0;
        int hi = array.length - 1;

        while (lo <= hi) {
            int mid = lo + ((hi - lo) >> 1);

            if (array[mid] > target) {
                hi = mid - 1;
            } else if (array[mid] < target) {
                lo = mid + 1;
            } else {
                if (mid == lo || array[mid-1] != array[mid]) {
                    return mid;
                } else {
                    hi = mid - 1;
                }
            }
        }

        return -1;
    }

    // 2. 查找最后一个值等于给定值的元素
    public static int bsLast(int[] array, int target) {
        int lo = 0;
        int hi = array.length - 1;

        while (lo <= hi) {
            int mid = lo + ((hi - lo) >> 1);

            if (array[mid] > target) {
                hi = mid - 1;
            } else if (array[mid] < target) {
                lo = mid + 1;
            } else {
                if (mid == hi || array[mid] != array[mid+1]) {
                    return mid;
                } else {
                    lo = mid + 1;
                }
            }
        }

        return -1;
    }
}
2019-02-11


1

kai
实现一个有序数组的二分查找算法:

public class BinarySearch {
    // 最简单的二分查找算法：针对有序无重复元素数组
    // 迭代
    public static int binarySearch(int[] array, int target) {
        if (array == null) return -1;

        int lo = 0;
        int hi = array.length-1; // 始终在[lo, hi]范围内查找target

        while (lo <= hi) {
            int mid = lo + ((hi - lo) >> 1); // 这里若是 (lo + hi) / 2 有可能造成整型溢出

            if (array[mid] > target) {
                hi = mid - 1;
            } else if (array[mid] < target) {
                lo = mid + 1;
            } else {
                return mid;
            }
        }

        return -1;
    }

    // 递归
    public static int binarySearchRecur(int[] array, int target) {
        if (array == null) return -1;
        return bs(array, target, 0, array.length-1);
    }

    private static int bs(int[] array, int target, int lo, int hi) {
        if (lo <= hi) {
            int mid = lo + ((hi - lo) >> 1);
            if (array[mid] > target) {
                return bs(array, target, lo, mid-1);
            } else if (array[mid] < target) {
                return bs(array, target, mid+1, hi);
            } else {
                return mid;
            }
        }

        return -1;
    }
}
2019-02-11


1

纯洁的憎恶
这道题似乎可以等价于从1到x中找到一个数y，使得y*y小于等于x，且（y+1）*（y+1）大于x。那么可以从1到x逐个尝试，提高效率可以采用二分查找方法，时间复杂度为O（logx）。
2019-02-09


1

黄丹
王争老师初三快乐！
这是今天两道题的解题思路和代码
1. O(n)时间内找到第K大的元素：
解题思路：利用快排中分区的思想，选择数组区间A[0...n-1]的左右一个元素A[n-1]作为pivot，对数组A[0...n-1]原地分区，这样数组就分成了三部分，A[0..p-1],A[p],A[p+1...n-1],如果p+1=k,那么A[p]就是要求解的元素，如果K>p+1,则说明第K大的元素在A[p+1...n-1]这个区间，否则在A[0...p-1]这个区间，递归的查找第K大的元素
2. Sqrt(x) （x 的平方根）
解题思路：利用二分查找的思想，从1到x查找x的近似平方根
代码：
https://github.com/yyxd/leetcode/blob/master/src/leetcode/sort/Problem69_Sqrt.java
2019-02-07


1

C_love
Use Binary Search

class Solution {
    public int mySqrt(int x) {
        if (x == 0 || x == 1) {
            return x;
        }
        
        int start = 0;
        int end = (x >> 1) + 1;
        
        while (start + 1 < end) {
            final int mid = start + ((end - start) >> 1);
            final int quotient = x / mid;
            if (quotient == mid) {
                return mid;
            } else if (quotient < mid) {
                end = mid;
            } else {
                start = mid;
            }
        }
        
        return start;
    }
}
编辑回复: 感谢您参与春节七天练的活动，为了表彰你在活动中的优秀表现，赠送您99元专栏通用阅码，我们会在3个工作日之内完成礼品发放，如有问题请咨询小明同学，微信geektime002。

2019-02-07


1

Geek_86533a
不断学习，不断练习到今天。发现自己的代码能力、思考问题的能力有了明显的进步。感谢！
2019-08-14



懒猫
打卡
2019-05-23



hopeful
#二分查找变种
import random
import time

def Array(n):
    a = []
    for i in range(n):
        a.append(random.randint(0 , n))
    return a
#查找第一个值等于给定值的元素
def find_1(n):
    array = Array(100)
    array = sorted(array)
    left = 0
    right = len(array)-1
    while left <= right:
        mid = int((left+right)/2)
        if array[mid] > n:
            right = mid - 1
        elif array[mid] < n:
            left = mid + 1
        else:
            if mid==0 or array[mid] != array[mid-1]:
                return mid
            else:
                right = mid - 1
    print("找不到")
    return -1

#查找最后一个值等于给定值的元素
def find_2(n):
    array = Array(100)
    array = sorted(array)
    left = 0
    right = len(array)-1
    while left <= right:
        mid = int((left+right)/2)
        if array[mid] > n:
            right = mid - 1
        elif array[mid] < n:
            left = mid + 1
        else:
            if mid==right or array[mid] != array[mid+1]:
                return mid
            else:
                left = mid + 1
    print("找不到")
    return -1

#查找第一个值大于等于给定值的元素
def find_3(n):
    array = Array(100)
    array = sorted(array)
    left = 0
    right = len(array)-1
    while left <= right:
        mid = int((left+right)/2)
        if array[mid] >= n:
            if mid==0 or array[mid-1]<n:
                return mid
            else:
                right = mid - 1
        else array[mid] < n:
            left = mid + 1
    print("找不到")
    return -1

#查找最后一个值小于等于给定值的元素
def find_4(n):
    array = Array(100)
    array = sorted(array)
    left = 0
    right = len(array)-1
    while left <= right:
        mid = int((left+right)/2)
        if array[mid] <= n:
            if mid==right or array[mid+1]>n:
                return mid
            else:
                left = mid + 1
        else array[mid] > n:
            right = mid - 1
    print("找不到")
    return -1
2019-02-17



hopeful
#实现一个有序数组的二分查找算法
import random
import time

def Array(n):
    a = []
    for i in range(n):
        a.append(random.randint(0 , n))
    return a

def find(n):
    array = Array(100)
    array = sorted(array)
    left = 0
    right = len(array)-1
    while left <= right:
        mid = int((left+right)/2)
        if array[mid] > n:
            right = mid - 1
        elif array[mid] < n:
            left = mid + 1
        else:
            return mid
    print("找不到")
    return -1
2019-02-16



拉欧
x 的平方根 go 语言实现
func mySqrt(x int) int{

if x==0{
return 0
}
min:=1
max:=x

for {
mid:=min+(max-min)/2
if mid*mid==x{
return mid
}else if mid*mid<x{
if (mid+1)*(mid+1)>x{
return mid
}else{
min=mid+1
}
}else{
max=mid-1
}

}
}
2019-02-15



TryTs
#include<iostream>
#include<cmath>
using namespace std;
double a = 1e-6;
double sqrt(double n){
double low = 0.0;
double high = n;

int i = 1000;

while(i--){
double mid = low + (high - low) / 2.0;
//cout<<"n:"<<n<<endl;
double square = mid * mid;
//cout<<"sq:"<<square<<endl;
//cout<<"s:"<<abs(square - n)<<endl;
if(abs(mid * mid - n) < a){
return mid;
}
else{

if(square > n){
high = mid;
}
else{
low = mid;
}
}
}
return -2.0;
}
int main(){
double t;
while(true){
cin>>t;
cout<<sqrt(t)<<endl;
}
}
2019-02-14


收起评论

2925






# 春节7天练 | Day 4：散列表和字符串



数据结构与算法之美
王争
前Google工程师
查看详情
59587 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

入门篇 (4讲)

基础篇 (38讲)

高级篇 (9讲)

43 | 拓扑排序：如何确定代码源文件的编译依赖关系？
44 | 最短路径：地图软件是如何计算出最优出行路径的？
45 | 位图：如何实现网页爬虫中的URL去重功能？
46 | 概率统计：如何利用朴素贝叶斯算法过滤垃圾短信？
47 | 向量空间：如何实现一个简单的音乐推荐系统？
48 | B+树：MySQL数据库索引是如何实现的？
49 | 搜索：如何用A*搜索算法实现游戏中的寻路功能？
50 | 索引：如何在海量数据中快速查找某个数据？
51 | 并行算法：如何利用并行处理提高算法的执行效率？
实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



春节7天练 | Day 4：散列表和字符串
王争 2019-02-08



00:29
讲述：修阳 大小：471.18K
你好，我是王争。初四好！

为了帮你巩固所学，真正掌握数据结构和算法，我整理了数据结构和算法中，必知必会的 30 个代码实现，分 7 天发布出来，供你复习巩固所用。今天是第四篇。

和昨天一样，你可以花一点时间，来完成测验。测验完成后，你可以根据结果，回到相应章节，有针对性地进行复习。

前几天的内容。如果你错过了，点击文末的“上一篇”，即可进入测试。

关于散列表和字符串的 4 个必知必会的代码实现
散列表
实现一个基于链表法解决冲突问题的散列表

实现一个 LRU 缓存淘汰算法

字符串
实现一个字符集，只包含 a～z 这 26 个英文字母的 Trie 树

实现朴素的字符串匹配算法

对应的 LeetCode 练习题（@Smallfly 整理）
字符串
Reverse String （反转字符串）
英文版：https://leetcode.com/problems/reverse-string/

中文版：https://leetcode-cn.com/problems/reverse-string/

Reverse Words in a String（翻转字符串里的单词）
英文版：https://leetcode.com/problems/reverse-words-in-a-string/

中文版：https://leetcode-cn.com/problems/reverse-words-in-a-string/

String to Integer (atoi)（字符串转换整数 (atoi)）
英文版：https://leetcode.com/problems/string-to-integer-atoi/

中文版：https://leetcode-cn.com/problems/string-to-integer-atoi/

做完题目之后，你可以点击“请朋友读”，把测试题分享给你的朋友，说不定就帮他解决了一个难题。

祝你取得好成绩！明天见！



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(19)

李皮皮皮皮皮
散列表的核心是散列函数和冲突解决算法，以及装载因子过大时如何扩容。散列函数的设计较为复杂，一般使用现有的函数，如murmur散列。冲突解决一般有开放寻址法和链表法。查看开源项目的源码实现很有意思，例如lua的table实现，是结合了两个方法的非常优雅的实现。根据装载因子扩容一般保持在2，在占用空间较大时慢慢缩减为1.5，1.25……如golang的实现。为了避免rehash时的延迟，可以使用先分配，后逐步散列的方法，redis就是使用这个方法的。
字符串是编程中一定会出现的问题，变种非常多，反转，反转单词，字串，最长字串，最长子序列等等，有时解决问题需要多种数据结构与算法的结合。
2019-02-08


3

hopeful
朴素字符串匹配算法
def nmatching(t, p):
 t代表主串，p代表模式串
    i = 0
    j = 0
    n = len(t)
    m = len(p)
    while i < n and j < m:
        if t[i] == p[j]:
            i = i+1
            j = j+1
        else:
            i = i-j+1
            j = 0 #i-j+1是关键，遇字符不等时将模式串t右移一个字符
    if j == m:
        return i-j #找到一个匹配，返回索引值
    return -1 #未找到，返回-1
2019-03-11


1

kai
实现一个 LRU 缓存淘汰算法:

import java.util.HashMap;
import java.util.Iterator;

public class LRU<K,V> {
    
    private Node head;
    private Node tail;
    private HashMap<K, Node> map;
    private int maxSize;

    private class Node {
        Node pre;
        Node next;
        K k;
        V v;
        public Node(K k, V v) {
            this.k = k;
            this.v = v;
        }
    }

    public LRU(int maxSize) {
        this.maxSize = maxSize;
        this.map = new HashMap<>(maxSize * 4 / 3);
        head = new Node(null, null);
        tail = new Node(null, null);
        head.next = tail;
        tail.pre = head;
    }

    public V get(K key) {
        if (!map.containsKey(key)) {
            return null;
        }
        Node node = map.get(key);
        unlink(node);
        appendToHead(node);
        return node.v;
    }
    public void put(K key, V value) {
        if (map.containsKey(key)) {
            Node node = map.get(key);
            unlink(node);
        }
        Node node = new Node(key, value);
        appendToHead(node);
        map.put(key, node);
        if (map.size() > maxSize) {
            Node toRemove = removeTail();
            map.remove(toRemove.k);
        }
    }
    private Node removeTail() {
        Node node = tail.pre;
        Node pre = node.pre;
        tail.pre = pre;
        pre.next = tail;
        node.next = null;
        node.pre = null;
        return node;
    }
    private void appendToHead(Node node) {
        Node next = head.next;
        node.next = next;
        node.pre = head;
next.pre = node;
        head.next = node;
    }
    private void unlink(Node node) {
        Node pre = node.pre;
        Node next = node.next;
        pre.next = next;
        next.pre = pre;
        node.pre = null;
        node.next = null;
    }
    
}
2019-02-11


1

黄丹
王争老师，新年的第四天快乐，已经很晚了，祝您好梦！
关于基于链表法解决冲突的散列表，就是使用一个数组，将值散列到数组下标上，但数组的每个值又是一个链表的头结点，当遇到冲突时就遍历该头结点后链表。其实java中hashmap底层的实现原理就是一个基于链表解决冲突的动态扩容的数组。大家有兴趣可以自己实现一下hashmap的底层数据结构，还是很有收获的。
今天leetcode上的三题都是关于字符串的，下面是我的解题思路和代码
1. Reverse String （反转字符串）
解题思路：这一题要求使用O(1)的空间将字符串进行反转，就是原地反转字符串，对字符串s[0…n-1]来说当i<n/2;将i与n-1-i位置的字符进行互换就行.
代码： https://github.com/yyxd/leetcode/blob/master/src/leetcode/strings/Problem344_ReverseString.java
2. Reverse Words in a String （翻转字符串里的单词）
解题思路：这一题我用的是java中的StringBuilder处理字符串，先用split函数将字符串按空格分开，但是当有多个连续空格时，一定要注意这种不能当做单词处理，要检查一下。
代码： https://github.com/yyxd/leetcode/blob/master/src/leetcode/strings/Problem151_ReverseWordsInString.java
3. String to Integer (atoi) 字符串转换整数 (atoi)）
解题思路：将字符串转化为整数,首先是对数字前面的+/-进行处理，遍历字符串，如果不是数字字符就break，自己不懂得地方在于如何将大于INT.MAX 的值转化为 INT.MAX,将INT.MIN的值化为 INT.MIN，我自己想到的解法是用更高精度的long去保存，然后转化成int类型的值
代码： https://github.com/yyxd/leetcode/blob/master/src/leetcode/strings/Problem8_atoi.java
2019-02-08


1

kai
哇塞，老师太牛了，过年都在更新，一直在跟着老师的课程在总结归纳，同时找来题目在练习，这个专栏很牛~
2019-02-08


1

hopeful
字符串转整数
class Solution:
    def myAtoi(self, str: str) :
        pattern = r"[\s]*[+-]?[\d]+"
        match = re.match(pattern, str)
        if match:
            res = int(match.group(0))
            if res > 2 ** 31 - 1:
                res = 2 ** 31 -1
            if res < - 2 ** 31:
                res = - 2 ** 31
        else:
            res = 0
        return res
2019-03-11



hopeful
反转字符串
class Solution:
    def reverseString(self, s):
        low = 0
        high = len(s)-1
        while low <= high:
            s[low] , s[high] = s[high] , s[low]
            low+=1
            high-=1
        return s
2019-02-19



你看起来很好吃
字符串转换整数python实现：
import math

class Solution:
    def myAtoi(self, str: 'str') -> 'int':
        result = 0

        i, N, former = 0, len(str), 1

        while i < N:
            if str[i] != ' ':
                break
            i += 1
            
        if i < N and (str[i] == '-' or str[i] == '+'):
            former = -1 if str[i] == '-' else 1
            i += 1
            
        while i < N:
            if str[i].isdigit():
                result = result * 10 + int(str[i])
                i += 1
            else:
                break

        result = result * former
        if result > (math.pow(2, 31) * -1) and result < (math.pow(2,31) - 1):
            return result
        elif former > 0 :
            return int(math.pow(2,31) - 1)
        else:
            return int(math.pow(2,31) * -1)
2019-02-10



纯洁的憎恶
1.从两端向中间两两对调，时间复杂度O（n）。

2.先去空格，O（n^2）。从两端向中间查找单词，找到一对单词s、t（s在前t在后），保存这两个单词，如果s长t短，把它们之间的字符串整体左移长度差个字符，反之整体右移长度差个字符，再把s和t按调整后位置向原数组赋值，O（n^2）。

3.如果字符串全为空、全为空格、首个非空格字符非法，则返回0。若首个合法字符位“-”则记录。int num=0；逐个读取数字部分字符a，若a合法，则num*=10，然后num+=a-‘0’，直到读取结束或者读到非法字符，此时如果记录的首个合法字符为“-”返回num*（-1），否则返回num。不知int型运算过程中结果值溢出，是否自动将值设置为边界值。如果不能就要在每次乘10的时候结合“-”考察一下是否越界。
编辑回复: 感谢您参与春节七天练的活动，为了表彰你在活动中的优秀表现，赠送您99元专栏通用阅码，我们会在3个工作日之内完成礼品发放，如有问题请咨询小明同学，微信geektime002。

2019-02-09



你看起来很好吃
反转字符串python实现：
class Solution:
    def reverseString(self, s: 'List[str]') -> 'None':
        """
        Do not return anything, modify s in-place instead.
        """
        i, N = 0, len(s)
        while i < N//2:
            s[i], s[N-1-i] = s[N-1-i], s[i]
            i += 1
            
        print(s)
2019-02-09



molybdenum
老师新年好，这是我第四天的作业
https://blog.csdn.net/github_38313296/article/details/86818634
编辑回复: 感谢您参与春节七天练的活动，为了表彰你在活动中的优秀表现，赠送您99元专栏通用阅码，我们会在3个工作日之内完成礼品发放，如有问题请咨询小明同学，微信geektime002。

2019-02-09



ext4
反转字符串
class Solution {
public:
    string reverseString(string s) {
        int length = s.length();
        if (length < 2) {
            return s;
        }
        int i = 0, j = length - 1;
        char temp;
        while (i < j) {
            temp = s[i];
            s[i] = s[j];
            s[j] = temp;
            i++;
            j--;
        }
        return s;
    }
};
2019-02-09



虎虎❤️
itoa

public class Solution {
public int myAtoi(String str) {
if (str.isEmpty())
return 0;
str = str.trim();
int i = 0, ans = 0, sign = 1, len = str.length();
if (str.charAt(i) == '-' || str.charAt(i) == '+')
sign = str.charAt(i++) == '+' ? 1 : -1;
for (; i < len; ++i) {
int tmp = str.charAt(i) - '0';
if (tmp < 0 || tmp > 9)
break;
if (ans > Integer.MAX_VALUE / 10
|| (ans == Integer.MAX_VALUE / 10 && Integer.MAX_VALUE % 10 < tmp))
return sign == 1 ? Integer.MAX_VALUE : Integer.MIN_VALUE;
else
ans = ans * 10 + tmp;
}
return sign * ans;
}
}
2019-02-08



_CountingStars
反转字符串 go 语言实现
package main

import "fmt"

func reverseString(s []byte) {
length := len(s)
for i := 0; i < length/2; i++ {
s[i], s[length-i-1] = s[length-i-1], s[i]
}
}

func main() {
testString := []byte{'h', 'e', 'l', 'l', 'o'}
fmt.Println(string(testString[:]))
reverseString(testString)
fmt.Println(string(testString[:]))
}
2019-02-08



失火的夏天
LRU缓存淘汰算法
    private class Node{
        private Node prev;
        private Node next;
        private int key;
        private int value;

        Node(int key,int value){
            this.key = key;
            this.value = value;
        }
    }

    private Node head;// 最近最少使用，类似列队的头，出队
    private Node tail;// 最近最多使用，类似队列的尾，入队
    private Map<Integer,Node> cache;
    private int capacity;

    public LRUCache(int capacity) {
        this.cache = new HashMap<>();
        this.capacity = capacity;
    }

    public int get(int key) {
        Node node = cache.get(key);
        if(node == null){
            return -1;
        }else{
            moveNode(node);
            return node.value;
        }
    }

    public void put(int key, int value) {
        Node node = cache.get(key);
        if (node != null){
            node.value = value;
            moveNode(node);
        }else {
            removeHead();
            addNode(new Node(key,value));
        }
        cache.put(key,node);
    }

    private void removeHead(){
        if (cache.size() == capacity){
            Node tempNode = head;
            cache.remove(head.key);
            head = head.next;
            tempNode.next = null;
            if (head != null)
                head.prev = null;
        }
    }

    private void addNode(Node node){
        if (head == null)
            head = tail = node;
        else
            addNodeToTail(node);
    }

    private void addNodeToTail(Node node){
        node.prev = tail;
        tail.next = node;
        tail = node;
    }

    private void moveNode(Node node){
        if(head == node && node != tail){
            head = node.next;
            head.prev = null;
            node.next = null;
            addNodeToTail(node);
        }else if (tail == node){
        }else {
            node.prev.next = node.next;
            node.next.prev = node.prev;
            node.next = null;
            addNodeToTail(node);
        }
    }
}
2019-02-08



峰
反转字符串
class Solution {
    public void reverseString(char[] s) {
        int start = 0;
        int end = s.length - 1;
        while(start < end){
            swap(s,start,end);
            start++;
            end--;
        }
    }
    
    public void swap(char[] array,int a,int b){
        char tmp = array[a];
        array[a] = array[b];
        array[b] = tmp;
    }
    
    
}
2019-02-08



老杨同志
//字符串转换整数
package com.jxyang.test.geek.day4.Solution;

class Solution2 {
    public int myAtoi(String str) {
        if(str==null){
            return 0;
        }
        char[] arr= str.toCharArray();
        boolean flag = false;
        boolean numBegin = false;
        int result = 0;
        for(int i =0;i<arr.length;i++){
            if(numBegin && (arr[i]=='-'||arr[i]=='+'||arr[i]==' ')){
                break;
            }else if(arr[i]==' ') {
                continue;
            }else if(arr[i]=='+'){
                numBegin = true;
                continue;
            }else if(arr[i]=='-'){
                flag = true;
                numBegin = true;
                continue;
            }else if(arr[i]>='0'&&arr[i]<='9'){
                numBegin = true;
                if(result==0){
                    result = flag?('0'-arr[i]):(arr[i]-'0');
                }else{
                    try{
                        result = Math.multiplyExact(result,10);
                        result = Math.addExact(result,flag?('0'-arr[i]):(arr[i]-'0'));
                    }catch (Exception e){
                        if(flag){
                            return Integer.MIN_VALUE;
                        }else{
                            return Integer.MAX_VALUE;
                        }
                    }
                }
            }else{
                break;
            }
        }
        return result;
    }
    public static void main(String[] args) {
        Solution2 solution2 = new Solution2();
        System.out.println(solution2.myAtoi("42"));
        System.out.println(solution2.myAtoi(" +0 123"));//期望123
        System.out.println(solution2.myAtoi(" -42"));
        System.out.println(solution2.myAtoi("4193 with words"));
        System.out.println(solution2.myAtoi("words and 987"));
        System.out.println(solution2.myAtoi("-91283472332"));//期望-2147483648
        System.out.println(solution2.myAtoi("+1"));//期望-2147483648
    }
}
编辑回复: 感谢您参与春节七天练的活动，为了表彰你在活动中的优秀表现，赠送您99元专栏通用阅码，我们会在3个工作日之内完成礼品发放，如有问题请咨询小明同学，微信geektime002。

2019-02-08



老杨同志
class Solution {
//反转字符串
    public void reverseString(char[] s) {
        if(s==null||s.length<2){
            return;
        }
        int l=0;
        int r=s.length-1;
        while (l<r){
            char tmp = s[l];
            s[l] = s[r];
            s[r] = tmp;
            l++;
            r--;
        }
    }
}
2019-02-08



C_love
Reverse Words in a String

public class Solution {
    public String reverseWords(String s) {
        final List<String> words = new ArrayList<>();
        final char[] charArray = s.toCharArray();
        
        int start = 0;
        int end = 0;
        while (end < s.length()) {
            if (' ' == charArray[end]) {
                if (start != end) {
                    words.add(getWord(charArray, start, end));
                    start = end;
                }
                start++;
                end++;
            } else {
                end++;
            }
        }
        
        if (start != end) {
            words.add(getWord(charArray, start, end));
        }
        
        Collections.reverse(words);
        return String.join(" ", words);
    }
    
    private String getWord(final char[] charArray, final int start, final int end) {
        char[] tmp = new char[end - start];
        int pos = 0;
        for(int i = start; i < end; i++) {
            tmp[pos++] = charArray[i];
        }
        return new String(tmp);
    }
}
2019-02-08


收起评论

1915





# 春节7天练 | Day 5：二叉树和堆



数据结构与算法之美
王争
前Google工程师
查看详情
59587 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

入门篇 (4讲)

基础篇 (38讲)

高级篇 (9讲)

43 | 拓扑排序：如何确定代码源文件的编译依赖关系？
44 | 最短路径：地图软件是如何计算出最优出行路径的？
45 | 位图：如何实现网页爬虫中的URL去重功能？
46 | 概率统计：如何利用朴素贝叶斯算法过滤垃圾短信？
47 | 向量空间：如何实现一个简单的音乐推荐系统？
48 | B+树：MySQL数据库索引是如何实现的？
49 | 搜索：如何用A*搜索算法实现游戏中的寻路功能？
50 | 索引：如何在海量数据中快速查找某个数据？
51 | 并行算法：如何利用并行处理提高算法的执行效率？
实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



春节7天练 | Day 5：二叉树和堆
王争 2019-02-09



00:20
讲述：修阳 大小：323.43K
你好，我是王争。春节假期进入尾声了。你现在是否已经准备返回工作岗位了呢？今天更新的是测试题的第五篇，我们继续来复习。

关于二叉树和堆的 7 个必知必会的代码实现
二叉树
实现一个二叉查找树，并且支持插入、删除、查找操作

实现查找二叉查找树中某个节点的后继、前驱节点

实现二叉树前、中、后序以及按层遍历

堆
实现一个小顶堆、大顶堆、优先级队列

实现堆排序

利用优先级队列合并 K 个有序数组

求一组动态数据集合的最大 Top K

对应的 LeetCode 练习题（@Smallfly 整理）
Invert Binary Tree（翻转二叉树）
英文版：https://leetcode.com/problems/invert-binary-tree/

中文版：https://leetcode-cn.com/problems/invert-binary-tree/

Maximum Depth of Binary Tree（二叉树的最大深度）
英文版：https://leetcode.com/problems/maximum-depth-of-binary-tree/

中文版：https://leetcode-cn.com/problems/maximum-depth-of-binary-tree/

Validate Binary Search Tree（验证二叉查找树）
英文版：https://leetcode.com/problems/validate-binary-search-tree/

中文版：https://leetcode-cn.com/problems/validate-binary-search-tree/

Path Sum（路径总和）
英文版：https://leetcode.com/problems/path-sum/

中文版：https://leetcode-cn.com/problems/path-sum/

做完题目之后，你可以点击“请朋友读”，把测试题分享给你的朋友。

祝你取得好成绩！明天见！



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(28)

李皮皮皮皮皮
平衡树的各种操作太烧脑了，左旋右旋，红黑树就更别提了。过段时间就忘。😢
2019-02-09


6

kai
树的前中后序遍历-递归实现：

public class TreeTraversal {

    public static class Node {
        public int value;
        public Node left;
        public Node right;

        public Node(int value) {
            this.value = value;
        }
    }

    // 二叉树的递归遍历
    public static void preOrderRecursive(Node head) {
        if (head == null) {
            return;
        }

        System.out.print(head.value + " ");
        preOrderRecursive(head.left);
        preOrderRecursive(head.right);
    }

    public static void inOrderRecursive(Node head) {
        if (head == null) {
            return;
        }

        inOrderRecursive(head.left);
        System.out.print(head.value + " ");
        inOrderRecursive(head.right);
    }

    public static void postOrderRecursive(Node head) {
        if (head == null) {
            return;
        }

        postOrderRecursive(head.left);
        postOrderRecursive(head.right);
        System.out.print(head.value + " ");
    }

}
2019-02-11


2

kai
树的前中后序遍历-非递归实现：
import java.util.Stack;


public class TreeTraversal {
    public static class Node {
        public int value;
        public Node left;
        public Node right;
        public Node(int value) {
            this.value = value;
        }
    }
    // 二叉树的非递归遍历
    public static void preOrder(Node head) {
        System.out.print("pre-order: ");
        if (head == null) {
            return;
        }
        Stack<Node> s = new Stack<>();
        s.push(head);
        while (!s.isEmpty()) {
            head = s.pop();
            System.out.print(head.value + " ");
            if (head.right != null) {
                s.push(head.right);
            }

            if (head.left != null) {
                s.push(head.left);
            }
        }
        System.out.println();
    }

    public static void inOrder(Node head) {
        System.out.print("in-order: ");
        if (head == null) {
            return;
        }
        Stack<Node> s = new Stack<>();
        while (!s.isEmpty() || head != null) {
            if (head != null) {
                s.push(head);
                head = head.left;
            } else {
                head = s.pop();
                System.out.print(head.value + " ");
                head = head.right;
            }
        }
        System.out.println();
    }

    public static void postOrder(Node head) {
        System.out.print("pos-order: ");
        if (head == null) {
            return;
        }

        Stack<Node> tmp = new Stack<>();
        Stack<Node> s = new Stack<>();

        tmp.push(head);
        while(!tmp.isEmpty()) {
            head = tmp.pop();
            s.push(head);

            if (head.left != null) {
                tmp.push(head.left);
            }

            if (head.right != null) {
                tmp.push(head.right);
            }
        }

        while (!s.isEmpty()) {
            System.out.print(s.pop().value + " ");
        }

        System.out.println();
    }
}
2019-02-11


1

kai
今天看了一下这一节的题目，发现校招面试的时候都考过，今天又刷了一下，总结了一波，相应的知识点也总结了一下~
2019-02-10


1

纯洁的憎恶
今天的题目很适合递归实现，当然递归公式离代码实现还是存在一定距离。
1.翻转二叉树（T）｛
当T为Null时则返回；
翻转二叉树（T的左子树）；
翻转二叉树（T的右子树）；
若T不为叶节点，则交换T的左右子树位置；
｝

2.最大深度（T）｛
当T为Null时，return 0；
return Max（最大深度（T左子树）+1，最大深度（T右子树）+1）；
｝
函数返回值即为最大深度。

3.验证二叉查找树（T，&最大值，&最小值）｛
当T为Null时，return true；
当T为叶节点时，最小值=最大值=当前节点，返回true；
左最大值=左最小值=T的值；
验证二叉查找树（T的左子树，&左最大值，&左最小值）；
右最大值=右最小值=T的值；
验证（T的右子树，&右最大值，&右最小值）；
T的值小于等于右最小值，并且大于等于左最大值时，最大值=右最大值，最小值=左最小值，之后返回true，否则返回false并结束。
｝
函数最终返回true则验证成功。

4.计算路径和（T，sum）｛
若T为Null返回false；
若T是叶节点，如果sum+T的值=目标值则返回true并结束，否则返回false；
计算路径和（T的左子树，sum+T的值）；
计算路径和（T的右子树，sum+T的值）；
｝
计算路径和（T，0）返回true时则存在于目标值相同的路径之和；
2019-02-10


1

_CountingStars
二叉树的最大深度 go 语言实现
/**
 * Definition for a binary tree node.
 * type TreeNode struct {
 * Val int
 * Left *TreeNode
 * Right *TreeNode
 * }
 */
func maxDepth(root *TreeNode) int {
    if root == nil {
        return 0
    }
    
    leftDepth :=0
    rightDepth :=0
    if root.Left != nil {
        leftDepth = maxDepth(root.Left)
    }
    
    if root.Right != nil {
        rightDepth = maxDepth(root.Right)
    }
    
    if leftDepth >= rightDepth {
        return leftDepth + 1
    } else {
        return rightDepth + 1
    }
}
2019-02-09


1

失火的夏天
// 翻转二叉树
public TreeNode invertTree(TreeNode root) {
        if(root == null){
return root;
}
TreeNode node = root;
Queue<TreeNode> queue = new LinkedList<>();
queue.add(node);
while(!queue.isEmpty()){
node = queue.poll();
TreeNode tempNode = node.left;
node.left = node.right;
node.right = tempNode;
if(node.left != null){
queue.offer(node.left);
}
if(node.right != null){
queue.offer(node.right);
}
}
        return root;
    }
// 二叉树的最大深度
public int maxDepth(TreeNode root) {
        if(root == null) return 0;
        return Math.max(maxDepth(root.left), maxDepth(root.right))+1;
    }
// 验证二叉查找树
public boolean isValidBST(TreeNode root) {
        if (root == null) {
return true;
}
Stack<TreeNode> stack = new Stack<>();
TreeNode node = root;
TreeNode preNode = null;
while(node != null || !stack.isEmpty()){
stack.push(node);
node = node.left;
while(node == null && !stack.isEmpty()){
node = stack.pop();
if(preNode != null){
if(preNode.val >= node.val){
return false;
}
}
preNode = node;
node = node.right;
}
}
        return true;
    }
// 路径总和
public boolean hasPathSum(TreeNode root, int sum) {
        if (root == null) {
            return false;
        }
        return hasPathSum(root, root.val, sum);
    }

    public boolean hasPathSum(TreeNode root, int tmp, int sum) {
        if (root == null) {
            return false;
        }
        if (root.left == null && root.right == null) {
            return tmp == sum;
        }
        if (root.left == null) {
            return hasPathSum(root.right, root.right.val + tmp, sum);
        }
        if (root.right == null) {
            return hasPathSum(root.left, root.left.val + tmp, sum);
        }
        return hasPathSum(root.left, root.left.val + tmp, sum) ||
                hasPathSum(root.right, root.right.val + tmp, sum);
    }
编辑回复: 感谢您参与春节七天练的活动，为了表彰你在活动中的优秀表现，赠送您99元专栏通用阅码，我们会在3个工作日之内完成礼品发放，如有问题请咨询小明同学，微信geektime002。

2019-02-09


1

懒猫
打卡
2019-06-14



付坤
https://github.com/DigDeeply/data-structures-learning/blob/0e14f4f69d1f3d45c3d16820cb771f6c242898e4/57-5-binary_tree/binary_tree.go

用数组实现的二叉查找树，支持增删查。
2019-04-01



hopeful
验证二叉搜索树
def isValidBST(self, root: TreeNode) -> bool:
        def inorderTraversal(root):
            if root == None:
                return []
            res = []
            res += inorderTraversal(root.left)
            res.append(root.val)
            res += inorderTraversal(root.right)
            return res
 
        res = inorderTraversal(root)
        if res != sorted(list(set(res))): return False
        return True
2019-03-11



hopeful
实现小顶堆
def makeSmallHeap(array):
    for i in range(int(len(array)/2) , -1 , -1):
        makeHeap(array , i , len(array))
def makeHeap(array , i ,N):
    while 2*i+1 < N:
        child = 2*i+1
        if child != N-1 and array[child] > array[child+1]:
            child+=1
        if array[child] < array[i]:
            temp = array[child]
            array[child] = array[i]
            array[i] = temp
            i = child
        else:
            break
2019-03-05



hopeful
实现大顶堆
def makeBigHeap(array):
    for i in range(int(len(array)/2) , -1 , -1):
        makeHeap(array , i , len(array))
def makeHeap(array , i ,N):
    while 2*i+1 < N:
        child = 2*i+1
        if child != N-1 and array[child] < array[child+1]:
            child+=1
        if array[child] > array[i]:
            temp = array[child]
            array[child] = array[i]
            array[i] = temp
            i = child
        else:
            break
2019-03-05



hopeful
堆排序
import random
import time

def Array(n):
    a = []
    for i in range(n):
        a.append(random.randint(0 , n))
    return a

def makeHeap(array , i ,N):
    while 2*i+1 < N:
        child = 2*i+1
        if child != N-1 and array[child] < array[child+1]:
            child+=1
        if array[child] > array[i]:
            temp = array[child]
            array[child] = array[i]
            array[i] = temp
            i = child
        else:
            break
def heapSort():
    array = Array(100)
    for i in range(int(len(array)/2) , -1 , -1):
        makeHeap(array , i , len(array))
    for i in range(len(array)-1 , -1 , -1):
        temp = array[0]
        array[0] = array[i]
        array[i] = temp
        makeHeap(array , 0 , i)
    print(array)
2019-03-05



Sharry
路径总和: 使用回溯法, 遍历每一条 root->leaf 的路线是否满足在和为 sum, 可以使用减枝操作

二叉树深度 = 左右子树中深度最大者 + 1

验证二叉搜索树:
1. 遍历每一个结点, 若都满足, 当前结点大于左子树中的最大值, 小于右子树中的最小值, 则说明为二叉搜索树
2. 中序遍历二叉搜索树, 若序列递增, 则说明为二叉搜索树
2019-02-25



hopeful
二叉树前中后序及层次遍历非递归版本
class Tree:
    def __init__(self, x):
        self.val = x
        self.left = None
        self.right = None

----前序----
def preOrder(Tree T):
    if T is None:
        return []
    list1 = []
    list2 = []
    list1.append(T)
    while len(list1) > 0:
        t = list1.pop()
        list2.append(t)
        if t.right not None:
            list1.append(t.right)
        if t.left not None:
            list1.append(t.left)
    return list2

----中序----
def inOrder(Tree T):
    if T is None:
        return []
    list1 = []
    list2 = []
    while T or len(list1)>0 :
        if T :
            list1.append(T)
            T = T.left
        else:
            T = list1.pop()
            list2.append(T)
            T = T.right
    return list2

----后序----
def postOrder(Tree T):
    if T is None:
        return []
    list1 = []
    list2 = []
    list1.append(T)
    while len(list1)>0 :
        t = list1.pop()
        list2.append(t)
        if t.left not None:
            list1.append(t.left)
        if t.right not None:
            list1.append(t.right)
    return list2[::-1]

----层次-----
def levelOrder():
    if T is None:
        return []
    list1 = []
    list2 = []
    list1.append(T)
    while len(list1)>0 :
        t = list1[0]
        del list1[0]
        list2.append(t)
        if t.left not None:
            list1.append(t.left)
        if t.right not None:
            list1.append(t.right)
    return list2
2019-02-16



abner
java实现二叉树前序、中序、后序和层次遍历
代码如下：
package tree;

import java.util.LinkedList;
import java.util.Queue;

public class BinaryTree {
    
    private Node root = null;
    
    public static class Node {
        
        private String data;
        private Node left;
        private Node right;
        
        public Node(String data, Node left, Node right) {
            this.data = data;
            this.left = left;
            this.right = right;
        }
    }
    
    public void preOrder(Node root) {
        if (null == root) {
            return ;
        }
        System.out.print(root.data + " ");
        preOrder(root.left);
        preOrder(root.right);
    }
    
    public void inOrder(Node root) {
        if (null == root) {
            return ;
        }
        inOrder(root.left);
        System.out.print(root.data + " ");
        inOrder(root.right);
    }
    
    public void postOrder(Node root) {
        if (null == root) {
            return ;
        }
        postOrder(root.left);
        postOrder(root.right);
        System.out.print(root.data + " ");
    }
    
    public void traverseByLayer(Node root) {
        if (null == root) {
            return ;
        }
        Queue<Node> queue = new LinkedList<Node>();
        queue.add(root);
        while (!queue.isEmpty()) {
            Node pNode = queue.peek();
            System.out.print(pNode.data + " ");
            queue.poll();
            if (root.left != null) {
                queue.add(root.left);
            }
            if (root.right != null) {
                queue.add(root.right);
            }
        }
    }
}
2019-02-14



拉欧
Path Sum（路径总和）go 语言实现
func hasPathSum(root *TreeNode, sum int) bool {

if root==nil{
return false
}
if root.Left==nil && root.Right==nil{
if root.Val==sum{
return true
}else{
return false
}

}
left:=false
if root.Left!=nil{
left=hasPathSum(root.Left,sum-root.Val)
}
right:=false
if root.Right!=nil{
right=hasPathSum(root.Right,sum-root.Val)
}
return left || right
}
2019-02-14



拉欧
Validate Binary Search Tree（验证二叉查找数） go语言实现

func isValidBST(root *TreeNode) bool {

if root==nil{
return true
}
less:=true
more:=true
if root.Left!=nil{
less=JudgeLess(root.Left,root.Val)
}
if root.Right!=nil{
more=JudgeMore(root.Right,root.Val)
}
if ! (less && more){
return false
}else{
return isValidBST(root.Left) && isValidBST(root.Right)
}
}

func JudgeLess(root *TreeNode,num int) bool{

if root.Val>=num{
return false
}
if root.Left!=nil && root.Right!=nil{
return JudgeLess(root.Left,num) && JudgeLess(root.Right,num)
}else if root.Left!=nil{
return JudgeLess(root.Left,num)
}else if root.Right!=nil{
return JudgeLess(root.Right,num)
}else{
return true
}
}

func JudgeMore(root *TreeNode,num int) bool{
if root.Val<=num{
return false
}
if root.Left!=nil && root.Right!=nil{
return JudgeMore(root.Left,num) && JudgeMore(root.Right,num)
}else if root.Left!=nil{
return JudgeMore(root.Left,num)
}else if root.Right!=nil{
return JudgeMore(root.Right,num)
}else{
return true
}
}
2019-02-14



拉欧
Invert Binary Tree（翻转二叉树） go 语言实现
func invertTree(root *TreeNode) *TreeNode {
if root==nil{
return root
}
temp:=root.Left
root.Left=root.Right
root.Right=temp
invertTree(root.Left)
invertTree(root.Right)
return root
}
2019-02-14



你看起来很好吃
路径之和python实现：

```
# Definition for a binary tree node.
# class TreeNode:
# def __init__(self, x):
# self.val = x
# self.left = None
# self.right = None
```

class Solution:
    def hasPathSum(self, root: 'TreeNode', sum: 'int') -> 'bool':
        if not root:
            return False
        
        if not root.left and not root.right and root.val == sum:
            return True
        
        sum -= root.val
        
        return self.hasPathSum(root.left, sum) or self.hasPathSum(root.right, sum)
2019-02-10


收起评论

2822






# 春节7天练 | Day 6：图



数据结构与算法之美
王争
前Google工程师
查看详情
59587 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

入门篇 (4讲)

基础篇 (38讲)

高级篇 (9讲)

43 | 拓扑排序：如何确定代码源文件的编译依赖关系？
44 | 最短路径：地图软件是如何计算出最优出行路径的？
45 | 位图：如何实现网页爬虫中的URL去重功能？
46 | 概率统计：如何利用朴素贝叶斯算法过滤垃圾短信？
47 | 向量空间：如何实现一个简单的音乐推荐系统？
48 | B+树：MySQL数据库索引是如何实现的？
49 | 搜索：如何用A*搜索算法实现游戏中的寻路功能？
50 | 索引：如何在海量数据中快速查找某个数据？
51 | 并行算法：如何利用并行处理提高算法的执行效率？
实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



春节7天练 | Day 6：图
王争 2019-02-10



00:17
讲述：修阳 大小：284.43K
你好，我是王争。初六好！

为了帮你巩固所学，真正掌握数据结构和算法，我整理了数据结构和算法中，必知必会的 30 个代码实现，分 7 天发布出来，供你复习巩固所用。今天是第六篇。

和之前一样，你可以花一点时间，来手写这些必知必会的代码。写完之后，你可以根据结果，回到相应章节，有针对性地进行复习。做到这些，相信你会有不一样的收获。

关于图的几个必知必会的代码实现
图
实现有向图、无向图、有权图、无权图的邻接矩阵和邻接表表示方法

实现图的深度优先搜索、广度优先搜索

实现 Dijkstra 算法、A* 算法

实现拓扑排序的 Kahn 算法、DFS 算法

对应的 LeetCode 练习题（@Smallfly 整理）
Number of Islands（岛屿的个数）
英文版：https://leetcode.com/problems/number-of-islands/description/

中文版：https://leetcode-cn.com/problems/number-of-islands/description/

Valid Sudoku（有效的数独）
英文版：https://leetcode.com/problems/valid-sudoku/

中文版：https://leetcode-cn.com/problems/valid-sudoku/

做完题目之后，你可以点击“请朋友读”，把测试题分享给你的朋友，说不定就帮他解决了一个难题。

祝你取得好成绩！明天见！



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(18)

kai
今天根据老师的课程，总结了一下图的相关知识点，然后用代码实现了一下图的相关的算法，感觉图还是要难于其他数据结构，需要接着多练习~
2019-02-10


2

李皮皮皮皮皮
图很复杂😢
2019-02-10


2

kai
实现图的深度优先搜索、广度优先搜索:

import java.util.ArrayList;
import java.util.HashSet;
import java.util.LinkedList;
import java.util.Queue;

public class BFSAndDFS {

    class Node {
        public int value; //Node 值
        public int in; //入度：指向该节点的边有几条
public int out; //出度：指向其他节点的边有几条
public ArrayList<Node> nexts;
public ArrayList<Edge> edges;

public Node(int value) {
this.value = value;
this.in = 0;
this.out = 0;
this.nexts = new ArrayList<>();
this.edges = new ArrayList<>();
}
}

    public static void bfs(Node node) {
        if (node == null) {
            return;
        }

        Queue<Node> queue = new LinkedList<>();
        HashSet<Node> set = new HashSet<>();
        queue.add(node);
        set.add(node);
        while (!queue.isEmpty()) {
            Node cur = queue.poll();
            System.out.print(cur.value + " ");
            for (Node next : cur.nexts) {
                if (!set.contains(next)) {
                    queue.add(next);
                    set.add(next);
                }
            }
        }
    }

    public static void dfs(Node node) {
        if (node == null) {
            return;
        }

        Stack<Node> stack = new Stack<>();
        HashSet<Node> set = new HashSet<>();
        stack.push(node);
        set.add(node);
        System.out.print(node.value + " ");
        while (!stack.isEmpty()) {
            Node cur = stack.pop();
            for (Node next : cur.nexts) {
                if (!set.contains(next)) {
                    stack.push(cur);
                    stack.push(next);
                    set.add(next);
                    System.out.print(next.value + " ");
                    break;
                }
            }
        }
    }
}
2019-02-11


1

纯洁的憎恶
1.在邻接矩阵中找出连通图个数即可。在每个顶点执行DFS或BFS，执行次数即为岛屿数，也可以使用并查集。

2. 依次考察9✖️9数独各行各列是否有重复数字（可以用9位数组统计），然后再考察每个3✖️3子矩阵是否有重复数字。都没有则成功。
2019-02-10


1

苦行僧
有效的数独确实可以用暴力匹配法解决
2019-08-26



Brandon
有效数独，就是穷举遍历方法求解，跟这一节练习的图，没有什么关系啊！放这个题目的时候是怎么考虑的啊？
作者回复: 好像确实暴力就能解决

2019-06-27



Nereus

并查集—go实现
func numIslands(grid [][]byte) int {
if len(grid) == 0 {
return 0
}

N := len(grid)*len(grid[0]) + 1

u := NewUnionSet(N)

for i := 0; i < len(grid); i ++ {
for j := 0; j < len(grid[i]); j ++ {
if grid[i][j] == '1' {
// 联通下边
if i+1 < len(grid) {
if grid[i+1][j] == '1' {
u.join(i*len(grid[i])+j, (i+1)*len(grid[i])+j)
}
}

// 联通右边
if j+1 < len(grid[i]) {
if grid[i][j+1] == '1' {
u.join(i*len(grid[i])+j, i*len(grid[i])+j+1)
}
}
} else {
u.join(i*len(grid[i])+j, N-1)
}
}
}

return u.counts() -1
}

type UnionSet []int

func NewUnionSet(n int) UnionSet {
var u UnionSet
u = make([]int, n)
for i := 0; i < len(u); i ++ {
u[i] = i
}
return u

}

func (u UnionSet) find(i int) int {
tmp := i
for u[tmp] != tmp {
tmp = u[tmp]
}

j := i
for j != tmp {
tt := u[j]
u[j] = tmp
j = tt
}

return tmp
}

func (u UnionSet) connected(i, j int) bool {
return u.find(i) == u.find(j)
}

func (u UnionSet) counts() int {
var count int
for idx, rec := range u {
if idx == rec {
count++
}
}
return count
}

func (u UnionSet) join(i, j int) {
x, y := u.find(i), u.find(j)
if x != y {
if y > x {
u[x] = y
} else {
u[y] = x
}
}
}
编辑回复: 感谢您参与春节七天练的活动，为了表彰你在活动中的优秀表现，赠送您10元无门槛优惠券，我们会在3个工作日之内完成礼品发放，如有问题请咨询小明同学，微信geektime002。

2019-02-14



拉欧
Valid Sudoku（有效的数独）go语言实现

func isValidSudoku(board [][]byte) bool {

isValid:=true
for i:=0;i<9;i++{
for j:=0;j<9;j++{
if board[i][j]=='.' {
continue
}else{
if !judgeLine(board,i,j){
return false
}
}
}
}

return isValid
}

func judgeLine(board [][]byte,i,j int) bool{
hash:=make(map[byte]int,9)
for k:=0;k<9;k++{
if board[i][k]!='.'{
if hash[board[i][k]]==0{
hash[board[i][k]]=1
}else{
return false
}
}
}
hash=make(map[byte]int,9)
for k:=0;k<9;k++{
if board[k][j]!='.' {
if hash[board[k][j]]==0{
hash[board[k][j]]=1
}else{
return false
}
}
}
hash=make(map[byte]int,9)
for m:=i/3*3;m<i/3*3+3;m++{
for n:=j/3*3;n<j/3*3+3;n++{
if board[m][n]!='.'{
if hash[board[m][n]]==0{
hash[board[m][n]]=1
}else{
return false
}
}
}
}
return true

}


2019-02-14



拉欧
Number of Islands（岛屿的个数）go语言实现，亲测通过：
func numIslands(grid [][]byte) int {

isSearch:=make([][]int,len(grid))
island:=0
for i:=0;i<len(isSearch);i++{
isSearch[i]=make([]int,len(grid[0]))
}
for i,line:=range grid{
for j,_:=range line{
if isSearch[i][j]==0 && grid[i][j]=='1'{
Search(grid,isSearch,i,j)
island++
}

}
}
return island
}

func Search(grid [][]byte,isSearch [][]int, i int,j int){
if isSearch[i][j]==1{
return
}
isSearch[i][j]=1
if grid[i][j]=='1'{
if i>=1{
Search(grid,isSearch,i-1,j)
}
if i<len(grid)-1{
Search(grid,isSearch,i+1,j)
}
if j>=1{
Search(grid,isSearch,i,j-1)
}
if j<len(grid[0])-1{
Search(grid,isSearch,i,j+1)
}
}else{
return
}
}
编辑回复: 感谢您参与春节七天练的活动，为了表彰你在活动中的优秀表现，赠送您99元专栏通用阅码，我们会在3个工作日之内完成礼品发放，如有问题请咨询小明同学，微信geektime002。

2019-02-14



molybdenum
island 我用的深搜，把所有的1探索，用visited保存访问过访问的，搜索次数便是岛屿个数
2019-02-11



小美
岛屿数Java实现
public int numIslands(char[][] grid) {
        int m = grid.length;
        if (m == 0) return 0;
        int n = grid[0].length;
        
        int ans = 0;
        for (int y = 0; y < m; ++y)
            for (int x = 0; x < n; ++x)
                if (grid[y][x] == '1') {
                    ++ans;
                    dfs(grid, x, y, n, m);
                }
        
        return ans;
    }
    
    private void dfs(char[][] grid, int x, int y, int n, int m) {
        if (x < 0 || y < 0 || x >= n || y >= m || grid[y][x] == '0')
            return;
        grid[y][x] = '0';
        dfs(grid, x + 1, y, n, m);
        dfs(grid, x - 1, y, n, m);
        dfs(grid, x, y + 1, n, m);
        dfs(grid, x, y - 1, n, m);
    }
编辑回复: 感谢您参与春节七天练的活动，为了表彰你在活动中的优秀表现，赠送您10元无门槛优惠券，我们会在3个工作日之内完成礼品发放，如有问题请咨询小明同学，微信geektime002。

2019-02-11



黄丹
已经初六啦，就快要到去学校的时间了，难受。
图的邻接矩阵表示法是使用一个二维数组int[0..n-1][0...n-1]来保存顶点和边的，对于无权图，1表示有边，0表示两个顶点没有变，有权图，值代表权重。
图的邻接表则是采用数组+链表的结构来表示的，数组里存的是顶点，链表存储的是边的信息，当然链表也可以换做二叉搜索树，散列表等高效查找的数据结构。
今天的两道leetcode题的解题思路和代码如下：
1. Number of Islands （岛屿的个数）
解题思路：遍历数组，遇到1时，使用深度/广度遍历，将连通的1都置为0，然后将岛屿个数加1.
代码：https://github.com/yyxd/leetcode/blob/master/src/leetcode/graph/Problem200_NumberofIslands.java
2. Valid Sudoku  （有效的数独）
解题思路：emm，不知道为什么这道题要放在图论的专题下，我的解法就是横着一行行判断，竖着一列列的判断，然后每个3*3的子块进行判断。没有用到图的知识。
代码：https://github.com/yyxd/leetcode/blob/master/src/leetcode/graph/Problem36_ValidSudoku.java
2019-02-10



虎虎❤️
基于临接表实现的联通分量求法， go 语言实现：
package graph_basics

type Components struct {
graph Graph
visited []bool
id []int
ccount int
}

func InitComponents(g Graph) *Components {
return &Components{
graph: g,
visited: make([]bool, g.V()),
id: make([]int, g.V()),
ccount: 0,
}
}

func (c *Components) dfs(index int) {
c.visited[index] = true
c.id[index] = c.ccount
adj := c.graph.Iterator(index)
for i := range adj {
if !c.visited[adj[i]] {
c.dfs(adj[i])
}
}
}

func (c *Components) CalculateComponents() {
for i := 0; i < c.graph.V(); i++ {
if c.visited[i] {
continue
}
c.dfs(i)
c.ccount++
}
}

func (c *Components) Count() int {
return c.ccount
}

func (c *Components) IsConnected(p int, q int) bool {
return c.id[p] == c.id[q]
}

临接表的实现：
package graph_basics

import "fmt"

type SparseGraph struct {
v int
e int
direct bool
g [][]int
}

func InitSparseGraph(n int, direct bool) *SparseGraph {
graph := make([][]int, n)
return &SparseGraph{
v: n,
e: 0,
direct: direct,
g: graph,
}
}

func (sg *SparseGraph) V() int {
return sg.v
}

func (sg *SparseGraph) E() int {
return sg.e
}

func (sg *SparseGraph) AddEdge(p int, q int) {
sg.g[p] = append(sg.g[p], q)
if !sg.direct {
sg.g[q] = append(sg.g[q], p)
}

sg.e++
}

func (sg *SparseGraph) HasEdge(p int, q int) bool {
for i := 0; i < len(sg.g[p]); i++ {
if sg.g[p][i] == q {
return true
}
}
return false
}

func (sg *SparseGraph) Show() {
for i := range sg.g {
fmt.Printf("vertex %d :\t", i)
for j := range sg.g[i] {
fmt.Printf("%d\t", sg.g[i][j])
}
fmt.Println()
}
}

func (sg *SparseGraph) Iterator(v int) []int {
return sg.g[v]
}
2019-02-10



你看起来很好吃
岛屿个数python实现(广度优先搜索算法)：
def numIslands(self, grid):
    if not grid:
        return 0
        
    count = 0
    for i in range(len(grid)):
        for j in range(len(grid[0])):
            if grid[i][j] == '1':
                self.dfs(grid, i, j)
                count += 1
    return count

def dfs(self, grid, i, j):
    if i<0 or j<0 or i>=len(grid) or j>=len(grid[0]) or grid[i][j] != '1':
        return
    grid[i][j] = '#'
    self.dfs(grid, i+1, j)
    self.dfs(grid, i-1, j)
    self.dfs(grid, i, j+1)
    self.dfs(grid, i, j-1)
2019-02-10



_CountingStars
有效的数独 go 语言实现
package main

import (
"fmt"
)

func hasRepeatedNumbers(numbers []byte) bool {
var numbersExistFlag [9]bool
for _, num := range numbers {
if num == '.' {
continue
}
index := num - '0' - 1
if numbersExistFlag[index] {
return true
}
numbersExistFlag[index] = true
}
return false
}

func isValidSudoku(board [][]byte) bool {
sudokuSize := 9
sudokuUnitSize := 3
for _, line := range board {
if hasRepeatedNumbers(line) {
return false
}
}

for columnIndex := 0; columnIndex < sudokuSize; columnIndex++ {
columnNumbers := make([]byte, 0)
for lineIndex := 0; lineIndex < sudokuSize; lineIndex++ {
columnNumbers = append(columnNumbers, board[lineIndex][columnIndex])
}
if hasRepeatedNumbers(columnNumbers) {
return false
}
}

sudokuUnitCountEachLine := sudokuSize / sudokuUnitSize
for i := 0; i < sudokuUnitCountEachLine; i++ {
for j := 0; j < sudokuUnitCountEachLine; j++ {
sudokuUnitNumbers := make([]byte, 0)
for _, line := range board[i*3 : (i+1)*3] {
sudokuUnitNumbers = append(sudokuUnitNumbers, line[j*3:(j+1)*3]...)
}

if hasRepeatedNumbers(sudokuUnitNumbers) {
return false
}
}
}

return true
}

func main() {
testData1 := [][]byte{
{'5', '3', '.', '.', '7', '.', '.', '.', '.'},
{'6', '.', '.', '1', '9', '5', '.', '.', '.'},
{'.', '9', '8', '.', '.', '.', '.', '6', '.'},
{'8', '.', '.', '.', '6', '.', '.', '.', '3'},
{'4', '.', '.', '8', '.', '3', '.', '.', '1'},
{'7', '.', '.', '.', '2', '.', '.', '.', '6'},
{'.', '6', '.', '.', '.', '.', '2', '8', '.'},
{'.', '.', '.', '4', '1', '9', '.', '.', '5'},
{'.', '.', '.', '.', '8', '.', '.', '7', '9'}}
fmt.Println(isValidSudoku(testData1))
}
编辑回复: 感谢您参与春节七天练的活动，为了表彰你在活动中的优秀表现，赠送您每日一课年度会员，我们会在3个工作日之内完成礼品发放，如有问题请咨询小明同学，微信geektime002。

2019-02-10



峰
island个数，从一个点从发，判断一个island的逻辑是如果本身点是water，那么必然不是island，如果是陆地，说明它能扩展成一个island，那么向上下左右进行扩展，然后再以扩展的陆地点又一直递归扩展，直到所有边界为0。而判断island的个数，就在此基础上去遍历所有点，并加上一个boolean[][]记录每个点是否已经被遍历或者扩展过。
2019-02-10



C_love
Valid Sudoku

class Solution {
    public boolean isValidSudoku(char[][] board) {
        for (int row = 0; row < 9; row++) {
            for (int col = 0; col < 9; col++) {
                if (board[row][col] == '.') continue;
                if (!isValid(board, row, col)) return false;
            }
        }
        return true;
    }
    
    private boolean isValid(char[][] board, final int row, final int col){
        char target=board[row][col];
        //check rows
        for (int i = 0; i < 9; i++) {
            if (i == row) continue;
            if (board[i][col] == target) return false;
        }
        
        //check cols
        for (int i = 0; i < 9; i++) {
            if (i == col) continue;
            if (board[row][i] == target) return false;
        }
        
        //check 3*3
        int rowStart = row / 3 * 3, colStart = col / 3 * 3;
        for (int i = rowStart; i < rowStart + 3; i++) {
            for (int j = colStart; j < colStart + 3; j++) {
                if (i == row && j == col) continue;
                if (board[i][j] == target) return false;
            }
        }
        
        return true;
    }
}
2019-02-10



ext4
有效的数独
class Solution {
  public:
    bool isValidSudoku(vector< vector<char> >& board) {
      set<char> numset;
      for (int i = 0; i < 9; i++) {
        numset.clear();
        for (int j = 0; j < 9; j++) {
          char val = board[i][j];
          if (val != '.') {
            if (numset.count(val) != 0) return false;
            numset.insert(val);
          }
        }
      }
      for (int j = 0; j < 9; j++) {
        numset.clear();
        for (int i = 0; i < 9; i++) {
          char val = board[i][j];
          if (val != '.') {
            if (numset.count(val) != 0) return false;
            numset.insert(val);
          }
        }
      }
      for (int i = 0; i < 3; i++) {
        for (int j = 0; j < 3; j++) {
          numset.clear();
          for (int p = 0; p < 3; p++) {
            for (int q = 0; q < 3; q++) {
              char val = board[i * 3 + p][j * 3 + q];
              if (val != '.') {
                if (numset.count(val) != 0) return false;
                numset.insert(val);
              }
            }
          }
        }
      }
      return true;
    }
};
编辑回复: 感谢您参与春节七天练的活动，为了表彰你在活动中的优秀表现，赠送您99元专栏通用阅码，我们会在3个工作日之内完成礼品发放，如有问题请咨询小明同学，微信geektime002。

2019-02-10


收起评论

1823






# 春节7天练 | Day 7：贪心、分治、回溯和动态规划




数据结构与算法之美
王争
前Google工程师
查看详情
59587 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

入门篇 (4讲)

基础篇 (38讲)

高级篇 (9讲)

43 | 拓扑排序：如何确定代码源文件的编译依赖关系？
44 | 最短路径：地图软件是如何计算出最优出行路径的？
45 | 位图：如何实现网页爬虫中的URL去重功能？
46 | 概率统计：如何利用朴素贝叶斯算法过滤垃圾短信？
47 | 向量空间：如何实现一个简单的音乐推荐系统？
48 | B+树：MySQL数据库索引是如何实现的？
49 | 搜索：如何用A*搜索算法实现游戏中的寻路功能？
50 | 索引：如何在海量数据中快速查找某个数据？
51 | 并行算法：如何利用并行处理提高算法的执行效率？
实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



春节7天练 | Day 7：贪心、分治、回溯和动态规划
王争 2019-02-10



00:34
讲述：修阳 大小：540.56K
你好，我是王争。今天是节后的第一个工作日，也是我们“春节七天练”的最后一篇。

几种算法思想必知必会的代码实现
回溯
利用回溯算法求解八皇后问题

利用回溯算法求解 0-1 背包问题

分治
利用分治算法求一组数据的逆序对个数
动态规划
0-1 背包问题

最小路径和（详细可看 @Smallfly 整理的 Minimum Path Sum）

编程实现莱文斯坦最短编辑距离

编程实现查找两个字符串的最长公共子序列

编程实现一个数据序列的最长递增子序列

对应的 LeetCode 练习题（@Smallfly 整理）
Regular Expression Matching（正则表达式匹配）
英文版：https://leetcode.com/problems/regular-expression-matching/

中文版：https://leetcode-cn.com/problems/regular-expression-matching/

Minimum Path Sum（最小路径和）
英文版：https://leetcode.com/problems/minimum-path-sum/

中文版：https://leetcode-cn.com/problems/minimum-path-sum/

Coin Change （零钱兑换）
英文版：https://leetcode.com/problems/coin-change/

中文版：https://leetcode-cn.com/problems/coin-change/

Best Time to Buy and Sell Stock（买卖股票的最佳时机）
英文版：https://leetcode.com/problems/best-time-to-buy-and-sell-stock/

中文版：https://leetcode-cn.com/problems/best-time-to-buy-and-sell-stock/

Maximum Product Subarray（乘积最大子序列）
英文版：https://leetcode.com/problems/maximum-product-subarray/

中文版：https://leetcode-cn.com/problems/maximum-product-subarray/

Triangle（三角形最小路径和）
英文版：https://leetcode.com/problems/triangle/

中文版：https://leetcode-cn.com/problems/triangle/

到此为止，七天的练习就结束了。这些题目都是我精选出来的，是基础数据结构和算法中最核心的内容。建议你一定要全部手写练习。如果一遍搞不定，你可以结合前面的章节，多看几遍，反复练习，直到能够全部搞定为止。

学习数据结构和算法，最好的方法就是练习和实践。我相信这在任何知识的学习过程中都适用。

最后，祝你工作顺利！学业进步！



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(28)

kai
听了老师的课程，第一遍的时候，只是在读，现在开始回顾：
课程相关的知识点，做了笔记：https://github.com/guokaide/algorithm/blob/master/summary/algorithm.md
课程涉及的题目，也在逐步总结当中：
https://github.com/guokaide/algorithm/blob/master/questions/questions.md

希望和大家一起进步，欢迎小伙伴们一起来讨论~
编辑回复: 感谢您参与春节七天练的活动，为了表彰你在活动中的优秀表现，赠送您99元专栏通用阅码，我们会在3个工作日之内完成礼品发放，如有问题请咨询小明同学，微信geektime002。

2019-02-11


5

kai
动态规划，感觉是面试必考内容，今天跟着这些题目再来复习一遍~
2019-02-11


3

kai
8皇后问题

public class EightQueen {

    private static final int QUEEN_NUMBER = 8; // 皇后个数
    private int[] columns = new int[QUEEN_NUMBER]; // 每个皇后存储的列 (row, col), row天然不相等
    private int total = 0;

    public int solution() {
        queen(0);
        return total;
    }

    private void queen(int row) {
        if (row == QUEEN_NUMBER) {
            total++;
        } else {
            for (int col = 0; col != QUEEN_NUMBER; col++) {
                columns[row] = col;
                if (isPut(row)) {
                    queen(row+1);
                }
            }
        }
    }

    private boolean isPut(int row) {
         for (int i = 0; i != row; i++) {
             if (columns[row] == columns[i] || row - i == Math.abs(columns[row]-columns[i])) {
                 return false;
             }
         }
         return true;
    }

}
2019-02-11


2

Richard
老师留的题都很不错，正在刷之前没做过的LeetCode题。
参与下答对三题送课程的活动:
Day 1：
1.求众数(Python)
class Solution:
    def majorityElement(self, nums):
        return sorted(nums)[len(nums) // 2]
2.缺失的第一个正数(Golang)
func firstMissingPositive(nums []int) int {
    if len(nums) == 0 {
return 1
}

var arr = make([]bool, len(nums)+1)
var idx = 1
for i := 0; i < len(nums); i++ {
if nums[i] >= 0 && nums[i] < len(arr) {
arr[nums[i]] = true
}
}

for i := 1; i < len(arr); i++ {
if arr[i] == false {
idx = i
break
} else {
idx = i + 1
}
}

return idx
}
Day 7:
3. 买卖股票的最佳时机(Python)
class Solution:
    def maxProfit(self, prices):
        if not prices:
            return 0
        min_price = prices[0]
        res = 0
        for i in prices[1:]:
            min_price = min(min_price, i)
            if res < i - min_price:
                res = i - min_price
        return res
编辑回复: 感谢您参与春节七天练的活动，为了表彰你在活动中的优秀表现，赠送您99元专栏通用阅码，我们会在3个工作日之内完成礼品发放，如有问题请咨询小明同学，微信geektime002。

2019-02-11


2

纯洁的憎恶
这冲刺压力有点大了😓
2019-02-10


2

黄丹
课程的最后一天，也是新年上班的第一天，感谢王老师的教育和陪伴，祝您生活开心，工作顺利。
今天的题目比前几天的都难一点，只做了三题，太累了TaT。对于动态规划和贪心总觉得很巧妙，如果想不到动态转移方程式，就很难做，但要是想到了，真的是豁然开朗。对于这一类题，还是要多锻炼，找动态转移方程式要从最后一个结果出发，去想这个结果可以由什么得到，知道之前所有结点的信息，如何推导出当前结点的信息，其实和高中学的归纳法有一点点像。
下面给出我今天做的三题的解题思路和代码
1. Problem 121. Best Time to Buy and Sell Stock
解题思路：这道题很久以前做的，我们可以维持两个变量 - 分别对应于最小谷值和最大利润（销售价格和最低价格之间的最大差异）的minprice 和maxprofit。
代码：https://github.com/yyxd/leetcode/blob/master/src/leetcode/array/easy/Problem121.java
2. Problem 120. Triangle
解题思路：这道题给一个由整数组成的三角形，自上而下寻找顶点到三角形边的最短的一条路径，设置一个数组A[0...n-1][0...n-1]，A[i][j]代表到达第i行第j列结点的最短路径 * DP转移方程式为：A[i][j]=min(A[i-1][j-1],A[i-1][j])+triangle[i][j] * 其中二维数组可以简化为一维数组，因为我们只需要上一行结点的信息 * 然后遍历到达最后一行的节点的路径，找到最短路径的值
代码：https://github.com/yyxd/leetcode/blob/master/src/leetcode/dp/Problem120_Triangle.java
3. Problem 322. Coin Change
解题思路：这道题是给定具有n个不同金额的硬币（硬币个数无限）coins[0...n-1]，给一个整数amount，是否给的硬币能正好达到整数，给出能组成整数最少需要的硬币个数. 解法是设置一个数组A[0...amount],进行初始化A[0]=0;A[1...amount] = -1;保存的是当给定金额为i时，所需要的最少的硬币。 * dp转移方程式为 A[k] = 1+min(A[k-coins[0]],A[k-coins[1]],....A[k-coins[n-1]]). * 这里要注意的是判断A[k]是否有解
代码：https://github.com/yyxd/leetcode/blob/master/src/leetcode/dp/Problem322_CoinChange.java
课程完结撒花，真的学到好多，自己以后还会反复回顾的，再次感谢王争老师，还有每天负责朗读的声音好好听的修阳小哥哥。
2019-02-11


1

李皮皮皮皮皮
每天一道算法题，风雨无阻（过年偷懒不算😛）
2019-02-11


1

_CountingStars
买卖股票的最佳时机 go 语言实现
package main

import "fmt"

func maxProfit(prices []int) int {
max := -1
for i := 0; i < len(prices); i++ {
for j := i + 1; j < len(prices); j++ {
profit := prices[j] - prices[i]
if profit > 0 && profit > max {
max = profit
}
}
}

if max == -1 {
return 0
}

return max
}

func main() {
testData1 := []int{7, 1, 5, 3, 6, 4}
testData2 := []int{7, 6, 4, 3, 1}

fmt.Println(maxProfit(testData1))
fmt.Println(maxProfit(testData2))
}
2019-02-11


1

明翼
请教下老师，遇到一个问题，给多个银行账号，假如每个账号每天都有交易，这样在坐标中可以画出时间和交易金额的曲线，求哪个曲线的更平滑或波动更大，银行账号的交易额度可能相差很大，银行账号交易梳理可能多个。
作者回复: 抱歉，这个我也不懂啊

2019-09-03



Hakon
老师，具体的是这样，比如物流公司，用户下单，需要根据最短路线或者最少花费来找出合适的中转路线。 比如需要送货到B城市，A城市发货，但是，很多路线，需要选最合适的路线，比如A到D中转再到E中转最后送货到B。
2019-07-10



Hakon
老师，请教下。关于物流中转路线，应该采用哪种算法合适？
作者回复: 麻烦说具体点吧 太笼统了

2019-07-10



Nereus
零钱兑换 - GO

func coinChange(coins []int, amount int) int {
var dp []int = make([]int, amount+1)
for _, record := range coins {
if amount >= record {
dp[record] = 1
}
}

for i := 1; i <= amount; i++ {
dp[i] = amount + 1
for _, record := range coins {
if i-record >= 0 {
dp[i] = min(dp[i-record]+1, dp[i])
}
}
}

if dp[amount] > amount {
return -1
}

return dp[amount]
}

func min(a, b int) int {
if a < b {
return a
}
return b
}

2019-02-19



拉欧
买卖股票的最佳时机 go 语言实现

func maxProfit(prices []int) int {

max:=0
for i:=0;i<len(prices);i++{
for j:=0;j<i;j++{
num:=prices[i]-prices[j]
if num>max{
max=num
}
}
}
return max
}
2019-02-15



拉欧
零钱兑换 go语言实现
func coinChange(coins []int, amount int) int {
    if amount==0{
return 0
}
if len(coins)==0 && amount!=0{
return -1
}

isSmall:=true
for _,coin:=range coins{
if coin<=amount{
isSmall=false
}
}
if isSmall{
return -1
}
grid:=make([]int,amount+1)


for _,coin:=range coins{
if coin<=amount{
grid[coin]=1
}
if coin==amount{
return 1
}
}
for i:=2;i<amount+1;i++{
newGrid:=make([]int,amount+1)
for j:=1;j<amount+1;j++{
for _,coin:=range coins{
if grid[j]==1 && j+coin<=amount{
newGrid[j]=1
newGrid[j+coin]=1
}
}
}
grid=newGrid
if grid[amount]==1{
return i
}
}
return -1
}
2019-02-15



拉欧
最小路径和 go实现

func minPathSum(grid [][]int) int {
    l:=len(grid)
w:=len(grid[0])
sum:=make([][]int,l)
for i:=0;i<l;i++{
sum[i]=make([]int,w)
}
sum[0][0]=grid[0][0]
for i:=1;i<w;i++{
sum[0][i]=grid[0][i]+sum[0][i-1]
}
for j:=1;j<l;j++{
sum[j][0]=grid[j][0]+sum[j-1][0]
}
for i:=1;i<l;i++{
for j:=1;j<w;j++{
sum[i][j]=less(sum[i-1][j],sum[i][j-1])+grid[i][j]
}
}

return sum[l-1][w-1]
}

func less(i,j int) int{
if i>j{
return j
}else{
return i
}
}
2019-02-15



拉欧
正则表达式匹配 go语言实现，还是看别人的提示搞出来的
func isMatch(s string, p string) bool {
    if len(p)==0{
if len(s)==0{
return true
}else{
return false
}
}
if len(p)==1{
if len(s)==1 && (s[0]==p[0] || p[0]=='.'){
return true
} else {
return false
}
}
if p[1]!='*'{
if len(s)==0{
return false
}
return (s[0]==p[0]||p[0]=='.') && isMatch(s[1:],p[1:])
}else{
for ;len(s)!=0 && (s[0]==p[0]||p[0]=='.');{
if isMatch(s,p[2:]){
return true
}
s=s[1:]
}
return isMatch(s,p[2:])
}



return true
}
2019-02-15



TryTs
//零钱兑换
#include<iostream>
#include<algorithm>
using namespace std;
int coins[10];
int amount;
int k;//k代表纸币的数目
int dp[20];//代表面值最大，也可以采用动态扩容的方式
int cmax = 32767;
int coinChange(int coins[],int amount){
for(int i = 1;i <= amount;i++){
dp[i] = cmax;
for(int j = 0;j < k;j++){
int t = coins[j];
if(i >= t && coins[i - t] != cmax){
dp[i] = min(dp[i - t] + 1,dp[i]);
}
}
}
if(dp[amount] < cmax && dp[amount] > 0){
return dp[amount];
}
else
return -1;
}
int main(){
k = 0;
while(true){
cin>>k;
for(int i = 0;i < k;i++){
cin>>coins[i];
}
cin>>amount;
cout<<coinChange(coins,amount)<<endl;
}
}
2019-02-14



TryTs
回溯0-1背包问题
#include<iostream>
using namespace std;
int v[10] = {2,2,4,6,3};
int M;//代表背包的容积
int n;
int cmax = 0;

void f(int w,int k){
// if(w == 0){
// if(w > max) max = w;
// }
if(w == M || k == n){
if(w > cmax) cmax = w;
return ;
}
f(w,k + 1);
if(w + v[k] <= M){
f(w + v[k],k + 1);
}
}
int main(){
//v[] = {2,2,4,6,3};
M = 9;
n = 5;
f(0,0);
cout<<cmax<<endl;
}
2019-02-14



TryTs
#include<iostream>
#include<cmath>
using namespace std;

int queen[100];
int sum = 0;
int n;
void Print(){
//cout<<"ss"<<endl;
for(int i = 0;i < n;i++){
cout<<"("<<i+1<<","<<queen[i] + 1<<")";
}
sum++;
cout<<endl;
}

void Queen(int queen[],int k){
if(k == n) {
Print();
//return ;
}
    int j = 0;
    for(int i = 0;i < n;i++){
     //j = i;
     for( j = 0;j < k;j++){
     if((queen[j] == i)||(abs(queen[j] - i) == abs(k - j)))
break;
}
if(j == k){
queen[k] = i;
Queen(queen,k+1);
}
}
}
int main(){
cin>>n;
Queen(queen,0);
cout<<sum<<endl;
}
2019-02-14



纯洁的憎恶
第一题，把39讲的代码改了一下。。。

public class Pattern {
  private boolean matched = false;
  private char[] pattern; // 正则表达式
  private int plen; // 正则表达式长度

  public Pattern(char[] pattern, int plen) {
    this.pattern = pattern;
    this.plen = plen;
  }

  public boolean match(char[] text, int tlen) { // 文本串及长度
    matched = false;
    if (pattern[0]='*')
           return matched;
   int i = 0;
   int j = 0;
   while (i<=plen&&j<=tlen&&pattern[i]!=text[j]&&pattern[i]!='.')
         i++;
    rmatch(0, 0, text, tlen);
    return matched;
  }

  private void rmatch(int ti, int pj, char[] text, int tlen) {
    if (matched) return; // 如果已经匹配了，就不要继续递归了
    if (ti == tlen){ //文本串到结尾了
      matched = true;
      return;
    }
    if (pattern[pj] == '*') { // * 匹配任意个字符
      for (int k = 0; k <= tlen-ti&&tex[ti+k]==text[ti]; ++k) {
        rmatch(ti+k, pj+1, text, tlen);
      }
    } else if (pattern[pj] == '.') { // . 匹配 0 个或者 1 个字符
      rmatch(ti, pj+1, text, tlen);
      rmatch(ti+1, pj+1, text, tlen);
    } else if (ti < tlen && pattern[pj] == text[ti]) { // 纯字符匹配才行
      rmatch(ti+1, pj+1, text, tlen);
    }
  }
}
2019-02-12


收起评论

2846





# 用户故事 | Jerry银银：这一年我的脑海里只有算法



数据结构与算法之美
王争
前Google工程师
查看详情
59587 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

入门篇 (4讲)

基础篇 (38讲)

高级篇 (9讲)

43 | 拓扑排序：如何确定代码源文件的编译依赖关系？
44 | 最短路径：地图软件是如何计算出最优出行路径的？
45 | 位图：如何实现网页爬虫中的URL去重功能？
46 | 概率统计：如何利用朴素贝叶斯算法过滤垃圾短信？
47 | 向量空间：如何实现一个简单的音乐推荐系统？
48 | B+树：MySQL数据库索引是如何实现的？
49 | 搜索：如何用A*搜索算法实现游戏中的寻路功能？
50 | 索引：如何在海量数据中快速查找某个数据？
51 | 并行算法：如何利用并行处理提高算法的执行效率？
实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



用户故事 | Jerry银银：这一年我的脑海里只有算法
Jerry银银 2019-02-13



08:20
讲述：修阳 大小：7.65M
比尔·盖茨曾说过：“如果你自以为是一个很好的程序员，请去读读 Donald E. Knuth 的《计算机程序设计艺术》吧……要是你真把它读下来了，就毫无疑问可以给我递简历了。”虽然比尔·盖茨推荐的是《计算机程序设计艺术》这本书，但是本质却折射出了算法的重要性。

大家好，我是 Jerry 银银，购买过算法专栏的同学应该时不时会看到我的留言！目前我是一名 Android 应用开发工程师，主要从事移动互联网教育软件的研发，坐标上海。

我为何要学算法？
细细想来，从毕业到现在，7 年多的时间，我的脑海里一直没有停止过思考这样一个问题：技术人究竟能够走多远，技术人的路究竟该如何走下去？相信很多技术人应该有同样的感受，因为技术的更新迭代实在是太快了，但是我心里明白：我得为长远做打算，否则，就算换公司、换工作，可能本质也不会有什么改变。

但是，我其实不太清楚自己到底应该往什么地方努力。于是，我翻阅了好多书籍，搜寻 IT 领域各种牛人的观点。多方比较之后，我终于决定，从基础开始，从计算机领域最基础、最重要的一门课开始。毫无疑问，这门课就是数据结构和算法。

我是如何遇见极客时间的？
既然找到了方向，那就开始吧。可是问题来了，从哪儿开始呢？大方向虽然有了，可是具体的实现细节还是得慢慢摸索。大学没怎么学，工作这么多年也没有刻意练习，起初我还真不知道从哪儿开始，只是买了本书，慢慢地啃，也找了一些简单的题目开始做。有过自学经历的同学，应该有同感吧？刚开始连单链表翻转这样简单的题都要折腾半天，真心觉得“痛苦”。

之前我在极客时间上订阅过“Java 核心技术 36 讲”，体会到了专栏和书本的不同。极客时间的专栏作者都是有着丰富的一线开发经验，能很好地把知识和实战结合在一起的大牛。这些课听起来非常爽。估计你应该经常跟我一样感叹：“哦！原来这些知识还可以这么使用！”当时我就在想，极客时间啥时候有一门算法课就好了。

说来真是巧，没多久，极客时间就推出了“数据结构与算法之美”。我试读了《为什么要学习数据结构和算法》和《数组：为什么很多编程语言中数组都从 0 开始编号？》这两篇之后，立即购买了。

到现在，专栏学完了，但是我依然记得，王争老师在《为什么要学习数据结构和算法》这篇文章里面提到的三句话，因为这每一句话都刺痛了我的小心脏！

第一句：业务开发工程师，你真的愿意做一辈子 CRUD Boy 吗？
第二句：基础架构研发工程师，写出达到开源水平的框架才是你的目标！
第三句：对编程还有追求？不想被行业淘汰？那就不要只会写凑合能用的代码！

我每天是怎么学专栏的？
于是，每天早上醒来，我的第一件事就是听专栏！专栏在每周的一、三、五更新，每周的这三天早上，我会听更新的文章。其它时间，我就听老的文章，当作复习。

听的过程，我一般会分这么几种情况。

第一种情况，更新的内容是我之前就已经学过的，基本已经掌握了的。这种情况下，听起来相对轻松点，基本上听一遍就够了。起床之后，再做一下老师给的思考题。这种情况在专栏的基础部分出现得比较多，像数组、链表、栈、队列、哈希表这些章节，我基本上都是这么过来的。

第二种情况，更新的内容是我学过的，但是还不太精通的。这种情况下，王争老师讲的内容都会将我的认知往前“推进”一步。顺利的话，我会在上班之前就搞懂今天更新的内容。这种情况是曾经没有接触过的内容，但是整体来说不难的理解的，比如跳表、递归等。

还有一种情况，就是听一遍不够，听完再看一遍也不行，上午上班之前也搞不定的。不过，我也不会急躁。我心里知道，我可能需要换换脑子，说不定，在上午工作期间，灵感会突然冒出来。这种情况一般出现在红黑树、字符串查找算法、动态规划这些章节。

到了中午休息时间，我会一个人在公司楼下转一圈，同样，还是听专栏、看专栏。

如果今天的文章，早上已经搞定了，我会重新看下其他同学的留言，看看其他同学是如何思考文章的课后思考题的，还有就是，我会看看其他同学学习过程中，会有哪些疑问，这些疑问自己曾经是否遇到过，现在是否已经完全解决了。

如果今天的文章，早上没有彻底搞懂，这种情况下，我会极力利用中午的时间去思考。

晚上的时间通常无法确定，我有时候会加班到很晚，回到家，再去啃算法，效率也不高。所以，我一般会在晚上“看”算法。为什么我会用双引号呢？是因为我真得只是“看”，目的就是加深印象。

以上基本是我工作日学专栏的“套路”。

等到了周末或者其它节假日，就是“打攻坚战”的时候了。估计很多上班族和我一样，只有周末才有大量集中思考的时间。这时候，我一般会通过做题来反向推动自己的算法学习。

像红黑树、Trie 树、递归、动态规划这些内容，我都是在周末和节假日搞懂的。虽然到现在对其中一些知识还不能达到游刃有余的地步，但是对一般的问题，大体上我都知道该如何抽象、如何拆解了。





我在学习算法时记的笔记
通过学习专栏，我有什么不一样的收获？
首先，专栏学习拓宽了我的知识面。例如，很多书本不讲的跳表，王争老师用了一篇文章来讲解。犹记得当我看完跳表时，心想，这么简单、易懂、高效的数据结构，为什么很多书籍都没有呢？这个专栏真的买值了！

其次，专栏的理论和实践结合很强。书籍是通用性很强的教材，一般很少会涉及软件系统是如何使用具体的数据结构和算法的。在专栏中，老师把对应的知识和实践相互结合，听起来特别过瘾！比如堆这种数据结构，理解起来不难，但是要用好它，还得下点功夫，经过老师一讲解，搭配音频，我的理解也变得更加深入了。

最后，专栏留言这个功能真的太好了，为自学带来了诸多便利，也让我获得了很多正向反馈。很多时候，经过相当长的一段时间思考，还是不能打通任督二脉，其实后来回想，当时就差那一层窗户纸了。于是，我在文末留下了自己的疑问，结果王争老师轻描淡写一句话我就明白了。

留言功能还有个非常大的好处。如果你用心学习，用心思考，用心留言，你的留言很大概率会被同伴点赞，很多时候还能被置顶。这本身就是一种正向反馈，也会更加促进自己的学习动力。还有一种更爽的体验，突然有一天早上，我照例醒来听专栏，突然听到了自己的名字。这个专栏 4 万多人订阅，老师居然记得我！可见王争老师真的认真看了每一条留言。

最后，我总结下自己学这个专栏的收获。尽管很多，但是我想用三句话来概括。

第一，写代码的时候，我会很自然地从时间和空间角度去衡量代码的优劣，时间、空间意识被加强了很多。

第二，学习算法的过程，有很多的“痛苦”，也正是因为这些“痛苦”，我学到了很多知识以外的东西。

第三，过程可能比知识更重要。要从过程中体会成长和精进的乐趣，而知识是附加产品！

专栏虽然结束，但是学习并没有结束。同学们，我们开头见！



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(27)

Jerry银银
今天的文章是我个人新年开工收到的最大红包
2019-02-13


218

吴庆
深有同感。 我也是一个毕业7年的嵌入式初级软件工程师，绕了一大圈才发现基础理论知识是何等重要。

吴军老师说过：
基础理论知识是一个人的基线，理论越强基线越高。再为自己定一个目标和向上攀附的阶梯，那么达到目标就是时间问题。
而很多野路子工程师搞了半辈子也未达到优秀工程师的基线。很多他们绞尽脑汁得出的高深学问，不过是正规工程师看起来很自然的东西。

关于工程师发展路线，或是成长阶段，吴军老师给出了一个参考(每一级能力相差一个数量级):
- 第五级： 能独立解决问题完成工程工作
  - 熟练应用工程知识和技能，无需他人指导，根据分配的需求完成任务。
- 第四级： 能指导和带领其他人一同完成更有影响力的工作
  - 根据大需求确立目标以及实现方式，并将解决方案进行分解，领导团队(分配、协调、沟通等)完成此目标
- 第三级： 能独立设计和实现产品，并且在市场上获得成功
  - 充分了解行业，提炼需求，并独立领导团队完成产品研发。随后可以将其量产化并营销至市场。
- 第二级： 能设计和实现别人不能做出的产品，具有不可替代性
  - 对行业有深入认知和独特见解，能够做出先前没有的产品，且别人无法复制。
- 第一级： 能开创一个产业
  - 站在科技最前沿，充分认识哪些科研成果已经成熟，在当前时代已经被满足，并将其产业化，形成巨大的生态链
2019-02-13


25

纯洁的憎恶
我本硕都是计算机专业，但工作却属于第二次工业革命就已经存在的传统工业领域。这几年，看着同学们在计算机领域一个接一个的实现财务自由，或在极客时间上开课，我深深的感到被时代抛弃了。同时也慢慢发现选择有时候真的比很多自己过去重视的东西更重要，而且没得选很可能也是一种优势。回去是不可能了，以我的年纪与天赋，很难带着数年的劣势去和新一代的工程师竞争。本应置身浪潮之中，却在智能时代掉队，既令人遗憾，也使人恐惧。

下面的路该怎么走？这是无论多么焦虑都要面对的问题。智能时代是变革的时代，在新生产力的驱动下，一些旧业态将被淘汰，新产业出现，还有一些传统产业被重新塑造、如虎添翼。投身于最新生产力的创造，无遗更机会成为时代的弄潮儿。然而，使新生产力迸发出最惊人创造力的场景，往往是在与传统产业的结合上。第一次工业革命的“蒸汽机+传统产业”，第二次工业革命的“发电机+传统产业”，二战后信息革命的“电子化+传统产业”，本世纪初的“互联网+传统产业”，以及当下的“机器智能+传统产业”，都成为或将成为人类文明加速腾飞的推进器。也许这是我的选择被赋予的新使命，当然它需要千万人的共同努力。新的时代已经来临，无论我们愿不愿意。在这个时代，我们可以做技术的主人，可以做技术的仆人，也可以做“隐身人”，但唯独不能站在技术的对立面。我不能做技术的敌人，也不想做“隐身人”，那么我就要同技术站在一起。

从哪里开始？单纯的写写Java和Python代码，也许可以建立与智能时代联系，但它难以建立宏观、深刻、系统的时代体感。我认为要从最根本的地方入手，直接切入这个时代的“第一性原理”，也就是机器智能的“第一性原理”。算法与数据结构是机器的思维方式，依旧是智能时代的灵魂，这里应该是我再出发的起点。相应的还有计算机体系结构、计算机网络、操作系统，以及有关的数学知识体系。然而这些知识我在学校都学过，仅仅再回忆一遍就可以吗？不，这远远不够。因为我需要更系统的学习，需要知道这些知识在工业界的最新进展与实践，需要把这些知识连接到更广泛的行业领域中举一反三，需要能够判断哪些任务适合交给机器而哪些还不能，需要引发更多有价值的深入思考……很幸运我遇到了极客时间。

带着问题学习、用学到的知识解决实际问题，是最高效的学习方法。记得在学校学习算法与数据结构的时候，我实在无法理解这些反直觉的机器逻辑，能够理解的知识点非常有限，更不用说形成完备知识体系了。更可惜的是，那时心浮气躁，没有沉下心由浅入深，却靠疯狂做题刷存在感，以题量衡量学习水平，实则是狗熊掰棒子、只见树木不见森林，更很少能与工业场景建立联系。走出校园后没有优质的学习环境，缺乏有效学习渠道，再想“补课”就难了。极客时间提供了比较优质的环境与渠道，降低了领域间的信息门槛，使我能够接触到一线工程师与技术人员的新视角，与工业界建立一定的联系。在这里计算机知识不是数字游戏与考试题，而是一个个真实的工程问题，有助于引导建立时代体感。

师傅领进门修行在个人。然而想学好算法与数据结构，乃至于达到个人目标，仅仅啃一遍王争老师的课是远远不够的。这是一个很好的开始，它很重要，但也只是一个开始，后面的路还要靠自己。这个时代没有地图，也没有路标，只有广阔的天地和一块指南针。那么就从更多的接触、更加系统的学习、更加深入的思考，以及第二遍阅读《算法与数据结构之美》开始吧。
2019-02-13


21

广洲
我也是通过Jerry银银的分享购买的专栏，我目前是在自学，刚起步的，学习的很痛苦、很吃力。但相对培训班那两万块的学费，我们这个专栏太值了。感谢王老师，感谢Jerry银银。
2019-02-13


7

lianlian
王争老师早上好啊，我第一个订阅的极客时间专栏就是数据结构与算法之美，看到第一篇中您写着“基础知识就像是一座大楼的地基，它决定了我们技术的高度”，我感到很惊喜，两年多前我也跟人说过“基础不是100分考60分，而是建摩天大楼的地基。”哈哈(ಡωಡ)hiahiahia 我是2018年11月11号晚上吧知道这个专栏，当天信号不好，我等到凌晨一点多购买成功后，迫不及待听了2节课才睡觉。王争老师的专栏太棒了，内容价值远超价格。走路，吃饭，空闲，学而时习之，勤加练习，不亦乐乎！感谢王争老师的分享o(^o^)o
2019-02-13


4


我还以为我真太差了，看到你是安卓工程师，我就放心了😂😂
2019-02-13

2

3

abner
半年时间过去了，我也是开始掉队的那一批，中后期开始慢慢赶上进度，虽然只是浏览了一遍，之后到现在开始从头仔细看，也结合着必知必会的30道题进行练习，感觉效果还是有的，接下来会投入更多的时间学习专栏，立个小目标：这周把必知必会30题做完，在2月底把专栏至少刷3遍。
另，老师开设这么好的一个专栏，真的谢谢!
2019-02-13


3

sakura
看到前辈们的文章感触很多，自己是一个大三安卓开发，学校课基本上不咋听，上学期在百度实习，现在准备阿里面试，但是面试时候全问我的都是操作系统编译原理数据结构比较多，自己觉得老师这门课讲的很好，真的是循序渐进，有时候自己偷懒没看，就堆了一大堆课现在边准备面试继续复习老师的课，很谢谢老师和那些在留言区总结知识的人。
2019-02-13


2

zixuan
厉害厉害，非常扎实。另外你的字写得好😄。
2019-02-13


2

aguan(^･ｪ･^)
谢谢老师。谢谢Jerry的分享。
2019-02-13


2

融梨
学习跟年龄无关，最开始跑不一定赢。让我想起《几何原本》的五个公理，在各个领域借鉴它的思想。
2019-04-09


1

Michael
这门课程是从去年十一月份买的，当时买了之后就发现非常值，讲的不枯燥，都能听的进去，就拿堆这个数据结构来说，我自己练习了真的至少有十几遍了，而且做LeetCode题目的时候，我自己都避免使用类库，每次自己都是手动实现一个堆自己用。我个人一般每篇文章会看两遍，难一点的例如红黑树，动态规划，回溯，分支会反复的看，做题，体会个中道理，感谢老师的专栏
2019-02-21


1

Zoctopus
在大学期间断断续续的学习了算法，参加了一些编程竞赛。本科毕业半年，在部门内算法老哥的指导下逐渐体会它在项目中的实际用途和神奇之处。
《数据结构和算法之美》是我在极客订阅的第一个专栏，我个人觉得看专栏和书的区别是——看书是一个人在看，而专栏里有老师的答疑，用户的相互探讨，集思广益。
半年时间过得很快，虽然专栏里的文章已经看过大半，但老师列出的课后练习和算法实战还没有完全掌握，专栏里的文章我仍需多次阅读。
谢谢老师！
2019-02-13


1

Anker
笔记做的漂亮呀
2019-02-13


1

$Jason
我也是掉队的那一批，学到20几的时候还是有点吃力，感觉之前学的都忘了，就又回头学，但是还是在排序那边绕的我很晕，学习很受挫。但是我不放弃，接着学。
2019-02-13


1

🎸 风筝
以前大学学习学得糊里糊涂的，工作后看了一些书但都只是掌握些皮毛，从来没有感觉能像这个专栏一样让我感觉那么清晰，老师太棒了，让我建立了自信心。
2019-07-16



涛涛
字写的漂亮，见字识人。
2019-03-30



vate
庆幸我在初步接触工作时能意识到底层基础原理得重要性，希望这能让我走得更远一点叭hhhh
2019-03-13



Being
感谢分享，在专栏上掉队了，但一直跟着自己的步伐在走，夯实基础
2019-02-18



木之乃禾
我才开始学，感谢各位在章节留言里留下的leetcode题号。😄大家共同进步。
2019-02-14


收起评论

2752






# 用户故事 | zixuan：站在思维的高处，才有足够的视野和能力欣赏“美”



数据结构与算法之美
王争
前Google工程师
查看详情
59587 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

入门篇 (4讲)

基础篇 (38讲)

高级篇 (9讲)

43 | 拓扑排序：如何确定代码源文件的编译依赖关系？
44 | 最短路径：地图软件是如何计算出最优出行路径的？
45 | 位图：如何实现网页爬虫中的URL去重功能？
46 | 概率统计：如何利用朴素贝叶斯算法过滤垃圾短信？
47 | 向量空间：如何实现一个简单的音乐推荐系统？
48 | B+树：MySQL数据库索引是如何实现的？
49 | 搜索：如何用A*搜索算法实现游戏中的寻路功能？
50 | 索引：如何在海量数据中快速查找某个数据？
51 | 并行算法：如何利用并行处理提高算法的执行效率？
实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



用户故事 | zixuan：站在思维的高处，才有足够的视野和能力欣赏“美”
zixuan 2019-02-15



12:35
讲述：修阳 大小：11.53M
大家好，我是 zixuan，在一家国内大型互联网公司做后端开发，坐标深圳，工作 5 年多了。今天和大家分享一下，我学习专栏的一些心得体会。

随着年龄的增长，我经历了不少业务、技术平台、中间件等多种环境和编程工具的迭代变更。与此同时，我越来越意识到，要做一名优秀的程序员，或者说，能够抵御年龄增长并且增值的程序员，有两样内功是必须持续积累的，那就是软件工程经验方法和算法应用能力。

通俗地讲，就是不论在什么系统或业务环境下、用什么编程工具，都能写出高质量、可维护、接口化代码的能力，以及分解并给出一个实际问题有效解决方案的能力。

我为什么会订阅这个专栏？
这也是为什么我在极客时间上看到王争老师的“数据结构与算法之美”的开篇词之后，果断地加入学习行列。同时，我也抱有以下两点期望。

第一，这个专栏是从工程应用，也就是解决实际问题的角度出发来讲算法的，原理和实践相辅相成，现学现用，并且重视思考过程。从我个人经验来看，这的确是比较科学的学习方法。我相信很多人和我一样，以前在学校里都学过算法，不过一旦不碰书了，又没有了应用场景后，很快就把学过的东西丢了，重新拾起来非常困难。

第二，从专栏的标题看出，王争老师试图带我们感受算法的“美”，那必将要先引导我们站在思维的高处，这样才有足够的视野和能力去欣赏这种“美”。我很好奇他会怎么做，也好奇我能否真正地改变以前的认知，切身地感受到“美”。

我是如何学习这个专栏的？
就这样，同时带着笃定和疑问，我上路了。经过几个月的认真学习，“数据结构与算法之美”成了我在极客时间打开次数最多，花费时间最多，完成度也最高的一门课。尽管如此，我觉得今后我很可能还会再二刷、多刷这门课，把它作为一个深入学习的索引入口。 接下来，我就从几个方面，跟你分享下，这半年我学习这个专栏的一些感受和收获。

1. 原理和实用并重：从实践中总结，应用到实践中去
学习的最终目的是为了解决实际问题，专栏里讲的很多方法甚至代码，都能够直接应用到大型项目中去，而不仅仅是简单的原理示例。

比如王争老师在讲散列表的时候，讲了实现一个工业级强度的散列表有哪些需要注意的点。基本上面面俱到，我在很多标准库里都找到了印证。再比如，老师讲的 LRU Cache、Bloom Filter、范围索引上的二分查找等等，也基本和我之前阅读 LevelDB 源代码时，看到的实现细节如出一辙，无非是编程语言的差别。

所以，看这几部分的时候，我觉得十分惊喜，因为我经历过相关的实际应用场景。反过来，专栏这种原理和实用并重的风格，也能帮助我今后在阅读开源代码时提升效率、增进理解。

另外，我觉察到，文章的组织结构，应该也是老师试图传达给我们的“他自己的学习方法”：从开篇介绍一个经典的实际问题开始（需求），到一步步思考引导（分析），再到正式引出相关的数据结构和算法（有效解决方案），再将其应用于开篇问题的解决（实现、测试），最后提出一个课后思考题（泛化、抽象、交流、提升）。

这个形式其实和解决实际工程问题的过程非常类似。我想，大部分工程师就是在一个个这样的过程中不断积累和提升自己的，所以我觉得这个专栏，不论是内容还是形式真的都很赞。



2. 学习新知识的角度：体系、全面、严谨、精炼，可视化配图易于理解
“全面”并不是指所有细节面面俱到。事实上，由于算法这门学科本身庞大的体量，这类专栏一般只能看作一个丰富的综述目录，或者深入学习的入口。尽管如此，王争老师依然用简洁精炼的语言 Cover 到了几乎所有最主要的数据结构和算法，以及它们背后的本质思想、原理和应用场景，知识体系结构全面完整并自成一体。

我发现只要能紧跟老师的思路，把每一节的内容理解透彻，到了语言实现部分，往往变成了一种自然的总结描述，所以代码本身并不是重点，重点是背后的思路。

例如，KMP 单模式串匹配和 AC 自动机多模式串匹配算法是我的知识盲区。以前读过几次 KMP 的代码，都没完全搞懂，于是就放弃了。至于 AC 自动机，惭愧地说，我压根儿就没怎么听说过。

但是，在专栏里，王争老师从 BruteForce 方法讲起，经过系统的优化思路铺垫，通俗的举例，再结合恰到好处的配图，最后给出精简的代码。我跟随着老师一路坚持下来，当我看到第二遍时突然就豁然开朗了。而当我真正理解了 AC 自动机的构建和工作原理之后，在某一瞬间，我的内心的确生出了一种美的感觉（或者更多的是“妙”吧？）。

AC 自动机构建的代码，让我不自觉地想到“编织”这个词。之前还觉得凌乱的、四处喷洒的指针，在这里一下子变成了一张有意义的网，编织的过程和成品都体现出了算法的巧妙。这类联想无疑加深了我对这类算法的理解，也许这也意味着，我可以把它正式加入到自己的算法工具箱里了。

另外一个例子是动态规划。以前应用 DP 的时候，我常常比较盲目，不知道怎么确定状态的表示，甚至需要几维的状态都不清楚，可以说是在瞎猜碰运气。经过老师从原理到实例的系统讲解后，我现在明白，原来 DP 本质上就是在压缩重复子问题，状态的定义可以通过最直接的回溯搜索来启发确定。明白这些之后，动态规划也被我轻松拿下了。

3. 已有知识加深的角度：促进思考，连点成线
之前看目录的时候，我发现专栏里包含了不少我已经知道的知识。但真正学习了之后，我发现，以前头脑中的不少概念知识点，是相对独立存在的，基本上一个点就对应固定的那几个场景，而在专栏里，王争老师比较注重概念之间的相互关联。对于这些知识，经过王争老师的讲解，基本可以达到交叉强化理解，甚至温故知新的效果。

比如老师会问你，在链表上怎么做二分查找？哈希和链表为什么经常在一起出现？这些问题我之前很少会考虑到，但是当我看到的时候，却启发出很多新的要点和场景（比如 SkipList、LRUCache）。

更重要的是，跟着专栏学习一段时间之后，我脑中原本的一些旧概念，也开始自发地建立起新的连接，连点成线，最后产生了一些我之前从未注意到的想法。

举个感触最深的例子。在跟随专栏做了大量递归状态跟进推演，以及递归树分析后，我现在深刻地认识到，递归这种编程技巧背后，其实是树和堆栈这两种看似关联不大的数据结构。为什么这么说呢？

堆栈和树在某个层面上，其实有着强烈的对应关系。我刚接触递归的时候，和大多数初学者一样，脑子很容易跟着机器执行的顺序往深里绕，就像 Debug 一个很深的函数调用链一样，每遇到一个函数就 step into，也就是递归函数展开 -> 下一层 -> 递归函数展开 -> 下一层 ->…，结果就是只有“递”，没有“归”，大脑连一次完整调用的一半都跑不完（或者跑完一次很辛苦），自然就会觉得无法分析。如下图，每个圈代表在某一层执行的递归函数，向下的箭头代表调用并进入下一层。



我初学递归时遇到的问题：有去无回，陷得太深
随着我处理了越来越多的递归，我慢慢意识到，为什么人的思考一定要 follow 机器的执行呢？在递归函数体中，我完全可以不用每遇到递归调用都展开并进入下一层（step into），而是可以直接假定下一层调用能够正确返回，然后我该干嘛就继续干嘛（step over），这样的话，我只需要保证最深一层的逻辑，也就是递归的终止条件正确即可。

原因也很简单，不管在哪一层，都是在执行递归函数这同一份代码，不同的层只有一些状态数据不同而已，所以我只需要保证递归函数代码逻辑的正确性，就确保了运行时任意一层的结果正确性。像这样说服自己可以随时 step over 后，我的大脑终于有“递”也有“归”了，后续事务也就能够推动了。



有一定经验后我如何思考递归：有去有回，自由把握
最近在学习这门课程的过程中，我进一步认识到，其实上面两个理解递归的方式，分别对应递归树的深度遍历和广度遍历。尽管机器只能按照深度优先的方式执行递归代码，但人写递归代码的时候更适合用广度的思考方式。当我在实现一个递归函数的时候，其实就是在确定这棵树的整体形状：什么时候终止，什么条件下生出子树，也就是说我实际上是在编程实现一棵树。

那递归树和堆栈又有什么关系呢？递归树中从根节点到树中任意节点的路径，都对应着某个时刻的函数调用链组成的堆栈。递归越深的节点越靠近栈顶，也越早返回。因而我们可以说，递归的背后是一棵树，递归的执行过程，就是在这棵树上做深度遍历的过程，每次进入下一层（“递”）就是压栈，每次退出当前层（“归”）就是出栈。所有的入栈、出栈形成的脉络就组成了递归树的形态。递归树是静态逻辑背景，而当前活跃堆栈是当前动态运行前景。



学完专栏后我怎么看待递归：胸有成“树”，化动为静
这样理解之后，编写或阅读递归代码的时候，我真的能够站得更高，看得更全面，也更不容易掉入一些细节陷阱里去了。

说到这里，我想起之前在不同时间做过的两道题，一道是计算某个长度为 n 的入栈序列可以有多少种出栈序列，另一道是计算包含 n 个节点的二叉树有多少种形状。我惊讶地发现，这两个量竟然是相等的（其实就是卡特兰数）。当时我并不理解为什么栈和树会存在这种关联，现在通过类似递归树的思路我觉得我能够理解了，那就是每种二叉树形状的中序遍历都能够对应上一种出栈顺序。

类似这样“旧知识新理解”还有很多，尽管专栏里并没有直接提到，但是这都是我跟随专栏，坚持边学边思考，逐步感受和收获的。

总结
基于以上谈的几点收获和感受，我再总结下我认为比较有用的、学习这个专栏的方法。

1. 紧跟老师思路走，尽量理解每一句话、每一幅配图，亲手推演每一个例子。

王争老师语言精炼。有些文字段落虽短，但背后的信息量却很大。为了方便我们理解，老师用了大量的例子和配图来讲解。即便是非常复杂、枯燥的理论知识，我们理解起来也不会太吃力。

当然有些地方确实有点儿难，这时我们可以退而求其次，“先保接口，再求实现”。例如，红黑树保持平衡的具体策略实现，我跟不下来，就暂时跳过去了，但是我只要知道，它是一种动态数据的高效平衡树，就不妨碍我先使用这个工具，之后再慢慢理解。

2. 在学的过程中回顾和刷新老知识点，并往工程实践上靠。学以致用是最高效的方法。

3. 多思考，思考比结果重要；多交流，亲身感受和其他同学一起交流帮助很大。

最后，感谢王争老师和极客时间，让我在这个专栏里有了不少新收获。祝王争老师事业蒸蒸日上，继续开创新品，也希望极客时间能够联合更多的大牛老师，开发出更多严谨又实用的精品课程！



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(15)

zixuan
感谢争哥和极客时间，收获很大～ 另外用一句话和大家共勉：人与人最小的差距在智商，最大的差距在坚持。一起加油💪
2019-02-15


78

Jerry银银
喜欢那段「递归」的描述，点赞！
2019-02-15


19

三木子
对递归的理解很有启发
2019-02-15


11


感谢大佬分享。看到你们有多年工作经验的人也学习不容易，我一学生也就不太慌了😂，一遍不会就多来几次。我做three sum都得好长时间
2019-02-15


5

小喵喵
王争老师：你好，我学这个专栏学到一半就被掉队了，原因是实在太难了，学不下去。加上自己的从事的工作还是业务工程师（CRUD Boy），又加上自己的大龄码农（10多年了，都35了）。今天又燃起了我的学习热情，不知道是不是又是三天打两天嗮网。像我这样的大龄码农，还要必要学这个吗？还来得及学这个吗？感觉自己前途一片渺茫，请老师指点迷津。谢谢。
作者回复: 可以读读这个文章 看对你有启发吗

https://mp.weixin.qq.com/s/t8z4KQMrTrR3NljtWJm2zg

2019-08-28


1

老王的老李头
栈和树那个很有意思
2019-04-26


1

杨锐
原来大家和我一样，在刚开始理解递归的时候，都被嵌套调用细节绕进去了
2019-02-16


1

纯洁的憎恶
上学的时候觉得递归、回溯、动态规划是最反直觉的，后来发现递归可以通过树、BFS+栈很好的转化为人更容易理解的样子。但是回溯与动态规划，我一直没有找到很好的理解方法，个人认为这还是需要大量的实践去满满体会。
2019-02-16


1

Liam
赞，我是通过数学归纳法的思想来理解递归，我们只需要考虑初始状态，并假定上一个状态已经确定的情况下，如何实现当前状态即可
2019-02-15


1

陈鹏
这是最后一期吗？
2019-02-15


1

谭小谭
数据结构与算法这门课对我有很大的帮助。
2019-02-15


1

🎸 风筝
老师，这个有没有纸质版的，想收藏，哈哈！以后可以随时翻翻
2019-07-16



jackie
总结写的很👍，自己的理解自成一体！
2019-03-26



Sharry
对递归的思考很深入，感谢分享
2019-03-04



halo
帮助了我理解递归
2019-02-16


收起评论

1555






# 总结课 | 在实际开发中，如何权衡选择使用哪种数据结构和算法？



数据结构与算法之美
王争
前Google工程师
查看详情
59587 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

入门篇 (4讲)

基础篇 (38讲)

高级篇 (9讲)

43 | 拓扑排序：如何确定代码源文件的编译依赖关系？
44 | 最短路径：地图软件是如何计算出最优出行路径的？
45 | 位图：如何实现网页爬虫中的URL去重功能？
46 | 概率统计：如何利用朴素贝叶斯算法过滤垃圾短信？
47 | 向量空间：如何实现一个简单的音乐推荐系统？
48 | B+树：MySQL数据库索引是如何实现的？
49 | 搜索：如何用A*搜索算法实现游戏中的寻路功能？
50 | 索引：如何在海量数据中快速查找某个数据？
51 | 并行算法：如何利用并行处理提高算法的执行效率？
实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



总结课 | 在实际开发中，如何权衡选择使用哪种数据结构和算法？
王争 2019-02-18



12:25
讲述：修阳 大小：11.38M
你好，我是王争，今天是一篇总结课。我们学了这么多数据结构和算法，在实际开发中，究竟该如何权衡选择使用哪种数据结构和算法呢？今天我们就来聊一聊这个问题，希望能帮你把学习带回实践中。

我一直强调，学习数据结构和算法，不要停留在学院派的思维中，只把算法当作应付面试、考试或者竞赛的花拳绣腿。作为软件开发工程师，我们要把数据结构和算法，应用到软件开发中，解决实际的开发问题。

不过，要想在实际的开发中，灵活、恰到好处地应用数据结构和算法，需要非常深厚的实战经验积累。尽管我在课程中，一直都结合实际的开发场景来讲解，希望带你真枪实弹的演练算法如何解决实际的问题。但是，在今后的软件开发中，你要面对的问题远比我讲的场景要复杂、多变、不确定。

要想游刃有余地解决今后你要面对的问题，光是熟知每种数据结构和算法的功能、特点、时间空间复杂度，还是不够的。毕竟工程上的问题不是算法题。算法题的背景、条件、限制都非常明确，我们只需要在规定的输入、输出下，找最优解就可以了。

而工程上的问题往往都比较开放，在选择数据结构和算法的时候，我们往往需要综合各种因素，比如编码难度、维护成本、数据特征、数据规模等，最终选择一个工程的最合适解，而非理论上的最优解。

为了让你能做到活学活用，在实际的软件开发中，不生搬硬套数据结构和算法，今天，我们就聊一聊，在实际的软件开发中，如何权衡各种因素，合理地选择使用哪种数据结构和算法？关于这个问题，我总结了六条经验。

1. 时间、空间复杂度不能跟性能划等号
我们在学习每种数据结构和算法的时候，都详细分析了算法的时间复杂度、空间复杂度，但是，在实际的软件开发中，复杂度不能与性能简单划等号，不能表示执行时间和内存消耗的确切数据量。为什么这么说呢？原因有下面几点。

复杂度不是执行时间和内存消耗的精确值

在用大 O 表示法表示复杂度的时候，我们会忽略掉低阶、常数、系数，只保留高阶，并且它的度量单位是语句的执行频度。每条语句的执行时间，并非是相同、确定的。所以，复杂度给出的只能是一个非精确量值的趋势。

代码的执行时间有时不跟时间复杂度成正比

我们常说，时间复杂度是 O(nlogn) 的算法，比时间复杂度是 O(n^2) 的算法，执行效率要高。这样说的一个前提是，算法处理的是大规模数据的情况。对于小规模数据的处理，算法的执行效率并不一定跟时间复杂度成正比，有时还会跟复杂度成反比。

对于处理不同问题的不同算法，其复杂度大小没有可比性

复杂度只能用来表征不同算法，在处理同样的问题，以及同样数据类型的情况下的性能表现。但是，对于不同的问题、不同的数据类型，不同算法之间的复杂度大小并没有可比性。

2. 抛开数据规模谈数据结构和算法都是“耍流氓”
在平时的开发中，在数据规模很小的情况下，普通算法和高级算法之间的性能差距会非常小。如果代码执行频率不高、又不是核心代码，这个时候，我们选择数据结构和算法的主要依据是，其是否简单、容易维护、容易实现。大部分情况下，我们直接用最简单的存储结构和最暴力的算法就可以了。

比如，对于长度在一百以内的字符串匹配，我们直接使用朴素的字符串匹配算法就够了。如果用 KMP、BM 这些更加高效的字符串匹配算法，实际上就大材小用了。因为这对于处理时间是毫秒量级敏感的系统来说，性能的提升并不大。相反，这些高级算法会徒增编码的难度，还容易产生 bug。

3. 结合数据特征和访问方式来选择数据结构
面对实际的软件开发场景，当我们掌握了基础数据结构和算法之后，最考验能力的并不是数据结构和算法本身，而是对问题需求的挖掘、抽象、建模。如何将一个背景复杂、开放的问题，通过细致的观察、调研、假设，理清楚要处理数据的特征与访问方式，这才是解决问题的重点。只有理清楚了这些东西，我们才能将问题转化成合理的数据结构模型，进而找到满足需求的算法。

比如我们前面讲过，Trie 树这种数据结构是一种非常高效的字符串匹配算法。但是，如果你要处理的数据，并没有太多的前缀重合，并且字符集很大，显然就不适合利用 Trie 树了。所以，在用 Trie 树之前，我们需要详细地分析数据的特点，甚至还要写些分析代码、测试代码，明确要处理的数据是否适合使用 Trie 树这种数据结构。

再比如，图的表示方式有很多种，邻接矩阵、邻接表、逆邻接表、二元组等等。你面对的场景应该用哪种方式来表示，具体还要看你的数据特征和访问方式。如果每个数据之间联系很少，对应到图中，就是一个稀疏图，就比较适合用邻接表来存储。相反，如果是稠密图，那就比较适合采用邻接矩阵来存储。

4. 区别对待 IO 密集、内存密集和计算密集
如果你要处理的数据存储在磁盘，比如数据库中。那代码的性能瓶颈有可能在磁盘 IO，而并非算法本身。这个时候，你需要合理地选择数据存储格式和存取方式，减少磁盘 IO 的次数。

比如我们在递归那一节讲过最终推荐人的例子。你应该注意到了，当时我给出的代码尽管正确，但其实并不高效。如果某个用户是经过层层推荐才来注册的，那我们获取他的最终推荐人的时候，就需要多次访问数据库，性能显然就不高了。

不过，这个问题解决起来不难。我们知道，某个用户的最终推荐人一旦确定，就不会变动。所以，我们可以离线计算每个用户的最终推荐人，并且保存在表中的某个字段里。当我们要查看某个用户的最终推荐人的时候，访问一次数据库就可以获取到。

刚刚我们讲了数据存储在磁盘的情况，现在我们再来看下，数据存储在内存中的情况。如果你的数据是存储在内存中，那我们还需要考虑，代码是内存密集型的还是 CPU 密集型的。

所谓 CPU 密集型，简单点理解就是，代码执行效率的瓶颈主要在 CPU 执行的效率。我们从内存中读取一次数据，到 CPU 缓存或者寄存器之后，会进行多次频繁的 CPU 计算（比如加减乘除），CPU 计算耗时占大部分。所以，在选择数据结构和算法的时候，要尽量减少逻辑计算的复杂度。比如，用位运算代替加减乘除运算等。

所谓内存密集型，简单点理解就是，代码执行效率的瓶颈在内存数据的存取。对于内存密集型的代码，计算操作都比较简单，比如，字符串比较操作，实际上就是内存密集型的。每次从内存中读取数据之后，我们只需要进行一次简单的比较操作。所以，内存数据的读取速度，是字符串比较操作的瓶颈。因此，在选择数据结构和算法的时候，需要考虑是否能减少数据的读取量，数据是否在内存中连续存储，是否能利用 CPU 缓存预读。

5. 善用语言提供的类，避免重复造轮子
实际上，对于大部分常用的数据结构和算法，编程语言都提供了现成的类和函数实现。比如，Java 中的 HashMap 就是散列表的实现，TreeMap 就是红黑树的实现等。在实际的软件开发中，除非有特殊的要求，我们都可以直接使用编程语言中提供的这些类或函数。

这些编程语言提供的类和函数，都是经过无数验证过的，不管是正确性、鲁棒性，都要超过你自己造的轮子。而且，你要知道，重复造轮子，并没有那么简单。你需要写大量的测试用例，并且考虑各种异常情况，还要团队能看懂、能维护。这显然是一个出力不讨好的事情。这也是很多高级的数据结构和算法，比如 Trie 树、跳表等，在工程中，并不经常被应用的原因。

但这并不代表，学习数据结构和算法是没用的。深入理解原理，有助于你能更好地应用这些编程语言提供的类和函数。能否深入理解所用工具、类的原理，这也是普通程序员跟技术专家的区别。

6. 千万不要漫无目的地过度优化
掌握了数据结构和算法这把锤子，不要看哪里都是钉子。比如，一段代码执行只需要 0.01 秒，你非得用一个非常复杂的算法或者数据结构，将其优化成 0.005 秒。即便你的算法再优秀，这种微小优化的意义也并不大。相反，对应的代码维护成本可能要高很多。

不过度优化并不代表，我们在软件开发的时候，可以不加思考地随意选择数据结构和算法。我们要学会估算。估算能力实际上也是一个非常重要的能力。我们不仅要对普通情况下的数据规模和性能压力做估算，还需要对异常以及将来一段时间内，可能达到的数据规模和性能压力做估算。这样，我们才能做到未雨绸缪，写出来的代码才能经久可用。

还有，当你真的要优化代码的时候，一定要先做 Benchmark 基准测试。这样才能避免你想当然地换了一个更高效的算法，但真实情况下，性能反倒下降了。

总结
工程上的问题，远比课本上的要复杂。所以，我今天总结了六条经验，希望你能把数据结构和算法用在刀刃上，恰当地解决实际问题。



我们在利用数据结构和算法解决问题的时候，一定要先分析清楚问题的需求、限制、隐藏的特点等。只有搞清楚了这些，才能有针对性地选择恰当的数据结构和算法。这种灵活应用的实战能力，需要长期的刻意锻炼和积累。这是一个有经验的工程师和一个学院派的工程师的区别。

好了，今天的内容就到这里了。最后，我想听你谈一谈，你在实际开发选择数据结构和算法时，有什么感受和方法呢？

欢迎在留言区写下你的想法，也欢迎你把今天的文章分享给你的朋友，帮助他在数据结构和算法的实际运用中走得更远。



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(21)

观弈道人
课程要结束了，可惜拉下好多内容。
2019-02-18


17

牧民牛仔
老师的课程设计的很合理，对应的数据结构及算法章节，随时可查，随时可以复习。点个赞
2019-02-18


9

李伟
在平时工作上，看到有些前人留下来的代码，看起来效率不是很高，但是却没有人去优化它，应该就是属于老师今天说的这种情况！
2019-02-18


7

猫头鹰爱拿铁
已经开始二刷了。二刷完后打算再做一遍习题吧。
关于选择数据结构这块，我觉得确实要好好研究下底层的数据结构实现。这个对自己的成长也是有好处的。例如看完hashmap的源码会对巧妙使用位运算提升性能有更深层次的体会。然后就是工程中还要考虑实际场景，例如并发等等，如果不研究深一点数据结构，哪怕对应到散列表，jdk有hashtable，hashmap，concurrentmap选啥呢。
2019-02-18


6

传说中的成大大
这篇文章让我想起了以前看书学习设计模式中德一个忠告，滥用设计模式比不用设计模式更糟糕！
2019-02-18


4

王子瑞Aliloke有事电联
学习好基础的知识，力求能开发出ES，Kafka，MQ 这一类的优秀开源工具。
一刷还没完成，但数据结构与算法，我一定会精通的，计划花200+小时的认真学习，精通数据结构与算法
2019-02-20


3

呦呦鹿鸣
是的，用最小的成本满足需求，这或许就是终极原则了。做设计时应该要有取舍，权衡各方面的优劣，切勿过度设计
2019-02-18


3

纯洁的憎恶
1.目标不同，评价标准不同。
2.根据环境特征选择解决方法。
3.将复杂、开放的问题，合理抽象为特定范式。
4.善于找到问题的瓶颈，并优先解决。
5.善于借助前人的经验，并尽可能理解他们的经历与选择。
6.注意成本收益，投入恰到好处，切忌严重过度投入。
2019-02-18


2

未来的胡先森
这门专栏要不断的回过头去复习巩固，关键还是要不断的 coding 练习
2019-02-18


2

Simune
因为工作原因中途掉队了，我还会回来的。多谢老师咯。
2019-02-20


1

integrity
慢慢看
2019-02-18


1

郑晨Cc
老师终于不更新新知识点了 上周才搞定了动态规划，就要见到曙光了 哈哈
2019-02-18


1

daniel李
总结的很好。

碰到大部分的工程师都是死磕时间复杂度，老是实际数据规模很小却用海量数据的假设来设计解决方案。空间复杂度不管，数据结构预处理成本不管
2019-07-12



安然自若
代码在哪里🧐
作者回复: https://github.com/wangzheng0822/algo

2019-07-09



小智e
学完打卡，面试前回来复习，老师讲到的工程方面的例子，面试的时候往往都会问到
2019-04-28



万里有云
学习数据结构于算法就和学习汇编语言一样，平时工作中很难直接用到，但它是软件运行的基础原理，理解和不理解还是有挺大的区别的。
2019-04-24



有朋自远方来
我工作中用不到算法。。。。。。
2019-03-11



Sharry
一路走来自己的数据结构与算法的知识终于有了体系了, 如老师所说, 我使用的打怪升级的方式, 每积攒一个技能, 便多收获一丝喜悦
2019-03-02



肖平亮 Sean
希望我也能在谷歌工作。
2019-02-26



Gordon
感谢王老师的陪伴，收获很多。
2019-02-23


收起评论

2176





# 结束语 | 送君千里，终须一别




数据结构与算法之美
王争
前Google工程师
查看详情
59587 人已学习
课程目录
已完结 73 讲
开篇词 (1讲)

入门篇 (4讲)

基础篇 (38讲)

高级篇 (9讲)

43 | 拓扑排序：如何确定代码源文件的编译依赖关系？
44 | 最短路径：地图软件是如何计算出最优出行路径的？
45 | 位图：如何实现网页爬虫中的URL去重功能？
46 | 概率统计：如何利用朴素贝叶斯算法过滤垃圾短信？
47 | 向量空间：如何实现一个简单的音乐推荐系统？
48 | B+树：MySQL数据库索引是如何实现的？
49 | 搜索：如何用A*搜索算法实现游戏中的寻路功能？
50 | 索引：如何在海量数据中快速查找某个数据？
51 | 并行算法：如何利用并行处理提高算法的执行效率？
实战篇 (5讲)

加餐：不定期福利 (6讲)

加餐：春节7天练 (7讲)

加餐：用户学习故事 (2讲)

结束语 (1讲)


数据结构与算法之美



结束语 | 送君千里，终须一别
王争 2019-02-20



04:44
讲述：修阳 大小：4.34M
专栏到今天真的要结束了。在写这篇结束语的时候，我的心情还是蛮复杂的，既有点如释重负，又有点不舍。如释重负，是因为我自己对专栏的整体质量非常满意；不舍，是因为我还想分享更多“压箱底”的东西给你。

专栏是在 2018 年 9 月发布的。在发布后的两三天时间里，就有 2 万多人订阅，同时也引来了很多争议。有人说，我就是随便拿个目录就来“割韭菜”。也有人说，数据结构和算法的书籍那么多，国外还有那么多动画、视频教程，为什么要来学我的专栏？

这些质疑我都非常理解，毕竟大部分基础学科的教材，的确是国外的更全面。实际上，在专栏构思初期，我就意识到了这一点。不夸张地讲，我几乎读过市面上所有有关数据结构和算法的书籍，所以，我也深知市面上的数据结构和算法书籍存在的问题。

尽管有很多书籍讲的通俗易懂，也有很多书籍全面、经典，但是大部分都偏理论，书中的例子也大多脱离真实的软件开发。这些书籍毫无疑问是有用的，但是看完书之后，很多人只是死记硬背了一些知识点而已。这样填鸭式的学习，对于锻炼思维、开拓眼界并没有太多作用。而且，从基础理论到应用实践，有一个非常大的鸿沟要跨越，这是大学教育的普遍不足之处，这也是为什么我们常常觉得大学里学过的很多知识都没用。

我本人是一个追求完美、极致的人，凡事都想做到最好，都想争第一。所以，就我个人而言，我也不允许自己写一个“太普通”“烂大街”的专栏。那时我就给自己立了一个 flag：我一定要写一个跟所有国内、国外经典书籍都不一样的专栏，写出一个可以长期影响一些人的专栏。

所以，在这个专栏写作过程中，我力争并非只是单纯地把某个知识点讲清楚，而是结合自己的理解、实践和经验来讲解。我写每篇文章的时候，几乎都是从由来讲起，做到让你知其然、知其所以然，并且列举大量的实际软件开发中的场景，给你展示如何利用数据结构和算法解决真实的问题。

除此之外，课后思考题我也不拿一些现成的 LeetCode 的题目来应付。这些题目都是我精心设计的、贴合具体实践、非常考验逻辑思维的问题。毫不夸张地讲，只把这些课后思考题做个解答，就可以写成一个有价值、有干货的专栏！

专栏到今天就要结束了。尽管有些内容稍有瑕疵，但我觉得我实现了最初给自己立下的 flag。那你又学的怎么样呢？

如果这是你第一次接触数据结构和算法，只是跟着学一遍，你可能不会完全理解所有的内容。关于这个专栏，我从来也不想标榜，我的专栏是易懂到地铁里听听就可以的。因为你要知道，没有难度的学习，也就没有收获。所以，作为初学者，你要想真的拿下数据结构和算法，时间允许的话，建议你再二刷、三刷。

如果你是有一定基础的小伙伴，希望你能够真的做到学以致用。在开发项目、阅读开源代码、理解中间件架构设计方面，多结合数据结构和算法，从本质上理解原理，掌握创新的源头。

如果你是数据结构和算法高手，那我的专栏应该也没有让你失望吧？我个人觉得，专栏里还是有很多可以给你惊喜的地方。对于你来说，哪怕只学到了一个之前没有接触的知识点，我觉得其实已经值得了。

送君千里终须一别。数据结构和算法的学习，我暂时只能陪你到这里了。感谢你订阅我的专栏，感谢这 5 个月的同行，真心希望我的专栏能对你有所帮助。

我知道，很多小伙伴都是“潜水党”，喜欢默默地学习，在专栏要结束的今天，我希望能听到你的声音，希望听听你学习这个专栏的感受和收获。最后，再次感谢！



© 版权归极客邦科技所有，未经许可不得传播售卖。 页面已增加防盗追踪，如有侵权极客邦将依法追究其法律责任。

Geek_a770cc
由作者筛选后的优质留言将会公开显示，欢迎踊跃留言。
Ctrl + Enter 发表
0/2000字
提交留言
精选留言(279)

  
王哥，我是一个低调的人，我一直都在，但是没有在留言区说过一句话。看过7，8个极客时间的专栏，这个专栏是我研究时间最长的，现在是正月十六早上的0点10分，窗外的烟花声渐渐停止，我也看了专栏大概3个小时了，想不到在准备关闭电脑的时候，看到了你的最后一篇《送君千里终须一别》。不知道说什么，但是就是说说，还是那句话，我一直都在，只是没说话，你没有选择我，而我一直陪伴你，谢谢你，王哥。
2019-02-20


120

Jerry银银
送君千里，终有一别；
人在江湖，终会再见。
2019-02-20


39

yongxiang
我的学习历程是怎样的？

刚开始学习启动晚了，再加上学习方法不对、静不下心来，始终不得要领，课后题看了也完全没有概念，很是烦躁。

最近两个月终于摸索到了合适清晰的学习方法：正如老师的文章一样，把注意点放在发现问题，解决问题上。

采用笨办法，拿一堆A4白纸、铅笔、便利贴，在便利贴上写下要学习的章节、1个小时的起始学习时间、完成后面说的步骤的哪几部分，然后郑重地贴在白纸上，最后在规定的时间结束时，写下完成的情况。

把学习的过程分解成以下的步骤：
1. 归纳提炼问题：先把标题、课前问题，课后问题写下来，把概述和段标题提炼成问题写下来，把文章的内容分解归纳成一个接一个问题写下来；
2. 查找答案：然后，将文章读一遍，看看前面问题的答案在哪里，文章还有没有回答其他的问题；
3. 动手实践：对着代码将文章中的算法过程的图自己推导画一遍，找出算法的关键线索在哪里；最后，将代码回忆输入编辑器，将文章图片中的例子数据输入进行测试，同时加入打印日志观察顺序过程，看看自己回忆输入的代码犯了什么错误，记录下来。

这样一遍下来，心中终于感觉踏实了，自己不用看文章也能写出代码来了，感觉掌握了这个算法的思想，紧跟老师的思路。

这两个多月，基本上每个周末都会去麦当劳学习（找了很多地方，发现只有在麦当劳能静下心来学习，学习效率最高）。每次有新的章节先学新的，如果章节中有联系前面章节的，抓紧把这些章节的进度赶上去。睡前有空，就翻一遍每次学习记录的笔记，回忆一下。

目前的学习进度是多少？

目前终于完成了大概70%的章节的学习，当然这一轮还没结束，课后题也还没开始完成，有些章节学了又忘了，对复杂度分析还是不熟练。我想还需要再重点突破一下，然后再来回滚动学习两遍。

这门课，我收获了什么？

一是，找到了合适的学习方法：问题、动手、分解，以及合适的场所；二是，收获了自信心，相信自己能学会算法；三是，现在看其他书籍、代码的时候，会注意它使用了什么数据结构与算法来，有什么优缺点，不像以前，即使看到了也不知道是什么。

最后，非常感谢王争老师，把这么宝贵的经验分享出来，提供了深入浅出、联系实际的文章。让我觉得，自己有希望成为一位真正的软件工程师，不是一辈子打杂。

路漫且长，终于有了点光，可以继续赶路。
作者回复: 老弟，写的太好了，有点感动！我觉得我做了一件非常有意义的事情。

2019-02-25


34

iPiece
争哥，你是带我进算法的人。
2019-02-20


23

广行
你是结束了，但我才刚刚开始。
作者回复: 不急 慢慢来

2019-02-24


11

Non-constant
知识需要沉淀，不可能学第一遍就100%掌握并学会应用。所以，反复迭代，忘了就多翻翻，慢慢地把知识进行内化，这，才是学习之道！
有时候慢，才是最快的。
2019-02-20


10

我来也
潜水党报道系列+1
从专栏刚出时就订阅了,从未落下每一篇文章.想不到转眼就近半年了.
可能第一遍有些知识没太懂,没关系.
我最近在复习动态规划的那3篇文章,又对老师说的"从由来讲起，做到让你知其然、知其所以然",有了更深的认同感.
别的地方,可能着重介绍状态定义和写出动态方程,有些复杂的场景会带一句"大家记住这个方程就可以了,不需要知道怎么来的".
但是老师的专栏真的是从基础理论"一个模型三个特征",从回溯->回溯+递归->动态规划->优化动态规划的空间复杂度,再到问题的变种,更到更复杂的实际问题.
让我知道了是怎么一步一步演变而来.
除了让我对该知识有了更深入及牢固的了解,还可以把该优化思想应用到平常工作中.
我是非科班出身,从没系统的学习过数据结构与算法,自己也下不了决心去刷专门的书籍.
但是跟着老师的专栏,我并没觉得枯燥,反倒觉得很有意思.可能是老师的讲解与实际结合的很紧密,也可能是老师的讲解让我知道了厉害的算法是怎么从无到有的.
感谢老师的付出,让我收获了很多,谢谢!
2019-02-20


9

Mr David
真心不舍！在极客的第一个专栏，真的学会了很多以前在书本上搞不明白的知识，而且专栏的实践性在工作中也给了很多启发，真心很好的专栏，目前在二刷，以后还会三刷，相信每次都会有新的体会！谢谢王争老师！提个小小的建议，希望老师能建个群，这样以后还能有机会继续跟老师和伙伴们交流～
2019-02-20


7

hopeful
作为一个现在已经是大三的学生，很早就已经知道数据结构与算法对于以后在编程领域长远发展的重要性，也知道大厂面试也会将数据结构与算法视为面试重点，所以在数据结构与算法这方面一直很重视。我在大二上学期的时候学了数据结构之后，去leetcode刷题的时候却连一些最简单的题目都不会，于是在下学期的时候花了很多时间去刷题。但是在刷题的过程中经常会陷入一些细节问题中无法脱离出来，没有办法写出通过所有case的代码，只能在网上看别人是怎么写的，但是过了几天又忘了。如此反反复复，让我觉得很受打击，同时也无法感受到算法在实际开发中的作用。对于我而言，这个专栏好就好在它是从对数据结构与算法的实践运用出发，告诉我们某些算法可以用在哪里，同时也没有涉及到太多太难的算法题，再加上基础篇的大部分都是已经学过的内容，所以看起来不是特别吃力，同时高级篇和实践篇对我而言也不像算法题那样难得离谱。可能是我智商不够，可能是我刷题不够多，可能是我一直掌握不到刷题方法，导致在刷题这方面我一直没什么进步，进大厂可能没什么希望了。但学了这个专栏后，我觉得，如果我能在毕业前把这个专栏的内容都吃透，那么，在大学毕业时，在数据结构与算法这方面，就没有什么遗憾了。谢谢王争老师和《数据结构与算法之美》专栏！
作者回复: 我刷过上千道题，刷题这件事情并不难。开始刷的时候，挫败感肯定是有的。要稍微掌握点技巧，循序渐进的刷。我有空了可以写写我刷题的一些经验、教训。

2019-02-20


5

DY
感谢王争老师，数据结构和算法确实让我学到了很多东西，发现了很多可以提升的地方。越学习越发现这个课程可以让我静下心来学习，更有动力去学习二遍三遍，并动手练练，因为第一遍的学习感觉自己如果再努努力多写代码练练，这门课程完全可以掌握的。看的第一遍使自己对数据结构和算法非常有信心。老师讲的太好了，期待推出新的专栏。
作者回复: 我的设计模式很快就要上线了...

2019-08-07


4

.&#47;+-@YOU
极客第一个专栏，一个字:值
2019-02-20


4

Heart_K
谢谢王争老师，为小伙伴们提供这么优质的专栏。课程结束了，但刷如此精品的内容的我们还没结束，潜水党前来报道，有些内容还没学太懂，听老师和放送内容的小伙伴分享，知道这是正常的，只要正视问题沉下心一定会慢慢攻克搞懂，做到知其然，知其所以然。期待老师以后能继续分享同样精品的课程。
难忘今宵，难忘今宵，
共祝愿老师好，学习专栏小伙伴好，
下个专栏再相邀，
青山在 人未老 人未老！
2019-02-20


4

润兹
默默支持，我是默默的潜水党！
2019-02-20


4

Jiemr
《数据结构与算法之美》是我买的第一个专栏，也是花时间最多的一个专栏，为此特意买了一个iPad在路上阅读，可惜app没有iPad版本。算法方面的书籍我买了很多，可这些书籍大部分都是很枯燥的理论为主，学习的时间也不连续，很难静下心来慢慢理解消化；本专栏以图文并茂的形式讲解理论知识则更容易理解一些，回过头再看书也更轻松。
我大部分时间都在潜水，第一次留言提问貌似王老师没看到，第二次留言却是告别，不知道之后遇到问题还会不会有回复？
期待王争老师的下一个专栏。
2019-02-20


4

牧民牛仔
王争老师这个专栏，可以说是花钱花得最值得一个课程了。五个月的学习，把以前学的那些易忘的理论知识一一梳理了一遍。特别是老师通过把工程中遇到的问题作为引子，慢慢地引入到对应的数据结构和算法的理论中这种教学方式，是非常易于接受的学习过程。基本上对于所有的算法和数据结构，日后再看到的话，只要想起老师提到的工程中的例子，就能全部都有印象了。
最后说一句谢谢，高质量的课程很少有，谢谢老师及你们团队的辛勤付出。
2019-02-21


3

lianlian
王争老师在开篇词说过“基础知识就像是一座大楼的地基，它决定了我们技术的高度”，和我以前说过的“基础不是100分考60分，而是建摩天大楼的地基”好像啊！这算是神交吗？哈哈(ಡωಡ)hiahiahia这个专栏是我在极客时间订阅的第一个专栏，2018年11月11晚上，那时信号不好，我等到12号凌晨一点多购买成功，连读2篇才愿意睡觉，这个专栏太棒了，价值远超价格。我时常复习和练习，在走路，吃饭和空闲时间。王争老师若还有其他专栏，我会毫不犹豫继续订阅学习。
2019-02-20


3

三木子
常回家看看哈
2019-02-20


3

路过蜻蜓
努力吧，一刷完成
2019-04-10


2

沉睡的木木夕
在这里说声谢谢！
再问个脸皮厚的问题，因为有蛮多人应该没跟上进度，我也是其中一个。现在专栏结束了，如果看到后面实在不懂，问问题是不是没人回复了 - -
作者回复: 过年前那一阵子工作比较忙，所以回复留言比较少。我自己挺抱歉的。后面会及时回复的。

2019-02-22


2

三件事
我只想说王哥你啥时候再开一个专栏？
作者回复: 先休息一下：）

2019-02-20


2
收起评论

99+99+


