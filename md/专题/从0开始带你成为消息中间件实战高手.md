
<!-- TOC -->

- [01 一个真实电商订单系统的整体架构、业务流程及负载情况](#01-一个真实电商订单系统的整体架构业务流程及负载情况)
    - [1、一个订单系统的业务流程](#1一个订单系统的业务流程)
    - [2、订单系统的非核心业务流程](#2订单系统的非核心业务流程)
    - [3、订单系统的真实生产负载情况](#3订单系统的真实生产负载情况)
- [03 系统面临的现实问题：下订单的同时还要发券、发红包、Push推送，性能太差！](#03-系统面临的现实问题下订单的同时还要发券发红包push推送性能太差)
    - [1、根据线上统计数据推算出系统的负载（系统压力是如何产生的）](#1根据线上统计数据推算出系统的负载系统压力是如何产生的)
    - [2、为什么系统的压力会越来越大？](#2为什么系统的压力会越来越大)
    - [3、如果系统压力越来越大会怎么样？](#3如果系统压力越来越大会怎么样)
- [05 系统面临的现实问题：订单退款时经常流程失败，无法完成退款！](#05-系统面临的现实问题订单退款时经常流程失败无法完成退款)
    - [1、再次回顾一个复杂的订单支付流程](#1再次回顾一个复杂的订单支付流程)
    - [2、对订单进行退款时需要干些什么？](#2对订单进行退款时需要干些什么)
    - [3、退款的最大问题：第三方支付系统如果退款失败怎么办？](#3退款的最大问题第三方支付系统如果退款失败怎么办)
    - [4、如果用户下单后一直不付款怎么办？](#4如果用户下单后一直不付款怎么办)
    - [5、如果有几十万订单没付款，难道要一直傻傻的扫描？](#5如果有几十万订单没付款难道要一直傻傻的扫描)
    - [总结](#总结)
- [07 系统面临的现实问题：第三方客户系统的对接耦合性太高，经常出问题！](#07-系统面临的现实问题第三方客户系统的对接耦合性太高经常出问题)
    - [2、老司机设计系统的必备经验：跟第三方系统打交道](#2老司机设计系统的必备经验跟第三方系统打交道)
    - [3、到底什么叫做“系统之间的耦合”？](#3到底什么叫做系统之间的耦合)
    - [4、订单系统有没有跟第三方物流系统耦合？](#4订单系统有没有跟第三方物流系统耦合)
    - [5、跟第三方系统耦合的痛苦：性能差，不稳定](#5跟第三方系统耦合的痛苦性能差不稳定)
- [09 系统面临的现实问题：大数据团队需要订单数据，该怎么办？](#09-系统面临的现实问题大数据团队需要订单数据该怎么办)
    - [2、大数据到底是干嘛的？](#2大数据到底是干嘛的)
    - [3、大数据团队直接从订单库里select数据出来](#3大数据团队直接从订单库里select数据出来)
    - [5、几百行的大SQL直接查线上库的危害](#5几百行的大sql直接查线上库的危害)
- [11 系统面临的现实问题：秒杀活动时数据库压力太大，该怎么缓解？](#11-系统面临的现实问题秒杀活动时数据库压力太大该怎么缓解)
    - [3、双11对一个订单系统到底有多大压力？](#3双11对一个订单系统到底有多大压力)
    - [5、今年的双11活动对系统压力会有多大？](#5今年的双11活动对系统压力会有多大)
- [13 阶段性复习：一张思维导图给你梳理高并发订单系统面临的技术痛点！](#13-阶段性复习一张思维导图给你梳理高并发订单系统面临的技术痛点)
- [14 阶段性复习：放大100倍压力，也要找出你系统的技术挑战！](#14-阶段性复习放大100倍压力也要找出你系统的技术挑战)
- [15 解决订单系统诸多问题的核心技术：消息中间件到底是什么？](#15-解决订单系统诸多问题的核心技术消息中间件到底是什么)
- [17 领导的要求：你来对 Kafka、RabbitMQ 以及 RocketMQ 进行技术选型调研](#17-领导的要求你来对-kafkarabbitmq-以及-rocketmq-进行技术选型调研)
    - [3、Kafka、RabbitMQ以及RocketMQ的调研对比](#3kafkarabbitmq以及rocketmq的调研对比)
- [19 新技术引入：给团队分享 RocketMQ 的架构原理和使用方式](#19-新技术引入给团队分享-rocketmq-的架构原理和使用方式)
    - [2、MQ如何集群化部署来支撑高并发访问？](#2mq如何集群化部署来支撑高并发访问)
    - [3、MQ如果要存储海量消息应该怎么做？](#3mq如果要存储海量消息应该怎么做)
    - [4、高可用保障：万一Broker宕机了怎么办？](#4高可用保障万一broker宕机了怎么办)
    - [5、数据路由：怎么知道访问哪个Broker？](#5数据路由怎么知道访问哪个broker)
- [21 设计生产架构之前的功课：消息中间件路由中心的架构原理是什么？](#21-设计生产架构之前的功课消息中间件路由中心的架构原理是什么)
    - [4、NameServer到底可以部署几台机器？](#4nameserver到底可以部署几台机器)
    - [5、Broker是把自己的信息注册到哪个NameServer上去？](#5broker是把自己的信息注册到哪个nameserver上去)
    - [6、系统如何从NameServer获取Broker信息？](#6系统如何从nameserver获取broker信息)
    - [7、如果Broker挂了，NameServer是怎么感知到的？](#7如果broker挂了nameserver是怎么感知到的)
    - [8、Broker挂了，系统是怎么感知到的？](#8broker挂了系统是怎么感知到的)
- [23 设计生产架构之前的功课：Broker的主从架构原理是什么？](#23-设计生产架构之前的功课broker的主从架构原理是什么)
    - [2、Master Broker是如何将消息同步给Slave Broker的？](#2master-broker是如何将消息同步给slave-broker的)
    - [3、RocketMQ 实现读写分离了吗？](#3rocketmq-实现读写分离了吗)
    - [4、如果Slave Broke挂掉了有什么影响？](#4如果slave-broke挂掉了有什么影响)
    - [5、如果Master Broker挂掉了该怎么办？](#5如果master-broker挂掉了该怎么办)
    - [6、基于Dledger实现RocketMQ高可用自动切换](#6基于dledger实现rocketmq高可用自动切换)
- [25 落地第一步：设计一套高可用的消息中间件生产部署架构](#25-落地第一步设计一套高可用的消息中间件生产部署架构)
    - [2、NameServer集群化部署，保证高可用性](#2nameserver集群化部署保证高可用性)
    - [3、基于Dledger的Broker主从架构部署](#3基于dledger的broker主从架构部署)
    - [4、Broker是如何跟NameServer进行通信的？](#4broker是如何跟nameserver进行通信的)
    - [5、使用MQ的系统都要多机器集群部署](#5使用mq的系统都要多机器集群部署)
    - [6、MQ的核心数据模型：Topic到底是什么？](#6mq的核心数据模型topic到底是什么)
    - [7、Topic作为一个数据集合是怎么在Broker集群里存储的？](#7topic作为一个数据集合是怎么在broker集群里存储的)
    - [8、生产者系统是如何将消息发送给Broker的？](#8生产者系统是如何将消息发送给broker的)
    - [9、消费者是如何从Broker上拉取消息的？](#9消费者是如何从broker上拉取消息的)
    - [10、整体架构：高可用、高并发、海量消息、可伸缩](#10整体架构高可用高并发海量消息可伸缩)
- [27 部署一个小规模的 RocketMQ 集群，为压测做好准备](#27-部署一个小规模的-rocketmq-集群为压测做好准备)
- [28 授人以渔：动手完成一个小规模的RocketMQ集群的部署进行练习](#28-授人以渔动手完成一个小规模的rocketmq集群的部署进行练习)
- [29 生产运维：如何对RocketMQ集群进行可视化的监控和管理？](#29-生产运维如何对rocketmq集群进行可视化的监控和管理)
- [31 RocketMQ生产集群准备：进行OS内核参数和JVM参数的调整](#31-rocketmq生产集群准备进行os内核参数和jvm参数的调整)
    - [1、压测前的准备工作](#1压测前的准备工作)
    - [2、对RocketMQ集群进行OS内核参数的调整](#2对rocketmq集群进行os内核参数的调整)
    - [3、对JVM参数进行调整](#3对jvm参数进行调整)
    - [4、对RocketMQ核心参数进行调整](#4对rocketmq核心参数进行调整)
    - [5、今日内容总结](#5今日内容总结)
- [33 对小规模RocketMQ集群进行压测，同时为生产集群进行规划](#33-对小规模rocketmq集群进行压测同时为生产集群进行规划)
    - [1、压测就是拼命往死了压吗？](#1压测就是拼命往死了压吗)
    - [2、一次RocketMQ小规模集群的压测](#2一次rocketmq小规模集群的压测)
    - [3、基于公司业务情况规划生产集群](#3基于公司业务情况规划生产集群)
    - [4、今日内容总结](#4今日内容总结)
- [35 阶段性复习：一张思维导图给你梳理消息中间件集群生产部署架构规划](#35-阶段性复习一张思维导图给你梳理消息中间件集群生产部署架构规划)
- [37 基于MQ实现订单系统的核心流程异步化改造，性能优化完成！](#37-基于mq实现订单系统的核心流程异步化改造性能优化完成)
- [39 基于MQ实现订单系统的第三方系统异步对接改造，解耦架构完成！](#39-基于mq实现订单系统的第三方系统异步对接改造解耦架构完成)
    - [4、什么叫做同步发送消息到RocketMQ？](#4什么叫做同步发送消息到rocketmq)
    - [5、什么叫做异步发送消息到RocketMQ？](#5什么叫做异步发送消息到rocketmq)
    - [6、什么叫做发送单向消息到RocketMQ？](#6什么叫做发送单向消息到rocketmq)
    - [8、什么叫做Push消费模式？](#8什么叫做push消费模式)
    - [9、什么叫做Pull消费模式？](#9什么叫做pull消费模式)
- [40 授人以渔：如果你们系统要对接第三方系统，应该如何设计？](#40-授人以渔如果你们系统要对接第三方系统应该如何设计)
- [41 基于MQ实现订单数据同步给大数据团队，应该如何设计？](#41-基于mq实现订单数据同步给大数据团队应该如何设计)
- [43 秒杀系统的技术难点以及秒杀商品详情页系统的架构设计](#43-秒杀系统的技术难点以及秒杀商品详情页系统的架构设计)
    - [4、不归订单管的部分：高并发的商品详情页请求](#4不归订单管的部分高并发的商品详情页请求)
    - [5、商品团队的秒杀架构优化：页面数据静态化](#5商品团队的秒杀架构优化页面数据静态化)
    - [6、商品团队的秒杀架构优化：多级缓存](#6商品团队的秒杀架构优化多级缓存)
- [45 基于MQ实现秒杀订单系统的异步化架构以及精准扣减库存的技术方案](#45-基于mq实现秒杀订单系统的异步化架构以及精准扣减库存的技术方案)
    - [2、用答题的方法避免作弊抢购以及延缓下单](#2用答题的方法避免作弊抢购以及延缓下单)
    - [3、为秒杀独立出来一套订单系统](#3为秒杀独立出来一套订单系统)
    - [4、基于Redis实现下单时精准扣减库存](#4基于redis实现下单时精准扣减库存)
    - [5、抢购完毕之后提前过滤无效请求](#5抢购完毕之后提前过滤无效请求)
    - [6、瞬时高并发下单请求进入RocketMQ进行削峰](#6瞬时高并发下单请求进入rocketmq进行削峰)
    - [7、秒杀架构的核心要点](#7秒杀架构的核心要点)
- [47 阶段性复习：一张思维导图给你梳理全面引入MQ的订单系统架构](#47-阶段性复习一张思维导图给你梳理全面引入mq的订单系统架构)
- [48 阶段性复习：思考一下，如果你们系统全面接入MQ，架构该如何设计？](#48-阶段性复习思考一下如果你们系统全面接入mq架构该如何设计)
- [49 精益求精：深入研究一下生产者到底如何发送消息的？](#49-精益求精深入研究一下生产者到底如何发送消息的)
    - [2、研究RocketMQ底层原理的顺序和思路](#2研究rocketmq底层原理的顺序和思路)
    - [3、创建Topic的时候为何要指定MessageQueue数量？](#3创建topic的时候为何要指定messagequeue数量)
    - [4、Topic、MessageQueue以及Broker之间到底是什么关系？](#4topicmessagequeue以及broker之间到底是什么关系)
    - [5、生产者发送消息的时候写入哪个MessageQueue？](#5生产者发送消息的时候写入哪个messagequeue)
    - [6、如果某个Broker出现故障该怎么办？](#6如果某个broker出现故障该怎么办)
- [51 精益求精：深入研究一下Broker是如何持久化存储消息的？](#51-精益求精深入研究一下broker是如何持久化存储消息的)
    - [1、为什么Broker数据存储是最重要的一个环节？](#1为什么broker数据存储是最重要的一个环节)
    - [2、CommitLog消息顺序写入机制](#2commitlog消息顺序写入机制)
    - [3、MessageQueue在数据存储中是体现在哪里呢？](#3messagequeue在数据存储中是体现在哪里呢)
    - [4、如何让消息写入CommitLog文件近乎内存写性能的？](#4如何让消息写入commitlog文件近乎内存写性能的)
    - [5、同步刷盘与异步刷盘](#5同步刷盘与异步刷盘)
- [53 精益求精：基于DLedger技术的Broker主从同步原理到底是什么？](#53-精益求精基于dledger技术的broker主从同步原理到底是什么)
    - [1、Broker高可用架构原理回顾](#1broker高可用架构原理回顾)
    - [2、基于DLedger技术替换Broker的CommitLog](#2基于dledger技术替换broker的commitlog)
    - [3、DLedger是如何基于Raft协议选举Leader Broker的？](#3dledger是如何基于raft协议选举leader-broker的)
    - [4、DLedger是如何基于Raft协议进行多副本同步的？](#4dledger是如何基于raft协议进行多副本同步的)
    - [5、如果Leader Broker崩溃了怎么办？](#5如果leader-broker崩溃了怎么办)
- [55 精益求精：深入研究一下消费者是如何获取消息处理以及进行ACK的？](#55-精益求精深入研究一下消费者是如何获取消息处理以及进行ack的)
    - [1、消费组到底是个什么概念？](#1消费组到底是个什么概念)
    - [2、集群模式消费 vs 广播模式消费](#2集群模式消费-vs-广播模式消费)
    - [3、重温MessageQueue、CommitLog、ConsumeQueue之间的关系](#3重温messagequeuecommitlogconsumequeue之间的关系)
    - [4、MessageQueue与消费者的关系](#4messagequeue与消费者的关系)
    - [5、Push模式 vs Pull模式](#5push模式-vs-pull模式)
    - [6、Broker是如何将消息读取出来返回给消费机器的？](#6broker是如何将消息读取出来返回给消费机器的)
    - [7、消费者机器如何处理消息、进行ACK以及提交消费进度？](#7消费者机器如何处理消息进行ack以及提交消费进度)
    - [8、如果消费组中出现机器宕机或者扩容加机器，会怎么处理？](#8如果消费组中出现机器宕机或者扩容加机器会怎么处理)
- [57 精益求精：消费者到底是根据什么策略从Master或Slave上拉取消息的？](#57-精益求精消费者到底是根据什么策略从master或slave上拉取消息的)
    - [2、CommitLog基于os cache提升写性能的回顾](#2commitlog基于os-cache提升写性能的回顾)
    - [3、一个很关键的问题：ConsumeQueue文件也是基于os cache的](#3一个很关键的问题consumequeue文件也是基于os-cache的)
    - [4、第二个关键问题：CommitLog是基于os cache+磁盘一起读取的](#4第二个关键问题commitlog是基于os-cache磁盘一起读取的)
    - [5、什么时候会从os cache读？什么时候会从磁盘读？](#5什么时候会从os-cache读什么时候会从磁盘读)
    - [6、Master Broker什么时候会让你从Slave Broker拉取数据？](#6master-broker什么时候会让你从slave-broker拉取数据)
- [59 探秘黑科技：RocketMQ 是如何基于Netty扩展出高性能网络通信架构的？](#59-探秘黑科技rocketmq-是如何基于netty扩展出高性能网络通信架构的)
    - [2、Reactor主线程与长短连接](#2reactor主线程与长短连接)
    - [3、Producer和Broker建立一个长连接](#3producer和broker建立一个长连接)
    - [4、基于Reactor线程池监听连接中的请求](#4基于reactor线程池监听连接中的请求)
    - [5、基于Worker线程池完成一系列准备工作](#5基于worker线程池完成一系列准备工作)
    - [6、基于业务线程池完成请求的处理](#6基于业务线程池完成请求的处理)
    - [7、为什么这套网络通信框架会是高性能以及高并发的？](#7为什么这套网络通信框架会是高性能以及高并发的)
- [61 探秘黑科技：基于mmap内存映射实现磁盘文件的高性能读写](#61-探秘黑科技基于mmap内存映射实现磁盘文件的高性能读写)
    - [1、mmap：Broker读写磁盘文件的核心技术](#1mmapbroker读写磁盘文件的核心技术)
    - [2、传统文件IO操作的多次数据拷贝问题](#2传统文件io操作的多次数据拷贝问题)
    - [3、RocketMQ是如何基于mmap技术+page cache技术优化的？](#3rocketmq是如何基于mmap技术page-cache技术优化的)
    - [4、基于mmap技术+pagecache技术实现高性能的文件读写](#4基于mmap技术pagecache技术实现高性能的文件读写)
    - [5、预映射机制 + 文件预热机制](#5预映射机制--文件预热机制)
    - [6、对今天文章的一点总结](#6对今天文章的一点总结)
- [65 阶段性复习：一张思维导图带你梳理 RocketMQ 的底层实现原理](#65-阶段性复习一张思维导图带你梳理-rocketmq-的底层实现原理)
- [66 阶段性复习：在深度了解RocketMQ底层原理的基础之上，多一些主动思考](#66-阶段性复习在深度了解rocketmq底层原理的基础之上多一些主动思考)
- [67 生产案例：从 RocketMQ 全链路分析一下为什么用户支付后没收到红包？](#67-生产案例从-rocketmq-全链路分析一下为什么用户支付后没收到红包)
    - [1、客服反馈的一个奇怪问题：支付之后没有收到红包](#1客服反馈的一个奇怪问题支付之后没有收到红包)
    - [2、订单系统推送消息到MQ的过程会丢失消息吗？](#2订单系统推送消息到mq的过程会丢失消息吗)
    - [3、消息到达MQ了，MQ自己会导致消息丢失吗？](#3消息到达mq了mq自己会导致消息丢失吗)
    - [4、就算消息进入磁盘了，你以为真的万无一失吗？](#4就算消息进入磁盘了你以为真的万无一失吗)
    - [5、即使红包系统拿到了消息，就一定不会丢失了吗？](#5即使红包系统拿到了消息就一定不会丢失了吗)
    - [6、用户支付之后红包到底为什么没发送出去呢？](#6用户支付之后红包到底为什么没发送出去呢)
- [68 发送消息零丢失方案：RocketMQ事务消息的实现流程分析](#68-发送消息零丢失方案rocketmq事务消息的实现流程分析)
    - [1、解决消息丢失的第一个问题：订单系统推送消息丢失](#1解决消息丢失的第一个问题订单系统推送消息丢失)
    - [2、发送half消息到MQ去，试探一下MQ是否正常](#2发送half消息到mq去试探一下mq是否正常)
    - [3、万一要是half消息写入失败了呢？](#3万一要是half消息写入失败了呢)
    - [4、half消息成功之后，订单系统完成自己的任务](#4half消息成功之后订单系统完成自己的任务)
    - [5、如果订单系统的本地事务执行失败了怎么办？](#5如果订单系统的本地事务执行失败了怎么办)
    - [6、如果订单系统完成了本地事务之后，接着干什么？](#6如果订单系统完成了本地事务之后接着干什么)
    - [7、让流程严谨一些：如果发送half消息成功了，但是没收到响应呢？](#7让流程严谨一些如果发送half消息成功了但是没收到响应呢)
    - [8、如果rollback或者commit发送失败了呢？](#8如果rollback或者commit发送失败了呢)
    - [9、停一下脚步，想想上面这个流程的意义在哪里？](#9停一下脚步想想上面这个流程的意义在哪里)
- [69 RocketMQ黑科技解密：事务消息机制的底层实现原理](#69-rocketmq黑科技解密事务消息机制的底层实现原理)
    - [1、half 消息是如何对消费者不可见的？](#1half-消息是如何对消费者不可见的)
    - [2、在什么情况下订单系统会收到half消息成功的响应？](#2在什么情况下订单系统会收到half消息成功的响应)
    - [3、假如因为各种问题，没有执行rollback或者commit会怎么样？](#3假如因为各种问题没有执行rollback或者commit会怎么样)
    - [4、如果执行rollback操作的话，如何标记消息回滚？](#4如果执行rollback操作的话如何标记消息回滚)
    - [5、如果执行commit操作，如何让消息对红包系统可见？](#5如果执行commit操作如何让消息对红包系统可见)
- [70 为什么解决发送消息零丢失方案，一定要使用事务消息方案？](#70-为什么解决发送消息零丢失方案一定要使用事务消息方案)
    - [2、一个小思考：能不能基于重试机制来确保消息到达MQ？](#2一个小思考能不能基于重试机制来确保消息到达mq)
    - [3、先执行订单本地事务，还是先发消息到MQ？](#3先执行订单本地事务还是先发消息到mq)
    - [4、把订单本地事务和重试发送MQ消息放到一个事务代码中](#4把订单本地事务和重试发送mq消息放到一个事务代码中)
    - [5、再说了，你就一定可以依靠本地事务回滚吗？](#5再说了你就一定可以依靠本地事务回滚吗)
    - [6、保证业务系统一致性的最佳方案：基于RocketMQ的事务消息机制](#6保证业务系统一致性的最佳方案基于rocketmq的事务消息机制)
- [71 用支付后发红包的案例场景，分析RocketMQ事物消息的代码实现细节](#71-用支付后发红包的案例场景分析rocketmq事物消息的代码实现细节)
    - [2、发送half事务消息出去](#2发送half事务消息出去)
    - [3、假如half消息发送失败，或者没收到half消息响应怎么办？](#3假如half消息发送失败或者没收到half消息响应怎么办)
    - [4、如果half消息成功了，如何执行订单本地事务？](#4如果half消息成功了如何执行订单本地事务)
    - [5、如果没有返回commit或者rollback，如何进行回调？](#5如果没有返回commit或者rollback如何进行回调)
- [72 Broker消息零丢失方案：同步刷盘 + Raft协议主从同步](#72-broker消息零丢失方案同步刷盘--raft协议主从同步)
    - [1、用了事务消息机制，消息就一定不会丢了吗？](#1用了事务消息机制消息就一定不会丢了吗)
    - [2、就算你走运，消息进了磁盘就不会丢了吗？](#2就算你走运消息进了磁盘就不会丢了吗)
    - [3、明确一个前提：保证消息写入MQ不代表不丢失](#3明确一个前提保证消息写入mq不代表不丢失)
    - [4、异步刷盘 vs 同步刷盘](#4异步刷盘-vs-同步刷盘)
    - [5、如何通过主从架构模式避免磁盘故障导致的数据丢失？](#5如何通过主从架构模式避免磁盘故障导致的数据丢失)
    - [6、MQ确保数据零丢失的方案总结](#6mq确保数据零丢失的方案总结)
- [73 Consumer消息零丢失方案：手动提交offset + 自动故障转移](#73-consumer消息零丢失方案手动提交offset--自动故障转移)
    - [1、红包系统拿到了消息就一定会派发红包吗？](#1红包系统拿到了消息就一定会派发红包吗)
    - [2、Kafka消费者的数据丢失问题](#2kafka消费者的数据丢失问题)
    - [3、RocketMQ消费者的与众不同的地方](#3rocketmq消费者的与众不同的地方)
    - [4、需要警惕的地方：不能异步消费消息](#4需要警惕的地方不能异步消费消息)
- [74 基于 RocketMQ 设计的全链路消息零丢失方案总结](#74-基于-rocketmq-设计的全链路消息零丢失方案总结)
    - [1、对全链路消息零丢失方案进行总结](#1对全链路消息零丢失方案进行总结)
    - [2、消息零丢失方案的优势与劣势](#2消息零丢失方案的优势与劣势)
    - [3、为什么消息零丢失方案会导致吞吐量大幅度下降？](#3为什么消息零丢失方案会导致吞吐量大幅度下降)
    - [4、消息零丢失方案到底适合什么场景？](#4消息零丢失方案到底适合什么场景)
- [75 生产案例：从 RocketMQ 底层原理分析为什么会重复发优惠券？](#75-生产案例从-rocketmq-底层原理分析为什么会重复发优惠券)
    - [3、订单系统发送消息到MQ的时候会重复吗？](#3订单系统发送消息到mq的时候会重复吗)
    - [4、重试是一把双刃剑：订单系统自己重复发送消息](#4重试是一把双刃剑订单系统自己重复发送消息)
    - [5、优惠券系统重复消费一条消息](#5优惠券系统重复消费一条消息)
    - [6、消息重复问题应该是一种家常便饭](#6消息重复问题应该是一种家常便饭)
- [76 对订单系统核心流程引入 幂等性机制，保证数据不会重复](#76-对订单系统核心流程引入-幂等性机制保证数据不会重复)
    - [1、到底什么是幂等性机制？](#1到底什么是幂等性机制)
    - [2、发送消息到MQ的时候如何保证幂等性？](#2发送消息到mq的时候如何保证幂等性)
    - [3、基于Redis缓存的幂等性机制](#3基于redis缓存的幂等性机制)
    - [4、有没有必要在订单系统环节保证消息不重复发送？](#4有没有必要在订单系统环节保证消息不重复发送)
    - [5、优惠券系统如何保证消息处理的幂等性？](#5优惠券系统如何保证消息处理的幂等性)
    - [6、MQ消息幂等性的方案总结](#6mq消息幂等性的方案总结)
- [77 如果优惠券系统的数据库宕机，如何用死信队列解决这种异常场景？](#77-如果优惠券系统的数据库宕机如何用死信队列解决这种异常场景)
    - [1、如果优惠券系统的数据库宕机，会怎么样？](#1如果优惠券系统的数据库宕机会怎么样)
    - [2、数据库宕机的时候，你还可以返回CONSUME_SUCCESS吗？](#2数据库宕机的时候你还可以返回consume_success吗)
    - [3、如果对消息的处理有异常，可以返回RECONSUME_LATER状态](#3如果对消息的处理有异常可以返回reconsume_later状态)
    - [4、RocketMQ是如何让你进行消费重试的？](#4rocketmq是如何让你进行消费重试的)
    - [5、如果连续重试16次还是无法处理消息，然后怎么办？](#5如果连续重试16次还是无法处理消息然后怎么办)
    - [6、消息处理失败场景下的方案总结](#6消息处理失败场景下的方案总结)
- [78 生产案例：为什么基于 RocketMQ 进行订单库数据同步时会消息乱序？](#78-生产案例为什么基于-rocketmq-进行订单库数据同步时会消息乱序)
    - [4、为什么基于MQ来传输数据会出现消息乱序？](#4为什么基于mq来传输数据会出现消息乱序)
    - [5、消息乱序：必须要正视的一个问题](#5消息乱序必须要正视的一个问题)
- [79 在RocketMQ中，如何解决订单数据库同步的消息乱序问题？](#79-在rocketmq中如何解决订单数据库同步的消息乱序问题)
    - [2、让属于同一个订单的binlog进入一个MessageQueue](#2让属于同一个订单的binlog进入一个messagequeue)
    - [3、真的这么简单吗？获取binlog的时候也得有序！](#3真的这么简单吗获取binlog的时候也得有序)
    - [4、Consumer有序处理一个订单的binlog](#4consumer有序处理一个订单的binlog)
    - [5、这就完了吗？没有，万一消息处理失败了可以走重试队列吗？](#5这就完了吗没有万一消息处理失败了可以走重试队列吗)
    - [6、有序消息方案与其他消息方案的结合](#6有序消息方案与其他消息方案的结合)
- [80 基于订单数据库同步场景，来分析RocketMQ的顺序消息机制的代码实现](#80-基于订单数据库同步场景来分析rocketmq的顺序消息机制的代码实现)
    - [1、如何让一个订单的binlog进入一个MessageQueue？](#1如何让一个订单的binlog进入一个messagequeue)
    - [2、消费者如何保证按照顺序来获取一个MessageQueue中的消息？](#2消费者如何保证按照顺序来获取一个messagequeue中的消息)
- [81 如何基于RocketMQ的数据过滤机制，提升订单数据库同步的处理效率](#81-如何基于rocketmq的数据过滤机制提升订单数据库同步的处理效率)
    - [1、混杂在一起的订单数据库的binlog](#1混杂在一起的订单数据库的binlog)
    - [2、处理不关注的表的binlog，有多么浪费时间！](#2处理不关注的表的binlog有多么浪费时间)
    - [3、在发送消息的时候，给消息设置tag和属性](#3在发送消息的时候给消息设置tag和属性)
    - [4、在消费数据的时候根据tag和属性进行过滤](#4在消费数据的时候根据tag和属性进行过滤)
    - [5、基于数据过滤减轻Consumer负担](#5基于数据过滤减轻consumer负担)
- [82 生产案例：基于延迟消息机制优化大量订单的定时退款扫描问题！](#82-生产案例基于延迟消息机制优化大量订单的定时退款扫描问题)
- [83 基于订单定时退款场景，来分析RocketMQ的延迟消息的代码实现](#83-基于订单定时退款场景来分析rocketmq的延迟消息的代码实现)
- [84 在RocketMQ的生产实践中积累的各种一手经验总结](#84-在rocketmq的生产实践中积累的各种一手经验总结)
- [85 企业级的RocketMQ集群如何进行权限机制的控制？](#85-企业级的rocketmq集群如何进行权限机制的控制)
- [86 如何对线上生产环境的RocketMQ集群进行消息轨迹的追踪？](#86-如何对线上生产环境的rocketmq集群进行消息轨迹的追踪)
- [087 由于消费系统故障导致的RocketMQ百万消息积压问题，应该如何处理？](#087-由于消费系统故障导致的rocketmq百万消息积压问题应该如何处理)
- [088 金融级的系统如何针对RocketMQ集群崩溃设计高可用方案？](#088-金融级的系统如何针对rocketmq集群崩溃设计高可用方案)
- [89 为什么要给RocketMQ增加消息限流功能保证其高可用性？](#89-为什么要给rocketmq增加消息限流功能保证其高可用性)
- [90 设计一套Kafka到RocketMQ的双写+双读技术方案，实现无缝迁移！](#90-设计一套kafka到rocketmq的双写双读技术方案实现无缝迁移)

<!-- /TOC -->

# 01 一个真实电商订单系统的整体架构、业务流程及负载情况

## 1、一个订单系统的业务流程

这个电商购物的流程中，订单系统是其中非常关键的一环。

![](../../pic/2020-03-28-09-56-58.png)


![](../../pic/2020-03-28-10-00-45.png)

那订单系统在下订单这个核心的业务流程中，他自身的业务流程又是什么样的呢？

- 1、简单来说，当用户对购物车中选中的一批商品确认下单的时候，会先出来一个确认订单的界面。用户得先确认这个订单中的商品、价格、运费无误，而且在这个过程中可以选择是否要使用优惠券、促销活动的。另外，用户还应该在这个界面中确认自己的快递方式，收件地址，是否要开发票以及发票的抬头是什么。当用户完成这些信息确认之后，就可以确定下单。

- 2/3、此时我们的订单系统最核心的一个环节就出现了，就是要根据APP端传递过来的种种信息，完成订单的创建。此时需要在数据库中创建对应的订单记录。

- 4/5/6、接着当你正式确认下单之后，除了在数据库中创建这个订单之外，还会跳转到支付界面，让你通过选择好的支付方式完成这个订单的支付。比如跳转到支付宝或者微信，让你在支付宝或者微信中完成支付

- 7、在完成了支付之后，一般来说，支付宝或者微信之类的支付系统，会反过来回调我们的一个接口，通知我们本次支付已经成功。

- 8、当我们收到支付成功的通知之后，就需要安排给用户进行配送发货。除此之外，我们的订单系统需要负责给用户发放优惠券一类的东西。因为一般电商APP都经常会做一些鼓励用户购买的活动，比如你购买之后送一些优惠券，下次购买可以抵用5块钱，或者给你发一个几块钱的现金红包。此外，还会给你发送一个push推送，通知你支付成功准备发货，这个推送很多时候是通过短信通知的。

我们看下面的图，在下面的图中就有支付完订单之后要做的一些事情：

## 2、订单系统的非核心业务流程

![](../../pic/2020-03-28-10-06-14.png)

- 1、下单模块主要是用于创建订单；

- 2、异步模块主要是在支付成功之后发优惠券、红包和推送；

- 3、查询模块主要是提供订单的查询。

- 4、另外，当用户查询到一个订单列表之后，有时肯定会因为各种原因想要退货，这个是不可避免的。

- 5、此外，订单系统除了自己要提供的功能模块之外，还需要跟公司以外的第三方公司的一些系统进行对接。比如你想要查看订单的配送状态，那么就需要订单系统从第三方物流公司的系统中进行查询，才能让你看到。

- 6、然后你应该知道，订单数据是一个公司的核心数据，很多时候公司内部的其他团队，比如大数据团队可能就需要获取订单数据进行分析，然后提供交易数据报表给公司的高层领导去看。

- 7、最后就是在类似双11、秒杀等大促场景下，可能大量的用户会蹲点守在手机前，等待一些特价促销的商品开卖之后进行抢购，此时可能会对订单系统会产。因此对于订单系统，往往要提供一个专门用于抗双11、秒杀等活动的大促模块，专门用于处理特殊活动下的高并发下单场景，这个模块也得加上：

## 3、订单系统的真实生产负载情况

- 1、几千万注册用户，每天APP活跃的用户数量是一两百万的样子，这个其实也不算少了，虽说我们是创业公司，但是也达到百万日活的体量了。然后每天新增的订单数量，目前大概是几十万的样子。

- 2、QPS系统每秒的查询数量，对我们来说，在往常每天的高峰期，大概最多会达到每秒2000左右的访问量，不算太大。

- 3、但是如果要是有那种特价商品限时秒杀的活动，那可能就会达到每秒1万以上的访问压力了。

这就是我们这个订单系统的整体压力了，你可以看到，压力主要在两方面：

- 一方面是订单系统日益增长的数据量

- 一方面是在大促活动时每秒上万的访问压力

我们仅仅是让开发好的系统直接连接一台数据库服务器，所有的数据都是存储在里面的。

然后也是由这台数据库服务器去抗所有的访问压力，所以现在订单系统经常会在一些大促活动的时候出现不稳定的情况。

因为随着数据库中的订单数据越来越多，数据库的读写性能就会越来越差，尤其在大促活动高峰期的时候，数据库访问压力剧增，读写性能会进一步下降，经常出现请求过慢，请求超时等问题。

所以，咱们团队的任务，就是要尽快在订单系统的架构中引入更多的技术，进行大量的架构优化，让我们的订单系统逐步逐步的趋向于稳定。

> 02 授人以渔：能概括一下你们系统的架构设计、业务流程以及负载情况吗？

然后你可以想一下，如果你的系统的用户量级增长百倍、千倍、甚至万倍呢？那么此时系统每天会增长多少数据量？每秒会有多少请求量？你的系统的生产负载会是一个什么样子？

# 03 系统面临的现实问题：下订单的同时还要发券、发红包、Push推送，性能太差！

## 1、根据线上统计数据推算出系统的负载（系统压力是如何产生的）

系统的高并发时间段是由产品的用户使用习惯决定的，这些用户的使用习惯直接决定了他们使用我们APP的频率、时间段和时长，一般每隔几天用一次我们的APP？每次使用一般在什么时间段？每次使用多长时间？

通过线上一些数据的统计，我们大致知道，咱们这个APP，基本上80%的用户都习惯于在晚上六点过后到凌晨十一点这几个小时使用，这个刚好是大家下班的时间，便于大家购物。所以在这几个小时内，可以认为有80万左右的用户会使用APP。

综合下来而言，根据线上系统的接口统计数据来看，晚上购物最活跃的时候，订单系统下单最顶点的高峰时段每秒会有超过2000的请求，这就是订单系统的最高负载。其他时候都比这个负载会低不少。

## 2、为什么系统的压力会越来越大？

现在线上的订单系统一共部署了8台机器，每台机器的配置是4核8G，这是互联网公司的标准配置，当然也有不少系统是用2核4G的机器部署的，那也是标准配置。

![](../../pic/2020-03-28-10-30-04.png)

但是这8台订单系统部署的服务器都是连接一台数据库服务器的，数据库服务器的配置是16核32G，而且是SSD固态硬盘的，用的是比较高配置比较贵的机器，因此性能会更好一些。这也是比较常规的数据库服务器的配置，但是一般也会用比如8核16G和机械硬盘等机器部署数据库。

![](../../pic/2020-03-28-10-31-03.png)

现在线上这样的一个机器部署情况，在高峰期每秒2000以上请求的情况下是很轻松可以抗住的

因为4核8G的机器一般每秒钟抗几百请求都没问题，现在才每秒两三百请求，CPU资源使用率都不超过50%。

然后数据库服务器因为用的是16核32G的配置，因此之前压测的时候知道他即使每秒上万请求也能做到，只不过那个已经是他的极限了，会导致数据库服务器的CPU、磁盘、网络、IO、内存的使用率几乎达到极限。

但是一般来说在每秒四五千的请求的话，这样的数据库服务器是没什么问题的，何况经过线上监控统计，现在数据库服务器在高峰期的每秒请求量也就是三四千的样子，因此基本上还没什么大问题。

## 3、如果系统压力越来越大会怎么样？

![](../../pic/2020-03-28-10-00-45.png)

在上面那个图的第8个步骤里，其实我们除了发优惠券、发红包、发送Push通知给用户之外，还要做很多其他的事情。

比如：对于一个电商APP而言，你卖掉了一个商品，就要扣减掉商品的库存，而且一旦用户成功支付了，你还得更新订单的状态变成待发货。

现在根据我们线上系统的统计，这个步骤8那里的多个子步骤全部执行完毕，加起来大概需要1秒~2秒的时间

有时候在高峰期负载压力很高的时候，如果数据库的负载较高，会导致数据库服务器的磁盘、IO、CPU的负载都很高，会导致数据库上执行的SQL语句性能有所下降。

因此在高峰期的时候，有的时候甚至需要几秒钟的时间完成上述几个步骤。

那么他的影响是什么呢？

想象一下，如果你是一个用户，结果你在支付完一个订单之后，界面上会有一个圈圈不停的旋转，让你等待好几秒之后才能提示支付成功。

对用户来说，几秒钟的时间，会让人非常不耐烦的！

所以，首先针对步骤8里的子步骤过多，速度过慢，让用户支付之后等待时间过长的问题，就是订单系统第一个亟需解决的问题。


> 04 授人以渔：你们系统的核心流程性能如何？有没有哪个环节拖慢了速度？

上一篇文章里，我们详细的给大家展示出来了对一个系统的用户使用习惯的分析，进而得出了用户对系统的使用频率、使用时间段以及使用时长。

然后就可以根据用户的使用情况，计算出来系统的负载，到底每秒钟会有多少请求去访问我们的这个系统。

再接着，根据系统的负载情况，我们要搞明白线上系统部署的机器情况和数据库的机器情况，每台机器的配置情况，然后想想到底每台机器可以抗多大的访问量。得出当前系统的整体压力。

接着我们要思考，在当前这样的系统压力下：

- 系统的核心业务流程性能如何？

- 核心流程的每个步骤要耗费多长时间？

- 现在核心流程的性能你满意吗？是否还有优化的空间？

- 在系统高峰期的时候，机器和数据库负载很高，是否对核心流程的性能有影响？

- 如果有影响的话，会有多大的影响？

# 05 系统面临的现实问题：订单退款时经常流程失败，无法完成退款！

## 1、再次回顾一个复杂的订单支付流程

订单支付过后的一系列流程，就在下面的图里，包含了扣减库存、更新订单状态、更新积分、发优惠券、发红包、发Push推送、通知仓储系统调度发货。

![](../../pic/2020-03-28-10-50-06.png)

## 2、对订单进行退款时需要干些什么？

那么订购单系统的第二个问题，就是订单支付的反向过程，退款

所以，本质上订单退款应该是一个订单支付的逆向过程，也就是说他应该做如下一些事：

- 重新给商品增加库存

- 更新订单状态为“已完成”

- 减少你的积分

- 收回你的优惠券和红包

- 发送Push告诉你退款完成了

- 通知仓储系统取消发货

- 最重要的是，需要通过第三方支付系统把钱重新退还给你。


而且如果电商平台都已经给你发货了，你才申请退款，实际上你还得把收到的商品给人家快递回去，等他们收到了商品再把钱退还给你。当然，这里我们简单起见，就说商品还没发货这种情况吧。

![](../../pic/2020-03-28-10-53-58.png)

## 3、退款的最大问题：第三方支付系统如果退款失败怎么办？

明哥这个时候说，其实在退款的时候，最大的问题还不是步骤太多执行太慢，最大的问题是假设你的库存增加完了，订单状态更新了，积分收回了，优惠券收回了，仓储系统中断发货了，然后Push推送告诉你说已经退款了，结果第三方支付系统退款失败了。

比如有可能是第三方支付系统自己的问题导致退款失败，也可能是你在调用第三方支付系统的时候，因为你自己的网络问题导致调用失败，就退款失败了。

总之，用户以为退款成功了，结果一查自己账户，钱就是没进来，这才是最要命的一个问题。


## 4、如果用户下单后一直不付款怎么办？

通常来说，用户在购物车里会加入很多的商品，然后选择下单跳转到一个订单确认界面，在这里确认收货地址、发票抬头、优惠券使用等一系列的问题，接着正式下这个订单。

接着用户对订单一旦确认完毕，就会提交订单，订单提交到订单系统之后，就会正式在数据库中创建一个订单出来

接着正常来说，就会跳转到支付界面让他进行付款了，但是万一这个人在付款界面犹豫了一下呢？结果自己把付款界面给关了，这不就是订单创建了，但是没支付么？

此时订单的状态“待支付”，而且只要你下了订单，你订单里涉及到的商品，都会有对应的锁定库存的一个工作，相当于给你预先保留好这些商品。

要是订单一直不付款，一直这么放着，他对应的商品库存就会一直锁定，别人都没法买了。

明哥接着说道：所以一般来说，我们的订单系统会启动一个后台线程，这个后台线程就是专门扫描数据库里那些待付款的订单。

如果发现超过24小时还没付款，就直接把订单状态改成“已关闭”了，释放掉锁定的那些商品库存。

![](../../pic/2020-03-28-10-56-30.png)

![](../../pic/2020-03-28-10-56-42.png)

## 5、如果有几十万订单没付款，难道要一直傻傻的扫描？

假设咱们现在数据库中积压了几十万笔待支付的订单，难道你要求一个后台线程不停的去扫描这几十万笔订单吗？这个效率明显是很低的啊！

万一以后有几百万笔未支付订单呢？难道要不停的扫描几百万笔待支付的订单？

所以这个就是订单支付之前最大的一个技术问题。


## 总结

截止目前可能存在的三个问题

- 1、支付之前，待支出订单处理；

- 2、支付时，处理流程复杂，耗时；

- 3、支付后退款，处理流程复杂而且可能退款失败；


> 06 授人以渔：你们系统出现过核心流程链路失败的情况吗？

# 07 系统面临的现实问题：第三方客户系统的对接耦合性太高，经常出问题！


## 2、老司机设计系统的必备经验：跟第三方系统打交道

在订单支付的时候，大部分核心步骤，其实都是在自己公司的系统里完成的，比如你更新订单的状态，是在自己公司的订单系统内部完成的；你扣减库存，是找自己公司内部的库存系统完成的；你在增加积分的时候，是找自己公司内部的积分系统完成的；你在派发优惠券、红包的时候，是找自己公司内部的营销系统完成的。

商品的出库发货，你找谁？

一般电商公司内部都会有自己的仓储系统，管理各种仓库和商品的发货，通常来说会选择去找一个距离你用户最近的一个仓库，然后从里面调度一些商品进行发货，在发货的时候还需要调用第三方物流公司的系统，通知物流公司去仓库里取货发货。

对于物流公司而言，必然会由自己的物流系统收到货运通知之后，自动通知自己的快递员或者运输队到对方仓库里取货，然后去派发货物给购买商品的用户。

![](../../pic/2020-03-28-11-06-45.png)

## 3、到底什么叫做“系统之间的耦合”？

举个例子，比如在我们的订单支付流程里，订单系统其实是要调用很多其他系统的，比如库存系统、积分系统、营销系统、仓储系统，等等。明哥说着，在图里画了好几个系统之间调用的红圈。

![](../../pic/2020-03-28-11-08-15.png)

好，那么我们现在来思考一个问题，假设促销系统现在有一个接口，专门是让你调用了以后派发优惠券的，现在这个接口接收的参数有5个，你要是调用这个接口，就必须给他传递5个参数过去，这个是没的说的。

现在问题来了，负责促销系统的工程师某一天突然有一个新的想法，他希望改一改这个接口，在接口调用的时候需要传递7个参数！

一旦他的这个新接口上线了，你还是给他传5个参数，那么他那里就会报错，这个派发优惠券的行为就会失败！

那在这样的一个情况下应该怎么办？

很简单，你作为订单系统的负责人，必须要配合促销系统去修改代码，既然他要7个参数，那么你就必须得在代码里调用他的接口的时候传递7个参数。并且你还得配合他的新接口去进行测试以及部署上线，你必须得围绕着他转，配合他。

在这种情况下，就说明你的订单系统跟促销系统是强耦合的。因为促销系统任何一点接口修改，都会牵扯你围着他转，去配合他， 耗费你们订单团队的人力和时间，说明你们两个系统耦合在一起了。

## 4、订单系统有没有跟第三方物流系统耦合？

订单系统要调用仓储系统的接口去发货，仓储系统在接到订单系统的调动之后，又要同时去调用第三方物流系统去生成物流单，通知人家去取货。

所以在上图的流程中，必须要等到第三方物流系统返回确认信息之后，仓储系统才能返回结果，订单系统才能结束对仓储系统的调用。

想想看，在这个情况下，订单系统不就跟仓储系统、第三方物流系统，全部耦合在一起了吗？

## 5、跟第三方系统耦合的痛苦：性能差，不稳定

所以你要记住一点：第三方系统，永远是不能完全信任的，他随时有可能出现意料之外的性能变差、接口失败的问题。

这就是你的系统跟第三方系统耦合在一起的痛苦：对方不可控，导致你的系统的性能和稳定性也不可控。

> 08 授人以渔：你们有没有跟第三方系统对接过，有遇到什么问题吗？

# 09 系统面临的现实问题：大数据团队需要订单数据，该怎么办？

## 2、大数据到底是干嘛的？

所以每天如果有100万用户来访问你的APP，积累下来的一些浏览行为、访问行为、交易行为都是各种数据，这个数据量很大，所以你可以称之为“大数据”


## 3、大数据团队直接从订单库里select数据出来

![](../../pic/2020-03-28-11-21-56.png)

明哥继续说道：现在我们的订单数据库，是直接对外暴露的，大数据团队是直接可以访问我们的订单数据库的。

他们有一个数据报表系统，那个系统每次在老板查看交易报表的时候，就会直接用一个几百行的大SQL，从我们的订单数据库里查出来需要的数据！

## 5、几百行的大SQL直接查线上库的危害

每次当有几十个几百行的大SQL同时运行在我们订单数据库里的时候，都会导致我们的数据库CPU负载很高，磁盘IO负载很高！

一旦我们的数据库负载很高，直接会导致我们的订单系统执行的一些增删改查的操作性能大幅度下降！

![](../../pic/2020-03-28-11-25-13.png)

> 10 授人以渔：你们有没有遇到过自己系统的数据，其他团队需要获取的？

不一定是像上一篇文章中那样是大数据团队到你这里来获取数据，但凡是其他系统要从你这里获取数据的，都是类似的情况。

给大家举一个例子，现在都流行微服务化，很多后台系统都是拆分为很多服务的，其实有的服务粒度比较粗，基本就是类似于一个子系统的概念。然后在服务之间可能都会互相进行数据的访问。

如何控制这个微服务并发访问能力？不影响核心业务

# 11 系统面临的现实问题：秒杀活动时数据库压力太大，该怎么缓解？

## 3、双11对一个订单系统到底有多大压力？

如果用户每秒会发起2000个请求到我们的订单系统的各类接口，包括下单接口、退款接口、查询接口等等，那么你觉得我们的订单系统每秒会执行多少条SQL在订单数据库上？

明哥接着解释，这个其实是一个有经验的工程师一般都会了解的一个估算方法，比如每秒订单系统的各类接口被调用2000次，平均每个接口会执行多少次数据库操作？

一般你可以认为平均每个接口会执行2~3次的数据库操作。

一般一个接口根据业务复杂度的不同，有的接口可能处理一个请求要执行五六次数据库操作，有的接口可能是1次数据库操作+两三个其他系统的接口调用（比如库存系统、营销系统）。

总之，一般来说，业务系统的接口处理逻辑，基本都集中在对自己的数据库的操作以及对其他系统的调用上。

所以大致在我们这里，结合线上数据库的可视化监控界面，基本可以知道，平均每次订单系统的接口调用，会执行2次数据库操作，我们观察数据库的监控界面，在最高峰的时候，每秒大概是有4000左右的请求。

![](../../pic/2020-03-28-12-40-24.png)

之前讲过，线上数据库是部署了一台服务器的，用的是高配置的16核32G以及SSD固态硬盘的机器，因此观察线上数据库的情况，在每秒4000请求的时候，虽然CPU、磁盘、IO等负载较高，但是基本还在承受范围内。

那么接着问题来了，如果在双11之类的超级大促活动中，我们的订单系统可能会面临多大的压力？以及订单数据库可能面临多大的压力？

## 5、今年的双11活动对系统压力会有多大？

明哥接着说，那么今年的双11活动对系统压力会有多大你知道吗？公司现在积累的注册用户已经千万级了，平时的日活用户都百万级，今年的双11参与活动的用户预计有可能会达到两三百万。

假设是这个量级的话，基本可以做一个设想，如果有200万用户参与双11活动，在双11购物最高峰的时候，肯定会比往年的高峰QPS高好几倍，预计有可能今年双11最高峰的时候，会达到每秒至少1万的QPS。

也就是说，光是系统被请求的QPS就会达到1万以上，那么系统请求数据库的QPS就会达到2万以上。仅仅凭借我们目前的数据库性能，是无论如何扛不住每秒2万请求的。

> 12 授人以渔：你们系统会不会遇到流量洪峰的场景，导致瞬时压力过大？

有些人会觉得，自己不知道怎么看这个QPS，那么大家完全可以自己写一个简单的QPS统计框架，在你的各个接口被调用的时候，先执行这个QPS统计框架的代码。

然后在QPS统计框架里计算各个接口每秒被访问的次数，然后输出到你的日志文件里去即可。

当然，更好的方式是采用一些可视化的监控系统去观察你的系统的QPS。

接着建议大家去观察一下自己线上数据库的QPS，一般也都是基于一些可视化监控系统去看的。

# 13 阶段性复习：一张思维导图给你梳理高并发订单系统面临的技术痛点！

![](../../pic/2020-03-28-12-48-10.png)

# 14 阶段性复习：放大100倍压力，也要找出你系统的技术挑战！

今天我就来带着大家梳理一下过去一个阶段的授人以渔环节，我们希望大家能够哪些问题进行深度的思考。

- 1、大家先思考一下系统的核心业务流程，当然不是指那种查询之类的操作。所谓核心链路指的是对你的系统进行的数据更新的操作，这才是核心链路，因为查询操作一般来说不涉及复杂的业务逻辑，主要是对数据的展示。对你的系统的核心链路分析一下，有哪些步骤，这些步骤各自的性能如何，综合起来让你的核心链路的性能如何？在这里是否有改进的空间？

- 2、大家可以思考一下，在你的系统中，是否有类似后台线程定时补偿的逻辑？比如订单长时间未支付就要自动关闭它，你们系统里有没有那种后台线程，会定时扫描你的数据，对异常数据进行补偿、自动修复等操作的？如果有的话，这种数据一般量有多大？如果没有，你可以思考一下，你们系统的核心数据是否需要类似的后台自动扫描机制？

- 3、大家可以思考一下，在你的系统里有没有跟第三方系统进行耦合？就是一些核心流程里需要同步调用第三方系统进行查询、更新等操作，第三方系统是否对你的核心链路有性能和稳定性上的影响？

- 4、大家可以思考一下，在你的核心链路中，是否存在那种关键步骤可能会失败的情况？万一失败了该怎么办？

- 5、大家可以思考一下，平时是否存在其他系统需要获取你们数据的情况？他们是如何获取你们数据的？是直接跑SQL从你们数据库里查询？或者是调用你们的接口来获取数据？是否存在这种情况？如果有，对你们有什么影响吗？

- 6、你们的系统是否存在流量洪峰的情况，有时候突然之间访问量增大好几倍，是否会对你们的系统产生无法承受的压力？


# 15 解决订单系统诸多问题的核心技术：消息中间件到底是什么？

那么消息中间件到底有什么用呢？异步化提升性能，降低系统耦合，流量削峰

![流量削峰场景](../../pic/2020-03-29-09-08-05.png)


# 17 领导的要求：你来对 Kafka、RabbitMQ 以及 RocketMQ 进行技术选型调研

具体来说，比如对于我们现在的情况，你只知道有一个MQ的概念，但是你要考虑一下：

- 业内常用的MQ有哪些？

- 每一种MQ各自的表现如何？

- 这些MQ在同等机器条件下，能抗多少QPS（每秒抗几千QPS还是几万QPS）？

- 性能有多高（发送一条消息给他要2ms还是20ms）？

- 可用性能不能得到保证（要是MQ部署的机器挂了怎么办）？

- 他们会不会丢失数据？

- 如果需要的话能否让他们进行线性的集群扩容（就是多加几台机器）？

- 消息中间件经常需要使用的一些功能他们都有吗（比如说延迟消息、事务消息、消息堆积、消息回溯、死信队列，等等）？

- 另外还得考虑这些MQ在文档是否齐全？社区是否活跃？在行业内是否广泛运用？是用什么语言编写的？


## 3、Kafka、RabbitMQ以及RocketMQ的调研对比

首先，小猛通过网上搜集资料，发现一般国内常用的MQ技术有四种实现，ActiveMQ、Kafka、RabbitMQ、RocketMQ，但是其中ActiveMQ主要是几年以前较多公司使用，现在几乎国内用的公司都很少了。

（1）Kafka的优势和劣势

先来说Kafka，小猛通过查阅一些Kafka的基本资料发现，首先Kafka的吞吐量几乎是行业里最优秀的，在常规的机器配置下，一台机器可以达到每秒十几万的QPS，相当的强悍。

Kafka性能也很高，基本上发送消息给Kafka都是毫秒级的性能。可用性也很高，Kafka是可以支持集群部署的，其中部分机器宕机是可以继续运行的。

但是**Kafka比较为人诟病的一点，似乎是丢数据方面的问题**，因为Kafka收到消息之后会写入一个磁盘缓冲区里，并没有直接落地到物理磁盘上去，所以要是机器本身故障了，可能会导致磁盘缓冲区里的数据丢失。

而且Kafka另外一个比较大的缺点，就是**功能非常的单一**，主要是支持发送消息给他，然后从里面消费消息，其他就没有什么额外的高级功能了。所以基于Kafka有限的功能，可能适用的场景并不是很多。

因此综上所述，以及查阅了Kafka技术在各大公司里的使用，基本行业里的一个标准，是把Kafka用在用户行为日志的采集和传输上，比如大数据团队要收集APP上用户的一些行为日志，这种日志就是用Kafka来收集和传输的。

因为那种日志适当丢失数据是没有关系的，而且一般量特别大，要求吞吐量要高，一般就是收发消息，不需要太多的高级功能，所以Kafka是非常适合这种场景的。



（2）RabbitMQ的优势和历史

再说RabbitMQ，在RocketMQ出现之前，国内大部分公司都从ActiveMQ切换到RabbitMQ来使用，包括很多一线互联网大厂，而且直到现在都有很多中小型公司在使用RabbitMQ。

RabbitMQ的优势在于可以保证数据不丢失，也能保证高可用性，即集群部署的时候部分机器宕机可以继续运行，然后支持部分高级功能，比如说死信队列，消息重试之类的，这些是他的优点。

但是他也有一些缺点，**最为人诟病的，就是RabbitMQ的吞吐量是比较低的**，一般就是每秒几万的级别，所以如果遇到特别特别高并发的情况下，支撑起来是有点困难的。

而且他进行集群扩展的时候（也就是加机器部署），还比较麻烦。

另外还有一个较为致命的缺陷，就是他的开发语言是erlang，国内很少有精通erlang语言的工程师，因此也没办法去阅读他的源代码，甚至修改他的源代码。

所以现在行业里的一个情况是，很多BAT等一线互联网大厂都切换到使用更加优秀的RocketMQ了，但是很多中小型公司觉得RabbitMQ基本可以满足自己的需求还在继续使用中，因为中小型公司并不需要特别高的吞吐量，RabbitMQ已经足以满足他们的需求了，而且也不需要部署特别大规模的集群，也没必要去阅读和修改RabbitMQ的源码。


（3）RocketMQ的优势和劣势

RocketMQ是阿里开源的消息中间件，久经沙场，非常的靠谱。他几乎同时解决了Kafka和RabbitMQ的缺陷。

RocketMQ的吞吐量也同样很高，单机可以达到10万QPS以上，而且可以保证高可用性，性能很高，而且支持通过配置保证数据绝对不丢失，可以部署大规模的集群，还支持各种高级的功能，比如说延迟消息、事务消息、消息回溯、死信队列、消息积压，等等。

而且RocketMQ是基于Java开发的，符合国内大多数公司的技术栈，很容易就可以阅读他的源码，甚至是修改他的源码。

所以现在国内很多一线互联网大厂都切换为使用RocketMQ了，他们需要RocketMQ的高吞吐量，大规模集群部署能力，以及各种高阶的功能去支撑自己的各种业务场景，同时还可以根据自己的需求定制修改RocketMQ的源码。

RocketMQ是非常适合用在Java业务系统架构中的，因为他很高的性能表现，还有他的高阶功能的支持，可以让我们解决各种业务问题。

当然，RocketMQ也有一点美中不足的地方，就是经过我的调查发现，RocketMQ的官方文档相对简单一些，但是Kafka和RabbitMQ的官方文档就非常的全面和详细，这可能是RocketMQ目前唯一的缺点。

（4）活跃的社区和广泛的运用

最后一点，基本上Kafka、RabbitMQ和RocketMQ的社区都还算活跃，更新频率都还可以，而且基本运用都非常的广泛。

尤其是Kafka和RabbitMQ，目前Kafka几乎是国内大数据领域日志采集传输的标准，RabbitMQ在各种中小公司里运用极为广泛，RocketMQ也是开始在一些大公司和其他公司里快速推行中。



# 19 新技术引入：给团队分享 RocketMQ 的架构原理和使用方式

- RocketMQ是如何集群化部署来承载高并发访问的？

- 如果RocketMQ中要存储海量消息，如何实现分布式存储架构？

## 2、MQ如何集群化部署来支撑高并发访问？

这里就先讲一个概念，假设RocketMQ部署在一台机器上，即使这台机器配置很高，但是一般来说一台机器也就是支撑10万+的并发访问。

那么这个时候，假设有大量的系统都要往RocketMQ里高并发的写入消息，可能达到每秒有几十万请求，这个时候怎么办呢？

没关系，RocketMQ是可以集群化部署的，可以部署在多台机器上，假设每台机器都能抗10万并发，然后你只要让几十万请求分散到多台机器上就可以了，让每台机器承受的QPS不超过10万不就行了。

![](../../pic/2020-03-29-09-23-25.png)

## 3、MQ如果要存储海量消息应该怎么做？

现在来说第二个问题，MQ会收到大量的消息，这些消息并不是立马就会被所有的消费方获取过去消费的，所以一般MQ都得把消息在自己本地磁盘存储起来，然后等待消费方获取消息去处理。

既然如此，MQ就得存储大量的消息，可能是几百万条，可能几亿条，甚至万亿条，这么多的消息在一台机器上肯定是没法存储的，RocketMQ是如何分布式存储海量消息的呢？

假设一共有1万条消息，分散发送给10台机器，可能每台机器就是接收到1000条消息。

其次，每台机器上部署的RocketMQ进程一般称之为Broker，每个Broker都会收到不同的消息，然后就会把这批消息存储在自己本地的磁盘文件里

这样的话，假设你有1亿条消息，然后有10台机器部署了RocketMQ的Broker，理论上不就可以让每台机器存储1000万条消息了吗？

![](../../pic/2020-03-29-09-25-59.png)


所以本质上RocketMQ存储海量消息的机制就是分布式的存储。

所谓分布式存储，就是把数据分散在多台机器上来存储，每台机器存储一部分消息，这样多台机器加起来就可以存储海量消息了！

## 4、高可用保障：万一Broker宕机了怎么办？

小猛继续说下一个问题，要是任何一台Broker突然宕机了怎么办？那不就会导致RocketMQ里一部分的消息就没了吗？这就会导致MQ的不可靠和不可用，这个问题怎么解决？

RocketMQ的解决思路是**Broker主从架构以及多副本策略**

![](../../pic/2020-03-29-09-27-57.png)

Master Broker收到消息之后会同步给Slave Broker，这样Slave Broker上就能有一模一样的一份副本数据！

这样同一条消息在RocketMQ整个集群里不就有两个副本了，一个在Master Broker里，一个在Slave Broker里！

这个时候如果任何一个Master Broker出现故障，还有一个Slave Broker上有一份数据副本，可以保证数据不丢失，还能继续对外提供服务，保证了MQ的可靠性和高可用性

## 5、数据路由：怎么知道访问哪个Broker？

现在又有一个问题了，对于系统来说，要发送消息到MQ里去，还要从MQ里消费消息

那么大家怎么知道有哪些Broker？怎么知道要连接到哪一台Broker上去发送和接收消息？这是一个大问题！

所以RocketMQ为了解决这个问题，有一个NameServer的概念，他也是独立部署在几台机器上的，然后所有的Broker都会把自己注册到NameServer上去，NameServer不就知道集群里有哪些Broker了？

然后对于我们的系统而言，如果他要发送消息到Broker，会找NameServer去获取路由信息，就是集群里有哪些Broker等信息

如果系统要从Broker获取消息，也会找NameServer获取路由信息，去找到对应的Broker获取消息。

![](../../pic/2020-03-29-09-30-34.png)

备注：broker会注册到全部的nameserver上，各个nameserver之间相互独立，没有信息的交互。

基本上这个就是RocketMQ最基本的一个架构原理图。


# 21 设计生产架构之前的功课：消息中间件路由中心的架构原理是什么？

![](../../pic/2020-03-29-09-30-34.png)

其实RocketMQ这个技术一共是包含了四个核心的部分：

- 1、就是他的NameServer，这个东西很重要，他要负责去管理集群里所有Broker的信息，让使用MQ的系统可以通过他感知到集群里有哪些Broker。

- 2、就是Broker集群本身了，必须得在多台机器上部署这么一个集群，而且还得用主从架构实现数据多副本存储和高可用。

- 3、就是向MQ发送消息的那些系统了，这些系统一般称之为生产者，这里也有很多细节是值得深究的，因为这些生产者到底是如何从NameServer拉取路由信息的？如何选择Broker机器建立连接以及发送消息的？

- 4、就是从MQ获取消息的那些系统，这些系统一般称之为消费者。

## 4、NameServer到底可以部署几台机器？

是一台机器？还是可以部署多台机器？如果部署多台机器，他们之间是怎么协同工作的？

那为什么NameServer要集群化部署？最主要的一个原因，就是**高可用性**

所以通常来说，NameServer一定会多机器部署，实现一个集群，起到高可用的效果，保证任何一台机器宕机，其他机器上的NameServer可以继续对外提供服务！

## 5、Broker是把自己的信息注册到哪个NameServer上去？

下一个问题：Broker在启动的时候是把自己的信息注册到哪个NameServer上去的？

有的人可能会猜测，是不是这样，比如一共有10台Broker机器，2个NameServer机器，然后其中5台Broker会把自己的信息注册到1个NameServer上去，另外5台Broker会把自己的信息注册到另外1个NameServer上去。

这样搞有一个最大的问题，如果1台NameServer上有5个Broker的信息，另外1个NameServer上有另外5个Broker的信息，那么此时任何一个NameServer宕机了，不就导致5个Broker的信息就没了吗？

所以这种做法是不靠谱的，会导致数据丢失，系统不可用。

因此正确答案是：**每个Broker启动都得向所有的NameServer进行注册**

也就是说，每个NameServer都会有一份集群中所有Broker的信息。

![](../../pic/2020-03-29-09-40-15.png)

在这个图里就示范了一个Master Broker得向两台NameServer都进行注册的情况，这才是真正的情况。


## 6、系统如何从NameServer获取Broker信息？

RocketMQ中的生产者和消费者自己主动去NameServer拉取Broker信息的。

![](../../pic/2020-03-29-09-41-54.png)

顺便在这里解释一下，图里的路由信息，大致可以理解为集群里的Broker信息以及其他相关的数据信息

通过这些路由信息，每个系统就知道发送消息或者获取消息去哪台Broker上去进行了，这起到一个把消息路由到一个Broker上的效果，所以一般我们把这种信息叫做路由信息。

## 7、如果Broker挂了，NameServer是怎么感知到的？

要解决这个问题，靠的是Broker跟NameServer之间的**心跳机制**，Broker会每隔30s给所有的NameServer发送心跳，告诉每个NameServer自己目前还活着。

每次NameServer收到一个Broker的心跳，就可以更新一下他的最近一次心跳的时间

然后NameServer会每隔10s运行一个任务，去检查一下各个Broker的最近一次心跳时间，如果某个Broker超过120s都没发送心跳了，那么就认为这个Broker已经挂掉了。

![](../../pic/2020-03-29-09-44-12.png)


## 8、Broker挂了，系统是怎么感知到的？

如果要发送消息的broker宕机了，会导致发送消息失败。

大家可以想一下，如果确实是那个情况，可以有两种解决办法。

- 首先，你可以考虑不发送消息到那台Broker，改成发到其他Broker上去。

- 其次，假设你必须要发送消息给那台Broker，那么他挂了，他的Slave机器是一个备份，可以继续使用，你是不是可以考虑等一会儿去跟他的Slave进行通信？

总之，这些都是思路，但是现在我们先知道，对于生产者而言，他是有一套容错机制的，即使一下子没感知到某个Broker挂了，他可以有别的方案去应对。

而且过一会儿，系统又会重新从NameServer拉取最新的路由信息了，此时就会知道有一个Broker已经宕机了。



> 22 授人以渔：要是没有这个路由中心，消息中间件可以正常运作么？

这个路由中心的角色需要去感知集群里所有的Broker节点，然后需要去配合生产者和消费者，让人家都能感知到集群里有哪些Broker，才能让各个系统跟MQ进行通信。

如果大家之前都对Kafka和RabbitMQ自行查阅资料有了一个基本的了解之后，就会发现Kafka的路由中心实际上是一个非常复杂、混乱的存在。他是由ZooKeeper以及某个作为Controller的Broker共同完成的。

RabbitMQ的话自己本身就是由集群每个节点同时扮演了路由中心的角色。

而RocketMQ是把路由中心抽离出来作为一个独立的NameServer角色运行的，因此可以说在路由中心这块，他的架构设计是最清晰明了的。

那么请大家在这里思考一个问题，RocketMQ把NameServer独立抽取出来运行，那么假设这个NameServer集群整体都故障了，失去了这个NameServer集群之后：

- RocketMQ还能正常运行吗？

- 生产者还能发送消息到Broker吗？

- 消费者还能从Broker拉取消息吗？

# 23 设计生产架构之前的功课：Broker的主从架构原理是什么？

## 2、Master Broker是如何将消息同步给Slave Broker的？

先来看第一个问题，我们都知道，为了保证MQ的数据不丢失而且具备一定的高可用性，所以一般都是得将Broker部署成Master-Slave模式的，也就是一个Master Broker对应一个Slave Broker

然后Master需要在接收到消息之后，将数据同步给Slave，这样一旦Master Broker挂了，还有Slave上有一份数据。

RocketMQ的Master-Slave模式采取的是Slave Broker不停的发送请求到Master Broker去拉取消息。

所以首先要明白这一点，就是RocketMQ自身的Master-Slave模式采取的是Pull模式拉取消息。

![](../../pic/2020-03-29-09-53-05.png)


## 3、RocketMQ 实现读写分离了吗？

下一个问题，既然Master Broker主要是接收系统的消息写入，然后会同步给Slave Broker，那么其实本质上Slave Broker也应该有一份一样的数据。

所以这里提出一个疑问，作为消费者的系统在获取消息的时候，是从Master Broker获取的？还是从Slave Broker获取的？

答案：**有可能从Master Broker获取消息，也有可能从Slave Broker获取消息**

作为消费者的系统在获取消息的时候会先发送请求到Master Broker上去，请求获取一批消息，此时Master Broker是会返回一批消息给消费者系统的

然后Master Broker在返回消息给消费者系统的时候，会根据当时Master Broker的负载情况和Slave Broker的同步情况，向消费者系统建议下一次拉取消息的时候是从Master Broker拉取还是从Slave Broker拉取。

举个例子，要是这个时候Master Broker负载很重，本身要抗10万写并发了，你还要从他这里拉取消息，给他加重负担，那肯定是不合适的。

所以此时Master Broker就会建议你从Slave Broker去拉取消息。

或者举另外一个例子，本身这个时候Master Broker上都已经写入了100万条数据了，结果Slave Broke不知道啥原因，同步的特别慢，才同步了96万条数据，落后了整整4万条消息的同步，这个时候你作为消费者系统可能都获取到96万条数据了，那么下次还是只能从Master Broker去拉取消息。

因为Slave Broker同步太慢了，导致你没法从他那里获取更新的消息了。

所以这一切都会由Master Broker根据情况来决定

![](../../pic/2020-03-29-09-56-05.png)

所以在写入消息的时候，通常来说肯定是选择Master Broker去写入的

但是在拉取消息的时候，有可能从Master Broker获取，也可能从Slave Broker去获取，一切都根据当时的情况来定。

## 4、如果Slave Broke挂掉了有什么影响？

有一点影响，但是影响不太大。

因为消息写入全部是发送到Master Broker的，然后消息获取也可以走Master Broker，只不过有一些消息获取可能是从Slave Broker去走的。

所以如果Slave Broker挂了，那么此时无论消息写入还是消息拉取，还是可以继续从Master Broke去走，对整体运行不影响。

只不过少了Slave Broker，会导致所有读写压力都集中在Master Broker上。

## 5、如果Master Broker挂掉了该怎么办？

这个时候就对消息的写入和获取都有一定的影响了。但是其实本质上而言，Slave Broker也是跟Master Broker一样有一份数据在的，只不过Slave Broker上的数据可能有部分没来得及从Master Broker同步。

但是此时RocketMQ可以实现直接自动将Slave Broker切换为Master Broker吗？

不能

在RocketMQ 4.5版本之前，都是用Slave Broker同步数据，尽量保证数据不丢失，但是一旦Master故障了，Slave是没法自动切换成Master的。

所以在这种情况下，如果Master Broker宕机了，这时就得手动做一些运维操作，把Slave Broker重新修改一些配置，重启机器给调整为Master Broker，这是有点麻烦的，而且会导致中间一段时间不可用。

所以这种Master-Slave模式**不是彻底的高可用模式，他没法实现自动把Slave切换为Master**

![](../../pic/2020-03-29-09-59-26.png)

## 6、基于Dledger实现RocketMQ高可用自动切换

在RocketMQ 4.5之后，这种情况得到了改变，因为RocketMQ支持了一种新的机制，叫做Dledger

本身这个东西是基于Raft协议实现的一个机制，实现原理和算法思想是有点复杂的，我们在这里先不细说。

简单来说，把Dledger融入RocketMQ之后，就可以让一个Master Broker对应多个Slave Broker，也就是说一份数据可以有多份副本，比如一个Master Broker对应两个Slave Broker。

此时一旦Master Broker宕机了，就可以在多个副本，也就是多个Slave中，通过Dledger技术和Raft协议算法进行leader选举，直接将一个Slave Broker选举为新的Master Broker，然后这个新的Master Broker就可以对外提供服务了。

整个过程也许只要10秒或者几十秒的时间就可以完成，这样的话，就可以实现Master Broker挂掉之后，自动从多个Slave Broker中选举出来一个新的Master Broker，继续对外服务，一切都是自动的。

![](../../pic/2020-03-29-10-01-31.png)

> 24 授人以渔：Broker主从同步有没有数据不一致问题？

希望大家今天在学习完RocketMQ的主从同步架构以及高可用切换机制之后，思考以下一些问题：

- 假设如果没有RocketMQ 4.5新版本引入的Dledger技术，仅仅是靠之前的Master-Slave主从同步机制，那么在Master崩溃的时候，可能会造成多长时间的系统不可用？这个时候如何能够尽快的恢复集群运行？依赖手工运维的话，如何能尽快的去完成这个运维操作？


- 在RocketMQ 4.5之后引入了Dledger技术可以做到自动选举新的Master，那么在Master崩溃一直到新的Master被选举出来的这个过程中，你觉得对于使用MQ的系统而言，会处于一个什么样的状态呢？

- 希望大家去研究一下Kafka和RabbitMQ的多副本和高可用机制，Kafka是如何在集群里维护多个副本的？出现故障的时候能否实现自动切换？RabbitMQ是如何在集群里维护多个数据副本的？出现故障的时候能否实现自动切换？

- 既然有主从同步机制，那么有没有主从数据不一致的问题？Slave永远落后Master一些数据，这就是主从不一致。那么这种不一致有没有什么问题？有办法保证主从数据强制一致吗？这样做又会有什么缺点呢？


# 25 落地第一步：设计一套高可用的消息中间件生产部署架构

## 2、NameServer集群化部署，保证高可用性

首先第一步，我们要让NameServer集群化部署，我建议可以部署在三台机器上，这样可以充分保证NameServer作为路由中心的可用性，哪怕是挂掉两台机器，只要有一个NameServer还在运行，就能保证MQ系统的稳定性。

![](../../pic/2020-03-29-10-06-55.png)

因为我上次分享的时候也说了，NameServer的设计是采用的Peer-to-Peer的模式来做的，也就是可以集群化部署，但是里面任何一台机器都是独立运行的，跟其他的机器没有任何通信。

每台NameServer实际上都会有完整的集群路由信息，包括所有的Broker节点信息，我们的数据信息，等等。所以只要任何一台NameServer存活下来，就可以保证MQ系统正常运行，不会出现故障。


## 3、基于Dledger的Broker主从架构部署

![](../../pic/2020-03-29-10-08-07.png)

每个Broker（不论是Master和Slave）都会把自己注册到所有的NameServer上去。然后Master Broker还会把数据同步给两个Slave Broker，保证一份数据在不同机器上有多份副本。

注：图中没有画出Slave Broker注册到NameServer。


## 4、Broker是如何跟NameServer进行通信的？

这个Broker会每隔30秒发送心跳到所有的NameServer上去，然后每个NameServer都会每隔10s检查一次有没有哪个Broker超过120s没发送心跳的，如果有，就认为那个Broker已经宕机了，从路由信息里要摘除这个Broker。

首先，Broker跟NameServer之间的通信是基于什么协议来进行的？

在RocketMQ的实现中，采用的是TCP长连接进行通信。

Broker会跟每个NameServer都建立一个TCP长连接，然后定时通过TCP长连接发送心跳请求过去

所以各个NameServer就是通过跟Broker建立好的长连接不断收到心跳包，然后定时检查Broker有没有120s都没发送心跳包，来判定集群里各个Broker到底挂掉了没有。

![](../../pic/2020-03-29-10-10-31.png)


## 5、使用MQ的系统都要多机器集群部署

下一步，我们一定会有很多的系统使用RocketMQ，有些系统是作为生产者往MQ发送消息，有些系统是作为消费者从MQ获取消息，当然还有的系统是既作为生产者，又作为消费者，所以我们要考虑这些系统的部署。

对于这些系统的部署本身不应该在MQ的考虑范围内，但是我们还是应该给出一个建议，就是无论作为生产者还是消费者的系统，都应该多机器集群化部署，保证他自己本身作为生产者或者消费者的高可用性。

## 6、MQ的核心数据模型：Topic到底是什么？

MQ中的数据模型是什么？你投递出去的消息在逻辑上到底是放到哪里去的？是队列吗？还是别的什么呢？

MQ中的核心数据模型，Topic，数据集合的意思

## 7、Topic作为一个数据集合是怎么在Broker集群里存储的？

这里就体现出来一个分布式存储的概念了。

我们可以在创建Topic的时候指定让他里面的数据分散存储在多台Broker机器上，比如一个Topic里有1000万条数据，此时有2台Broker，那么就可以让每台Broker上都放500万条数据。

这样就可以把一个Topic代表的数据集合分布式存储在多台机器上了。

而且另外很重要的一件事是，每个Broke在进行定时的心跳汇报给NameServer的时候，都会告诉NameServer自己当前的数据情况，比如有哪些Topic的哪些数据在自己这里，这些信息都是属于路由信息的一部分。

![](../../pic/2020-03-29-10-15-03.png)

## 8、生产者系统是如何将消息发送给Broker的？

首先我们之前说过，在发送消息之前，得先有一个Topic，然后在发送消息的时候你得指定你要发送到哪个Topic里面去。

接着既然你知道你要发送的Topic，那么就可以跟NameServer建立一个TCP长连接，然后定时从他那里拉取到最新的路由信息，包括集群里有哪些Broker，集群里有哪些Topic，每个Topic都存储在哪些Broker上。

然后生产者系统自然就可以通过路由信息找到自己要投递消息的Topic分布在哪几台Broker上，此时可以根据负载均衡算法，从里面选择一台Broke机器出来，比如round robine轮询算法，或者是hash算法，都可以。

总之，选择一台Broker之后，就可以跟那个Broker也建立一个TCP长连接，然后通过长连接向Broker发送消息即可.

Broker收到消息之后就会存储在自己本地磁盘里去。

![](../../pic/2020-03-29-10-18-15.png)

这里唯一要注意的一点，就是生产者一定是投递消息到Master Broker的，然后Master Broker会同步数据给他的Slave Brokers，实现一份数据多份副本，保证Master故障的时候数据不丢失，而且可以自动把Slave切换为Master提供服务。

## 9、消费者是如何从Broker上拉取消息的？

消费者系统其实跟生产者系统原理是类似的，他们也会跟NameServer建立长连接，然后拉取路由信息，接着找到自己要获取消息的Topic在哪几台Broker上，就可以跟Broker建立长连接，从里面拉取消息了。

![](../../pic/2020-03-29-10-19-42.png)

这里唯一要注意的一点是，消费者系统可能会从Master Broker拉取消息，也可能从Slave Broker拉取消息，都有可能，一切都看具体情况。

## 10、整体架构：高可用、高并发、海量消息、可伸缩

![](../../pic/2020-03-29-10-26-09.png)

备注：不仅master broker需要注册，slave broker也需要。

整个这套生产架构是实现完全高可用的，因为NameServer随便一台机器挂了都不怕，他是集群化部署的，每台机器都有完整的路由信息；

Broker随便挂了一台机器也不怕，挂了Slave对集群没太大影响，挂了Master也会基于Dledger技术实现自动Slave切换为Master；

生产者系统和消费者系统随便挂了一台都不怕，因为他们都是集群化部署的，其他机器会接管工作。

而且这个架构可以抗下高并发，因为假设订单系统对订单Topic要发起每秒10万QPS的写入，那么只要订单Topic分散在比如5台Broker上，实际上每个Broker会承载2万QPS写入，也就是说高并发场景下的10万QPS可以分散到多台Broker上抗下来。

然后集群足以存储海量消息，因为所有数据都是分布式存储的，每个Topic的数据都是存储在多台Broker机器上的，用集群里多台Master Broker就足以存储海量的消息。

所以，用多个Master Broker部署的方式，加上Topic分散在多台Broker上的机制，可以抗下高并发访问以及海量消息的分布式存储。

最后，这套架构还具备伸缩性，就是说如果要抗更高的并发，存储跟多的数据，完全可以在集群里加入更多的Broker机器，这样就可以线性扩展集群了。

# 27 部署一个小规模的 RocketMQ 集群，为压测做好准备

实战，暂时skip

# 28 授人以渔：动手完成一个小规模的RocketMQ集群的部署进行练习

实战，暂时skip

# 29 生产运维：如何对RocketMQ集群进行可视化的监控和管理？

实战，暂时skip


# 31 RocketMQ生产集群准备：进行OS内核参数和JVM参数的调整

## 1、压测前的准备工作

![](../../pic/2020-03-29-10-28-15.png)

对于生产环境的中间件集群，不能直接用各种默认参数启动，因为那样可能有很多问题，或者没法把中间件的性能发挥出来。

对于一个中间件而言，第一步，你需要对他部署的机器的OS内核参数进行一定的调整（也就是linux操作系统的一些内核参数）

因为OS内核参数很多默认值未必适合生产环境的系统运行，有些参数的值需要调整大一些，才能让中间件发挥出来性能。

![](../../pic/2020-03-29-10-29-43.png)

接着下一步需要思考的一个问题，就是一般中间件，比如RocketMQ、MyCat、Elasticsearch、Kafka之类的东西，很多都是Java开发的，或者是基于JVM的Scala开发的（比如Kafka）

所以你可以认为在一台机器上部署和启动一个中间件系统，说白了就是启动一个JVM进程，由这个JVM进程来运行中间件系统内的所有代码，然后实现中间件系统的各种功能。

![](../../pic/2020-03-29-10-30-29.png)

所以其实对于一个生产环境的中间件系统而言，在部署和启动之前，需要关注的第二个东西就是JVM的各种参数

![](../../pic/2020-03-29-10-31-17.png)

最后第三件事情，就是中间件系统自己本身的一些核心参数的设置，比如你的中间件系统会开启很多线程处理请求和工作负载，然后还会进行大量的网络通信，同时会进行大量的磁盘IO类的操作。

所以以上三点，就是对任何一个中间件系统，在进行压力测试以及生产环境部署之前，都必须要进行调整的！

当然如果是普通的那种Java Web业务系统，通常而言上线之前主要关注的就是JVM的参数而已，对os内核参数以及业务系统自身参数大多数情况下都没有太多的要求

但是中间件系统而言，往往必须要对**os内核参数、jvm参数以及自身核心参数**都做出相对应的合理的调整，再进行压测和上线。


## 2、对RocketMQ集群进行OS内核参数的调整

（1）vm.overcommit_memory

“vm.overcommit_memory”这个参数有三个值可以选择，0、1、2。

如果值是0的话，在你的中间件系统申请内存的时候，os内核会检查可用内存是否足够，如果足够的话就分配内存给你，如果感觉剩余内存不是太够了，干脆就拒绝你的申请，导致你申请内存失败，进而导致中间件系统异常出错。

因此一般需要将这个参数的值调整为1，意思是把所有可用的物理内存都允许分配给你，只要有内存就给你来用，这样可以避免申请内存失败的问题。

可以用如下命令修改：echo 'vm.overcommit_memory=1' >> /etc/sysctl.conf。


（2）vm.max_map_count

这个参数的值会影响中间件系统可以开启的线程的数量，同样也是非常重要的

如果这个参数过小，有的时候可能会导致有些中间件无法开启足够的线程，进而导致报错，甚至中间件系统挂掉。

他的默认值是65536，但是这个值有时候是不够的，比如我们大数据团队的生产环境部署的Kafka集群曾经有一次就报出过这个异常，说无法开启足够多的线程，直接导致Kafka宕机了。

因此建议可以把这个参数调大10倍，比如655360这样的值，保证中间件可以开启足够多的线程。

可以用如下命令修改：echo 'vm.max_map_count=655360' >> /etc/sysctl.conf。

（3）vm.swappiness

这个参数是用来控制进程的swap行为的，这个简单来说就是os会把一部分磁盘空间作为swap区域，然后如果有的进程现在可能不是太活跃，就会被操作系统把进程调整为睡眠状态，把进程中的数据放入磁盘上的swap区域，然后让这个进程把原来占用的内存空间腾出来，交给其他活跃运行的进程来使用。

如果这个参数的值设置为0，意思就是尽量别把任何一个进程放到磁盘swap区域去，尽量大家都用物理内存。

如果这个参数的值是100，那么意思就是尽量把一些进程给放到磁盘swap区域去，内存腾出来给活跃的进程使用。

默认这个参数的值是60，有点偏高了，可能会导致我们的中间件运行不活跃的时候被迫腾出内存空间然后放磁盘swap区域去。

因此通常在生产环境建议把这个参数调整小一些，比如设置为10，尽量用物理内存，别放磁盘swap区域去。

可以用如下命令修改：echo 'vm.swappiness=10' >> /etc/sysctl.conf。

（4）ulimit

这个是用来控制linux上的最大文件链接数的，默认值可能是1024，一般肯定是不够的，因为你在大量频繁的读写磁盘文件的时候，或者是进行网络通信的时候，都会跟这个参数有关系

对于一个中间件系统而言肯定是不能使用默认值的，如果你采用默认值，很可能在线上会出现如下错误：error: too many open files。

因此通常建议用如下命令修改这个值：echo 'ulimit -n 1000000' >> /etc/profile。

（5）一点小小的总结

其实大家综合思考一下这几个参数，会发现到最后要调整的东西，无非都是跟磁盘文件IO、网络通信、内存管理、线程数量有关系的，因为我们的中间件系统在运行的时候无非就是跟这些打交道。

- 中间件系统肯定要开启大量的线程（跟vm.max_map_count有关）

- 而且要进行大量的网络通信和磁盘IO（跟ulimit有关）

- 然后大量的使用内存（跟vm.swappiness和vm.overcommit_memory有关）

所以对OS内核参数的调整，往往也就是围绕跟中间件系统运行最相关的一些东西。


## 3、对JVM参数进行调整

在为启动Broker设置对应的JVM参数和其他一些参数，我们可以把其中JVM相关的参数抽取出来给大家解释一下：

```
“-server -Xms8g -Xmx8g -Xmn4g -XX:+UseG1GC -XX:G1HeapRegionSize=16m -XX:G1ReservePercent=25 -XX:InitiatingHeapOccupancyPercent=30 -XX:SoftRefLRUPolicyMSPerMB=0 -verbose:gc -Xloggc:/dev/shm/mq_gc_%p.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCApplicationStoppedTime -XX:+PrintAdaptiveSizePolicy -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=30m -XX:-OmitStackTraceInFastThrow -XX:+AlwaysPreTouch -XX:MaxDirectMemorySize=15g -XX:-UseLargePages -XX:-UseBiasedLocking”
```

-server：这个参数就是说用服务器模式启动，这个没什么可说的，现在一般都是如此

-Xms8g -Xmx8g -Xmn4g：这个就是很关键的一块参数了，也是重点需要调整的，就是默认的堆大小是8g内存，新生代是4g内存，但是我们的高配物理机是48g内存的

-XX:+UseG1GC -XX:G1HeapRegionSize=16m：这几个参数也是至关重要的，这是选用了G1垃圾回收器来做分代回收，对新生代和老年代都是用G1来回收.这里把G1的region大小设置为了16m，这个因为机器内存比较多，所以region大小可以调大一些给到16m，不然用2m的region，会导致region数量过多的

-XX:G1ReservePercent=25：这个参数是说，在G1管理的老年代里预留25%的空闲内存，保证新生代对象晋升到老年代的时候有足够空间，避免老年代内存都满了，新生代有对象要进入老年代没有充足内存了。默认值是10%，略微偏少，这里RocketMQ给调大了一些

-XX:InitiatingHeapOccupancyPercent=30：这个参数是说，当堆内存的使用率达到30%之后就会自动启动G1的并发垃圾回收，开始尝试回收一些垃圾对象。默认值是45%，这里调低了一些，也就是提高了GC的频率，但是避免了垃圾对象过多，一次垃圾回收耗时过长的问题

-XX:SoftRefLRUPolicyMSPerMB=0：这个参数默认设置为0了，在JVM优化专栏中，救火队队长讲过这个参数引发的案例，其实建议这个参数不要设置为0，避免频繁回收一些软引用的Class对象，这里可以调整为比如1000

-verbose:gc -Xloggc:/dev/shm/mq_gc_%p.log -XX:+PrintGCDetails -XX:+PrintGCDateStamps -XX:+PrintGCApplicationStoppedTime -XX:+PrintAdaptiveSizePolicy -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=5 -XX:GCLogFileSize=30m 这一堆参数都是控制GC日志打印输出的，确定了gc日志文件的地址，要打印哪些详细信息，然后控制每个gc日志文件的大小是30m，最多保留5个gc日志文件。


-XX:-OmitStackTraceInFastThrow：这个参数是说，有时候JVM会抛弃一些异常堆栈信息，因此这个参数设置之后，就是禁用这个特性，要把完整的异常堆栈信息打印出来

-XX:+AlwaysPreTouch：这个参数的意思是我们刚开始指定JVM用多少内存，不会真正分配给他，会在实际需要使用的时候再分配给他。所以使用这个参数之后，就是强制让JVM启动的时候直接分配我们指定的内存，不要等到使用内存的时候再分配

-XX:MaxDirectMemorySize=15g：这是说RocketMQ里大量用了NIO中的direct buffer，这里限定了direct buffer最多申请多少，如果你机器内存比较大，可以适当调大这个值，如果有朋友不了解direct buffer是什么，可以自己查阅一些资料。

-XX:-UseLargePages -XX:-UseBiasedLocking：这两个参数的意思是禁用大内存页和偏向锁，这两个参数对应的概念每个要说清楚都得一篇文章，所以这里大家直接知道人家禁用了两个特性即可。

最后我们做一点小的总结，RocketMQ默认的JVM参数是采用了**G1垃圾回收器，默认堆内存大小是8G**

这个其实完全可以根据大家的机器内存来调整，你可以增大一些也是没有问题的，然后就是一些G1的垃圾回收的行为参数做了调整，这个一般我们不用去动，然后就是对GC日志打印做了设置，这个一般也不用动。其余的就是禁用一些特性，开启一些特性，这些都直接维持RocketMQ的默认值即可。

## 4、对RocketMQ核心参数进行调整

之前讲解集群部署的时候给大家提过，在下面的目录里有dledger的示例配置文件：rocketmq/distribution/target/apache-rocketmq/conf/dledger

在这里主要是有一个较为核心的参数：sendMessageThreadPoolNums=16

这个参数的意思就是RocketMQ内部用来发送消息的线程池的线程数量，默认是16

其实这个参数可以根据你的机器的CPU核数进行适当增加，比如机器CPU是24核的，可以增加这个线程数量到24或者30，都是可以的。

## 5、今日内容总结

- 1、中间件系统在压测或者上生产之前，需要对三大块参数进行调整：**OS内核参数、JVM参数以及中间件核心参数**

- 2、OS内核参数主要调整的地方都是跟磁盘IO、网络通信、内存管理以及线程管理有关的，需要适当调节大小

- 3、JVM参数需要我们去中间件系统的启动脚本中寻找他的默认JVM参数，然后根据机器的情况，对JVM的堆内存大小，新生代大小，Direct Buffer大小，等等，做出一些调整，发挥机器的资源

- 4、中间件核心参数主要也是关注其中跟网络通信、磁盘IO、线程数量、内存 管理相关的，根据机器资源，适当可以增加网络通信线程，控制同步刷磁盘或者异步刷磁盘，线程数量有多少，内存中一些队列的大小

# 33 对小规模RocketMQ集群进行压测，同时为生产集群进行规划

## 1、压测就是拼命往死了压吗？

什么叫最合适的最高负载呢？在RocketMQ的TPS和机器的资源使用率和负载之间取得一个平衡。

比如RocketMQ集群在机器资源使用率极高的极端情况下可以扛到10万TPS，但是当他仅仅抗下8万TPS的时候，你会发现cpu负载、内存使用率、IO负载和网卡流量，都负载较高，但是可以接受，机器比较安全，不至于宕机。

那么这个8万TPS实际上就是最合适的一个最高负载，也就是说，哪怕生产环境中极端情况下，RocketMQ的TPS飙升到8万TPS，你知道机器资源也是大致可以抗下来的，不至于出现机器宕机的情况。

所以我们做压测，其实最主要的是综合TPS以及机器负载，尽量找到一个最高的TPS同时机器的各项负载在可承受范围之内，这才是压测的目的。


## 2、一次RocketMQ小规模集群的压测

以下压测过程以及压测结果，都是根据我们之前真实的RocketMQ压测报告总结而来，非常的有代表性，大家完全可以结合我们之前说的机器配置来参考一下

（1）RocketMQ的TPS和消息延时

我们让两个Producer不停的往RocketMQ集群发送消息，每个Producer所在机器启动了80个线程，相当于每台机器有80个线程并发的往RocketMQ集群写入消息。而RocketMQ集群是1主2从组成的一个dledger模式的高可用集群，只有一个Master Broker会接收消息的写入。然后有2个Cosumer不停的从RocketMQ集群消费数据。

每条数据的大小是500个字节，大家一定要牢记这个数字，因为这个数字是跟后续的网卡流量有关的。

我们发现，一条消息从Producer生产出来到经过RocketMQ的Broker存储下来，再到被Consumer消费，基本上这个时间跨度不会超过1秒钟，这些这个性能是正常而且可以接受的。

同时在RocketMQ的管理工作台中可以看到，Master Broker的TPS（也就是每秒处理消息的数量），可以稳定的达到7万左右，也就是每秒可以稳定处理7万消息。

（2）cpu负载情况

其次我们检查了一下Broker机器上的CPU负载，可以通过top、uptime等命令来查看

比如执行top命令就可以看到cpu load和cpu使用率，这就代表了cpu的负载情况。

在你执行了top命令之后，往往可以看到如下一行信息：

load average：12.03，12.05，12.08

类似上面那行信息代表的是cpu在1分钟、5分钟和15分钟内的cpu负载情况

比如我们一台机器是24核的，那么上面的12意思就是有12个核在使用中。换言之就是还有12个核其实还没使用，cpu还是有很大余力的。这个cpu负载其实是比较好的，因为并没有让cpu负载达到极限。

（3）内存使用率

使用free命令就可以查看到内存的使用率，根据当时的测试结果，机器上48G的内存，仅仅使用了一部分，还剩下很大一部分内存都是空闲可用的，或者是被RocketMQ用来进行磁盘数据缓存了。所以内存负载是很低的。

（4）JVM GC频率

使用jstat命令就可以查看RocketMQ的JVM的GC频率，基本上新生代每隔几十秒会垃圾回收一次，每次回收过后存活的对象很少，几乎不进入老年代。因此测试过程中，Full GC几乎一次都没有。

（5）磁盘IO负载

接着可以检查一下磁盘IO的负载情况。

首先可以用top命令查看一下IO等待占用CPU时间的百分比，你执行top命令之后，会看到一行类似下面的东西：

Cpu(s):  0.3% us,  0.3% sy,  0.0% ni, 76.7% id, 13.2% wa,  0.0% hi,  0.0% si。

在这里的13.2% wa，说的就是磁盘IO等待在CPU执行时间中的百分比

如果这个比例太高，说明CPU执行的时候大部分时间都在等待执行IO，也就说明IO负载很高，导致大量的IO等待。

这个当时我们压测的时候，是在40%左右，说明IO等待时间占用CPU执行时间的比例在40%左右，这是相对高一些，但还是可以接受的，只不过如果继续让这个比例提高上去，就很不靠谱了，因为说明磁盘IO负载可能过高了。

（6）网卡流量

使用如下命令可以查看服务器的网卡流量：sar -n DEV 1 2

通过这个命令就可以看到每秒钟网卡读写数据量了。当时我们的服务器使用的是千兆网卡，千兆网卡的理论上限是每秒传输128M数据，但是一般实际最大值是每秒传输100M数据。

因此当时我们发现的一个问题就是，在RocketMQ处理到每秒7万消息的时候，每条消息500字节左右的大小的情况下，每秒网卡传输数据量已经达到100M了，就是已经达到了网卡的一个极限值了。

因为一个Master Broker服务器，每秒不光是通过网络接收你写入的数据，还要把数据同步给两个Slave Broker，还有别的一些网络通信开销。

因此实际压测发现，每条消息500字节，每秒7万消息的时候，服务器的网卡就几乎打满了，无法承载更多的消息了。


备注：每条消息500字节，每秒7万消息会产生30M的带宽，加上同步2个slave差不多100M？

（7）针对压测的一点小总结

最后针对本次压测做一点小的总结，实际上经过压测，最终发现我们的服务器的性能瓶颈在网卡上，因为网卡每秒能传输的数据是有限的

因此当我们使用平均大小为500字节的消息时，最多就是做到RocketMQ单台服务器每秒7万的TPS，而且这个时候cpu负载、内存负载、jvm gc负载、磁盘io负载，基本都还在正常范围内。

只不过这个时候网卡流量基本已经打满了，无法再提升TPS了。

因此在这样的一个机器配置下，RocketMQ一个比较靠谱的TPS就是7万左右。

## 3、基于公司业务情况规划生产集群

因此在部署的时候，小猛建议是对NameServer采用3台机器部署就足够了，而对于Broker而言采用6台机器来部署，2个Master Broker和4个Slave Broker，这样2个Master Broker每秒最多可以处理十几万消息，4个Slave Broker同时也能每秒提供高吞吐的数据消费，而且全面保证高可用性。

![](../../pic/2020-03-29-11-08-02.png)

## 4、今日内容总结

- 1、到底应该如何压测：应该在TPS和机器的cpu负载、内存使用率、jvm gc频率、磁盘io负载、网络流量负载之间取得一个平衡，尽量让TPS尽可能的提高，同时让机器的各项资源负载不要太高。

- 2、实际压测过程：采用几台机器开启大量线程并发读写消息，然后观察TPS、cpu load（使用top命令）、内存使用率（使用free命令）、jvm gc频率（使用jstat命令）、磁盘io负载（使用top命令）、网卡流量负载（使用sar命令），不断增加机器和线程，让TPS不断提升上去，同时观察各项资源负载是否过高。

- 3、生产集群规划：根据公司的后台整体QPS来定，稍微多冗余部署一些机器即可，实际部署生产环境的集群时，使用高配置物理机，同时合理调整os内核参数、jvm参数、中间件核心参数，如此即可

# 35 阶段性复习：一张思维导图给你梳理消息中间件集群生产部署架构规划

![](../../pic/2020-03-29-11-14-57.png)

![](../../pic/2020-03-29-11-16-03.png)


# 37 基于MQ实现订单系统的核心流程异步化改造，性能优化完成！

![](../../pic/2020-03-29-11-17-01.png)

针对这些问题，实际上比较合适的就是从第一个问题开始解决，因为下单流程性能较差是目前比较明显的问题，而且是比较严重影响用户体验的。而订单退款失败这种是属于小概率出现的问题，即使出现也可以通过人工处理给解决。

接着我们来做一个小小的总结，当各个系统都落地该方案之后，并且部署上线之后，订单系统就会如下图红圈所示，每次支付成功后仅仅更新自己的订单状态，同步扣减库存，接着就会发送消息到RocketMQ里去。

![](../../pic/2020-03-29-11-20-22.png)

然后推送系统、营销系统、积分系统、仓储系统一旦部署了改造后的代码，就会如下图红圈所示，从RocketMQ里不停的获取订单消息并且执行对应的业务逻辑。

![](../../pic/2020-03-29-11-20-46.png)

通过上述改造，可以将订单核心流程的性能从1秒~几秒的情况优化到100ms+，可以实现10倍性能提升的效果。


生产者示例代码：

![](../../pic/2020-03-29-11-23-01.png)


消费者示例代码：

![](../../pic/2020-03-29-11-22-23.png)

# 39 基于MQ实现订单系统的第三方系统异步对接改造，解耦架构完成！

## 4、什么叫做同步发送消息到RocketMQ？

![](../../pic/2020-03-29-11-25-34.png)

所谓同步，意思就是你通过这行代码发送消息到MQ去，SendResult sendResult = producer.send(msg)，然后你会卡在这里，代码不能往下走了。你要一直等待MQ返回一个结果给你，你拿到了SendResult之后，接着你的代码才会继续往下走。

这个就是所谓的同步发送模式。


## 5、什么叫做异步发送消息到RocketMQ？

首先在构造Producer的时候加入下面红框中的代码：

![](../../pic/2020-03-29-11-27-15.png)

接着把发送消息的代码改成如下所示：

![](../../pic/2020-03-29-11-27-34.png)

这个意思就是说，你把消息发送出去，然后上面的代码就直接往下走了，不会卡在这里等待MQ返回结果给你！

然后当MQ返回结果给你的时候，Producer会回调你的SendCallback里的函数，如果发送成功了就回调onSuccess函数，如果发送失败了就回调onExceptino函数。

这个就是所谓的异步发送，异步的意思就是你发送消息的时候不会卡在上面那行代码等待MQ返回结果给你，会继续执行下面的别的代码，当MQ返回结果给你的时候，会回调你的函数！


## 6、什么叫做发送单向消息到RocketMQ？

还有一种发送消息的方法，叫做发送单向消息，就是用下面的代码来发送消息：

![](../../pic/2020-03-29-11-28-57.png)

这个sendOneway的意思，就是你发送一个消息给MQ，然后代码就往下走了，根本不会关注MQ有没有返回结果给你，你也不需要MQ返回的结果，无论发送的消息是成功还是失败，都不关你的事。

## 8、什么叫做Push消费模式？

![](../../pic/2020-03-29-11-30-19.png)

大家注意里面Consumer的类名：DefaultMQPushConsumer。

其实很简单，就是Broker会主动把消息发送给你的消费者，你的消费者是被动的接收Broker推送给过来的消息，然后进行处理。

这个就是所谓的Push模式，意思就是Broker主动推送消息给消费者。

## 9、什么叫做Pull消费模式？

![](../../pic/2020-03-29-11-32-03.png)

在上述代码中，我们可以看到使用的Consumer类是DefaultMQPullConsumer，从名字里就可以看到使用了Pull消费模式。

也就是说，Broker不会主动推送消息给Consumer，而是消费者主动发送请求到Broker去拉取消息过来。

# 40 授人以渔：如果你们系统要对接第三方系统，应该如何设计？

- 1，思考一下你们的系统是否跟第三方系统存在耦合的问题？尤其是在核心数据链路中，是否存在因为耦合了第三方系统导致性能经常出现抖动的问题？如果有类似的问题，能否在核心链路中引入MQ来跟第三方系统进行解耦？如果解耦之后能对你们核心链路的性能有多高的提升？

- 2，大家去调研思考一下Kafka和RabbitMQ在使用的时候，有几种消息发送模式？有几种消息消费模式？你们系统如果使用了MQ技术的话，那么你们平时使用的哪种消息发送模式？你们平时使用的是哪种消息消费模式？为什么？

- 3，大家先提前自己思考一下，几种消息发送模式下，在什么场景应该选用什么消息发送模式？几种消息消费模式下，在什么场景下应该选用什么消息消费模式？


# 41 基于MQ实现订单数据同步给大数据团队，应该如何设计？

基于MySQL Binlog同步系统订单数据给大数据团队

这种系统会监听MySQL数据库的Binlog，所谓Binlog大致可以理解为MySQL的增删改操作日志。

然后MySQL Binlog同步系统会将监听到的MySQL Binlog（也就是增删改操作日志）发送给你的系统，让你来处理这些增删改操作日志。

这种MySQL Binlog系统现在是有不少成熟的开源技术方案的，比如阿里开源的Canal，以及Linkedin开源的Databus，都可以监听MySQL Binlog，然后将MySQL Binlog发送给你的系统，交给你去处理。

因此完全可以将数据同步方案修改为如下所示，采用Canal监听MySQL Binlog，然后直接发送到RocketMQ里。然后大数据团队的数据同步系统从RocketMQ中获取到MySQL Binlog，也就获取到了订单数据库的增删改操作，接着把增删改操作还原到自己的数据库中去就可以。

而且这样的一套方案还有一个额外的好处，就是由订单技术团队将完整的订单数据库的MySQL Binlog推送到RocketMQ里

无论是大数据团队，还是未来公司的其他技术团队，比如说开放平台团队，人工智能团队，等等，只要想要订单数据，都可以直接从这个RocketMQ里去获取完整的订单数据。

![](../../pic/2020-03-29-11-40-32.png)

说到这里，我们要给大家解释一下，实际上大数据团队并没有必要仅仅只通过MySQL来出数据报表，完全可以采用Hadoop、Spark、Flink等大数据技术来出数据报表。

![](../../pic/2020-03-29-11-41-17.png)

# 43 秒杀系统的技术难点以及秒杀商品详情页系统的架构设计

## 4、不归订单管的部分：高并发的商品详情页请求

明哥接着介绍，其实秒杀活动主要涉及到的并发压力就是两块，一个是高并发的读，一个是高并发的写。

那么这些秒杀商品页面是从哪儿加载出来的呢？本质上来说是从商品技术团队负责的商品详情页系统中加载出来的，我们看下面的图，图中引入了一个商品详情页系统的概念，他负责提供我们看到的各种秒杀商品页面。

所以首先这个商品详情页系统就是在秒杀活动开始之前最先被大量用户高并发访问的一个系统了！

大家可以思考一个问题，如果没有秒杀活动的时候，其实大量的用户是分散在不同的时间段里来逛我们的APP的，而且逛的是不同的人会看不同的商品的页面。

但是在秒杀活动的时候，他面临的第一个问题就是，可能几十万人，甚至百万级的用户，会同一时间频繁的访问同一个秒杀商品的页面

## 5、商品团队的秒杀架构优化：页面数据静态化

页面数据静态化+多级缓存

首先第一步，秒杀商品页面必须是将其数据做到静态化，这是什么意思呢？

简单来说是这样，如果让秒杀商品页面是动态化的，那么每次一个用户只要访问这个商品详情页，就必须发送一次请求到后端的商品详情页系统来获取数据。

比如商品的标题、副标题、价格、优惠策略、库存、大量的图片、商品详情说明、售后政策等等，这一大堆的东西都是商品详情页的数据。

那么你可以选择让用户浏览这个秒杀商品的时候，每次都发送请求到后台去加载这些数据过来，然后渲染出来给用户看这个商品页面，这就是所谓的动态模式。

如果这商品详情页里的大量数据都是存储在商品团队的数据库里的，那么岂不是大量的用户同时频繁访问这个商品详情页，会直接导致商品详情页系统承受高并发的访问？同时导致商品数据库承受高并发的访问？

所以首先需要将这个秒杀活动的商品详情页里的数据做成静态化的，也就是说提前就从数据库里把这个页面需要的数据都提取出来组装成一份静态数据放在别的地方，避免每次访问这个页面都要访问后端数据库。


## 6、商品团队的秒杀架构优化：多级缓存

接着就是多级缓存的架构，我们会使用CDN + Nginx + Redis的多级缓存架构

什么意思呢？就是说秒杀商品详情页的数据，首先会放一份在离用户地理位置比较近的CDN上

比如我们公司的机房在上海，系统也部署在上海，那么对于陕西的用户，难道每次都要发送请求到我们的上海机房里来获取数据吗？

不是，我们完全可以将一些静态化好的数据放在陕西的一个CDN上。同样对于广州的用户，可以把这些静态化好的数据放在广州的CDN上，这个CDN现在都是各种云厂商提供的服务，我们先看下面的图。

然后不同地方的用户在加载这个秒杀商品的详情页数据时，都是从就近的CDN上加载的，不需要每次请求都发送到我们公司在上海的机房去。

这个CDN缓存就是我们多级缓存架构里的第一级缓存。

那如果因为缓存过期之类的问题，CDN上没有用户要加载的商品详情页数据怎么办呢？

此时用户就会发送请求到我们公司的机房里的机器上去请求加载这个商品的数据了，这个时候我们需要在Nginx这样的服务器里做一级缓存。

在Nginx中是可以基于Lua脚本实现本地缓存的，我们可以提前把秒杀商品详情页的数据放到Nginx中进行缓存，如果请求发送过来，可以从Nginx中直接加载缓存数据，不需要把请求转发到我们商品系统上去，看下面的图。

这个时候如果在Nginx服务器上也没加载到秒杀商品的数据呢？

比如同样因为Nginx上的缓存数据过期之类的问题，导致没找到我们需要的数据。

此时就可以由Nginx中的Lua脚本发送请求到Redis集群中去加载我们提前放进去的秒杀商品数据，如下面的图。

如果在Redis中还是没有找到呢？

那么就由Nginx中的Lua脚本直接把请求转发到商品详情页系统里去加载就可以了，此时就会直接从数据库中加载数据出来，如下图所示

但是一般来说数据一般是可以从CDN、Nginx、Redis中加载到的，可能只有极少的请求会直接访问到商品系统去从数据库里加载商品页数据。

![](../../pic/2020-03-29-11-53-52.png)

通过这样的一套方案，我们就可以把用于秒杀活动的商品详情页数据进行静态化，然后把静态化以后的一串商品数据（比如可能就是一个大的JSON串）放到CDN、Ngxin、Redis组成的多级缓存里去，这样大量的用户同时访问这个秒杀商品页面就对我们的商品系统本身没什么压力了。

因为分布在全国各地的用户的大量请求都是分散发送给各个地方的CDN的，所以CDN就分摊掉了大量的请求。而即使请求到达了我们的后台系统，都是由轻松单机抗10万+并发的Nginx和Redis来返回商品数据的。

# 45 基于MQ实现秒杀订单系统的异步化架构以及精准扣减库存的技术方案

## 2、用答题的方法避免作弊抢购以及延缓下单

![](../../pic/2020-03-29-11-56-46.png)

## 3、为秒杀独立出来一套订单系统

把秒杀业务和正常业务区分开互不影响。

![](../../pic/2020-03-29-11-57-43.png)

## 4、基于Redis实现下单时精准扣减库存

扣减库存应该怎么来扣呢？如果还是直接由订单系统调用库存系统的接口，然后访问库存数据库去扣减，那么势必导致瞬时压力过大，可能让库存系统的压力很大。

通常在秒杀场景下，一般会将每个秒杀商品的库存提前写入Redis中，然后当请求到来之后，就直接对Redis中的库存进行扣减

![](../../pic/2020-03-29-11-58-51.png)

## 5、抢购完毕之后提前过滤无效请求

其实在Redis中的库存被扣减完之后，就说明后续其他的请求都没有必要发送到秒杀系统中了，因为商品已经被抢购完毕了

此时我们可以让Nginx在接收到后续请求的时候，直接就把后续请求过滤掉。

比如一旦商品抢购完毕，可以在ZooKeeper中写入一个秒杀完毕的标志位，然后ZK会反向通知Nginx中我们自己写的Lua脚本，通过Lua脚本后续在请求过来的时候直接过滤掉，不要向后转发了。

![](../../pic/2020-03-29-11-59-48.png)

这样的话，如果有50万人同时抢购1万件商品，其实最多就前面1万人发送的请求会抢购到商品，之后的49万请求都会在Nginx层面直接被拦截掉，过滤掉这些无效请求，返回响应告诉他们商品库存已经没了。

这样可以最大幅度削减对后端秒杀系统的请求压力。


## 6、瞬时高并发下单请求进入RocketMQ进行削峰

接着我们来考虑下，哪怕是有1万件商品同时被1万人秒杀成功了，那么可能瞬间会有1万请求涌入正常的订单系统进行后续的处理，此时可能还是会有瞬间上万请求访问到订单数据库中创建订单。

也就是说，对于秒杀系统而言，如果判断发现通过Redis完成了库存扣减，此时库存还大于0，就说明秒杀成功了需要生成订单，此时就直接发送一个消息到RocketMQ中即可。

然后让普通订单系统从RocketMQ中消费秒杀成功的消息进行常规性的流程处理即可，比如创建订单，等等。

这样的话，瞬间上万并发的压力会被RocketMQ轻松抗下来，然后普通的订单系统可以根据自己的工作负载慢慢的从RocketMQ中拉取秒杀成功的消息，然后进行后续操作就可以了，不会对订单数据库造成过大的压力。

否则如果你让瞬间产生的一万或者几万的订单请求直接访问订单数据库，必然还是会让他压力过大，需要额外增加机器，那是没有必要的。

因此在这里利用RocketMQ抗下每秒几万并发的下单请求，然后让订单系统以每秒几千的速率慢慢处理就可以了，也就是延迟个可能几十秒，这些下单请求就会处理完毕。

![](../../pic/2020-03-29-12-02-00.png)

## 7、秒杀架构的核心要点

![](../../pic/2020-03-29-12-02-44.png)

对于瞬时超高并发抢购商品的场景，首先必须要避免直接基于数据库进行高并发的库存扣减，因为那样会对库存数据库造成过大的压力

因为数据库单机可能每秒只能抗几千请求，但是改成直接基于Redis进行高并发扣减库存，每秒可以轻松抗几万请求。

一旦库存扣减为0之后，秒杀结束，因此实际上可能只有前面少量请求可以进入后台系统，后续占据99%的请求，都可以直接在Nginx层面被拦截掉，不会转发到后台系统造成任何压力

接着瞬时生成的大量秒杀成功后的订单请求，不会直接交给订单系统去处理，否则也可能会对订单数据库瞬时造成过大压力

此时会直接写入RocketMQ中进行削峰，让RocketMQ轻松抗下高并发压力，让订单系统慢慢消费和处理下单操作

所以通过上述分析，我们发现，像秒杀这种瞬时超高并发的场景，我们架构优化的核心就是独立出来一套系统专门处理，避免高并发请求落在MySQL上

# 47 阶段性复习：一张思维导图给你梳理全面引入MQ的订单系统架构


在这个阶段里，我们初步的把RocketMQ技术融入到了一些订单系统的场景案例中，让大家感受到了如何用MQ技术来解决链路过长导致的性能较差的问题，以及耦合第三方系统导致的性能不稳定的问题，还有耦合其他团队导致自己数据存储被不规范访问的问题，包括瞬时高并发下的过高压力问题。

而且初步带大家认识了一下RocketMQ的消息生产和消费的最基本的使用例子，其实学完这个阶段之后，大家如果在自己的系统中发现一些技术问题是需要用MQ来解决的，已经可以初步的去进行业务分析、引入MQ技术、落地MQ技术来解决自己的问题了。


![](../../pic/2020-03-29-12-06-27.png)


# 48 阶段性复习：思考一下，如果你们系统全面接入MQ，架构该如何设计？


- 1、你们的系统中是否存在核心链路环节过多导致性能较差的问题？如果有的话，是否可以引入MQ进行适当异步化提升链路性能？

- 2、你们的系统是否存在核心链路耦合了第三方系统，进而导致链路性能不稳定的问题？如果有，是否可以引入MQ进行第三方系统的解耦，避免核心链路的性能受到影响？

- 3、你们的系统是否存在有其他团队直接耦合访问你们数据库的情况，进而导致你们的数据库性能不稳定？如果有的话，是否可以引入MQ来推送你们的核心数据出去，跟其他团队进行解耦？

- 4、你们的系统是否存在瞬时超高并发的场景？如果有的话，是否可以引入MQ来进行瞬时流量削峰，避免为了应对瞬时超高并发从而不停的增加机器？


# 49 精益求精：深入研究一下生产者到底如何发送消息的？

## 2、研究RocketMQ底层原理的顺序和思路

- 1、对生产者往Broker集群发送消息的底层原理做一个研究
- 2、看看Broker对于接收到的消息，到底是如何存储到磁盘上去的？
- 3、基于DLedger技术部署的Broker高可用集群，到底如何进行数据同步的？
- 4、消费者到底是基于什么策略选择Master或Slave拉取数据的？
- 5、消费者是如何从Broker拉取消息回来，进行处理以及ACK的？如果消费者故障了会如何处理？

## 3、创建Topic的时候为何要指定MessageQueue数量？

像这些Topic就可以在之前我们讲过的RocketMQ可视化工作台里去创建，在里面就可以创建一个Topic出来，在创建Topic的时候需要指定一个很关键的参数，就是MessageQueue

简单来说，就是你要指定你的这个Topic对应了多少个队列，也就是多少个MessageQueue。

## 4、Topic、MessageQueue以及Broker之间到底是什么关系？

比如你现在有一个Topic，我们为他指定创建了4个MessageQueue，那么我们接着来思考一下，这个Topic的数据在Broker集群中是如何分布的？

之前最早我们给大家讲过，每个Topic的数据都是分布式存储在多个Broker中的。

但是我们如何决定这个Topic的哪些数据放这个Broker上，哪些数据放那个Broker上？这是一个问题

所以在这里RocketMQ引入了MessageQueue的概念，本质上就是一个数据分片的机制。

在这个机制中，假设你的Topic有1万条数据，然后你的Topic有4个MessageQueue，那么大致可以认为会在每个MessageQueue中放入2500条数据

当然，这个不是绝对的，有可能有的MessageQueue的数据多，有的数据少，这个要根据你的消息写入MessageQueue的策略来定。

但是我们这里先假定在每个MessageQueue中会平均分配Topic的数据吧，那么下一个问题来了，我们有4个MessageQueue平均分配了Topic的数据，这些MessageQueue放在哪里？

当然是放在Broker上了！

也就是说，很有可能就是在2个Broker上，每个Broker放两个MessageQueue，我们看下面的图就是这个示意。

![](../../pic/2020-03-29-15-46-27.png)

所以其实MessageQueue就是RocketMQ中非常关键的一个数据分片机制，他通过MessageQueue将一个Topic的数据拆分为了很多个数据分片，然后在每个Broker机器上都存储一些MessageQueue。

通过这个方法，就可以实现Topic数据的分布式存储！

## 5、生产者发送消息的时候写入哪个MessageQueue？

要解决这个问题，大家首先就要记得之前我们讲解过的一个重要的点，生产者会跟NameServer进行通信获取Topic的路由数据。

所以生产者从NameServer中就会知道，一个Topic有几个MessageQueue，哪些MessageQueue在哪台Broker机器上，哪些MesssageQueue在另外一台Broker机器上，这些都会知道

然后呢，现在我们暂时先认为生产者会均匀的把消息写入各个MessageQueue，就是比如这个生产者发送出去了20条数据，那么4个MessageQueue就是每个都会写入5条数据。

至于其他的写入MessageQueue的策略，我们后续会结合其他的高阶功能和业务场景来讲解，现在大家先不要去纠结这个问题。

![](../../pic/2020-03-29-15-48-45.png)

通过这个方法，是不是就可以让生产者把写入请求分散给多个Broker？是不是也可以让每个Broker都均匀分摊到一定的写入请求压力？

这样假设单个Broker可以抗每秒7万并发，那么两个Broker就可以抗每秒14万并发！这样就可以实现RocketMQ集群抗下每秒10万+超高并发的场景了！

另外通过这个方法，是不是就可以让一个Topic中的数据分散在多个MessageQueue中，进而分散在多个Broker机器上？这样就可以实现RocketMQ集群分布式存储海量的消息数据了！

## 6、如果某个Broker出现故障该怎么办？

接下来我们分析一下，如果某个Broker临时出现故障了，比如Master Broker挂了，此时正在等待的其他Slave Broker自动热切换为Master Broker，那么这个时候对这一组Broker就没有Master Broker可以写入了

如果你还是按照之前的策略来均匀把数据写入各个Broker上的MessageQueue，那么会导致你在一段时间内，每次访问到这个挂掉的Master Broker都会访问失败，这个似乎不是我们想要的样子。

对于这个问题，通常来说建议大家在Producer中开启一个开关，就是sendLatencyFaultEnable

一旦打开了这个开关，那么他会有一个自动容错机制，比如如果某次访问一个Broker发现网络延迟有500ms，然后还无法访问，那么就会自动回避访问这个Broker一段时间，比如接下来3000ms内，就不会访问这个Broker了。

这样的话，就可以避免一个Broker故障之后，短时间内生产者频繁的发送消息到这个故障的Broker上去，出现较多次数的异常。而是在一个Broker故障之后，自动回避一段时间不要访问这个Broker，过段时间再去访问他。

那么这样过一段时间之后，可能这个Master Broker就已经恢复好了，比如他的Slave Broker切换为了Master可以让别人访问了。

> 50 授人以渔：Kafka、RabbitMQ有类似MessageQueue的数据分片机制吗

- Kafka、RabbitMQ他们有类似的数据分片机制吗？
- 他们是如何把一个逻辑上的数据集合概念（比如一个Topic）给在物理上拆分为多个数据分片的？
- 拆分后的多个数据分片又是如何在物理的多台机器上分布式存储的？
- 为什么一定要让MQ实现数据分片的机制？
- 如果不实现数据分片机制，让你来设计MQ中一个数据集合的分布式存储，你觉得好设计吗？

# 51 精益求精：深入研究一下Broker是如何持久化存储消息的？

## 1、为什么Broker数据存储是最重要的一个环节？

很简单，实际上类似RocketMQ、Kafka、RabbitMQ的消息中间件系统，他们不只是让你写入消息和获取消息那么简单，他们本身最重要的就是提供强大的数据存储能力，可以把亿万级的海量消息存储在自己的服务器的磁盘上。

这样的话，各种不同的系统从MQ中消费消息的时候，才可以从MQ服务器的磁盘中读取到自己需要的消息。

否则如果MQ不在机器磁盘上存储大量的消息，如果消息都放在自己的内存里，一个是内存很可能放不下，另外一个是可能你机器重启，内存里的消息就会全部丢失了。


所以大家首先要明确一点，Broker数据存储实际上才是一个MQ最核心的环节，他决定了生产者消息写入的吞吐量，决定了消息不能丢失，决定了消费者获取消息的吞吐量，这些都是由他决定的。

## 2、CommitLog消息顺序写入机制

首先我们来思考一下，当生产者的消息发送到一个Broker上的时候，他接收到了一条消息，接着他会对这个消息做什么事情？

首先第一步，他会把这个消息直接写入磁盘上的一个日志文件，叫做CommitLog，直接顺序写入这个文件，如下图。

这个CommitLog是很多磁盘文件，每个文件限定最多1GB，Broker收到消息之后就直接追加写入这个文件的末尾，就跟上面的图里一样。如果一个CommitLog写满了1GB，就会创建一个新的CommitLog文件。

![](../../pic/2020-03-29-16-00-26.png)


## 3、MessageQueue在数据存储中是体现在哪里呢？

接着我们会发现一个问题，如果写入这个Broker的消息都是进入到CommitLog中去存储的，那么上次我们提到的MessageQueue是体现在哪里的呢？

其实在Broker中，对Topic下的每个MessageQueue都会有一系列的ConsumeQueue文件。

这是什么意思呢？

就是在Broker的磁盘上，会有下面这种格式的一系列文件：

$HOME/store/consumequeue/{topic}/{queueId}/{fileName}

上面那一串东西是什么意思？

我们之前说过，对每个Topic你不是在这台Broker上都会有一些MessageQueue吗？所以你会看到，{topic}指代的就是某个Topic，{queueId}指代的就是某个MessageQueue。

然后对存储在这台Broker机器上的Topic下的一个MessageQueue，他有很多的ConsumeQueue文件，这个ConsumeQueue文件里存储的是一条消息对应在CommitLog文件中的offset偏移量。

首先我们假设有一个Topic，他有4个MessageQueue，然后在两台Broker机器上，每台Broker机器会存储两个MessageQueue。

那么此时假设生产者选择对其中一个MessageQueue写入了一条消息，此时消息会发送到Broker上。

然后Broker必然会把这个消息写入自己的CommitLog文件中，是不是？

我们继续看下面的图，我在图里加入了两个ConsumeQueue，分别叫做ConsumeQueue0和ConsumeQueue1，他们分别对应着Topic里的MessageQueue0和MessageQueue1。

也就是说，Topic下的MessageQueue0和MessageQueue1就放在这个Broker机器上，而且他们每个MessageQueue目前在磁盘上就对应了一个ConsumeQueue，所以就是MessageQueue0对应着Broker磁盘上的ConsumeQueue0，MessageQueue1对应着磁盘上的ConsumeQueue1。

接着假设Queue的名字叫做：TopicOrderPaySuccess，那么此时在Broker磁盘上应该有如下两个路径的文件：

$HOME/store/consumequeue/TopicOrderPaySuccess/MessageQueue0/ConsumeQueue0磁盘文件

$HOME/store/consumequeue/TopicOrderPaySuccess/MessageQueue1/ConsumeQueue1磁盘文件

然后呢，当你的Broker收到一条消息写入了CommitLog之后，其实他同时会将这条消息在CommitLog中的物理位置，也就是一个文件偏移量，就是一个offset，写入到这条消息所属的MessageQueue对应的ConsumeQueue文件中去。

比如现在这条消息在生产者发送的时候是发送给MessageQueue0的，那么此时Broker就会将这条消息在CommitLog中的offset偏移量，写入到MessageQueue0对应的ConsumeQueue0中去，如下图所示。

所以实际上，ConsumeQueue0中存储的是一个一个消息在CommitLog文件中的物理位置，也就是offset

所以其实大家看下面的图，图里展示出来的是ConsumeQueue中的一个物理位置其实是对CommitLog文件中一个消息的引用。

![](../../pic/2020-03-29-16-11-59.png)


实际上在ConsumeQueue中存储的每条数据不只是消息在CommitLog中的offset偏移量，还包含了消息的长度，以及tag hashcode，一条数据是20个字节，每个ConsumeQueue文件保存30万条数据，大概每个文件是5.72MB。

所以实际上Topic的每个MessageQueue都对应了Broker机器上的多个ConsumeQueue文件，保存了这个MessageQueue的所有消息在CommitLog文件中的物理位置，也就是offset偏移量。

## 4、如何让消息写入CommitLog文件近乎内存写性能的？

接着我们给大家讲一个比较关键的概念：对于生产者把消息写入到Broker时，Broker会直接把消息写入磁盘上的CommitLog文件，那么Broker是如何提升整个过程的性能的呢？

因为这个部分的性能提升会直接提升Broker处理消息写入的吞吐量，比如你写入一条消息到CommitLog磁盘文件假设需要10ms，那么每个线程每秒可以处理100个写入消息，假设有100个线程，每秒只能处理1万个写入消息请求。

但是如果你把消息写入CommitLog磁盘文件的性能优化为只需要1ms，那么每个线程每秒可以处理1000个消息写入，此时100个线程每秒可以处理10万个写入消息请求。所以大家可以明显看到，Broker把接收到的消息写入CommitLog磁盘文件的性能，对他的TPS有很大的影响。

所以在这里，Broker是基于OS操作系统的**PageCache和顺序写**两个机制，来提升写入CommitLog文件的性能的。

首先Broker是以顺序的方式将消息写入CommitLog磁盘文件的，也就是每次写入就是在文件末尾追加一条数据就可以了，对文件进行顺序写的性能要比对文件随机写的性能提升很多

另外，数据写入CommitLog文件的时候，其实不是直接写入底层的物理磁盘文件的，而是先进入OS的PageCache内存缓存中，然后后续由OS的后台线程选一个时间，异步化的将OS PageCache内存缓冲中的数据刷入底层的磁盘文件。

我们看下面的图，图里示意出了，数据先写入OS的PageCache缓存中，然后后续由OS自己的线程将缓存里的数据刷入磁盘中。

![](../../pic/2020-03-29-16-16-32.png)

所以在这样的优化之下，采用**磁盘文件顺序写+OS PageCache写入+OS异步刷盘的策略**，基本上可以让消息写入CommitLog的性能跟你直接写入内存里是差不多的，所以正是如此，才可以让Broker高吞吐的处理每秒大量的消息写入。

## 5、同步刷盘与异步刷盘

对的，在上述的异步刷盘模式下，生产者把消息发送给Broker，Broker将消息写入OS PageCache中，就直接返回ACK给生产者了。

问题肯定是有的，如果生产者认为消息写入成功了，但是实际上那条消息此时是在Broker机器上的os cache中的，如果此时Broker直接宕机，那么是不是os cache中的这条数据就会丢失了？

所以异步刷盘的的策略下，可以让消息写入吞吐量非常高，但是可能会有数据丢失的风险，这个是大家需要清除的。

另外一种模式叫做同步刷盘，如果你使用同步刷盘模式的话，那么生产者发送一条消息出去，broker收到了消息，必须直接强制把这个消息刷入底层的物理磁盘文件中，然后才会返回ack给producer，此时你才知道消息写入成功了。

只要消息进入了物理磁盘上，那么除非是你的物理磁盘坏了导致数据丢失，否则正常来说数据就不会丢失了，我们看下面的图，就是示意了同步刷盘的效果。

![](../../pic/2020-03-29-16-18-48.png)

如果broker还没有来得及把数据同步刷入磁盘，然后他自己挂了，那么此时对producer来说会感知到消息发送失败了，然后你只要不停的重试发送就可以了，直到有slave broker切换成master broker重新让你可以写入消息，此时可以保证数据是不会丢的。

但是如果你强制每次消息写入都要直接进入磁盘中，必然导致每条消息写入性能急剧下降，导致消息写入吞吐量急剧下降，但是可以保证数据不会丢失。

> 52 授人以渔：同步刷盘和异步刷盘分别适用于什么场景呢？

异步刷盘可以提供超高的写入吞吐量，但是有丢失数据的风险，这个适用于什么业务场景？在你所知道的业务场景，或者工作接触过的业务场景中，有哪些场景需要超高的写入吞吐量，但是可以适度接受数据丢失？

同步刷盘会大幅度降低写入吞吐量，但是可以让你的数据不丢失，你接触哪些场景，是严格要求数据务必不能丢失任何一条，但是吞吐量并没有那么高的呢？

另外，大家可以去结合本节的内容，去查找资料看看，Kafka、RabbitMQ他们的broker收到消息之后是如何写入磁盘的？采用的是同步刷盘还是异步刷盘的策略？为什么？

# 53 精益求精：基于DLedger技术的Broker主从同步原理到底是什么？

## 1、Broker高可用架构原理回顾

首先，我们回顾一下，上一次已经讲到，producer写入消息到broker之后，broker会将消息写入本地CommitLog磁盘文件里去，然后还有一些ConsumeQueue会存储Topic下各个MessageQueue的消息的物理位置。

![](../../pic/2020-03-29-16-23-22.png)

而且我们给大家说过，如果要让Broker实现高可用，那么必须有一个Broker组，里面有一个是Leader Broker可以写入数据，然后让Leader Broker接收到数据之后，直接把数据同步给其他的Follower Broker

![](../../pic/2020-03-29-16-23-52.png)

这样的话，一条数据就会在三个Broker上有三份副本，此时如果Leader Broker宕机，那么就直接让其他的Follower Broker自动切换为新的Leader Broker，继续接受客户端的数据写入就可以了。

## 2、基于DLedger技术替换Broker的CommitLog

首先大家要知道，Broker上述高可用架构就是基于DLedger技术来实现的，所以首先第一步，我们先要知道DLedger技术可以干什么。

DLedger技术实际上首先他自己就有一个CommitLog机制，你把数据交给他，他会写入CommitLog磁盘文件里去，这是他能干的第一件事情。

所以首先我们在下面的图里可以看到，如果基于DLedger技术来实现Broker高可用架构，实际上就是用DLedger先替换掉原来Broker自己管理的CommitLog，由DLedger来管理CommitLog

![](../../pic/2020-03-29-16-25-29.png)

所以首先第一步大家要知道的是，我们需要使用DLedger来管理CommitLog，然后Broker还是可以基于DLedger管理的CommitLog去构建出来机器上的各个ConsumeQueue磁盘文件。

## 3、DLedger是如何基于Raft协议选举Leader Broker的？

既然我们现在知道首先基于DLedger替换各个Broker上的CommitLog管理组件了，那么就是每个Broker上都有一个DLedger组件了

接着我们思考一下，如果我们配置了一组Broker，比如有3台机器，DLedger是如何从3台机器里选举出来一个Leader的？


实际上DLedger是基于Raft协议来进行Leader Broker选举的，那么Raft协议中是如何进行多台机器的Leader选举的呢？

这需要发起一轮一轮的投票，通过三台机器互相投票选出来一个人作为Leader。

简单来说，三台Broker机器启动的时候，他们都会投票自己作为Leader，然后把这个投票发送给其他Broker。

我们举一个例子，Broker01是投票给自己的，Broker02是投票给自己的，Broker03是投票给自己的，他们都把自己的投票发送给了别人。

此时在第一轮选举中，Broker01会收到别人的投票，他发现自己是投票给自己，但是Broker02投票给Broker02自己，Broker03投票给Broker03自己，似乎每个人都很自私，都在投票给自己，所以第一轮选举是失败的。

因为大家都投票给自己，怎么选举出来一个Leader呢？

接着每个人会进入一个随机时间的休眠，比如说Broker01休眠3秒，Broker02休眠5秒，Broker03休眠4秒。

此时Broker01必然是先苏醒过来的，他苏醒过来之后，直接会继续尝试投票给自己，并且发送自己的选票给别人。

接着Broker03休眠4秒后苏醒过来，他发现Broker01已经发送来了一个选票是投给Broker01自己的，此时他自己因为没投票，所以会尊重别人的选择，就直接把票投给Broker01了，同时把自己的投票发送给别人。

接着Broker02苏醒了，他收到了Broker01投票给Broker01自己，收到了Broker03也投票给了Broker01，那么他此时自己是没投票的，直接就会尊重别人的选择，直接就投票给Broker01，并且把自己的投票发送给别人。

此时所有人都会收到三张投票，都是投给Broker01的，那么Broker01就会当选为Leader。

其实只要有（3台机器 / 2） + 1个人投票给某个人，就会选举他当Leader，这个（机器数量 / 2） + 1就是大多数的意思。

这就是Raft协议中选举leader算法的简单描述，简单来说，他确保有人可以成为Leader的核心机制就是一轮选举不出来Leader的话，就让大家随机休眠一下，先苏醒过来的人会投票给自己，其他人苏醒过后发现自己收到选票了，就会直接投票给那个人。

依靠这个随机休眠的机制，基本上几轮投票过后，一般都是可以快速选举出来一个Leader。

因此我们看下图，在三台Broker机器刚刚启动的时候，就是靠这个DLedger基于Raft协议实现的leader选举机制，互相投票选举出来一个Leader，其他人就是Follower，然后只有Leader可以接收数据写入，Follower只能接收Leader同步过来的数据。

![](../../pic/2020-03-29-16-30-22.png)


## 4、DLedger是如何基于Raft协议进行多副本同步的？

接着我们来说一下，Leader Broker收到消息之后，是如何基于DLedger把数据同步给其他Broker的。

DLedger在进行同步的时候是采用Raft协议进行多副本同步的，我们接下来聊一下Raft协议中的多副本同步机制。

数据同步会分为两个阶段，一个是uncommitted阶段，一个是commited阶段

首先Leader Broker上的DLedger收到一条数据之后，会标记为uncommitted状态，然后他会通过自己的DLedgerServer组件把这个uncommitted数据发送给Follower Broker的DLedgerServer。

![](../../pic/2020-03-29-16-32-40.png)

接着Follower Broker的DLedgerServer收到uncommitted消息之后，必须返回一个ack给Leader Broker的DLedgerServer，然后如果Leader Broker收到超过半数的Follower Broker返回ack之后，就会将消息标记为committed状态。

然后Leader Broker上的DLedgerServer就会发送commited消息给Follower Broker机器的DLedgerServer，让他们也把消息标记为comitted状态。

这个就是基于Raft协议实现的两阶段完成的数据同步机制。

## 5、如果Leader Broker崩溃了怎么办？

如果Leader Broker挂了，此时剩下的两个Follower Broker就会重新发起选举，他们会基于DLedger还是采用Raft协议的算法，去选举出来一个新的Leader Broker继续对外提供服务，而且会对没有完成的数据同步进行一些恢复性的操作，保证数据不会丢失。

我们看下面的图，就是示意了Leader Broker挂了之后，Follower Broker成为了新的Leader Broker，然后生产者写入新的Leader Broker的一个过程。

新选举出来的Leader会把数据通过DLedger同步给剩下的一个Follower Broker。

![](../../pic/2020-03-29-16-38-44.png)

> 54 授人以渔：采用Raft协议进行主从数据同步，会影响TPS吗？

今天我们想让大家思考一个问题，基于DLedger技术管理CommitLog之后，可以自动在一组Broker中选举出来一个Leader

然后在Leader接收消息写入的时候，基于DLedger技术写入本地CommitLog中，这个其实跟之前让Broker自己直接写入CommitLog是没什么区别的。

但是有区别的一点在于，Leader Broker上的DLedger在收到一个消息，将uncommitted消息写入自己本地存储之后，还需要基于Raft协议的算法，去采用两阶段的方式把uncommitted消息同步给其他Follower Broker

必须要超过一半的Follower Broker的DLedger对uncommitted消息返回ack，此时Leader Broker才能返回ACK给生产者，说这次写入成功了。

当然很多人会有疑问，那么不需要等他们执行了commit操作之后再返回给生产者吗？

实际上在这里只要有超过半数的Follower Broker都写入uncommitted消息之后，就可以返回给生产者了。

因此哪怕此时Leader Broker宕机了，超过半数的Follower Broker上也是有这个消息的，只不过是uncommitted状态，但是新选举的Leader Broker可以根据剩余Follower Broker上这个消息的状态去进行数据恢复，比如把消息状态调整为committed。

也就是说，这样的一个架构对每次写入都平添了一个成本，每次写入都必须有超过半数的Follower Broker都写入消息才可以算做一次写入成功

那么大家思考一个问题，这样做是不是会对Leader Broker的写入性能产生影响？是不是会降低TPS？


# 55 精益求精：深入研究一下消费者是如何获取消息处理以及进行ACK的？

## 1、消费组到底是个什么概念？

消费者组的意思，就是让你给一组消费者起一个名字。比如我们有一个Topic叫“TopicOrderPaySuccess”，然后假设有库存系统、积分系统、营销系统、仓储系统他们都要去消费这个Topic中的数据。

此时我们应该给那四个系统分别起一个消费组的名字，比如说：stock_consumer_group，marketing_consumer_group，credie_consumer_group，wms_consumer_group。

设置消费组的方式是在代码里进行的，类似下面这样：

![](../../pic/2020-03-29-16-44-35.png)

然后比如库存系统部署了4台机器，每台机器上的消费者组的名字都是“stock_consumer_group”，那么这4台机器就同属于一个消费者组，以此类推，每个系统的几台机器都是属于各自的消费者组的。

然后给大家先解释一下不同消费者之间的关系，假设库存系统和营销系统作为两个消费者组，都订阅了“TopicOrderPaySuccess”这个订单支付成功消息的Topic，此时假设订单系统作为生产者发送了一条消息到这个Topic，如下图所示。

此时这条消息是怎么被消费的呢？

正常情况下来说，这条消息进入Broker之后，库存系统和营销系统作为两个消费组，每个组都会拉取到这条消息。

也就是说这个订单支付成功的消息，库存系统会获取到一条，营销系统也会获取到一条，他们俩都会获取到这条消息。

但是下一个问题来了，库存系统这个消费组里有两台机器，是两台机器都获取到这条消息？还是说只有一台机器会获取到这条消息？

答案是，正常情况下来说，库存系统的两台机器中只有一台机器会获取到这条消息，营销系统也是同理。

我们看下面的图，示意了对于一条订单支付成功的消息，库存系统的一台机器获取到了，营销系统的一台机器也获取到了。

当然为了画图方便，图里是让营销系统从Master Broker拉取的，库存系统从Slave Broker拉取的。          

![](../../pic/2020-03-29-16-47-23.png)

这就是在消费的时候我们要给大家介绍的第一个知识点，不同的系统应该设置不同的消费组，如果不同的消费组订阅了同一个Topic，对Topic里的一条消息，每个消费组都会获取到这条消息。


## 2、集群模式消费 vs 广播模式消费

接着我们给大家介绍下一个概念，就是对于一个消费组而言，他获取到一条消息之后，如果消费组内部有多台机器，到底是只有一台机器可以获取到这个消息，还是每台机器都可以获取到这个消息？

这个就是集群模式和广播模式的区别。

默认情况下我们都是集群模式，也就是说，一个消费组获取到一条消息，只会交给组内的一台机器去处理，不是每台机器都可以获取到这条消息的。


但是我们可以通过如下设置来改变为广播模式：

consumer.setMessageModel(MessageModel.BROADCASTING);

如果修改为广播模式，那么对于消费组获取到的一条消息，组内每台机器都可以获取到这条消息。但是相对而言广播模式其实用的很少，常见基本上都是使用集群模式来进行消费的。

## 3、重温MessageQueue、CommitLog、ConsumeQueue之间的关系

![](../../pic/2020-03-29-16-53-21.png)


## 4、MessageQueue与消费者的关系

接着我们来想一个问题，对于一个Topic上的多个MessageQueue，是如何由一个消费组中的多台机器来进行消费的呢？

其实这里的源码实现细节是较为复杂的，但我们可以简单的理解为，他会均匀的将MessageQueue分配给消费组的多台机器来消费。

举个例子，假设我们的“TopicOrderPaySuccess”有4个MessageQueue，这4个MessageQueue分布在两个Master Broker上，每个Master Broker上有2个MessageQueue。

然后库存系统作为一个消费组里有两台机器，那么正常情况下，当然最好的就是让这两台机器每个都负责2个MessageQueue的消费了

比如库存系统的机器01从Master Broker01上消费2个MessageQueue，然后库存系统的机器02从Master Broker02上消费2个MessageQueue，这样不就把消费的负载均摊到两台Master Broker上去了？

所以你大致可以认为一个Topic的多个MessageQueue会均匀分摊给消费组内的多个机器去消费，这里的一个原则就是，一个MessageQueue只能被一个消费机器去处理，但是一台消费者机器可以负责多个MessageQueue的消息处理。

## 5、Push模式 vs Pull模式

现在我们已经知道了一个消费组内的多台机器是分别负责一部分MessageQueue的消费的，那么既然如此，每台机器都必须去连接到对应的Broker，尝试消费里面的MessageQueue对应的消息了。

此时就要涉及到两种消费模式了，之前我们也提到过，一个是Push，一个是Pull。

实际上，这两个消费模式本质是一样的，都是消费者机器主动发送请求到Broker机器去拉取一批消息下来。

Push消费模式本质底层也是基于这种消费者主动拉取的模式来实现的，只不过他的名字叫做Push而已，意思是Broker会尽可能实时的把新消息交给消费者机器来进行处理，他的消息时效性会更好。

一般我们使用RocketMQ的时候，消费模式通常都是基于他的Push模式来做的，因为Pull模式的代码写起来更加的复杂和繁琐，而且Push模式底层本身就是基于消息拉取的方式来做的，只不过时效性更好而已。

Push模式的实现思路我这里简单说一下：当消费者发送请求到Broker去拉取消息的时候，如果有新的消息可以消费那么就会立马返回一批消息到消费机器去处理，处理完之后会接着立刻发送请求到Broker机器去拉取下一批消息。

所以消费机器在Push模式下会处理完一批消息，立马发起请求拉取下一批消息，消息处理的时效性非常好，看起来就跟Broker一直不停的推送消息到消费机器一样。

另外Push模式下有一个请求挂起和长轮询的机制，也要给大家简单介绍一下。

当你的请求发送到Broker，结果他发现没有新的消息给你处理的时候，就会让请求线程挂起，默认是挂起15秒，然后这个期间他会有后台线程每隔一会儿就去检查一下是否有的新的消息给你，另外如果在这个挂起过程中，如果有新的消息到达了会主动唤醒挂起的线程，然后把消息返回给你。

当然其实消费者进行消息拉取的底层源码是非常复杂的，涉及到大量的细节，但是他的核心思路大致就是如此，我们只要知道，哪怕是用常见的Push模式消费，本质也是消费者不停的发送请求到broker去拉取一批一批的消息就行了。


## 6、Broker是如何将消息读取出来返回给消费机器的？

其实这里要涉及到两个概念，分别是ConsumeQueue和CommitLog。

假设一个消费者机器发送了拉取请求到Broker了，他说我这次要拉取MessageQueue0中的消息，然后我之前都没拉取过消息，所以就从这个MessageQueue0中的第一条消息开始拉取好了。

于是，Broker就会找到MessageQueue0对应的ConsumeQueue0，从里面找到第一条消息的offset，如下图所示。

![](../../pic/2020-03-29-17-01-43.png)

接着Broker就需要根据ConsumeQueue0中找到的第一条消息的地址，去CommitLog中根据这个offset地址去读取出来这条消息的数据，然后把这条消息的数据返回给消费者机器，如下图所示。

![](../../pic/2020-03-29-17-02-07.png)

所以其实消费消息的时候，本质就是根据你要消费的MessageQueue以及开始消费的位置，去找到对应的ConsumeQueue读取里面对应位置的消息在CommitLog中的物理offset偏移量，然后到CommitLog中根据offset读取消息数据，返回给消费者机器。

## 7、消费者机器如何处理消息、进行ACK以及提交消费进度？

接着消费者机器拉取到一批消息之后，就会将这批消息回调我们注册的一个函数，如下面这样子：

![](../../pic/2020-03-29-17-04-53.png)

当我们处理完这批消息之后，消费者机器就会提交我们目前的一个消费进度到Broker上去，然后Broker就会存储我们的消费进度

比如我们现在对ConsumeQueue0的消费进度假设就是在offset=1的位置，那么他会记录下来一个ConsumeOffset的东西去标记我们的消费进度，那么下次这个消费组只要再次拉取这个ConsumeQueue的消息，就可以从Broker记录的消费位置开始继续拉取，不用重头开始拉取了。

## 8、如果消费组中出现机器宕机或者扩容加机器，会怎么处理？

这个时候其实会进入一个rabalance的环节，也就是说重新给各个消费机器分配他们要处理的MessageQueue。

给大家举个例子，比如现在机器01负责MessageQueue0和Message1，机器02负责MessageQueue2和MessageQueue3，现在机器02宕机了，那么机器01就会接管机器02之前负责的MessageQueue2和MessageQueue3。

或者如果此时消费组加入了一台机器03，此时就可以把机器02之前负责的MessageQueue3转移给机器03，然后机器01就仅仅负责一个MessageQueue2的消费了，这就是负载重平衡的概念。

![](../../pic/2020-03-29-17-07-20.png)


> 56 授人以渔：消费者到底什么时候可以认为是处理完消息了？

![](../../pic/2020-03-29-17-08-59.png)


# 57 精益求精：消费者到底是根据什么策略从Master或Slave上拉取消息的？

## 2、CommitLog基于os cache提升写性能的回顾

接着如果大家要搞明白到底什么时候从Master Broker拉取消息，什么时候从Slave Broker拉取消息，首先得搞明白一个很关键的问题，那就是拉取消息的时候必然会先读取ConsumeQueue文件，这个ConsumeQueue文件的读取是如何优化的？

要搞明白这个ConsumeQueue文件的读取是如何进行性能优化的，我们又得先回顾一下之前讲过的CommitLog文件写入的优化原理，其实他本质就是基于os cache来进行优化的


也就是说，broker收到一条消息，会写入CommitLog文件，但是会先把CommitLog文件中的数据写入os cache(操作系统管理的缓存)中去，如下图。

然后os自己有后台线程，过一段时间后会异步把os cache缓存中的CommitLog文件的数据刷入磁盘中去，如下图。

![](../../pic/2020-03-29-17-12-41.png)

就是依靠这个**写入CommitLog时先进入os cache缓存，而不是直接进入磁盘的机制**，就可以实现broker写CommitLog文件的性能是内存写级别的，这才能实现broker超高的消息接入吞吐量。

## 3、一个很关键的问题：ConsumeQueue文件也是基于os cache的

所以接下来我们就可以看一个很关键的问题了，那就是ConsumeQueue会被大量的消费者发送的请求给高并发的读取，所以ConsumeQueue文件的读操作是非常频繁的，而且同时会极大的影响到消费者进行消息拉取的性能和消费吞吐量。

所以实际上broker对ConsumeQueue文件同样也是基于os cache来进行优化的

也就是说，对于Broker机器的磁盘上的大量的ConsumeQueue文件，在写入的时候也都是优先进入os cache中的

而且os自己有一个优化机制，就是读取一个磁盘文件的时候，他会自动把磁盘文件的一些数据缓存到os cache中。

而且大家之前知道ConsumeQueue文件主要是存放消息的offset，所以每个文件很小，30万条消息的offset就只有5.72MB而已。所以实际上ConsumeQueue文件们是不占用多少磁盘空间的，他们整体数据量很小，几乎可以完全被os缓存在内存cache里。

大家看下面的图，我们示意了ConsumeQueue文件几乎都是放在os cache里的。

![](../../pic/2020-03-29-17-15-42.png)

所以实际上在消费者机器拉取消息的时候，第一步大量的频繁读取ConsumeQueue文件，几乎可以说就是跟读内存里的数据的性能是一样的，通过这个就可以保证数据消费的高性能以及高吞吐

## 4、第二个关键问题：CommitLog是基于os cache+磁盘一起读取的

接着我们来看第二个比较关键的问题，在进行消息拉取的时候，先读os cache里的少量ConsumeQueue的数据，这个性能是极高的，然后第二步就是要根据你读取到的offset去CommitLog里读取消息的完整数据了。

那么大家可以思考一下，这个从CommitLog里读取消息完整数据是如何读取的？是从os cache里读取？还是从磁盘里读取？

答案是：两者都有

因为CommitLog是用来存放消息的完整数据的，所以内容量是很大的，毕竟他一个文件就要1GB，所以整体完全有可能多达几个TB。

所以你思考一下，这么多的数据，可能都放在os cache里吗？

明显是不可能的，因为os cache用的也是机器的内存，一般多也就几十个GB而已，何况Broker自身的JVM也要用一些内存，留个os cache的内存只是一部分罢了，比如10GB~20GB的内存，所以os cache对于CommitLog而言，是无法把他全部数据都放在里面给你读取的！

也就是说，os cache对于CommitLog而言，主要是提升文件写入性能，当你不停的写入的时候，很多最新写入的数据都会先停留在os cache里，比如这可能有10GB~20GB的数据。

之后os会自动把cache里的比较旧的一些数据刷入磁盘里，腾出来空间给更新写入的数据放在os cache里，所以大部分数据可能多达几个TB都是在磁盘上的

![](../../pic/2020-03-29-17-18-47.png)


所以最终结论来了，当你拉取消息的时候，可以轻松从os cache里读取少量的ConsumeQueue文件里的offset，这个性能是极高的，但是当你去CommitLog文件里读取完整消息数据的时候，会有两种可能。

- 1，如果你读取的是那种刚刚写入CommitLog的数据，那么大概率他们还停留在os cache中，此时你可以顺利的直接从os cache里读取CommitLog中的数据，这个就是内存读取，性能是很高的。

- 2，你也许读取的是比较早之前写入CommitLog的数据，那些数据早就被刷入磁盘了，已经不在os cache里了，那么此时你就只能从磁盘上的文件里读取了，这个性能是比较差一些的。

## 5、什么时候会从os cache读？什么时候会从磁盘读？

其实这个问题很简单了，如果你的消费者机器一直快速的在拉取和消费处理，紧紧的跟上了生产者写入broker的消息速率，那么你每次拉取几乎都是在拉取最近人家刚写入CommitLog的数据，那几乎都在os cache里。

但是如果broker的负载很高，导致你拉取消息的速度很慢，或者是你自己的消费者机器拉取到一批消息之后处理的时候性能很低，处理的速度很慢，这都会导致你跟不上生产者写入的速率。

比如人家都写入10万条数据了，结果你才拉取了2万条数据，此时有5万条最新的数据是在os cache里，有3万条你还没拉取的数据是在磁盘里，那么当后续你再拉取的时候，必然很大概率是从磁盘里读取早就刷入磁盘的3万条数据。

接着之前在os cache里的5万条数据可能又被刷入磁盘了，取而代之的是更新的几万条数据在os cache里，然后你再次拉取的时候，又会从磁盘里读取刷入磁盘里的5万条数据，相当于你每次都在从磁盘里读取数据了！

## 6、Master Broker什么时候会让你从Slave Broker拉取数据？

其实这个问题我们上一个小节已经解释了一部分了，假设此时你的broker里已经写入了10万条数据，但是你仅仅拉取了2万条数据，下次你拉取的时候，是从第2万零1条数据开始继续往后拉取的，是不是？

也就是说，此时你有8万条数据是没有拉取的！

然后broker自己是知道机器上当前的整体物理内存有多大的，而且他也知道自己可用的最大空间占里面的比例，他是知道自己的消息最多可以在内存里放多少的！比如他心知肚明，他最多也就在内存里放5万条消息而已！

因为他知道，他最多只能利用10GB的os cache去放消息，这么多内存最多也就放5万左右的消息。

然后这个时候你过来拉取消息，他发现你还有8万条消息没有拉取，这个8万条消息他发现是大于10GB内存最多存放的5万条消息的，那么此时就说明，肯定有3万条消息目前是在磁盘上的，不在os cache内存里！

所以他经过上述判断，会发现此时你很大概率会从磁盘里加载3万条消息出来！他会认为，出现这种情况，很可能是因为自己作为master broker负载太高了，导致没法及时的把消息给你，所以你落后的进度比较多。

这个时候，他就会告诉你，我这次给你从磁盘里读取3万条消息，但是下次你还是从slave broker去拉取吧！

以上就是这个关键问题的解答，本质是对比你当前没有拉取消息的数量和大小，以及最多可以存放在os cache内存里的消息的大小，如果你没拉取的消息超过了最大能使用的内存的量，那么说明你后续会频繁从磁盘加载数据，此时就让你从slave broker去加载数据了！

> 58 授人以渔：消费者是跟所有Broker建立连接，还是跟部分Broker建立连接？

![](../../pic/2020-03-29-17-28-17.png)


# 59 探秘黑科技：RocketMQ 是如何基于Netty扩展出高性能网络通信架构的？

- RocketMQ是如何基于Netty扩展出高性能网络通信架构的？

- 基于mmap内存映射实现CommitLog磁盘文件的高性能读写

## 2、Reactor主线程与长短连接

首先，作为Broker而言，他会有一个Reactor主线程。

没关系，你先别管“Reactor”是个什么东西，总之就先知道有这么个名字就行了，我们看下面的图里，你会发现Broker里有这么一个名字的线程，而且这个线程是负责监听一个网络端口的，比如监听个2888，39150这样的端口。

![](../../pic/2020-03-29-17-34-19.png)

接着假设我们有一个Producer他现在想要跟Broker建立一个TCP长连接，可能有的朋友对这个长连接、短连接，也有点不明所以

```
没关系，一句话解释一下短连接：如果你要给别人发送一个请求，必须要建立连接 -> 发送请求 -> 接收响应 -> 断开连接，下一次你要发送请求的时候，这个过程得重新来一遍

每次建立一个连接之后，使用这个连接发送请求的时间是很短的，很快就会断开这个连接，所以他存在时间太短了，就是短连接。

长连接的话，就是反过来的意思，你建立一个连接 -> 发送请求 -> 接收响应 -> 发送请求 -> 接收响应 -> 发送请求 -> 接收响应

大家会发现，当你建立好一个长连接之后，可以不停的发送请求和接收响应，连接不会断开，等你不需要的时候再断开就行了，这个连接会存在很长时间，所以是长连接。

那么TCP长连接是什么意思呢？

如果你对网络没太多的了解，简单理解为TCP就是一个协议，所谓协议的意思就是，按照TCP这个协议规定好的步骤建立连接，按照他规定好的步骤发送请求。

比如你要建立一个TCP连接，必须先给对方发送他规定好的几个数据，然后人家按照规定返回给你几个数据，你再给人家发送几个数据，一切都按TCP的规定来。按照规定来，大家就可以建立一个TCP连接。

所以TCP长连接，就是按照这个TCP协议建立的长连接。

```
## 3、Producer和Broker建立一个长连接

接着比如有一个Producer他就要跟Broker建立一个TCP长连接了，此时Broker上的这个Reactor主线程，他会在端口上监听到这个Producer建立连接的请求

![](../../pic/2020-03-29-17-34-55.png)

接着这个Reactor主线程就专门会负责跟这个Producer按照TCP协议规定的一系列步骤和规范，建立好一个长连接。但是现在问题来了，在Broker里用什么东西代表跟Producer之间建立的这个长连接呢？

答案是：SocketChannel

Producer里面会有一个SocketChannel，Broker里也会有一个SocketChannel，这两个SocketChannel就代表了他们俩建立好的这个长连接。

![](../../pic/2020-03-29-17-35-51.png)

接着下一个问题来了，既然Producer和Broker之间已经通过SocketChannel维持了一个长连接了，接着Producer是不是应该会通过这个SocketChannel去发送消息给Broker？


## 4、基于Reactor线程池监听连接中的请求

但是这个时候别急！我们还不能让Producer发送消息给Broker，因为虽然我们有一个SocketChannel组成的长连接，但是他仅仅是一个长连接而已！

假设Producer此时通过SocketChannel发送消息给到Broker那边的SocketChannel了，但是Broker里是哪个线程来负责从SocketChannel里获取这个消息呢？这是一个很大的问题！

所以我们接着要引入一个概念，就是**Reactor线程池**，你也先别管这里的“Reactor”是什么意思，你只要知道有一个这个名字的线程池就可以了，这个线程池里默认是3个线程！

然后Reactor主线程建立好的每个连接SocketChannel，都会交给这个Reactor线程池里的其中一个线程去监听请求。

![](../../pic/2020-03-29-17-37-55.png)

好，现在有了Reactor线程池这个概念，我们总算是可以让Producer发送请求过来了，他发送一个消息过来到达Broker里的SocketChannel，此时Reactor线程池里的一个线程会监听到这个SocketChannel中有请求到达了！

## 5、基于Worker线程池完成一系列准备工作

接着Reactor线程从SocketChannel中读取出来一个请求，这个请求在正式进行处理之前，必须就先要进行一些准备工作和预处理，比如SSL加密验证、编码解码、连接空闲检查、网络连接管理，诸如此类的一些事

那么问题又来了，这些事让谁来干呢？

这个时候需要引入一个新的概念，叫做Worker线程池，他默认有8个线程，此时Reactor线程收到的这个请求会交给Worker线程池中的一个线程进行处理，会完成上述一系列的准备工作

![](../../pic/2020-03-29-17-39-10.png)

## 6、基于业务线程池完成请求的处理

那么现在如果Worker线程完成了一系列的预处理之后，比如SSL加密验证、编码解码、连接空闲检查、网络连接管理，等等，接着就需要对这个请求进行正式的业务处理了！我们来给大家举个例子。

比如对于你发送过来的消息，大家还记得我们之前讲解的Broker数据存储机制吗？

你接收到了消息，肯定是要写入CommitLog文件的，后续还有一些ConsumeQueue之类的事情需要处理，类似这种操作，就是业务处理逻辑。

这个时候，就得继续把经过一系列预处理之后的请求转交给业务线程池

比如对于处理发送消息请求而言，就会把请求转交给SendMessage线程池，而且如果大家还有一点点印象的话，其实在之前讲集群部署的时候，我们讲到过这个SendMessage线程是可以配置的，你配置的越多，自然处理消息的吞吐量越高。

![](../../pic/2020-03-29-17-40-39.png)

## 7、为什么这套网络通信框架会是高性能以及高并发的？

原因很简单，假设我们只有一个线程来处理所有的网络连接的请求，包括读写磁盘文件之类的业务操作，那么会导致我们的并发能力必然很低。

所以必须专门分配一个Reactor主线程出来，就是专门负责跟各种Producer、Consumer之类的建立长连接。

一旦连接建立好之后，大量的长连接均匀的分配给Reactor线程池里的多个线程。

每个Reactor线程负责监听一部分连接的请求，这个也是一个优化点，通过多线程并发的监听不同连接的请求，可以有效的提升大量并发请求过来时候的处理能力，可以提升网络框架的并发能力。

接着后续对大量并发过来的请求都是基于Worker线程池进行预处理的，当Worker线程池预处理多个请求的时候，Reactor线程还是可以有条不紊的继续监听和接收大量连接的请求是否到达。

而且最终的读写磁盘文件之类的操作都是交给业务线程池来处理的，当他并发执行多个请求的磁盘读写操作的时候，不影响其他线程池同时接收请求、预处理请求，没任何的影响。

所以最终的效果就是：

- Reactor主线程在端口上监听Producer建立连接的请求，建立长连接
- Reactor线程池并发的监听多个连接的请求是否到达
- Worker请求并发的对多个请求进行预处理
- 业务线程池并发的对多个请求进行磁盘读写业务操作

这些事情全部是利用不同的线程池并发执行的！任何一个环节在执行的时候，都不会影响其他线程池在其他环节进行请求的处理！

这样的一套网络通信架构，最终实现的效果就是可以高并发、高吞吐的对大量网络连接发送过来的大量请求进行处理，这是保证Broker实现高吞吐的一个非常关键的环节，就是这套网络通信架构。

因此对于这类中间件，如果你给他部署在高配置的物理机上，有几十个CPU核，那么此时你可以增加他的各种线程池的线程数量，这样就可以让各个环节同时高并发的处理大量的请求，由大量的CPU核来支持大量线程的并发工作。

> 60 授人以渔：BIO、NIO、AIO以及Netty之间的关系是什么？

实际上RocketMQ的网络通信架构就是基于Netty扩展实现的，包括Reactor主线程和Reactor线程池，这两个本质都是Netty封装好的概念，Netty自己就是基于Reactor模型去实现的。


# 61 探秘黑科技：基于mmap内存映射实现磁盘文件的高性能读写

## 1、mmap：Broker读写磁盘文件的核心技术

今天我们要给大家介绍一个非常关键的黑科技，很多人可能都不太熟悉，这个技术就是mmap技术，而Broker中就是大量的使用mmap技术去实现CommitLog这种大磁盘文件的高性能读写优化的。

通过之前的学习，我们知道了一点，就是Broker对磁盘文件的写入主要是借助直接写入os cache来实现性能优化的，因为直接写入os cache，相当于就是写入内存一样的性能，后续等os内核中的线程异步把cache中的数据刷入磁盘文件即可。

那么今天我们就要对这个过程中涉及到的mmap技术进行一定的分析。

## 2、传统文件IO操作的多次数据拷贝问题

首先我们先来给大家分析一下，假设RocketMQ没有使用mmap技术，就是使用最传统和基本的普通文件IO操作去进行磁盘文件的读写，那么会存在什么样的性能问题？

答案是：多次数据拷贝问题

首先，假设我们有一个程序，这个程序需要对磁盘文件发起IO操作读取他里面的数据到自己这儿来，那么会经过以下一个顺序：


首先从磁盘上把数据读取到内核IO缓冲区里去，然后再从内核IO缓存区里读取到用户进程私有空间里去，然后我们才能拿到这个文件里的数据


为了读取磁盘文件里的数据，是不是发生了两次数据拷贝？没错，所以这个就是普通的IO操作的一个弊端，必然涉及到两次数据拷贝操作，对磁盘读写性能是有影响的。

那么如果我们要将一些数据写入到磁盘文件里去呢？

那这个就是一样的过程了，必须先把数据写入到用户进程私有空间里去，然后从这里再进入内核IO缓冲区，最后进入磁盘文件里去.

在数据进入磁盘文件的过程中，是不是再一次发生了两次数据拷贝？没错，所以这就是传统普通IO的问题，有两次数据拷贝问题。

![](../../pic/2020-03-29-17-50-01.png)


## 3、RocketMQ是如何基于mmap技术+page cache技术优化的？

首先，RocketMQ底层对CommitLog、ConsumeQueue之类的磁盘文件的读写操作，基本上都会采用mmap技术来实现。

如果具体到代码层面，就是基于JDK NIO包下的MappedByteBuffer的map()函数，来先将一个磁盘文件（比如一个CommitLog文件，或者是一个ConsumeQueue文件）映射到内存里来

这里我必须给大家解释一下，**这个所谓的内存映射是什么意思**

其实有的人可能会误以为是直接把那些磁盘文件里的数据给读取到内存里来了，类似这个意思，但是并不完全是对的。

因为刚开始你建立映射的时候，并没有任何的数据拷贝操作，其实磁盘文件还是停留在那里，只不过他把物理上的磁盘文件的一些地址和用户进程私有空间的一些虚拟内存地址进行了一个映射


![](../../pic/2020-03-29-17-52-21.png)

这个地址映射的过程，就是JDK NIO包下的MappedByteBuffer.map()函数干的事情，底层就是基于mmap技术实现的。

另外这里给大家说明白的一点是，这个mmap技术在进行文件映射的时候，一般有大小限制，在1.5GB~2GB之间

所以RocketMQ才让CommitLog单个文件在1GB，ConsumeQueue文件在5.72MB，不会太大。这样限制了RocketMQ底层文件的大小，就可以在进行文件读写的时候，很方便的进行内存映射了。

然后接下来要给大家讲的一个概念，就是之前给大家说的PageCache，实际上在这里就是对应于虚拟内存

![](../../pic/2020-03-29-17-53-33.png)

## 4、基于mmap技术+pagecache技术实现高性能的文件读写

接下来就可以对这个已经映射到内存里的磁盘文件进行读写操作了，比如要写入消息到CommitLog文件，你先把一个CommitLog文件通过MappedByteBuffer的map()函数映射其地址到你的虚拟内存地址。

接着就可以对这个MappedByteBuffer执行写入操作了，写入的时候他会直接进入PageCache中，然后过一段时间之后，由os的线程异步刷入磁盘中，如下图我们可以看到这个示意。

![](../../pic/2020-03-29-17-54-39.png)

对了！就是上面的图里，似乎只有一次数据拷贝的过程，他就是从PageCache里拷贝到磁盘文件里而已！这个就是你使用mmap技术之后，相比于传统磁盘IO的一个性能优化。

接着如果我们要从磁盘文件里读取数据呢？

那么此时就会判断一下，当前你要读取的数据是否在PageCache里？如果在的话，就可以直接从PageCache里读取了！

比如刚写入CommitLog的数据还在PageCache里，此时你Consumer来消费肯定是从PageCache里读取数据的。

但是如果PageCache里没有你要的数据，那么此时就会从磁盘文件里加载数据到PageCache中去，如下图

而且PageCache技术在加载数据的时候还会将你加载的数据块的临近的其他数据块也一起加载到PageCache里去。

![](../../pic/2020-03-29-17-56-17.png)

大家可以看到，在你读取数据的时候，其实也仅仅发生了一次拷贝，而不是两次拷贝，所以这个性能相较于传统IO来说，肯定又是提高了。

## 5、预映射机制 + 文件预热机制

接着给大家说几个Broker针对上述的磁盘文件高性能读写机制做的一些优化：

- （1）内存预映射机制：Broker会针对磁盘上的各种CommitLog、ConsumeQueue文件预先分配好MappedFile，也就是提前对一些可能接下来要读写的磁盘文件，提前使用MappedByteBuffer执行map()函数完成映射，这样后续读写文件的时候，就可以直接执行了。

- （2）文件预热：在提前对一些文件完成映射之后，因为映射不会直接将数据加载到内存里来，那么后续在读取尤其是CommitLog、ConsumeQueue的时候，其实有可能会频繁的从磁盘里加载数据到内存中去。所以其实在执行完map()函数之后，会进行madvise系统调用，就是提前尽可能多的把磁盘文件加载到内存里去。

通过上述优化，才真正能实现一个效果，就是写磁盘文件的时候都是进入PageCache的，保证写入高性能；同时尽可能多的通过map + madvise的映射后预热机制，把磁盘文件里的数据尽可能多的加载到PageCache里来，后续对CosumeQueue、CommitLog进行读取的时候，才能尽可能从内存里读取数据。

## 6、对今天文章的一点总结

今天我们在之前给大家讲解的PageCache技术基础之上，引入了Broker底层大量采用的mmap技术

实际上在Broker读写磁盘的时候，是大量把mmap技术和pagecache技术结合起来使用的，通过mmap技术减少数据拷贝次数，然后利用pagecache技术实现尽可能优先读写内存，而不是物理磁盘。

> 62 授人以渔：思考一个小问题，Java工程师真的只会Java就可以了吗？

> 63 抛砖引玉：通过本专栏的大白话讲解之后，再去深入阅读一些书籍和源码

> 64 授人以渔：一个学习方法的探讨，如何深入研究一个技术？

# 65 阶段性复习：一张思维导图带你梳理 RocketMQ 的底层实现原理

大家目前已经一点点学习了RocketMQ的一些底层原理，包括他的MessageQueue的概念以及在Broker上的分布式存储，以及Producer写入消息的底层原理，还有Broker的数据存储机制，以及Broker高可用架构的实现原理，包括Consumer的底层原理，以及基于Broker读写分离架构读取消息的原理。

![](../../pic/2020-03-29-18-03-23.png)

# 66 阶段性复习：在深度了解RocketMQ底层原理的基础之上，多一些主动思考

- 1、Kafka、RabbitMQ他们有类似的数据分片机制吗？他们是如何把一个逻辑上的数据集合概念（比如一个Topic）给在物理上拆分为多个数据分片的？然后拆分后的多个数据分片又是如何在物理的多台机器上分布式存储的？


- 2、为什么一定要让MQ实现数据分片的机制？如果不实现数据分片机制，让你来设计MQ中一个数据集合的分布式存储，你觉得好设计吗？

- 3、同步刷盘和异步刷盘两种策略，分别适用于什么不同的场景呢？

- 4、异步刷盘可以提供超高的写入吞吐量，但是有丢失数据的风险，这个适用于什么业务场景？在你所知道的业务场景，或者工作接触过的业务场景中，有哪些场景需要超高的写入吞吐量，但是可以适度接受数据丢失？

- 5、同步刷盘会大幅度降低写入吞吐量，但是可以让你的数据不丢失，你接触哪些场景，是严格要求数据务必不能丢失任何一条，但是吞吐量并没有那么高的呢？

- 6、Kafka、RabbitMQ他们的broker收到消息之后是如何写入磁盘的？采用的是同步刷盘还是异步刷盘的策略？为什么？

- 7、每次写入都必须有超过半数的Follower Broker都写入消息才可以算做一次写入成功，那么大家思考一个问题，这样做是不是会对Leader Broker的写入性能产生影响？是不是会降低TPS？是不是必须要在所有的场景都这么做？为什么呢？

- 8、一般我们获取到一批消息之后，什么时候才可以认为是处理完这批消息了？是刚拿到这批消息就算处理完吗？还是说要对这批消息执行完一大堆的数据库之类的操作，才算是处理完了？

- 9、如果获取到了一批消息，还没处理完呢，结果机器就宕机了，此时会怎么样？这些消息会丢失，再也无法处理了吗？如果获取到了一批消息，已经处理完了，还买来得及提交消费进度，此时机器宕机了，会怎么样呢？

- 10、消费者机器到底是跟少数几台Broker建立连接，还是跟所有Broker都建立连接？这是不少朋友之前在评论区提出的问题，但是我想这里大家肯定都有自己的答案了。

- 11、RocketMQ是支持主从架构下的读写分离的，而且什么时候找Slave Broker读取大家也都了解的很清楚了，那么大家思考一下，Kafka、RabbitMQ他们支持主从架构下的读写分离吗？支持Slave Broker的读取吗？为什么呢？

- 12、如果支持读写分离的话，有没有一种可能，就是出现主从数据不一致的问题？比如有的数据刚刚到Master Broker和部分Slave Broker，但是你刚好是从那个没有写入数据的Slave Broker去读取了？


- 13、消费吞吐量似乎是跟你的处理速度有很大关系，如果你消费到一批数据，处理太慢了，会导致你严重跟不上数据写入的速度，这会导致你后续几乎每次拉取数据都会从磁盘上读取，而不是os cache里读取，所以你觉得你在拉取到一批消息处理的时候，应该有哪些要点需要注意的？


# 67 生产案例：从 RocketMQ 全链路分析一下为什么用户支付后没收到红包？

## 1、客服反馈的一个奇怪问题：支付之后没有收到红包

按理来说，订单系统在完成支付之后，会推送一条消息到RocketMQ里去，然后红包系统会从RocketMQ里接收那条消息去给用户发现金红包，我们看下图。

![](../../pic/2020-03-29-18-12-58.png)

但是从订单系统和红包系统当天那个时间段的日志来看，居然只看到了订单系统有推送消息到RocketMQ的日志，但是并没有看到红包系统从RocketMQ中接收消息以及发现金红包的日志。

于是大家推测，问题可能就出在这儿了，是不是支付订单消息在传输的过程中丢失了？导致现金红包没有派发出去！

那么接着我们就来一步一步分析一下，对于MQ的使用过程中，到底有哪些地方会导致消息丢失？


## 2、订单系统推送消息到MQ的过程会丢失消息吗？

![](../../pic/2020-03-29-18-15-30.png)

所以首先我们在使用任何一个MQ的时候，无论是RocketMQ，还是RabbitMQ，或者是Kafka，大家都要明确一点：不一定你发送消息出去就一定会成功，有可能就会失败，此时你的代码里可能会抛出异常，也可能不会抛出异常，这都不好说，具体要看到底什么原因导致的消息推送失败。

## 3、消息到达MQ了，MQ自己会导致消息丢失吗？

接着我们来看下一个问题，即使我们的订单系统成功的把消息写入了MQ，此时我们就可以想当然的认为你写成功了，消息就一定不会丢失了吗？

这个也是未必的，我们来分析一下为什么

因为通过之前的RocketMQ的底层原理的分析，我们现在都明确了一点，就是你的消息写入MQ之后，其实MQ可能仅仅是把这个消息给写入到page cache里，也就是操作系统自己管理的一个缓冲区，这本质也是内存

![](../../pic/2020-03-29-18-16-30.png)

大家注意图里的示意，可能你认为写成功了一个消息，但是此时仅仅进入了os cache，还没写入磁盘呢。然后这个时候，假如要是出现了Broker机器的崩溃，大家思考一下，机器一旦宕机，是不是os cache内存中的数据就没了？


## 4、就算消息进入磁盘了，你以为真的万无一失吗？

![](../../pic/2020-03-29-18-17-19.png)

显然不能想的那么简单，因为如果你的磁盘出现故障，比如磁盘坏了，你上面存储的数据还是会丢失。所以如果消息进入了broker机器的磁盘之后，万一你实在是点儿背，赶上机器刚好磁盘坏了，可能上面的消息也就都丢失了


## 5、即使红包系统拿到了消息，就一定不会丢失了吗？

这也是未必的。要解释这个问题，我们就要牵扯到消息的offset这个概念了。

之前其实我们已经给大家在底层原理分析的部分详细解释了MQ底层的存储结构，包括消息的offset的概念

说白了，offset就是代表了一个消息的标识，代表了他的位置

我们给大家举个例子，看下图，假设现在有两个消息，offset分别为1和2。

![](../../pic/2020-03-29-18-19-15.png)

现在我们假设红包系统已经获取到了消息1了，然后消息1此时就在他的内存里，正准备运行代码去派发现金红包呢，但是要注意，此时还没派发现金红包

我们都知道，默认情况下，MQ的消费者有可能会自动提交已经消费的offset，那么如果此时你还没处理这个消息派发红包的情况下，MQ的消费者可能直接自动给你提交这个消息1的offset到broker去了，标识为你已经成功处理了这个消息，我们看下图。

接着恰巧在这个时候，我们的红包系统突然重启了，或者是宕机了，或者是可能在派发红包的时候更新数据库失败了，总之就是他突然故障了，红包系统的机器重启了一下，然后此时内存里的消息1必然就丢失了，而且红包也没发出去

![](../../pic/2020-03-29-18-20-11.png)

## 6、用户支付之后红包到底为什么没发送出去呢？

其实原因有多种可能，比如订单系统推送消息到MQ就失败了，压根儿就没推送过去；

或者是消息确实推送到MQ了，但是结果MQ自己机器故障，把消息搞丢了；

或者是红包系统拿到了消息，但是他把消息搞丢了，结果红包还没来得及发。

如果真的在生产环境里要搞明白这个问题，就必须要打更多的日志去一点点分析消息到底是在哪个环节丢失了？

如果订单系统推送了消息，结果红包系统连消息都没收到，那可能消息根本就没发到MQ去，或者MQ自己搞丢了消息。

如果红包系统收到了消息，结果红包没派发，那么就是红包系统搞丢了消息。

![](../../pic/2020-03-29-18-22-20.png)

# 68 发送消息零丢失方案：RocketMQ事务消息的实现流程分析

## 1、解决消息丢失的第一个问题：订单系统推送消息丢失

在RocketMQ中，有一个非常强悍有力的功能，就是事务消息的功能，凭借这个事务级的消息机制，就可以让我们确保订单系统推送给出去的消息一定会成功写入MQ里，绝对不会半路就搞丢了。

## 2、发送half消息到MQ去，试探一下MQ是否正常

首先作为我们的订单系统而言，假设他收到了一个订单支付成功的通知之后，他必然是需要在自己的订单数据库里做一些增删改操作的，比如更新订单状态之类的。

可能有的朋友会觉得，订单系统不就是先在自己数据库里做一些增删改操作，然后就直接发个消息到MQ去，让其他关注这个订单支付成功消息的系统去从MQ获取消息做对应的处理就可以了么？

事实上还真不是这么简单。

在基于RocketMQ的事务消息机制中，我们首先要让订单系统去发送一条half消息到MQ去，这个half消息本质就是一个订单支付成功的消息，只不过你可以理解为他这个消息的状态是half状态，这个时候红包系统是看不见这个half消息的

然后我们去等待接收这个half消息写入成功的响应通知，我们看下面的图

![](../../pic/2020-03-29-18-25-32.png)

看到这儿可能有的朋友就开始有点郁闷了，可能会觉得你没事儿先发个half消息给MQ干什么？

大家先别着急，你可以想一下，假设你二话不说让订单系统直接做了本地的数据库操作，比如订单状态都更新为了已完成，然后你再发送消息给MQ，结果报出一堆异常，发现MQ挂了。

这个时候，必然导致你没法通过消息通知到红包系统去派发红包，那用户一定会发现自己订单支付了，结果红包没收到。

所以，在这里我们首先第一件事，不是先让订单系统做一些增删改操作，而是先发一个half消息给MQ以及收到他的成功的响应，初步先跟MQ做个联系和沟通

大概这个意思就是说，确认一下MQ还活着，MQ也知道你后续可能想发送一条很关键的不希望丢失的消息给他了！

## 3、万一要是half消息写入失败了呢？

可能你发现报错了，可能MQ就挂了，或者这个时候网络就是故障了，所以导致你的half消息都没发送成功，总之你现在肯定没法跟MQ通信了。

这个时候你的订单系统就应该执行一系列的回滚操作，比如对订单状态做一个更新，让状态变成“关闭交易”，同时通知支付系统自动进行退款，这才是正确的做法。

因为你订单虽然支付了，但是包括派发红包、发送优惠券之类的后续操作是无法执行的，所以此时必然应该把钱款退还给用户，说交易失败了。


## 4、half消息成功之后，订单系统完成自己的任务

接着我们来考虑第二种情况，你的half消息写成功了，这个时候你应该干什么呢？

这个时候你的订单系统就应该在自己本地的数据库里执行一些增删改操作了，因为一旦half消息写成功了，就说明MQ肯定已经收到这条消息了，MQ还活着，而且目前你是可以跟MQ正常沟通的。

![](../../pic/2020-03-29-18-29-21.png)

## 5、如果订单系统的本地事务执行失败了怎么办？

比如订单系统的数据库当时也有网络异常，或者数据库挂了，总而言之，就是你想把订单更新为“已完成”这个状态，是干不成了。

这个时候其实也很简单，直接就是让订单系统发送一个rollback请求给MQ就可以了。这个意思就是说，你可以把之前我发给你的half消息给删除掉了，因为我自己这里都出问题了，已经无力跟你继续后续的流程了。

![](../../pic/2020-03-29-18-30-28.png)

当然你发送rollback请求给MQ删除那个half消息之后，你的订单系统就必须走后续的回退流程了，就是通知支付系统退款。

当然这里可能还有一些订单系统自己的高可用降级的机制需要考虑，比如数据库无法更新了，此时你可能需要在机器本地磁盘文件里写入订单支付失败的记录。

然后你可以开一个后台线程在MySQL数据库恢复之后 ，再把订单状态更新为“已关闭”。不过这个不在我们讨专栏的范围之内。

## 6、如果订单系统完成了本地事务之后，接着干什么？

如果订单系统成功完成了本地的事务操作，比如把订单状态都更新为“已完成”了，此时你就可以发送一个commit请求给MQ，要求让MQ对之前的half消息进行commit操作，让红包系统可以看见这个订单支付成功消息

![](../../pic/2020-03-29-18-31-54.png)

之前我们也提到过了，所谓的half消息实际就是订单支付成功的消息，只不过他的状态是half。也就是他是half状态的时候，红包系统是看不见他的，没法获取到这条消息，必须等到订单系统执行commit请求，消息被commit之后，红包系统才可以看到和获取这条消息进行后续处理。


## 7、让流程严谨一些：如果发送half消息成功了，但是没收到响应呢？

大致的事务消息的流程是讲完了，但是接着让我们来进行比较严谨的分析，如果我们把half消息发送给MQ了，MQ给保存下来了，但是MQ返回给我们的响应我们没收到呢？此时会发生什么事情？

这个时候我们没收到响应，可能就会网络超时报错，也可能直接有其他的异常错误，这个时候订单系统会误以为是发送half消息到MQ失败了，订单系统就直接会执行退款流程了，订单状态也会标记为“已关闭”。

![](../../pic/2020-03-29-18-34-01.png)


但这个时候MQ已经存储下来一条half消息了，那对这个消息怎么处理？

其实RocketMQ这里有一个补偿流程，他会去扫描自己处于half状态的消息，如果我们一直没有对这个消息执行commit/rollback操作，超过了一定的时间，他就会回调你的订单系统的一个接口

他会问问你：这个消息到底怎么回事？你到底是打算commit这个消息还是要rollback这个消息？

![](../../pic/2020-03-29-18-34-50.png)

这个时候我们的订单系统就得去查一下数据库，看看这个订单当前的状态，一下发现订单状态是“已关闭”，此时就知道，你必然得发送rollback请求给MQ去删除之前那个half消息了！


![](../../pic/2020-03-29-18-35-28.png)


## 8、如果rollback或者commit发送失败了呢？

我们再假设一种场景，如果订单系统是收到了half消息写入成功的响应了，同时尝试对自己的数据库更新了，然后根据失败或者成功去执行了rollback或者commit请求，发送给MQ了，结果因为网络故障，导致rollback或者commit请求发送失败了呢？

这个时候其实也很简单，因为MQ里的消息一直是half状态，所以说他过了一定的超时时间会发现这个half消息有问题，他会回调你的订单系统的接口

你此时要判断一下，这个订单的状态如果更新为了“已完成”，那你就得再次执行commit请求，反之则再次执行rollback请求。

本质这个MQ的回调就是一个补偿机制，如果你的half消息响应没收到，或者rollback、commit请求没发送成功，他都会来找你问问对half消息后续如何处理。

再假设一种场景，如果订单系统收到了half消息写入成功的响应了，同时尝试对自己的数据库更新了，然后根据失败或者成功去执行了rollback或者commit请求，发送给MQ了。很不巧，mq在这个时候挂掉了，导致rollback或者commit请求发送失败，怎么办？

如果是这种情况的话，那就等mq自己重启了，重启之后他会扫描half消息，然后还是通过上面说到的补偿机制，去回调你的接口

## 9、停一下脚步，想想上面这个流程的意义在哪里？

其实很简单，如果你的MQ有问题或者网络有问题，half消息根本都发不出去，此时half消息肯定是失败的，那么订单系统就不会执行后续流程了！

如果要是half消息发送出去了，但是half消息的响应都没收到，然后执行了退款流程，那MQ会有补偿机制来回调找你询问要commit还是rollback，此时你选择rollback删除消息就可以了，不会执行后续流程！

如果要是订单系统收到half消息了，结果订单系统自己更新数据库失败了，那么他也会进行回滚，不会执行后续流程了！

如果要是订单系统收到half消息了，然后还更新自己数据库成功了，订单状态是“已完成”了，此时就必然会发送commit请求给MQ，一旦消息commit了，那么必然保证红包系统可以收到这个消息！

而且即使你commit请求发送失败了，MQ也会有补偿机制，回调你接口让你判断是否重新发送commit请求

总之，就是你的订单系统只要成功了，那么必然要保证MQ里的消息是commit了可以让红包系统看到他！

所以大家可以结合我们的图思考一下上述流程，通过这套事务消息的机制，是不是就可以保证我们的订单系统一旦成功执行了数据库操作，就一定会通知到红包系统去派发红包？至少订单系统到MQ之间的消息传输是不会有丢失的问题了！


# 69 RocketMQ黑科技解密：事务消息机制的底层实现原理

## 1、half 消息是如何对消费者不可见的？

我们之前已经说过了RocketMQ事务消息的全流程，在这个流程中，第一步就是要由订单系统去发送一个half消息给MQ

然后当时我们给大家说过，对于这个half消息，红包系统这个时候是看不到他的，没法消费这条消息去处理，那这个half消息是如何做到不给人家红包系统看到的呢？

咱们先举个例子，订单系统发送了一个half状态的订单支付消息到“OrderPaySuccessTopic”里去，这是一个Topic

然后呢，红包系统也是订阅了这个“OrderPaySuccessTopic”从里面获取消息的，我们看下图示意。

当然我们从之前的底层原理剖析的环节都知道，其实你写入一个Topic，最终是定位到这个Topic的某个MessageQueue，然后定位到一台Broker机器上去，然后写入的是Broker上的CommitLog文件，同时将消费索引写入MessageQueue对应的ConsumeQueue文件

所以通过上面的图我们知道，如果你写入一条half消息到OrderPaySuccessTopic里去，会定位到这个Topic的一个MessageQueue，然后定位到上图RocketMQ的一台机器上去，接着按理说，消息会写入CommitLog。

同时消息的offset会写入MessageQueue对应的ConsumeQueue，这个ConsumeQueue是属于OrderPaySuccuessTopic的，然后红包系统按理说会从这个ConsumeQueue里获取到你写入的这个half消息。

但是实际上红包系统却没法看到这条消息，其本质原因就是RocketMQ一旦发现你发送的是一个half消息，他不会把这个half消息的offset写入OrderPaySuccessTopic的ConsumeQueue里去。


他会把这条half消息写入到自己内部的“**RMQ_SYS_TRANS_HALF_TOPIC**”这个Topic对应的一个ConsumeQueue里去

![](../../pic/2020-03-29-18-43-56.png)

真相大白了，所以对于事务消息机制之下的half消息，RocketMQ是写入内部Topic的ConsumeQueue的，不是写入你指定的OrderPaySuccessTopic的ConsumeQueue的。所以你的红包系统自然无法从OrderPaySuccessTopic的ConsumeQueue中看到这条half消息了


## 2、在什么情况下订单系统会收到half消息成功的响应？

简单来说，结合上面的内容，大家就可以清晰判断出，必须要half消息进入到RocketMQ内部的RMQ_SYS_TRANS_HALF_TOPIC的ConsumeQueue文件了，此时就会认为half消息写入成功了，然后就会返回响应给订单系统。

所以这个时候，一旦你的订单系统收到这个half消息写入成功的响应，必然就知道这个half消息已经在RocketMQ内部了。


## 3、假如因为各种问题，没有执行rollback或者commit会怎么样？

其实这个时候他会在后台有定时任务，定时任务会去扫描RMQ_SYS_TRANS_HALF_TOPIC中的half消息，如果你超过一定时间还是half消息，他会回调订单系统的接口，让你判断这个half消息是要rollback还是commit

![](../../pic/2020-03-29-18-45-47.png)

## 4、如果执行rollback操作的话，如何标记消息回滚？

之前我们说，RocketMQ会把这个half消息给删除，但是大家觉得删除消息是真的会在磁盘文件里删除吗？

显示不是的

因为RocketMQ都是顺序把消息写入磁盘文件的，所以在这里如果你执行rollback，他的本质就是用一个OP操作来标记half消息的状态

RocketMQ内部有一个OP_TOPIC，此时可以写一条rollback OP记录到这个Topic里，标记某个half消息是rollback了，如下图。

![](../../pic/2020-03-29-18-47-13.png)

另外给大家说一下，假设你一直没有执行commit/rollback，RocketMQ会回调订单系统的接口去判断half消息的状态，但是他最多就是回调15次，如果15次之后你都没法告知他half消息的状态，就自动把消息标记为rollback。

## 5、如果执行commit操作，如何让消息对红包系统可见？

其实也很简单，你执行commit操作之后，RocketMQ就会在OP_TOPIC里写入一条记录，标记half消息已经是commit状态了。

接着需要把放在RMQ_SYS_TRANS_HALF_TOPIC中的half消息给写入到OrderPaySuccessTopic的ConsumeQueue里去，然后我们的红包系统可以就可以看到这条消息进行消费了，如下图。

![](../../pic/2020-03-29-18-48-38.png)


# 70 为什么解决发送消息零丢失方案，一定要使用事务消息方案？

我们真的有必要使用这么复杂的机制去确保消息到达MQ，而且绝对不会丢吗？

毕竟这么复杂的机制完全有可能导致整体性能比较差，而且吞吐量比较低，是否有更加简单的方法来确保消息一定可以到达MQ呢？


## 2、一个小思考：能不能基于重试机制来确保消息到达MQ？

那么我们先搞清楚一个问题，我们发送消息到MQ，然后我们可以等待MQ返回响应给我们，在什么样的情况下，MQ会返回响应给我们呢？

答案显而易见，就是MQ收到消息之后写入本地磁盘文件了，当然这个时候可能仅仅是写入os cache而已，但是只要他写入自己本地存储了，就会返回响应给我们。

那么只要我们在代码中发送消息到MQ之后，同步等待MQ返回响应给我们，一直等待，如果半路中有网络异常或者MQ内部异常，我们肯定会收到一个异常，比如网络错误，或者请求超时之类的。

如果我们在收到异常之后，就认为消息到MQ发送失败了，然后再次重试尝试发送消息到MQ，接着再次同步等待MQ返回响应给我们，这样反复重试，是否可以确保消息一定会到达MQ？

理论上似乎在一些短暂网络异常的场景下，我们是可以通过不停的重试去保证消息到达MQ的，因为如果短时间网络异常了消息一直没法发送，我们只要不停的重试，网络一旦恢复了，消息就可以发送到MQ了。

如果要是反复重试多次发现一直没法把消息投递到MQ，此时我们就可以直接让订单系统回滚之前的流程，比如发起退款流程，判定本次订单支付交易失败了。

看起来这个简单的同步发送消息 + 反复重试的方案，也可以做到保证消息一定可以投递到MQ中，大家想想是不是？

确实如此，而且在基于Kafka作为消息中间件的消息零丢失方案中，对于发送消息这块，因为Kafka本身不具备RocketMQ这种事务消息的高级功能，所以一般我们都是对Kafka会采用同步发消息 + 反复重试多次的方案，去保证消息成功投递到Kafka的。

但是如果是在类似我们目前这个较为复杂的订单业务场景中，仅仅采用同步发消息 + 反复重试多次的方案去确保消息绝对投递到MQ中，似乎还是不够的，接下来我们分析一下在复杂业务场景下，这里有什么问题。

## 3、先执行订单本地事务，还是先发消息到MQ？

如果我们先执行订单本地事务，接着再发送消息到MQ的话，看起来伪代码可能是这样的：

![](../../pic/2020-03-29-21-41-20.png)


上面那段伪代码看着似乎天衣无缝，先执行订单本地事务，接着发送消息到MQ，如果订单本地事务执行失败了，则不会继续发送消息到MQ了；

如果订单事务执行成功了，发送MQ失败了，自动进行几次重试，重试如果一直失败，就回滚订单事务。

但是这里有一个问题，假设你刚执行完成了订单本地事务了，结果还没等到你发送消息到MQ，结果你的订单系统突然崩溃了！

这就导致你的订单状态可能已经修改为了“已完成”，但是消息却没发送到MQ去！这就是这个方案最大的隐患。

![](../../pic/2020-03-29-21-42-56.png)

如果出现这种场景，那你的多次重试发送MQ之类的代码根本没机会执行！而且订单本地事务还已经执行成功了，你的消息没发送出去，红包系统没机会派发红包，必然导致用户支付成功了，结果看不到自己的红包！

## 4、把订单本地事务和重试发送MQ消息放到一个事务代码中

我们接着来考虑下一个问题，这个时候有人会想到一个新的想法，如果把订单本地事务代码和发送MQ消息的代码放到一个事务代码中呢？

![](../../pic/2020-03-29-21-44-30.png)

上面这个代码看起来似乎解决了我们的问题，就是在这个方法上加入事务，在这个事务方法中，我们哪怕执行了orderService.finishOrderPay()，但是其实也仅仅执行了一些增删改SQL语句，还没提交订单本地事务。

如果发送MQ消息失败了，而且多次重试还不奏效，则我们抛出异常会自动回滚订单本地事务；

如果你刚执行了orderService.finishOrderPay()，结果订单系统直接崩溃了，此时订单本地事务会回滚，因为根本没提交过。

但是对于这个方案，还是非常的不理想，原因就出在那个MQ多次重试的地方

假设用户支付成功了，然后支付系统回调通知你的订单系统说，有一笔订单已经支付成功了，这个时候你的订单系统卡在多次重试MQ的代码那里，可能耗时了好几秒种，此时回调通知你的系统早就等不及可能都超时异常了。

而且你把重试MQ的代码放在这个逻辑里，可能会导致订单系统的这个接口性能很差

![](../../pic/2020-03-29-21-46-27.png)

## 5、再说了，你就一定可以依靠本地事务回滚吗？

除了我们上面说的那个问题之外，我可能还不得不给很多寄希望于订单事务和发送MQ消息包裹在一个事务代码中的朋友，泼一盆冷水，大家觉得我们一定可以依靠本地事务回滚吗？

![](../../pic/2020-03-29-21-47-10.png)

大家着重在里面看，我们虽然在方法上加了事务注解，但是代码里还有更新Redis缓存和Elasticsearch数据的代码逻辑，如果你要是已经完成了订单数据库更新、Redis缓存更新、ES数据更新了，结果没法送MQ呢订单系统崩溃了。

虽然订单数据库的操作会回滚，但是Redis、Elasticsearch中的数据更新会自动回滚吗？

不会的，因为他们根本没法自动回滚，此时数据还是会不一致的。所以说，完全寄希望于本地事务自动回滚是不现实的。


## 6、保证业务系统一致性的最佳方案：基于RocketMQ的事务消息机制

所以分析完了这个同步发送消息 + 反复多次重试的方案之后，我们会发现他实际落地的时候是可以的，但是里面存在一些问题

比如可能会让订单事务执行成功，结果消息没发送出去，或者是订单事务执行成功了，但是反复多次重试发送消息到MQ极为耗时，导致调用你接口的人频繁超时异常。

所以真正要保证消息一定投递到MQ，同时保证业务系统之间的数据完全一致，业内最佳的方案还是用基于RocketMQ的事务消息机制。

因为这个方案落地之后，他可以保证你的订单系统的本地事务一旦成功，那么必然会投递消息到MQ去，通知红包系统去派发红包，保证业务系统的数据是一致的。而且整个流程中，你没必要进行长时间的阻塞和重试。

如果half消息发送就失败了，你就直接回滚整个流程。如果half消息发送成功了，后续的rollback或者commit发送失败了，你不需要自己去卡在那里反复重试，你直接让代码结束即可，因为后续MQ会过来回调你的接口让你判断再次rollback or commit的。

# 71 用支付后发红包的案例场景，分析RocketMQ事物消息的代码实现细节

## 2、发送half事务消息出去

![](../../pic/2020-03-29-21-50-56.png)


## 3、假如half消息发送失败，或者没收到half消息响应怎么办？

此时我们其实会在执行“producer.sendMessageInTransaction(msg, null)”的时候，收到一个异常，发现消息发送失败了。

所以我们可以用下面的代码去关注half消息发送失败的问题：

![](../../pic/2020-03-29-21-53-01.png)

那如果一直没有收到half消息发送成功的通知呢？

针对这个问题，我们可以把发送出去的half消息放在内存里，或者写入本地磁盘文件，后台开启一个线程去检查，如果一个half消息超过比如10分钟都没有收到响应，那就自动触发回滚逻辑。


## 4、如果half消息成功了，如何执行订单本地事务？

刚才代码里有一个TransactionListener，这个类也是我们自己定义的，如下所示：

![](../../pic/2020-03-29-21-54-18.png)


## 5、如果没有返回commit或者rollback，如何进行回调？

![](../../pic/2020-03-29-21-55-04.png)


# 72 Broker消息零丢失方案：同步刷盘 + Raft协议主从同步

## 1、用了事务消息机制，消息就一定不会丢了吗？

假设咱们现在订单系统已经通过事务消息的机制，通过half消息 + commit的方式，把消息在MQ里提交了

也就是说，现在对于MQ而言，那条消息已经进入到他的存储层了，可以被红包系统看到了

但是我们先稍微等一下，你的这条消息在commit之后，会从half topic里进入OrderPaySuccessTopic中，但是此时仅仅是消息进入了这个你预定的Topic而已，仅仅是可以被红包系统看到而已，此时可能你的红包系统还没来得及去获取这条消息。

然后恰巧在此时，你的这条消息又仅仅停留在os cache中，还没进入到ConsumeQueue磁盘文件里去，然后此时这台机器突然宕机了，os cache中的数据全部丢失，此时必然会导致你的消息丢失，红包系统再没机会读到这条消息了。

## 2、就算你走运，消息进了磁盘就不会丢了吗？

即使消息已经进入磁盘文件了，但是这个时候红包系统还没来得及消费这条消息，然后此时这台机器的磁盘突然就坏了，就会一样导致消息丢失，而且可能消息再也找不回来了，同样会丢失数据。


## 3、明确一个前提：保证消息写入MQ不代表不丢失

因为即使你写入MQ成功了，这条消息也大概率是仅仅停留在MQ机器的os cache中，一旦机器宕机内存里的数据都会丢失，或者哪怕消息已经进入了MQ机器的磁盘文件里，但是磁盘一旦坏了，消息也会丢失。

如果消息丢失了，你的红包系统还没来得及消费，那么他就永远没机会消费和派发红包了，所以对于你而言，如果你仅仅只是使用MQ的话，可能不清楚MQ集群内部发生过的一些机器故障，也就不清楚数据丢失的具体原因了。

## 4、异步刷盘 vs 同步刷盘

说到这里，我们终于可以进入正题了，到底怎么去确保消息写入MQ之后，MQ自己不要随便丢失数据呢？

解决这个问题的第一个关键点，就是将**异步刷盘调整为同步刷盘**

所谓的异步刷盘，就是之前我们一直说的那种模式。

也就是说，你的消息即使成功写入了MQ，他也就在机器的os cache中，没有进入磁盘里，要过一会儿等操作系统自己把os cache里的数据实际刷入磁盘文件中去

所以在异步刷盘的模式下，我们的写入消息的吞吐量肯定是极高的，毕竟消息只要进入os cache这个内存就可以了，写消息的性能就是写内存的性能，那每秒钟可以写入的消息数量肯定更多了，但是这个情况下，可能就会导致数据的丢失。

所以如果一定要确保数据零丢失的话，可以调整MQ的刷盘策略，我们需要调整broker的配置文件，将其中的flushDiskType配置设置为：SYNC_FLUSH，默认他的值是ASYNC_FLUSH，即默认是异步刷盘的。

如果调整为同步刷盘之后，我们写入MQ的每条消息，只要MQ告诉我们写入成功了，那么他们就是已经进入了磁盘文件了！

比如我们发送half消息的时候，只要MQ返回响应是half消息发送成功了，那么就说明消息已经进入磁盘文件了，不会停留在os cache里。

## 5、如何通过主从架构模式避免磁盘故障导致的数据丢失？

其实道理也很简单，我们必须要对Broker使用主从架构的模式

也就是说，必须让一个Master Broker有一个Slave Broker去同步他的数据，而且你一条消息写入成功，必须是让Slave Broker也写入成功，保证数据有多个副本的冗余。

![](../../pic/2020-03-29-22-04-34.png)

这样一来，你一条消息但凡写入成功了，此时主从两个Broker上都有这条数据了，此时如果你的Master Broker的磁盘坏了，但是Slave Broker上至少还是有数据的，数据是不会因为磁盘故障而丢失的。

对于主从同步的架构，我们本来就是讲解了基于DLedger技术和Raft协议的主从同步架构，你如果采用了这套架构，对于你所有的消息写入，只要他写入成功，那就一定会通过Raft协议同步给其他的Broker机器，这里的原理我们之前都已经讲解过了，大家有遗忘的回去看看即可。

## 6、MQ确保数据零丢失的方案总结

所以通过今天的分析，我们知道了，只要你把Broker的刷盘策略调整为同步刷盘，那么绝对不会因为机器宕机而丢失数据；

只要你采用了主从架构的Broker集群，那么一条消息写入成功，就意味着多个Broker机器都写入了，此时任何一台机器的磁盘故障，数据也是不会丢失的。

最起码只要Broker层面保证写入的数据不丢失，那就一定可以让红包系统消费到这条消息了！


# 73 Consumer消息零丢失方案：手动提交offset + 自动故障转移

## 1、红包系统拿到了消息就一定会派发红包吗？

![](../../pic/2020-03-29-22-06-55.png)

我们之前也给大家分析过这个问题，如果红包系统已经拿到了这条消息，但是消息目前还在他的内存里，还没执行派发红包的逻辑，此时他就直接提交了这条消息的offset到broker去说自己已经处理过了，我们看下图。

![](../../pic/2020-03-29-22-07-55.png)

接着红包系统在上图这个状态的时候就直接崩溃了，内存里的消息就没了，红包也没派发出去，结果Broker已经收到他提交的消息offset了，还以为他已经处理完这条消息了。

等红包系统重启的时候，就不会再次消费这条消息了。

关于这个问题，我们之前通过画图的方式，已经清晰的展示了消息offset错误提交之后，导致红包系统可能无法再次获取到这条消息的问题。

所以我们在这里，首先要明确一点，那就是即使你保证发送消息到MQ的时候绝对不会丢失，而且MQ收到消息之后一定不会把消息搞丢失，但是你的红包系统在获取到消息之后还是可能会搞丢。


## 2、Kafka消费者的数据丢失问题

虽然我们这个专栏主要是依托RocketMQ来讲解消息中间件技术的原理、生产架构以及技术方案的，但是其实我们这里涉及到的各种技术思想，包括MQ数据丢失问题以及解决方案，在Kafka、RabbitMQ等其他中间件里也是完全适用的。

所以对我们目前讲解的这个消费者数据丢失的问题，其实完全可以套用到Kafka中去，因为Kafka的消费者采用的消费的方式跟RocketMQ是有些不一样的，如果按照Kafka的消费模式，就是会产生数据丢失的风险。

也就是说Kafka消费者可能会出现上图说的，拿到一批消息，还没来得及处理呢，结果就提交offset到broker去了，完了消费者系统就挂掉了，这批消息就再也没机会处理了，因为他重启之后已经不会再次获取提交过offset的消息了。


## 3、RocketMQ消费者的与众不同的地方

![](../../pic/2020-03-29-22-10-55.png)

![](../../pic/2020-03-29-22-11-09.png)

大家会发现，RocketMQ的消费者中会注册一个监听器，就是上面小块代码中的MessageListenerConcurrently这个东西，当你的消费者获取到一批消息之后，就会回调你的这个监听器函数，让你来处理这一批消息。

然后当你处理完毕之后，你才会返ConsumeConcurrentlyStatus.CONSUME_SUCCESS作为消费成功的示意，告诉RocketMQ，这批消息我已经处理完毕了。

所以对于RocketMQ而言，其实只要你的红包系统是在这个监听器的函数中先处理一批消息，基于这批消息都派发完了红包，然后返回了那个消费成功的状态，接着才会去提交这批消息的offset到broker去。

所以在这个情况下，如果你对一批消息都处理完毕了，然后再提交消息的offset给broker，接着红包系统崩溃了，此时是不会丢失消息的

那么如果是红包系统获取到一批消息之后，还没处理完，也就没返回ConsumeConcurrentlyStatus.CONSUME_SUCCESS这个状态呢，自然没提交这批消息的offset给broker呢，此时红包系统突然挂了，会怎么样？

其实在这种情况下，你对一批消息都没提交他的offset给broker的话，broker不会认为你已经处理完了这批消息，此时你突然红包系统的一台机器宕机了，他其实会感知到你的红包系统的一台机器作为一个Consumer挂了。

接着他会把你没处理完的那批消息交给红包系统的其他机器去进行处理，所以在这种情况下，消息也绝对是不会丢失的


## 4、需要警惕的地方：不能异步消费消息

所以大家也看到了，在默认的Consumer的消费模式之下，必须是你处理完一批消息了，才会返回ConsumeConcurrentlyStatus.CONSUME_SUCCESS这个状态标识消息都处理结束了，去提交offset到broker去。

在这种情况下，正常来说是不会丢失消息的，即使你一个Consumer宕机了，他会把你没处理完的消息交给其他Consumer去处理。

但是这里我们要警惕一点，就是我们不能在代码中对消息进行异步的处理，如下错误的示范，我们开启了一个子线程去处理这批消息，然后启动线程之后，就直接返回ConsumeConcurrentlyStatus.CONSUME_SUCCESS状态了

![](../../pic/2020-03-29-22-14-27.png)

如果要是用这种方式来处理消息的话，那可能就会出现你开启的子线程还没处理完消息呢，你已经返回ConsumeConcurrentlyStatus.CONSUME_SUCCESS状态了，就可能提交这批消息的offset给broker了，认为已经处理结束了。

然后此时你红包系统突然宕机，必然会导致你的消息丢失了！

因此在RocketMQ的场景下，我们如果要保证消费数据的时候别丢消息，你就老老实实的在回调函数里处理消息，处理完了你再返回ConsumeConcurrentlyStatus.CONSUME_SUCCESS状态表明你处理完毕了！

# 74 基于 RocketMQ 设计的全链路消息零丢失方案总结

## 1、对全链路消息零丢失方案进行总结

- 1、发送消息到MQ的零丢失
    - 方案一（同步发送消息 + 反复多次重试）
    - 方案二（事务消息机制），两者都有保证消息发送零丢失的效果，但是经过分析，事务消息方案整体会更好一些

- 2、MQ收到消息之后的零丢失：开启同步刷盘策略 + 主从架构同步机制，只要让一个Broker收到消息之后同步写入磁盘，同时同步复制给其他Broker，然后再返回响应给生产者说写入成功，此时就可以保证MQ自己不会弄丢消息

- 3、消费消息的零丢失：采用RocketMQ的消费者天然就可以保证你处理完消息之后，才会提交消息的offset到broker去，只要记住别采用多线程异步处理消息的方式即可

但是今天我们除了总结这个方案之外，我们还需要对消息零丢失方案进行一些优劣分析。

## 2、消息零丢失方案的优势与劣势

如果在系统中落地一套消息零丢失方案，不管是哪个系统，不管是哪个场景，都可以确保消息流转的过程中不会丢失，看起来似乎很有吸引力，这也是消息零丢失方案的优势所在，可以让系统的数据都是正确的，不会有丢失的。

但是他的劣势在哪里呢？

显而易见的是，你用了这套方案之后，会让你整个从头到尾的消息流转链路的性能大幅度下降，让你的MQ的吞吐量大幅度的下降

比如本身你的系统和MQ配合起来，每秒可以处理几万条消息的，结果当你落地消息零丢失方案之后，可能每秒只能处理几千条消息了。

为什么会这样呢？我们接下来一步一步分析一下。

## 3、为什么消息零丢失方案会导致吞吐量大幅度下降？

我们先来看这个发送消息到MQ的环节，如果我们仅仅只是简单的把消息发送到MQ，那么不过就是一次普通的网络请求罢了，我们就是发送请求到MQ然后接收响应回来，这个性能自然很高，吞吐量也是很高的

![](../../pic/2020-03-29-22-19-43.png)

但是如果你改成了基于事务消息的机制之后呢？

那么此时这里的实现原理图如下所示，这里涉及到half消息、commit or rollback、写入内部topic、回调机制，等诸多复杂的环节

不说别的，光是你成功发送一条消息，都至少要half + commit两次请求。

![](../../pic/2020-03-29-22-20-27.png)

所以当你一旦上了如此复杂的方案之后，势必会导致你的发送消息的性能大幅度下降，同时发送消息到MQ的吞吐量大幅度下降。

接着我们再看MQ收到消息之后的行为，在MQ收到消息之后，一样会让性能大幅度下降。

首先MQ的一台broker机器收到了消息之后，必然直接把消息刷入磁盘里，这个性能就远远低于你写入os cache了，完全不是一个数量级的，比如你写入os cache相当于是内存，可能仅仅需要0.1ms，但是你写入磁盘文件可能就需要10ms！如下图。

![](../../pic/2020-03-29-22-21-14.png)

接着你的这台broker机器还必须直接把消息复制给其他的broker，完成多副本的冗余，这个过程涉及到两台broker机器之间的网络通信，另外一台broker机器写数据到自己本地磁盘去，同样会比较慢，如下图。

![](../../pic/2020-03-29-22-21-41.png)

在broker完成了上述两个步骤之后，接着才能返回响应告诉你说这次消息写入已经成功了，大家试想一下，写入一条消息需要强制同步刷磁盘，而且还需要同步复制消息给其他的broker机器

这两个步骤一加入，可能原本10ms的事儿就会变成100ms了！所以这里也势必会导致性能大幅度下降，MQ的broker的吞吐量会大幅度下降。

最后看你的消费者，当你的消费者拿到消息之后，比如他直接开启一个子线程去处理这批消息，然后他就直接返回CONSUME_SUCCESS状态了，接着他就可以去处理下一批消息了！如果这样的话，你消费消息的速度会很快，吞吐量会很高！


但是如果为了保证数据不丢失，你必须是处理完一批消息再返回CONSUME_SUCCESS状态，那么此时你消费者处理消息的速度会降低，吞吐量 自然也会下降了！

## 4、消息零丢失方案到底适合什么场景？

所以简单一句话，如果你一定要上消息零丢失方案，那么必然导致从头到尾的性能下降以及MQ的吞吐量下降。

所以一般大家不要轻易在随便一个业务里就上如此重的一套方案，要明白这背后的成本！

那么消息零丢失方案到底适用于什么场景呢？

一般我们建议，对于跟金钱、交易以及核心数据相关的系统和核心链路，可以上这套消息零丢失方案。

比如支付系统，他是绝对不能丢失任何一条消息的，你的性能可以低一些，但是不能有任何一笔支付记录丢失。

比如订单系统，公司一般是不能轻易丢失一个订单的，毕竟一个订单就对应一笔交易，如果订单丢失，用户还支付成功了，你轻则要给用户赔付损失，重则弄不好要经受官司，特别是一些B2B领域的电商，一笔线上交易可能多大几万几十万。


所以对这种非常非常核心的场景和少数几条核心链路，才会建议大家上这套复杂的消息0丢失方案。

而对于其他大部分没那么核心的场景和系统，其实即使丢失一些数据，也不会导致太大的问题，此时可以不采取这些方案，或者说你可以在其他的场景里做一些简化。

比如你可以把事务消息方案退化成“同步发送消息 + 反复重试几次”的方案，如果发送消息失败，就重试几次，但是大部分时候可能不需要重试，那么也不会轻易的丢失消息的！最多在这个方案里，可能会出现一些数据不一致的问题。

或者你把broker的刷盘策略改为异步刷盘，但是上一套主从架构，即使一台机器挂了，os cache里的数据丢失了，但是其他机器上还有数据。但是大部分时候broker不会随便宕机，那么异步刷盘策略下性能还是很高的。

所以说，对于非核心的链路，非金钱交易的链路，大家可以适当简化这套方案，用一些方法避免数据轻易丢失，但是同时性能整体很高，即使有极个别的数据丢失，对非核心的场景，也不会有太大的影响。


# 75 生产案例：从 RocketMQ 底层原理分析为什么会重复发优惠券？

那么接下来我们需要思考的问题就是，为什么优惠券会对同一个消息重复处理两次呢？


## 3、订单系统发送消息到MQ的时候会重复吗？

可能有的朋友乍一看觉得应该不可能，但是其实在生产环境中运行的系统，显然是有可能把一个消息重复发两次的！

首先，假设用户在支付成功之后，我们的订单系统收到了一个支付成功的通知，接着他就向MQ发送了一条订单支付成功的消息，这个大家都知道没有什么问题。

但是偏偏可能因为不知道什么原因，你的订单系统处理的速度有点慢，我们看下图。

![](../../pic/2020-03-29-22-29-17.png)

然后可能就因为你的订单系统处理的速度有点慢了，这就导致支付系统跟你订单系统之间的请求出现了超时，此时有可能支付系统再次重试调用了你订单系统的接口去通知你，这个订单支付成功了，然后你的订单系统这个时候可能又一次推送了一条消息到MQ里去，相当于是一个订单支付成功的消息，你重复推送了两次到MQ！

此时相当于是MQ里就会对一个订单的支付成功消息，总共有两条。

那如果你订单系统对一个订单重复推送了两次支付成功消息到MQ，MQ里对一个订单有两条重复的支付成功消息，优惠券系统必然会消费到一个订单的两条重复的支付成功消息，也必然会针对这个订单给用户重复的派发两个优惠券

所以大家看到这里，通过一步一图的方式，可以很清晰的看到我们用于发送消息到MQ的订单系统，如果出现了接口超时等问题，可能会导致上游的支付系统重试调用订单系统的接口，进而导致订单系统对一个消息重复发送两条到MQ里去！


## 4、重试是一把双刃剑：订单系统自己重复发送消息

接着我们来考虑第二种情况，假设支付系统没有对一个订单重复调用你的订单系统的接口，而是你订单系统自己可能就重复发送消息到MQ里去


假设我们的订单系统为了保证消息一定能投递到MQ里去，因此采用了重试的代码，我们之前也讲过这个伪代码的示意

我们看下面的代码片段，如果发现MQ发送有异常，则会进行几次重试。

![](../../pic/2020-03-29-22-31-36.png)

但是这种重试的方式，其实是一把双刃剑，因为正是这个重试就可能导致消息重复发送

我们来考虑一个情况，假设你发送了一条消息到MQ了，其实MQ是已经接收到这条消息了，结果MQ返回响应给你的时候，网络有问题超时了，就是你没能及时收到MQ返回给你的响应。

但是大家一定要明确一点，此时MQ里其实是已经有你发送过去的消息了，只不过他返回给你的响应没能给到你而已！

这个时候，你的代码里可能会发现一个网络超时的异常，然后你就会进行重试再次发送这个消息到MQ去，然后MQ必然会收到一条一模一样的消息，进而导致你的消息重复发送了！

所以这种重试代码大家在使用的时候一定要小心！因为他还是有一定的概率会导致你重发消息的！

## 5、优惠券系统重复消费一条消息

接着我们继续来看，即使你没有重复发送消息到MQ，哪怕MQ里就一条消息，优惠券系统也有可能会重复进行消费


假设你的优惠券系统拿到了一条订单成功支付的消息，然后都已经进行处理了，也就是说都已经对这个订单给你发了一张优惠券了，本来我们之前讲过，这个时候他应该返回一个CONSUME_SUCCESS的状态，然后提交消费进度offset到broker的。

但是不巧的是，你刚刚发完优惠券，还没来得及提交消息offset到broker呢！优惠券系统就进行了一次重启！比如可能优惠券系统的代码更新了，需要重启进行重新部署。


这时因为你没提交这条消息的offset给broker，broker并不知道你已经处理完了这条消息，然后优惠券系统重启之后，broker就会再次把这条消息交给你，让你再一次进行处理，然后你会再一次发送一张优惠券，导致重复发送了两次优惠券！

这就是对同一条消息，优惠券系统重复处理两次的原因。

## 6、消息重复问题应该是一种家常便饭

实际上大家要知道，对类似优惠券系统这样的业务系统，我们肯定是会频繁的更新代码的，可能每隔几天就需要重启一次系统进行代码的更新

所以其实你重启优惠券系统的时候，可能有一批消息刚处理完，还没来得及提交offset给broker呢，然后你重启之后就会再一次重复处理这批消息，这种情况可能是家常便饭！

另外就是对于系统之间的调用，有的时候出现超时和重试的情况也是很常见的，所以你负责发消息到MQ的系统，很可能时不时的出现一次超时，然后被别人重试调用你的接口，你可能会重复发送一条消息到MQ里去，这可能也是家常便饭！

因此在使用MQ的时候，大家应该对消息重复问题习惯他，当做必须处理的一个问题。

# 76 对订单系统核心流程引入 幂等性机制，保证数据不会重复

## 1、到底什么是幂等性机制？

这个幂等性机制，其实就是用来避免对同一个请求或者同一条消息进行重复处理的机制，所谓的幂等，他的意思就是，比如你有一个接口，然后如果别人对一次请求重试了多次，来调用你的接口，你必须保证自己系统的数据是正常的，不能多出来一些重复的数据，这就是幂等性的意思。

那么对于我们的MQ而言，就是你从MQ里获取消息的时候，要保证对同一个消息只能处理一次，不能重复处理多次，导致出现重复的数据。

因此要解决MQ的消息重复问题，关键就是要引入幂等性机制。


## 2、发送消息到MQ的时候如何保证幂等性？

现在我们先来看第一个问题，当我们的订单系统发送消息到MQ的时候需要保证幂等性吗？

我们都知道，订单系统的接口可能会被重复调用导致发送重复的消息到MQ去，也可能自己有重试机制导致发送重复的消息到MQ。

那么我们如果想要让订单系统别发送重复的消息到MQ去，应该怎么做呢？

大体上来说，常见的方案有两种。

第一个方案就是业务判断法，也就是说你的订单系统必须要知道自己到底是否发送过消息到MQ去，消息到底是否已经在MQ里了。

我们举个例子，当支付系统重试调用你的订单系统的接口时，你需要发送一个请求到MQ去，查询一下当前MQ里是否存在针对这个订单的支付消息？如果MQ告诉你，针对id=1100这个订单的支付成功消息，在我这里已经有了，你之前已经写入进来了，那么订单系统就可以不要再次发送这条消息到MQ去了。

这个业务判断法的核心就在于，你的消息肯定是存在于MQ里的，到底发没发送过，只有MQ知道。如果没发送过这个消息，MQ里肯定没有这个消息，如果发送过这个消息，MQ里肯定给有这个消息。

所以当你的订单系统的接口被重试调用的时候，你这个接口上来就应该发送请求到MQ里去查询一下，比如对订单id=1100这个订单的支付成功消息，在你MQ那里有没有？如果有的话，我就不再重复发送消息了！

## 3、基于Redis缓存的幂等性机制

接着我们来讲第二种方法，就是状态判断法

这个方法的核心在于，你需要引入一个Redis缓存来存储你是否发送过消息的状态，如果你成功发送了一个消息到MQ里去，你得在Redis缓存里写一条数据，标记这个消息已经发送过，我们看下图。

![](../../pic/2020-03-29-22-44-58.png)

那么当你的订单接口被重复调用的时候，你只要根据订单id去Redis缓存里查询一下，这个订单的支付消息是否已经发送给MQ了，如果发送过了，你就别再次发送了！

其实两种幂等性机制都是很常用的，但是大家这里一定要知道一个事情，那就是对于基于Redis的状态判断法，有可能没办法完全做到幂等性。

举个例子，你的支付系统发送请求给订单系统，然后已经发送消息到MQ去了，但是此时订单系统突然崩溃了，没来得及把消息发送的状态写入Redis。

这个时候如果你的订单系统在其他机器上部署了，或者他重启了，那么这个时候订单系统被重试调用的时候，他去找Redis查询消息发送状态，会以为消息没发送过，然后会再次发送重复消息到MQ去

所以这种方案一般情况下是可以做到幂等性的，但是如果有时候你刚发送了消息到MQ，还没来得及写Redis，系统就挂了，之后你的接口被重试调用的时候，你查Redis还以为消息没发过，就会发送重复的消息到MQ去。

## 4、有没有必要在订单系统环节保证消息不重复发送？

所以在我们这个场景中，如果在订单系统环节要保证消息不重复发送，要不然就是直接通过查询MQ来判断消息是否发过，要不然就是通过引入Redis来保存消息发送状态。其实这两种方案都不是太好。

因为RocketMQ虽然是支持你查询某个消息是否存在的，这个功能我们后面的案例会讲他的功能使用和底层原理，但是在这个环节你直接从MQ查询消息是没这个必要的，他的性能也不是太好，会影响你的接口的性能。

另外基于Redis的消息发送状态的方案，在极端情况下还是没法100%保证幂等性，所以也不是特别好的一个方案。

所以对于我们而言，在这里建议是不用在这个环节保证幂等性，也就是我们可以默许他可能会发送重复的消息到MQ里去。


## 5、优惠券系统如何保证消息处理的幂等性？

其实这里就比较简单了，直接基于业务判断法就可以了，因为优惠券系统每次拿到一条消息后给用户发一张优惠券，实际上核心就是在数据库里给用户插入一条优惠券记录

![](../../pic/2020-03-29-22-48-36.png)

那么如果优惠券系统从MQ那里拿到一个订单的两条重复的支付成功消息，这个时候其实很简单，他只要先去优惠券数据库中查询一下，比如对订单id=1100的订单，是否已经发放过优惠券了，是否有优惠券记录，如果有的话，就不要重复发券了！

通过这个业务判断的方法，就可以简单高效的避免消息的重复处理了，我们看下图。

## 6、MQ消息幂等性的方案总结

一般来说，对于MQ的重复消息问题而言，我们往MQ里重复发送一样的消息其实是还可以接收的，因为MQ里有多条重复消息，他不会对系统的核心数据直接造成影响，但是我们关键要保证的，是你从MQ里获取消息进行处理的时候，必须要保证消息不能重复处理。


这里的话，要保证消息的幂等性，我们优先推荐的其实还是业务判断法，直接根据你的数据存储中的记录来判断这个消息是否处理过，如果处理过了，那就别再次处理了。因为我们要知道，基于Redis的消息发送状态的方案，在一些极端情况下还是没法完全保证幂等性的。

# 77 如果优惠券系统的数据库宕机，如何用死信队列解决这种异常场景？

## 1、如果优惠券系统的数据库宕机，会怎么样？

之前我们已经分析和解决了MQ实践使用过程中可能存在的消息丢失问题和消息重复问题，现在假设我们可以基本确保MQ的消息不丢失，同时不会对消息进行重复处理，在正常流程下，基本没什么问题了。

那么接着我们来看下一个问题，假设我们的MQ使用都没问题，但是如果我们的优惠券系统的数据库宕机了呢？

因为我们一直都是假设了一个场景，就是订单支付成功之后会推送消息到MQ，然后优惠券系统、红包系统会从MQ里获取消息去执行后续的处理，比如发红包或者发优惠券。

那么如果这个时候，优惠券系统的数据库宕机了，就必然会导致我们从MQ里获取到消息之后是没办法进行处理的，我们看下图。

![](../../pic/2020-03-29-22-52-08.png)

所以针对这样的一个坑爹的异常场景我们应该怎么处理？优惠券系统应该怎么对消息进行重试？重试多少次才行？万一反复重试都没法成功，这个时候消息应该放哪儿去？直接给扔了吗？

我们今天就对这个实际的生产场景进行分析。


## 2、数据库宕机的时候，你还可以返回CONSUME_SUCCESS吗？

在下面的代码片段中，清晰可以看到，我们注册了一个监听器回调函数，当Consumer获取到消息之后，就会交给我们的函数来处理。

![](../../pic/2020-03-29-22-53-03.png)

而且我们之前还对这个方法进行了分析，我们可以在这个回调函数中对消息进行处理，比如发红包、发优惠券之类的，处理完成之后，就可以返回一个状态告诉RocketMQ Consumer这批消息的处理结果。

比如，如果返回的是CONSUME_SUCCESS，那么Consumer就知道这批消息处理完成了，就会对提交这批消息的Offset到broker去，然后下次就会继续从broker获取下一批消息来处理了。

但是如果此时我们在上面的回调函数中，对一批消息发优惠券的时候，因为数据库宕机了，导致优惠券发放逻辑无法完成，此时我们还能返回CONSUME_SUCCESS状态吗？

如果你返回的话，下一次就会处理下一批消息，但是这批消息其实没处理成功，此时必然导致这批消息就丢失了。

肯定会导致有一批用户没法收到优惠券的！

## 3、如果对消息的处理有异常，可以返回RECONSUME_LATER状态

所以实际上如果我们因为数据库宕机等问题，对这批消息的处理是异常的，此时没法处理这批消息，我们就应该返回一个RECONSUME_LATER状态

他的意思是，我现在没法完成这批消息的处理，麻烦你稍后过段时间再次给我这批消息让我重新试一下！

![](../../pic/2020-03-29-22-54-50.png)

## 4、RocketMQ是如何让你进行消费重试的？

那么RocketMQ在收到你返回的RECONSUME_LATER状态之后，是如何让你进行消费重试的呢？

简单来说，RocketMQ会有一个针对你这个ConsumerGroup的重试队列。如果遗忘了ConsumerGroup消费组概念的朋友可以再回过头去复习一下。

如果你返回了RECONSUME_LATER状态，他会把你这批消息放到你这个消费组的重试队列中去

比如你的消费组的名称是“VoucherConsumerGroup”，意思是优惠券系统的消费组，那么他会有一个“%RETRY%VoucherConsumerGroup”这个名字的重试队列，我们看下图的示意。

![](../../pic/2020-03-29-22-56-32.png)

然后过一段时间之后，重试队列中的消息会再次给我们，让我们进行处理。如果再次失败，又返回了RECONSUME_LATER，那么会再过一段时间让我们来进行处理，默认最多是重试16次！每次重试之间的间隔时间是不一样的，这个间隔时间可以如下进行配置：

messageDelayLevel=1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h

上面这段配置的意思是，第一次重试是1秒后，第二次重试是5秒后，第三次重试是10秒后，第四次重试是30秒后，第五次重试是1分钟后，以此类推，最多重试16次！


## 5、如果连续重试16次还是无法处理消息，然后怎么办？

那么如果在16次重试范围内消息处理成功了，自然就没问题了，但是如果你对一批消息重试了16次还是无法成功处理呢？

这个时候就需要另外一个队列了，叫做死信队列，所谓的死信队列，顾名思义，就是死掉的消息就放这个队列里。

那么什么叫死掉的消息呢？

其实就是一批消息交给你处理，你重试了16次还一直没处理成功，就不要继续重试这批消息了，你就认为他们死掉了就可以了。然后这批消息会自动进入死信队列。

死信队列的名字是“%DLQ%VoucherConsumerGroup”，我们其实在RocketMQ的管理后台上都是可以看到的。

![](../../pic/2020-03-29-22-58-23.png)

那么对死信队列中的消息我们怎么处理？

其实这个就看你的使用场景了，比如我们可以专门开一个后台线程，就是订阅“%DLQ%VoucherConsumerGroup”这个死信队列，对死信队列中的消息，还是一直不停的重试。

## 6、消息处理失败场景下的方案总结

这一次我们就搞清楚了另外一个生产环境下的问题，就是消费者底层的一些依赖可能有故障了，比如数据库宕机，缓存宕机之类的，此时你就没办法完成消息的处理了，那么可以通过一些返回状态去让消息进入RocketMQ自带的重试队列，同时如果反复重试还是不行，可以让消息进入RocketMQ自带的死信队列，后续针对死信队列中的消息进行单独的处理就可以了。


# 78 生产案例：为什么基于 RocketMQ 进行订单库数据同步时会消息乱序？

## 4、为什么基于MQ来传输数据会出现消息乱序？

其实非常简单，我们之前都学习过，可以给每个Topic指定多个MessageQueue，然后你写入消息的时候，其实是会把消息均匀分发给不同的MessageQueue的。

比如我们这里在写入binlog到MQ的时候，可能会把insert binlog写入到一个MessageQueue里去，update binlog写入到另外一个MessageQueue里去

![](../../pic/2020-03-29-23-02-15.png)

接着大数据系统在获取binlog的时候，可能会部署多台机器组成一个Consumer Group，对于Consumer Group中的每台机器都会负责消费一部分MessageQueue的消息，所以可能一台机器从上图的ConsumeQueue01中获取到了insert binlog，一台机器从上图的ConsumeQueue02中获取到了update binlog

![](../../pic/2020-03-29-23-02-58.png)

因为我们看到上图中，是两台机器上的大数据系统并行的去获取binlog，所以完全有可能是其中一个大数据系统先获取到了update binlog去执行了更新操作，此时存储中没有数据，自然是没法更新的。

然后另外一个大数据系统再获取到insert binlog去执行插入操作，最终导致只有一个字段值为0的订单数据，如下图：

## 5、消息乱序：必须要正视的一个问题

所以经过本文的分析，我们完全可以清晰的看到，在使用MQ的时候出现消息乱序是非常正常的一个问题，因为我们原本有顺序的消息，完全可能会分发到不同的MessageQueue中去，然后不同机器上部署的Consumer可能会用混乱的顺序从不同的MessageQueue里获取消息然后处理。


# 79 在RocketMQ中，如何解决订单数据库同步的消息乱序问题？


## 2、让属于同一个订单的binlog进入一个MessageQueue

给大家举个例子，比如对一个订单，我们先后执行了insert、update两条SQL语句，也就对应了2个binlog。

那么我们现在就必须要想办法让这个订单的2个binlog都直接进入到Topic下的一个MessageQueue里去。

那么我们这个时候应该怎么做呢？我们完全可以根据订单id来进行判断，我们可以往MQ里发送binlog的时候，根据订单id来判断一下，如果订单id相同，你必须保证他进入同一个MessageQueue。

我们这里可以采用取模的方法，比如有一个订单id是1100，那么他可能有2个binlog，对这两个binlog，我们必须要用订单id=1100对MessageQueue的数量进行取模，比如MessageQueue一共有15个，那么此时订单id=1100对15取模，就是5

也就是说，凡是订单id=1100的binlog，都应该进入位置为5的MessageQueue中去！

通过这个方法，我们就可以让一个订单的binlog都按照顺序进入到一个MessageQueue中去，看下面的图：

![](../../pic/2020-03-29-23-06-01.png)

## 3、真的这么简单吗？获取binlog的时候也得有序！

我们来思考一下，真的就上面说的那么简单，只要一个订单的binlog都进入一个MessageQueue就搞定这个问题了吗？

显然不是！

我们要考虑到一个问题，首先，我们的MySQL数据库的binlog一定都是有顺序的。

比如，订单系统对订单数据库执行了两条SQL，先是insert语句，然后是update语句。那么此时MySQL数据库自己必然是在磁盘文件里按照顺序先写入insert语句的binlog，然后写入update语句的binlog，如下图所示：

![](../../pic/2020-03-29-23-08-17.png)

当我们从MySQL数据库中获取他的binlog的时候，此时也必须是按照binlog的顺序来获取的，也就是说比如Canal作为一个中间件从MySQL那里监听和获取binlog，那么当binlog传输到Canal的时候，也必然是有先后顺序的，先是insert binlog，然后是update binlog，如下图所示。

![](../../pic/2020-03-29-23-08-57.png)

接着我们将binlog发送给MQ的时候，必须将一个订单的binlog都发送到一个MessageQueue里去，而且发送过去的时候，也必须是严格按照顺序来发送的

只有这样，最终才能让一个订单的binlog进入同一个MessageQueue，而且还是有序的，如下图所示：

![](../../pic/2020-03-29-23-09-28.png)

所以我们必须要严格做到以上几点，才能保证一个订单的binlog绝对有序的进入一个MessageQueue中。

## 4、Consumer有序处理一个订单的binlog

接着我们可以想一下，一个Consumer可以处理多个MessageQueue的消息，但是一个MessageQueue只能交给一个Consumer来进行处理，所以一个订单的binlog只会有序的交给一个Consumer来进行处理！

我们看下图，这样的话一个大数据系统就可以获取到一个订单的有序的binlog，然后有序的根据binlog把数据还原到自己的存储中去。

![](../../pic/2020-03-29-23-10-54.png)


## 5、这就完了吗？没有，万一消息处理失败了可以走重试队列吗？

绝对不是，我之前给大家讲过，在Consumer处理消息的时候，可能会因为底层存储挂了导致消息处理失败，之前我们说过，此时可以返回RECONSUME_LATER状态，然后broker会过一会儿自动给我们重试。

但是这个方案用在我们的有序消息中可以吗？

那绝对是不行的，因为如果你的consumer获取到订单的一个insert binlog，结果处理失败了，此时返回了RECONSUME_LATER，那么这条消息会进入重试队列，过一会儿才会交给你重试。

但是此时broker会直接把下一条消息，也就是这个订单的update binlog交给你来处理，此时万一你执行成功了，就根本没有数据可以更新！又会出现消息乱序的问题，我们看下图

![](../../pic/2020-03-29-23-12-28.png)

所以对于有序消息的方案中，如果你遇到消息处理失败的场景，就必须返回SUSPEND_CURRENT_QUEUE_A_MOMENT这个状态，意思是先等一会儿，一会儿再继续处理这批消息，而不能把这批消息放入重试队列去，然后直接处理下一批消息。


## 6、有序消息方案与其他消息方案的结合


如果你一定要求消息是有序的，那么必须得用上述的有序消息方案，同时对这个方案，如果你要确保消息不丢失，那么可以和消息零丢失方案结合起来，如果你要避免消息重复处理，还需要在消费者那里处理消息的时候，去看一下，消息如果已经存在就不能重复插入，等等。

同时还需要设计自己的消息处理失败的方案，也就是不能进入重试队列，而是暂停等待一会儿，继续处理这批消息。


# 80 基于订单数据库同步场景，来分析RocketMQ的顺序消息机制的代码实现

## 1、如何让一个订单的binlog进入一个MessageQueue？

我们先来看第一个代码落地的分析，首先要实现消息顺序，必须让一个订单的binlog都进入一个MessageQueue中，此时我们可以写如下的代码：

![](../../pic/2020-03-29-23-14-54.png)

在上面的代码片段中，我们可以看到，关键因素就是两个，一个是发送消息的时候传入一个MessageQueueSelector，在里面你要根据订单id和MessageQueue数量去选择这个订单id的数据进入哪个MessageQueue。

同时在发送消息的时候除了带上消息自己以外，还要带上订单id，然后MessageQueueSelector就会根据订单id去选择一个MessageQueue发送过去，这样的话，就可以保证一个订单的多个binlog都会进入一个MessageQueue中去。

## 2、消费者如何保证按照顺序来获取一个MessageQueue中的消息？

接着我们来看第二块，就是消费者如何按照顺序，来获取一个MessageQueue中的消息？

![](../../pic/2020-03-29-23-16-07.png)

在上面的代码中，大家可以注意一下，我们使用的是MessageListenerOrderly这个东西，他里面有Orderly这个名称

也就是说，Consumer会对每一个ConsumeQueue，都仅仅用一个线程来处理其中的消息。

比如对ConsumeQueue01中的订单id=1100的多个binlog，会交给一个线程来按照binlog顺序来依次处理。否则如果ConsumeQueue01中的订单id=1100的多个binlog交给Consumer中的多个线程来处理的话，那还是会有消息乱序的问题。


# 81 如何基于RocketMQ的数据过滤机制，提升订单数据库同步的处理效率

## 1、混杂在一起的订单数据库的binlog

首先我们都知道，一个数据库中可能会包含很多表的数据，比如订单数据库，他里面除了订单信息表以外，可能还包含很多其他的表。

所以我们在进行数据库binlog同步的时候，很可能是把一个数据库里所有表的binlog都推送到MQ里去的！

所以在MQ的某个Topic中，可能是混杂了订单数据库里几个甚至十几个表的binlog数据的，不一定仅仅包含我们想要的表的binlog数据！

## 2、处理不关注的表的binlog，有多么浪费时间！

那么此时假设我们的大数据系统仅仅关注订单数据库中的表A的binlog，并不关注其他表的binlog，那么大数据系统可能需要在获取到所有表的binlog之后，对每条binlog判断一下，是否是表A的binlog？

如果不是表A的binlog，那么就直接丢弃不要处理；如果是表A的binlog，才会去进行处理！

但是这样的话，必然会导致大数据系统处理很多不关注的表的binlog，也会很浪费时间，降低消息的效率。

## 3、在发送消息的时候，给消息设置tag和属性

针对这个问题，我们可以采用RocketMQ支持的数据过滤机制，来让大数据系统仅仅关注他想要的表的binlog数据即可。

首先，我们在发送消息的时候，可以给消息设置tag和属性，我们看下面的代码。

![](../../pic/2020-03-29-23-20-01.png)

上面的代码清晰的展示了我们发送消息的时候，其实是可以给消息设置tag、属性等多个附加的信息的。


## 4、在消费数据的时候根据tag和属性进行过滤

接着我们可以在消费的时候根据tag和属性进行过滤，比如我们可以通过下面的代码去指定，我们只要tag=TableA和tag=TableB的数据。

![](../../pic/2020-03-29-23-20-48.png)

## 5、基于数据过滤减轻Consumer负担

今天学习了这块知识后，我们以后就知道在使用MQ的时候，如果MQ里混杂了大量的数据，可能Consumer仅仅对其中一部分数据感兴趣，此时可以在Consumer端使用tag等数据过滤语法，过滤出自己感兴趣的数据来消费。


# 82 生产案例：基于延迟消息机制优化大量订单的定时退款扫描问题！

针对下单后没有支付订单的处理

我们看下图，可能你的订单系统就需要有一个后台线程，不停的扫描订单数据库里所有的未支付状态的订单，看他如果超过30分钟了还没支付，那么就必须自动把订单状态 更新为“已关闭”

![](../../pic/2020-03-29-23-22-24.png)


但是这里就引入了一个问题，就是订单系统的后台线程必须要不停的扫描各种未支付的订单，这种实现方式实际上并不是很好。

一个原因是未支付状态的订单可能是比较多的，然后你需要不停的扫描他们，可能每个未支付状态的订单要被扫描N多遍，才会发现他已经超过30分钟没支付了。


另外一个是很难去分布式并行扫描你的订单。因为假设你的订单数据量特别的多，然后你要是打算用多台机器部署订单扫描服务，但是每台机器扫描哪些订单？怎么扫描？什么时候扫描？这都是一系列的麻烦问题。

因此针对类似这种场景，MQ里的**延迟消息**往往就会出场了，他是特别适合在这种场景里使用的，而且在实际项目中，MQ的延迟消息使用的往往是很多的。

所谓延迟消息，意思就是说，我们订单系统在创建了一个订单之后，可以发送一条消息到MQ里去，我们指定这条消息是延迟消息，比如要等待30分钟之后，才能被订单扫描服务给消费到

![](../../pic/2020-03-29-23-24-43.png)

这样当订单扫描服务在30分钟后消费到了一条消息之后，就可以针对这条消息的信息，去订单数据库里查询这个订单，看看他在创建过后都过了30分钟了，此时他是否还是未支付状态？

如果此时订单还是未支付状态，那么就可以关闭他，否则订单如果已经支付了，就什么都不用做了，我们看下图

![](../../pic/2020-03-29-23-25-17.png)

这种方式就比你用后台线程扫描订单的方式要好的多了，一个是对每个订单你只会在他创建30分钟后查询他一次而已，不会反复扫描订单多次。

另外就是如果你的订单数量很多，你完全可以让订单扫描服务多部署几台机器，然后对于MQ中的Topic可以多指定一个MessageQueue，这样每个订单扫描服务的机器作为一个Consumer都会处理一部分订单的查询任务。

所以MQ的延迟消息，是非常常用并且非常有用的一个功能。

# 83 基于订单定时退款场景，来分析RocketMQ的延迟消息的代码实现

上一篇文章我们分析了延迟消息的使用场景，这篇文章我们分析一下RocketMQ中对延迟消息的代码实现

其实RocketMQ对延迟消息的支持是很好的，实现起来也非常的容易，我们先看发送延迟消息的代码示例。

![](../../pic/2020-03-29-23-26-55.png)

大家看上面的代码，其实发送延迟消息的核心，就是设置消息的delayTimeLevel，也就是延迟级别

RocketMQ默认支持一些延迟级别如下：1s 5s 10s 30s 1m 2m 3m 4m 5m 6m 7m 8m 9m 10m 20m 30m 1h 2h

所以上面代码中设置延迟级别为3，意思就是延迟10s，你发送出去的消息，会过10s被消费者获取到。那么如果是订单延迟扫描场景，可以设置延迟级别为16，也就是对应上面的30分钟。

接着我们看看一个消费者的代码示例，比如订单扫描服务，正常他会对每个订单创建的消息，在30分钟以后才获取到，然后去查询订单状态，判断如果是未支付的订单，就自动关闭这个订单

![](../../pic/2020-03-29-23-28-23.png)

把延迟消息的使用搞明白了之后，想必大家以后在自己的系统中就可以使用延迟消息去支持一些特殊的业务场景了。

# 84 在RocketMQ的生产实践中积累的各种一手经验总结

- （1）灵活的运用 tags来过滤数据

之前我们讲解过基于tags来过滤数据的功能，其实在真正的生产项目中，建议大家合理的规划Topic和里面的tags，一个Topic代表了一类业务消息数据，然后对于这类业务消息数据，如果你希望继续划分一些类别的话，可以在发送消息的时候设置tags。

举个例子，比如我们都知道现在常见的外卖平台有美团外卖、饿了么外卖还有别的一些外卖，那么假设你现在一个系统要发送外卖订单数据到MQ里去，就可以针对性的设置tags，比如不同的外卖数据都到一个“WaimaiOrderTopic”里去。

但是不同类型的外卖可以有不同的tags：“meituan_waimai”，“eleme_waimai”，“other_waimai”，等等。

然后对你消费“WaimaiOrderTopic”的系统，可以根据tags来筛选，可能你就需要某一种类别的外卖数据罢了。

- （2）基于消息key来定位消息是否丢失

之前我们给大家讲过，在消息0丢失方案中，可能要解决的是消息是否丢失的问题，那么如果消息真的丢失了，我们是不是要排查？此时是不是要从MQ里查一下，这个消息是否丢失了？

那么怎么从MQ里查消息是否丢失呢？

可以基于消息key来实现，比如通过下面的方式设置一个消息的key为订单id：message.setKeys(orderId)，这样这个消息就具备一个key了。

接着这个消息到broker上，会基于key构建hash索引，这个hash索引就存放在IndexFile索引文件里。

然后后续我们可以通过MQ提供的命令去根据key查询这个消息，类似下面这样：mqadmin queryMsgByKey -n 127.0.0.1:9876 -t SCANRECORD -k orderId

- （3）消息零丢失方案的补充

之前我们给大家分析过消息零丢失方案，其实在消息零丢失方案中还有一个问题，那就是MQ集群彻底故障了，此时就是不可用了，那么怎么办呢？

其实对于一些金融级的系统，或者跟钱相关的支付系统，或者是广告系统，类似这样的系统，都必须有超高级别的高可用保障机制。

一般假设MQ集群彻底崩溃了，你生产者就应该把消息写入到本地磁盘文件里去进行持久化，或者是写入数据库里去暂存起来，等待MQ恢复之后，然后再把持久化的消息继续投递到MQ里去。

- （4）提高消费者的吞吐量

如果消费的时候发现消费的比较慢，那么可以提高消费者的并行度，常见的就是部署更多的consumer机器

但是这里要注意，你的Topic的MessageQueue得是有对应的增加，因为如果你的consumer机器有5台，然后MessageQueue只有4个，那么意味着有一个consumer机器是获取不到消息的。

然后就是可以增加consumer的线程数量，可以设置consumer端的参数：consumeThreadMin、consumeThreadMax，这样一台consumer机器上的消费线程越多，消费的速度就越快。

此外，还可以开启消费者的批量消费功能，就是设置consumeMessageBatchMaxSize参数，他默认是1，但是你可以设置的多一些，那么一次就会交给你的回调函数一批消息给你来处理了，此时你可以通过SQL语句一次性批量处理一些数据，比如：update xxx set xxx where id in (xx,xx,xx)。

通过批量处理消息的方式，也可以大幅度提升消息消费的速度。

- （5）要不要消费历史消息

其实consumer是支持设置从哪里开始消费消息的，常见的有两种：一个是从Topic的第一条数据开始消费，一个是从最后一次消费过的消息之后开始消费。对应的是：CONSUME_FROM_LAST_OFFSET，CONSUME_FROM_FIRST_OFFSET

一般来说，我们都会选择CONSUME_FROM_FIRST_OFFSET，这样你刚开始就从Topic的第一条消息开始消费，但是以后每次重启，你都是从上一次消费到的位置继续往后进行消费的。




# 85 企业级的RocketMQ集群如何进行权限机制的控制？

todo skip

# 86 如何对线上生产环境的RocketMQ集群进行消息轨迹的追踪？

也就是说，对于一个消息，我想要知道，这个消息是什么时候从哪个Producer发送出来的？他在Broker端是进入到了哪个Topic里去的？他在消费者层面是被哪个Consumer什么时候消费出来的？


我们有时候对于一条消息的丢失，可能就想要了解到这样的一个消息轨迹，协助我们去进行线上问题的排查，所以此时就可以使用RocketMQ支持的消息轨迹功能，我们看下面的配置过程。

首先需要在broker的配置文件里开启traceTopicEnable=true这个选项，此时就会开启消息轨迹追踪的功能。

接着当我们开启了上述的选项之后，我们启动这个Broker的时候会自动创建出来一个内部的Topic，就是RMQ_SYS_TRACE_TOPIC，这个Topic就是用来存储所有的消息轨迹追踪的数据的。

接着做好上述这一切事情之后，我们需要在发送消息的时候开启消息轨迹，此时创建Producer的时候要用如下的方式，下面构造函数中的第二个参数，就是enableMsgTrace参数，他设置为true，就是说可以对消息开启轨迹追踪。

![](../../pic/2020-03-29-23-36-35.png)

在订阅消息的时候，对于Consumer也是同理的，在构造函数的第二个参数设置为true，就是开启了消费时候的轨迹追踪。

其实大家可以思考一下，一旦当我们在Broker、Producer、Consumer都配置好了轨迹追踪之后，其实Producer在发送消息的时候，就会上报这个消息的一些数据到内置的RMQ_SYS_TRACE_TOPIC里去

此时会上报如下的一些数据：Producer的信息、发送消息的时间、消息是否发送成功、发送消息的耗时。

接着消息到Broker端之后，Broker端也会记录消息的轨迹数据，包括如下：消息存储的Topic、消息存储的位置、消息的key、消息的tags。

然后消息被消费到Consumer端之后，他也会上报一些轨迹数据到内置的RMQ_SYS_TRACE_TOPIC里去，包括如下一些东西：Consumer的信息、投递消息的时间、这是第几轮投递消息、消息消费是否成功、消费这条消息的耗时。

接着如果我们想要查询消息轨迹，也很简单，在RocketMQ控制台里，在导航栏里就有一个消息轨迹，在里面可以创建查询任务，你可以根据messageId、message key或者Topic来查询，查询任务执行完毕之后，就可以看到消息轨迹的界面了。

在消息轨迹的界面里就会展示出来刚才上面说的Producer、Broker、Consumer上报的一些轨迹数据了。

# 087 由于消费系统故障导致的RocketMQ百万消息积压问题，应该如何处理？

我们先来思考一下，遇到百万消息积压大概是个什么场景。

先来一个比较真实的生产场景，我们曾经有一个系统，他就是由生产者系统和消费者系统两个环节组成的，生产者系统会负责不停的把消息写入RocketMQ里去，然后消费者系统就是负责从RocketMQ里消费消息。

这个系统在生产环境是有高峰和低谷的，在晚上几个小时的高峰期内，大概就会有100多万条消息进入RocketMQ。然后消费者系统从RocketMQ里获取到消息之后，会依赖一些NoSQL数据库去进行一些业务逻辑的实现。

然后有一天晚上就出现了一个问题，消费者系统依赖的NoSQL数据库就挂掉了，导致消费者系统自己也没法运作了，此时就没法继续从RocketMQ里消费数据和处理了，消费者系统几乎就处于停滞不动的状态。


然后生产者系统在晚上几个小时的高峰期内，就往MQ里写入了100多万的消息，此时都积压在MQ里了，根本没人消费和处理。


针对这种紧急的线上事故，一般来说有几种方案可以快速搞定他，如果这些消息你是允许丢失的，那么此时你就可以紧急修改消费者系统的代码，在代码里对所有的消息都获取到就直接丢弃，不做任何的处理，这样可以迅速的让积压在MQ里的百万消息被处理掉，只不过处理方式就是全部丢弃而已。

但是往往对很多系统而言，不能简单粗暴的丢弃这些消息，所以最常见的办法，还是先等待消费者系统底层依赖的NoSQL数据库先恢复了，恢复之后，就可以根据你的线上Topic的MessageQueue的数量来看看如何后续处理。

假如你的Topic有20个MessageQueue，然后你只有4个消费者系统在消费，那么每个消费者系统会从5个MessageQueue里获取消息，所以此时如果你仅仅依靠4个消费者系统是肯定不够的，毕竟MQ里积压了百万消息了。

所以此时你可以临时申请16台机器多部署16个消费者系统的实例，然后20个消费者系统同时消费，每个人消费一个MessageQueue的消息，此时你会发现你消费的速度提高了5倍，很快积压的百万消息都会被处理完毕。

但是这里你同时要考虑到你的消费者系统底层依赖的NoSQL数据库必须要能抗住临时增加了5倍的读写压力，因为原来就4个消费者系统在读写NoSQL，现在临时变成了20个消费者系统了。

当你处理完百万积压的消息之后，就可以下线多余的16台机器了。

这是一个最最常见的处理百万消息积压的办法，大体思路跟石杉老师在《互联网Java工程师面试突击（第一季）》里讲解的方案是一样的，只不过这里细化到根据RocketMQ的技术原理来讲解。

那么如果你的Topic总共就只有4个MessageQueue，然后你就只有4个消费者系统呢？

这个时候就没办法扩容消费者系统了，因为你加再多的消费者系统，还是只有4个MessageQueue，没法并行消费。

所以此时往往是临时修改那4个消费者系统的代码，让他们获取到消息然后不写入NoSQL，而是直接把消息写入一个新的Topic，这个速度是很快的，因为仅仅是读写MQ而已。

然后新的Topic有20个MessageQueue，然后再部署20台临时增加的消费者系统，去消费新的Topic后写入数据到NoSQL里去，这样子也可以迅速的增加消费者系统的并行处理能力，使用一个新的Topic来允许更多的消费者系统并行处理。

# 088 金融级的系统如何针对RocketMQ集群崩溃设计高可用方案？

比如跟金钱相关的一些系统，他可能需要依赖MQ去传递消息，如果你MQ突然崩溃了，可能导致很多跟钱相关的东西就会出问题。

针对这种场景，我们通常都会在你发送消息到MQ的那个系统中设计高可用的降级方案，**这个降级方案通常的思路是，你需要在你发送消息到MQ代码里去try catch捕获异常，如果你发现发送消息到MQ有异常，此时你需要进行重试。**


如果你发现连续重试了比如超过3次还是失败，说明此时可能就是你的MQ集群彻底崩溃了，此时你必须把这条重要的消息写入到本地存储中去，可以是写入数据库里，也可以是写入到机器的本地磁盘文件里去，或者是NoSQL存储中去，几种方式我们都做过，具体要根据你们的具体情况来决定。

之后你要不停的尝试发送消息到MQ去，一旦发现MQ集群恢复了，你必须有一个后台线程可以把之前持久化存储的消息都查询出来，然后依次按照顺序发送到MQ集群里去，这样才能保证你的消息不会因为MQ彻底崩溃会丢失。

这里要有一个很关键的注意点，就是你把消息写入存储中暂存时，一定要保证他的顺序，比如按照顺序一条一条的写入本地磁盘文件去暂存消息。

而且一旦MQ集群故障了，你后续的所有写消息的代码必须严格的按照顺序把消息写入到本地磁盘文件里去暂存，这个顺序性是要严格保证的。

只要有这个方案在，那么哪怕你的MQ集群突然崩溃了，你的系统也是不会丢失消息的，对于一些跟金钱相关的金融系统、广告系统来说，这种高可用的方案设计，是非常的有必要的。

# 89 为什么要给RocketMQ增加消息限流功能保证其高可用性？

今天先给大家讲第一个内容，就是RocketMQ的限流，这个功能我们文章里不会带着大家去做出来，但是会给大家讲一下为什么要给RocketMQ增加限流功能保证其高可用性呢？其实本质上来说，限流功能就是对系统的一个保护功能。

大家可以思考一个场景，假如有一个新来的工程师，因为没搞明白RocketMQ到底应该怎么使用，结果代码里写出了一个大bug，导致他负责的系统拼命的往MQ里不停的写入消息，可能一下子流量激增会导致MQ出现故障。

下面的代码就是曾经真实我们见过的一个工程师写出来的代码，大家可以看看：

![](../../pic/2020-03-29-23-46-11.png)

上面是简化以后的代码，实际上当时那段代码里混杂了很多的业务逻辑，但是当时出现的一个问题，就是业务代码报错了然后进入了catch代码块，结果那个工程师居然在catch代码块里写了一个while死循环，不停的发送消息。


而且上述系统当时是部署在10多台机器上的一个系统，所以相当于10多台机器都频繁的开足CPU的马力，拼命的往MQ里写消息，瞬间就导致MQ集群的TPS飙升，里面混入了大量的重复消息，而且MQ集群都快挂了。

所以针对这种场景，其实站在MQ的角度而言，你是没有办法去避免各种系统用上述的白痴方法来使用你的，毕竟公司大了，什么样的人都有，什么样的情况都可能出现，所以对MQ而言，你就必须去改造一下开源MQ的内核源码。


在接收消息这块，必须引入一个限流机制，也就是说要限制好，你这台机器每秒钟最多就只能处理比如3万条消息，根据你的MQ集群的压测结果来，你可以通过压测看看你的MQ最多可以抗多少QPS，然后就做好限流。

一般来说，限流算法可以采取**令牌桶算法**，也就是说你每秒钟就发放多少个令牌，然后只能允许多少个请求通过。关于限流算法的实现，不在我们的讨论范围内，大家可以自己查阅一下资料，也并不是很难。

我们这里主要是给大家讲一下，很多互联网大厂其实都会改造开源MQ的内核源码，引入限流机制，然后只能允许指定范围内的消息被在一秒内被处理，避免因为一些异常的情况，导致MQ集群挂掉。


# 90 设计一套Kafka到RocketMQ的双写+双读技术方案，实现无缝迁移！

今天的第二个技术问题，假设你们公司本来线上的MQ用的主要是Kafka，现在要从Kafka迁移到RocketMQ去，那么这个迁移的过程应该怎么做呢？应该采用什么样的技术方案来做迁移呢？

这里我们给大家介绍一个MQ集群迁移过程中的双写+双读技术方案。

简单来说，如果你要做MQ集群迁移，是不可能那么的简单粗暴的，因为你不可能说在某一个时间点突然之间就说把所有的Producer系统都停机，然后更新他的代码，接着全部重新上线，然后所有Producer系统都把消息写入到RocketMQ去了

一般来说，首先你要做到双写，也就是说，在你所有的Producer系统中，要引入一个双写的代码，让他同时往Kafka和RocketMQ中去写入消息，然后多写几天，起码双写要持续个1周左右，因为MQ一般都是实时数据，里面数据也就最多保留一周。

当你的双写持续一周过后，你会发现你的Kafka和RocketMQ里的数据看起来是几乎一模一样了，因为MQ反正也就保留最近几天的数据，当你双写持续超过一周过后，你会发现Kafka和RocketMQ里的数据几乎一模一样了。

但是光是双写还是不够的，还需要同时进行双读，也就是说在你双写的同时，你所有的Consumer系统都需要同时从Kafka和RocketMQ里获取消息，分别都用一模一样的逻辑处理一遍。

只不过从Kafka里获取到的消息还是走核心逻辑去处理，然后可以落入数据库或者是别的存储什么的，但是对于RocketMQ里获取到的消息，你可以用一样的逻辑处理，但是不能把处理结果具体的落入数据库之类的地方。

你的Consumer系统在同时从Kafka和RocketMQ进行消息读取的时候，你需要统计每个MQ当日读取和处理的消息的数量，这点非常的重要，同时对于RocketMQ读取到的消息处理之后的结果，可以写入一个临时的存储中。

同时你要观察一段时间，当你发现持续双写和双读一段时间之后，如果所有的Consumer系统通过对比发现，从Kafka和RocketMQ读取和处理的消息数量一致，同时处理之后得到的结果也都是一致的，此时就可以判断说当前Kafka和RocketMQ里的消息是一致的，而且计算出来的结果也都是一致的。

这个时候就可以实施正式的切换了，你可以停机Producer系统，再重新修改后上线，全部修改为仅仅写RocketMQ，这个时候他数据不会丢，因为之前已经双写了一段时间了，然后所有的Consumer系统可以全部下线后修改代码再上线，全部基于RocketMQ来获取消息，计算和处理，结果写入存储中。

基本上对于类似的一些重要中间件的迁移，往往都会采取双写的方法，双写一段时间，然后观察两个方案的结果都一致了，你再正式 下线旧的一套东西。

